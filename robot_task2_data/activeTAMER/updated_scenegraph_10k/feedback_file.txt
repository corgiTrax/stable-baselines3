Current timestep = 0. State = [[-0.24279101 -0.05079548  0.11565594  1.        ]]. Action = [[ 0.67852783 -0.29481584  0.8597002   0.00302041]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 0 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 0 is tensor(0.3813, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 0 of 1
Current timestep = 1. State = [[-0.23273605 -0.05737476  0.12364475  1.        ]]. Action = [[-0.59444827  0.05494595 -0.17433655  0.49508083]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 1 is tensor(0.3630, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1 of -1
Current timestep = 2. State = [[-0.23434708 -0.0572727   0.12322439  1.        ]]. Action = [[-0.97154903  0.68440723  0.8630501   0.14896679]]. Reward = [0.]
Curr episode timestep = 2
Action ignored: Workspace boundary
Scene graph at timestep 2 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 2 is tensor(0.3286, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 2 of -1
Current timestep = 3. State = [[-0.2546611   0.00559868  0.1244341   1.        ]]. Action = [[-0.6735431   0.4514506  -0.67821383 -0.7470698 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 4. State = [[-0.2551673   0.00611205  0.11140665  1.        ]]. Action = [[-0.51751107 -0.16711736 -0.29556215 -0.58134365]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Scene graph at timestep 4 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 4 is tensor(0.2770, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 4 of -1
Current timestep = 5. State = [[-0.25516072  0.00623357  0.11140039  1.        ]]. Action = [[-0.7910961   0.23736787 -0.00701773  0.2304914 ]]. Reward = [0.]
Curr episode timestep = 1
Action ignored: Workspace boundary
Scene graph at timestep 5 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 5 is tensor(0.2613, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 5 of -1
Current timestep = 6. State = [[-0.25516072  0.00623357  0.11140039  1.        ]]. Action = [[-0.56313807 -0.92901134  0.07218134 -0.71885294]]. Reward = [0.]
Curr episode timestep = 2
Action ignored: Workspace boundary
Scene graph at timestep 6 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 6 is tensor(0.2045, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 6 of -1
Current timestep = 7. State = [[-0.25516072  0.00623357  0.11140039  1.        ]]. Action = [[-0.77979773 -0.97614515 -0.7634711  -0.34009695]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: Workspace boundary
Scene graph at timestep 7 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 7 is tensor(0.1915, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 7 of -1
Current timestep = 8. State = [[-0.25516072  0.00623357  0.11140039  1.        ]]. Action = [[-0.8030961  -0.44648892 -0.07178867 -0.4554925 ]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: Workspace boundary
Scene graph at timestep 8 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 8 is tensor(0.1804, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 8 of -1
Current timestep = 9. State = [[-0.26001507  0.04934145  0.12281355  1.        ]]. Action = [[ 0.1859709 -0.6249193 -0.5918077 -0.7886238]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 10. State = [[-0.24750602  0.05714879  0.10904597  1.        ]]. Action = [[ 0.9088969   0.12600338 -0.19884348  0.3050964 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 10 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 10 is tensor(0.1326, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 10 of 0
Current timestep = 11. State = [[-0.21808629  0.06101466  0.10237739  1.        ]]. Action = [[ 0.68444073 -0.03066403  0.07613719  0.6496707 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 11 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 11 is tensor(0.1189, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 11 of 1
Current timestep = 12. State = [[-0.26029107 -0.04677275  0.12127344  1.        ]]. Action = [[ 0.6758635   0.97706985  0.53062475 -0.8560733 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 13. State = [[-0.26093102 -0.05125292  0.10824247  1.        ]]. Action = [[-0.62034976 -0.4946745   0.18851435  0.82586133]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Scene graph at timestep 13 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 13 is tensor(0.0820, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 13 of -1
Current timestep = 14. State = [[-0.2591147  -0.0561082   0.11455879  1.        ]]. Action = [[-0.14120245 -0.18155342  0.91561675  0.7357135 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 14 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 14 is tensor(0.0577, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 14 of 1
Current timestep = 15. State = [[-0.24755146 -0.10106783  0.12253894  1.        ]]. Action = [[ 0.6515585   0.9218066  -0.04722172 -0.11750025]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 16. State = [[-0.24147177 -0.12296592  0.11589694  1.        ]]. Action = [[ 0.36234033 -0.6151359   0.8718407   0.9885118 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 16 is [True, False, False, True, False, False, False, True, False, True]
State prediction error at timestep 16 is tensor(0.0295, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 16 of 1
Current timestep = 17. State = [[-0.22445111 -0.12689173  0.11730536  1.        ]]. Action = [[ 0.92867017  0.61174655 -0.9152812   0.11174357]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 17 is [True, False, False, True, False, False, False, True, False, True]
State prediction error at timestep 17 is tensor(0.0392, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 17 of -1
Current timestep = 18. State = [[-0.2603782   0.03800126  0.12147753  1.        ]]. Action = [[-0.48026538  0.2891469  -0.190593   -0.6601941 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 19. State = [[-0.2589026   0.04284425  0.10875485  1.        ]]. Action = [[-0.8285814  -0.8547247   0.25538993  0.05174673]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Scene graph at timestep 19 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 19 is tensor(0.0204, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 19 of -1
Current timestep = 20. State = [[-0.25295314 -0.159835    0.12379229  1.        ]]. Action = [[-0.19744205 -0.84531546  0.42760134 -0.38958722]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 21. State = [[-0.24869323 -0.17999229  0.11540812  1.        ]]. Action = [[ 0.34200454 -0.21285814  0.73646975  0.9604777 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 21 is [True, False, False, True, False, False, False, True, False, True]
State prediction error at timestep 21 is tensor(0.0231, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 21 of 1
Current timestep = 22. State = [[-0.24214084 -0.17515971  0.12094904  1.        ]]. Action = [[-0.10097253  0.8216822   0.11881888  0.29804265]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 22 is [True, False, False, True, False, False, False, True, False, True]
State prediction error at timestep 22 is tensor(0.0463, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 22 of 1
Current timestep = 23. State = [[-0.26183003  0.10434445  0.12300391  1.        ]]. Action = [[ 0.59103084 -0.49121273 -0.75374836 -0.3149798 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 24. State = [[-0.25907436  0.11637371  0.1109699   1.        ]]. Action = [[-0.8220484   0.87738323  0.01405942 -0.12772667]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Scene graph at timestep 24 is [True, False, False, False, False, True, False, True, False, True]
State prediction error at timestep 24 is tensor(0.0447, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 24 of -1
Current timestep = 25. State = [[-0.25423074  0.10990588  0.11850195  1.        ]]. Action = [[ 0.12047124 -0.48658574  0.97931015  0.5888587 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 25 is [True, False, False, False, False, True, False, True, False, True]
State prediction error at timestep 25 is tensor(0.0328, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 25 of 1
Current timestep = 26. State = [[-0.24349448  0.10330387  0.128384    1.        ]]. Action = [[ 0.63615024  0.08472228 -0.5264524   0.3000102 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 26 is [True, False, False, False, False, True, False, True, False, True]
State prediction error at timestep 26 is tensor(0.0529, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 26 of -1
Current timestep = 27. State = [[-0.2570092  -0.01855675  0.12194639  1.        ]]. Action = [[-0.48924315  0.4243219   0.7693044  -0.38544905]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 28. State = [[-0.25829184 -0.02015695  0.10848583  1.        ]]. Action = [[-0.36463392 -0.3061564   0.13987756  0.94475245]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Scene graph at timestep 28 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 28 is tensor(0.0459, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 28 of -1
Current timestep = 29. State = [[-0.25801495 -0.02016947  0.10848635  1.        ]]. Action = [[-0.25321126 -0.7532712  -0.41090274  0.83565676]]. Reward = [0.]
Curr episode timestep = 1
Action ignored: Workspace boundary
Scene graph at timestep 29 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 29 is tensor(0.0461, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 29 of -1
Current timestep = 30. State = [[-0.24806146 -0.02061627  0.10811442  1.        ]]. Action = [[ 0.8021374   0.06753659 -0.10397267  0.39903224]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 30 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 30 is tensor(0.0665, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 30 of -1
Current timestep = 31. State = [[-0.22097947 -0.0213435   0.10998638  1.        ]]. Action = [[0.93181777 0.10455859 0.86713815 0.32591617]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 31 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 31 is tensor(0.0558, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 31 of 1
Current timestep = 32. State = [[-0.18907826 -0.01317598  0.12447797  1.        ]]. Action = [[0.35496986 0.54472625 0.18514681 0.7924943 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 32 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 32 is tensor(0.0719, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 32 of 1
Current timestep = 33. State = [[-0.2609611   0.03950456  0.12147355  1.        ]]. Action = [[-0.4195559   0.44921708  0.9389255  -0.66257   ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 34. State = [[-0.25934592  0.04433157  0.108646    1.        ]]. Action = [[-0.43352515 -0.6844082  -0.82371604 -0.7817713 ]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Scene graph at timestep 34 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 34 is tensor(0.0579, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 34 of -1
Current timestep = 35. State = [[-0.25226846  0.03475368  0.11046613  1.        ]]. Action = [[ 0.42225683 -0.73666394  0.36278427  0.8392105 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 35 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 35 is tensor(0.0725, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 35 of 0
Current timestep = 36. State = [[-0.24511254  0.0238955   0.11276259  1.        ]]. Action = [[-0.51657623  0.3824954   0.85548747  0.7612685 ]]. Reward = [0.]
Curr episode timestep = 2
Action ignored: Workspace boundary
Scene graph at timestep 36 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 36 is tensor(0.0714, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 36 of -1
Current timestep = 37. State = [[-0.24314976  0.00848121  0.10977211  1.        ]]. Action = [[ 0.15746665 -0.9975699  -0.41939783  0.39380586]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 37 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 37 is tensor(0.0753, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 37 of -1
Current timestep = 38. State = [[-0.26513758  0.16615091  0.12553148  1.        ]]. Action = [[-0.02416641 -0.78710127  0.01271939 -0.27632654]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 39. State = [[-0.25767523 -0.1579294   0.12012437  1.        ]]. Action = [[ 0.48092747 -0.2767669   0.7143159  -0.76134974]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 40. State = [[-0.248035   -0.18296787  0.10756459  1.        ]]. Action = [[ 0.9171964  -0.47284603  0.00531662  0.17145324]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 40 is [True, False, False, True, False, False, False, True, False, True]
State prediction error at timestep 40 is tensor(0.0959, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 40 of -1
Current timestep = 41. State = [[-0.23648168 -0.18573444  0.1009208   1.        ]]. Action = [[-0.4820385   0.53332806 -0.25525415  0.98180556]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 41 is [True, False, False, True, False, False, False, True, False, True]
State prediction error at timestep 41 is tensor(0.0943, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 41 of -1
Current timestep = 42. State = [[-0.2527481  -0.03485198  0.12470523  1.        ]]. Action = [[-0.08463669 -0.34094816 -0.24496007 -0.3924452 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 43. State = [[-0.24127777 -0.03732803  0.10449129  1.        ]]. Action = [[ 0.9540067   0.18023455 -0.69329476  0.48654187]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 43 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 43 is tensor(0.0863, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 43 of -1
Current timestep = 44. State = [[-0.25819707 -0.07150043  0.11894494  1.        ]]. Action = [[ 0.6242001  -0.67001367 -0.45075315 -0.26066142]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 45. State = [[-0.25189838 -0.16626233  0.12281401  1.        ]]. Action = [[ 0.7632222   0.91091514  0.69859624 -0.6664656 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 46. State = [[-0.25319764 -0.18186887  0.10083983  1.        ]]. Action = [[-0.03405148  0.07981265 -0.71304333  0.4563706 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 46 is [True, False, False, True, False, False, False, True, False, True]
State prediction error at timestep 46 is tensor(0.1060, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 46 of -1
Current timestep = 47. State = [[-0.2485387  -0.08208168  0.12522684  1.        ]]. Action = [[ 0.01087618 -0.32492816  0.77151227 -0.15295297]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 48. State = [[-0.25371164 -0.09813067  0.12383222  1.        ]]. Action = [[ 0.76702523  0.7491325   0.65283084 -0.6343098 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 49. State = [[-0.25348225 -0.11561001  0.11335077  1.        ]]. Action = [[ 0.03950012 -0.43250692  0.6046388   0.6823814 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 49 is [True, False, False, True, False, False, False, True, False, True]
State prediction error at timestep 49 is tensor(0.1019, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 49 of 1
Current timestep = 50. State = [[-2.5153297e-01  9.7273092e-04  1.2591043e-01  1.0000000e+00]]. Action = [[ 0.7819848  -0.5700984  -0.01404232 -0.42125404]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 51. State = [[-0.25782412  0.05075004  0.12451793  1.        ]]. Action = [[-0.3240106  -0.75207    -0.13869274 -0.29718298]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 52. State = [[-0.24867888  0.0490097   0.11621542  1.        ]]. Action = [[ 0.4532386  -0.5799687   0.7098247   0.24578822]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 52 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 52 is tensor(0.1051, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 52 of 1
Current timestep = 53. State = [[-0.22653973  0.04015964  0.1337357   1.        ]]. Action = [[ 0.9481567  -0.03949589  0.7981951   0.1815741 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 53 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 53 is tensor(0.1029, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 53 of 1
Current timestep = 54. State = [[-0.26386997  0.15183625  0.1203614   1.        ]]. Action = [[-0.36167026  0.80512977 -0.56599414 -0.12301618]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 55. State = [[-0.2510986   0.16827397  0.11591005  1.        ]]. Action = [[ 0.54721785 -0.06374633  0.96348524  0.8094281 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 55 is [True, False, False, False, False, True, False, True, False, True]
State prediction error at timestep 55 is tensor(0.1072, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 55 of 1
Current timestep = 56. State = [[-0.23850486  0.16807187  0.12867965  1.        ]]. Action = [[-0.8394038   0.52827     0.8115418   0.83683014]]. Reward = [0.]
Curr episode timestep = 1
Action ignored: Workspace boundary
Scene graph at timestep 56 is [True, False, False, False, False, True, False, True, False, True]
State prediction error at timestep 56 is tensor(0.1035, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 56 of -1
Current timestep = 57. State = [[-0.23706663  0.16457112  0.14110717  1.        ]]. Action = [[-0.34381723 -0.30501032  0.9419689   0.79793906]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 57 is [True, False, False, False, False, True, False, True, False, True]
State prediction error at timestep 57 is tensor(0.1101, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 57 of 1
Current timestep = 58. State = [[-0.25779834 -0.16922946  0.11933298  1.        ]]. Action = [[ 0.07591498 -0.7948161  -0.16926068 -0.6828363 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 59. State = [[-0.2583474   0.17436627  0.12796795  1.        ]]. Action = [[ 0.878508    0.49228847  0.9325702  -0.23421574]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 60. State = [[-0.25595212  0.19416797  0.11456699  1.        ]]. Action = [[-0.7825338  -0.48226273  0.23293054  0.8884785 ]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Scene graph at timestep 60 is [True, False, False, False, False, True, False, True, False, True]
State prediction error at timestep 60 is tensor(0.1144, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 60 of -1
Current timestep = 61. State = [[-0.2635698   0.0932127   0.12039115  1.        ]]. Action = [[ 0.49565804 -0.8221064   0.56836426 -0.21197194]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 62. State = [[-0.24969892  0.10280668  0.10596835  1.        ]]. Action = [[ 0.79531026 -0.20035875 -0.14555955  0.5667825 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 62 is [True, False, False, False, False, True, False, True, False, True]
State prediction error at timestep 62 is tensor(0.1212, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 62 of -1
Current timestep = 63. State = [[-0.25588936 -0.1542463   0.11911494  1.        ]]. Action = [[-0.65188044  0.8158417   0.06627524 -0.38997507]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 64. State = [[-0.24583933 -0.16414927  0.10885052  1.        ]]. Action = [[0.79669905 0.51321006 0.5851264  0.8229692 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 64 is [True, False, False, True, False, False, False, True, False, True]
State prediction error at timestep 64 is tensor(0.1252, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 64 of 0
Current timestep = 65. State = [[-0.23563117 -0.15245044  0.10833815  1.        ]]. Action = [[-0.48667777  0.3797784  -0.37797475  0.6690512 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 65 is [True, False, False, True, False, False, False, True, False, True]
State prediction error at timestep 65 is tensor(0.1274, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 65 of -1
Current timestep = 66. State = [[-0.25203505 -0.05693435  0.12401701  1.        ]]. Action = [[-0.07752109  0.9511223   0.01204073 -0.11734223]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 67. State = [[-0.24590087 -0.05350201  0.11007746  1.        ]]. Action = [[ 0.5117221   0.7516153  -0.09213614  0.95146143]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 67 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 67 is tensor(0.1230, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 67 of 1
Current timestep = 68. State = [[-0.22675091 -0.03900026  0.11003649  1.        ]]. Action = [[0.7295873  0.29751778 0.22247648 0.25086105]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 68 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 68 is tensor(0.1362, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 68 of 1
Current timestep = 69. State = [[-0.20345826 -0.03101406  0.11502128  1.        ]]. Action = [[ 0.52963233 -0.07088327  0.33768916  0.75251055]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 69 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 69 is tensor(0.1344, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 69 of 1
Current timestep = 70. State = [[-0.19648917 -0.0457636   0.12475877  1.        ]]. Action = [[-0.9735227  -0.84563136  0.566273    0.41013598]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 70 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 70 is tensor(0.1069, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 70 of 0
Current timestep = 71. State = [[-0.20871623 -0.06411503  0.13275167  1.        ]]. Action = [[ 0.97764564  0.12111008 -0.7932134   0.70563745]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Scene graph at timestep 71 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 71 is tensor(0.1169, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 71 of -1
Current timestep = 72. State = [[-0.21610734 -0.07381206  0.14381906  1.        ]]. Action = [[-0.69558   -0.51331    0.8715546  0.834661 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 72 is [True, False, False, True, False, False, False, True, False, True]
State prediction error at timestep 72 is tensor(0.1149, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 72 of 1
Current timestep = 73. State = [[-0.23245117 -0.08681609  0.16023156  1.        ]]. Action = [[ 0.34437537 -0.20807284 -0.7617767   0.48436677]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 73 is [True, False, False, True, False, False, False, True, False, True]
State prediction error at timestep 73 is tensor(0.1311, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 73 of -1
Current timestep = 74. State = [[-0.23808065 -0.08025911  0.15366329  1.        ]]. Action = [[-0.6766922   0.6828481   0.29816175  0.18086195]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 74 is [True, False, False, True, False, False, False, True, False, True]
State prediction error at timestep 74 is tensor(0.1359, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 74 of -1
Current timestep = 75. State = [[-0.24034785 -0.06323215  0.15338998  1.        ]]. Action = [[ 0.43224943  0.4765973  -0.07997483  0.43127298]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 75 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 75 is tensor(0.1369, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 75 of 0
Current timestep = 76. State = [[-0.22772616 -0.06199139  0.15531449  1.        ]]. Action = [[ 0.82104087 -0.7793918   0.09002328  0.5662508 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 76 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 76 is tensor(0.1164, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 76 of 1
Current timestep = 77. State = [[-0.21814996 -0.08906326  0.16018808  1.        ]]. Action = [[-0.52608603 -0.9685128   0.18745327  0.09428418]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 77 is [True, False, False, True, False, False, False, True, False, True]
State prediction error at timestep 77 is tensor(0.1177, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 77 of -1
Current timestep = 78. State = [[-0.22763829 -0.12677245  0.16546094  1.        ]]. Action = [[-0.30894637 -0.9469745   0.18771005  0.66173005]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 78 is [True, False, False, True, False, False, False, True, False, True]
State prediction error at timestep 78 is tensor(0.1181, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 78 of -1
Current timestep = 79. State = [[-0.25472376 -0.16909193  0.12388824  1.        ]]. Action = [[ 0.38714647 -0.16485393 -0.3909487  -0.26279426]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 80. State = [[-0.25153792 -0.11481156  0.12498489  1.        ]]. Action = [[ 0.9894128  -0.386981    0.80557334 -0.60360956]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 81. State = [[-0.24727955 -0.13715528  0.11731792  1.        ]]. Action = [[ 0.37354898 -0.6205707   0.8473339   0.76962686]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 81 is [True, False, False, True, False, False, False, True, False, True]
State prediction error at timestep 81 is tensor(0.1054, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 81 of 1
Current timestep = 82. State = [[-0.23380153 -0.15967707  0.12734081  1.        ]]. Action = [[ 0.5421741  -0.65224475 -0.02356201  0.84692717]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 82 is [True, False, False, True, False, False, False, True, False, True]
State prediction error at timestep 82 is tensor(0.1076, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 82 of 1
Current timestep = 83. State = [[-0.2532052  -0.15879726  0.12498002  1.        ]]. Action = [[ 0.25471544  0.57336724  0.6352453  -0.03323734]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 84. State = [[-0.25370312 -0.17472728  0.11251521  1.        ]]. Action = [[-0.84594274 -0.34458524  0.39591026  0.8021462 ]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Scene graph at timestep 84 is [True, False, False, True, False, False, False, True, False, True]
State prediction error at timestep 84 is tensor(0.1025, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 84 of -1
Current timestep = 85. State = [[-0.2524339  0.0262277  0.1276839  1.       ]]. Action = [[ 0.28686726  0.7953501   0.57957006 -0.5118698 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 86. State = [[-0.2629175   0.11114107  0.12373292  1.        ]]. Action = [[-0.05428213 -0.6334168   0.46999252 -0.57275134]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 87. State = [[-0.26011705  0.1226882   0.11162531  1.        ]]. Action = [[-0.46025646 -0.45073736  0.78084886 -0.6383984 ]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Scene graph at timestep 87 is [True, False, False, False, False, True, False, True, False, True]
State prediction error at timestep 87 is tensor(0.0993, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 87 of -1
Current timestep = 88. State = [[-0.24680386  0.12749425  0.11885459  1.        ]]. Action = [[0.7571094  0.28653514 0.84601307 0.788744  ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 88 is [True, False, False, False, False, True, False, True, False, True]
State prediction error at timestep 88 is tensor(0.0904, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 88 of 1
Current timestep = 89. State = [[-0.25807917  0.00403284  0.12006595  1.        ]]. Action = [[ 0.04496026 -0.864155   -0.13196093 -0.69105554]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 90. State = [[-0.24579392 -0.00390381  0.11352459  1.        ]]. Action = [[ 0.8968532  -0.61889994  0.9012654   0.51727176]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 90 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 90 is tensor(0.0842, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 90 of 1
Current timestep = 91. State = [[-0.21446131 -0.02136921  0.13726623  1.        ]]. Action = [[ 0.75274    -0.33466935  0.9888104   0.90710366]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 91 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 91 is tensor(0.0826, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 91 of 1
Current timestep = 92. State = [[-0.1935919  -0.02681024  0.15985914  1.        ]]. Action = [[ 0.6502578   0.14457417  0.16326785 -0.03411043]]. Reward = [0.]
Curr episode timestep = 2
Action ignored: No entry zone
Scene graph at timestep 92 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 92 is tensor(0.1165, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 92 of -1
Current timestep = 93. State = [[-0.18903835 -0.03045016  0.17397453  1.        ]]. Action = [[ 0.1331861  -0.16867399  0.97063446  0.8813205 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 93 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 93 is tensor(0.0970, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 93 of 1
Current timestep = 94. State = [[-0.17697151 -0.03893601  0.21352892  1.        ]]. Action = [[ 0.517342   -0.28137815  0.92705584  0.9035269 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 94 is [True, False, False, False, True, False, False, True, False, True]
State prediction error at timestep 94 is tensor(0.0982, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 94 of 1
Current timestep = 95. State = [[-0.16459867 -0.05671988  0.249645    1.        ]]. Action = [[-0.38663393 -0.6481003   0.8737507   0.9354682 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 95 is [True, False, False, False, True, False, True, False, False, True]
State prediction error at timestep 95 is tensor(0.1020, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 95 of 1
Current timestep = 96. State = [[-0.16437048 -0.08320182  0.28452587  1.        ]]. Action = [[ 0.54677963 -0.7485298   0.86985826  0.77313066]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 96 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 96 is tensor(0.1088, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 96 of 1
Current timestep = 97. State = [[-0.15342864 -0.10747815  0.3004873   1.        ]]. Action = [[ 0.15404248 -0.4540047  -0.9199967   0.49402618]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 97 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 97 is tensor(0.1220, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 97 of 0
Current timestep = 98. State = [[-0.2568659  -0.08091255  0.10738247  1.        ]]. Action = [[-0.84653336  0.6480731   0.96242476 -0.01828498]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 99. State = [[-0.24994732 -0.0888659   0.0887337   1.        ]]. Action = [[ 0.6888479  0.0766139 -0.4393494  0.835305 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 100. State = [[-0.25409344 -0.11617951  0.1208443   1.        ]]. Action = [[ 0.41455507 -0.97745275  0.6571889  -0.59139425]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 101. State = [[-0.24676852 -0.12670168  0.10131221  1.        ]]. Action = [[ 0.78930926  0.01125336 -0.5310987   0.9068638 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 102. State = [[-0.23231253 -0.12799735  0.08763576  1.        ]]. Action = [[-0.64082456  0.5029223  -0.7468692  -0.763439  ]]. Reward = [0.]
Curr episode timestep = 1
Action ignored: Workspace boundary
Current timestep = 103. State = [[-0.2344051  -0.12358303  0.08516674  1.        ]]. Action = [[-0.55512667  0.48520374  0.23092973  0.6343684 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 104. State = [[-0.2377618  -0.120441    0.08434612  1.        ]]. Action = [[-0.881317   -0.91383684  0.08544219  0.8486296 ]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: Workspace boundary
Current timestep = 105. State = [[-0.2430777  -0.12868813  0.09012695  1.        ]]. Action = [[-0.4603728  -0.660771    0.56035864  0.7243459 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 106. State = [[-0.25422972  0.02085952  0.12609471  1.        ]]. Action = [[ 0.35195267  0.06340325 -0.27382386 -0.81272405]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 107. State = [[-0.25322053  0.02503314  0.1120192   1.        ]]. Action = [[-0.50577885 -0.8876463   0.94529176  0.94096816]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Current timestep = 108. State = [[-0.24386507  0.0392999   0.1112283   1.        ]]. Action = [[ 0.74790347  0.8759153  -0.14658737  0.805207  ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 109. State = [[-0.22091453  0.06657919  0.09873689  1.        ]]. Action = [[ 0.7705753   0.57254004 -0.6140953   0.59889436]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 110. State = [[-0.21153249  0.07580254  0.07409801  1.        ]]. Action = [[-0.44100702 -0.37717426 -0.725088    0.80153596]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 110 is [True, False, False, False, False, True, False, True, False, True]
State prediction error at timestep 110 is tensor(0.1057, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 110 of -1
Current timestep = 111. State = [[-0.19710436  0.07093526  0.06342322  1.        ]]. Action = [[ 0.87134385 -0.02025336  0.89537406  0.9600756 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 112. State = [[-0.17389847  0.05940874  0.08476896  1.        ]]. Action = [[ 0.32959044 -0.62343746  0.98301435  0.8000014 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 113. State = [[-0.16535841  0.04993077  0.10806652  1.        ]]. Action = [[0.5601082  0.05033255 0.32998753 0.9661672 ]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 114. State = [[-0.16210997  0.04853816  0.10979192  1.        ]]. Action = [[ 0.4581232  -0.38570505  0.08105016  0.563396  ]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 115. State = [[-0.16190259  0.04799712  0.11004804  1.        ]]. Action = [[ 0.9514271   0.4304706  -0.7284057   0.05630398]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 116. State = [[-0.1665617   0.05147086  0.10517424  1.        ]]. Action = [[-0.5447317   0.23681617 -0.60601294  0.30282712]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 117. State = [[-0.17143467  0.06145624  0.10626607  1.        ]]. Action = [[-0.13654655  0.32306683  0.52069664  0.4655118 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 118. State = [[-0.17553955  0.06921522  0.1078392   1.        ]]. Action = [[0.863803   0.81114364 0.06987894 0.3382845 ]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: No entry zone
Current timestep = 119. State = [[-0.18097487  0.08132433  0.10883245  1.        ]]. Action = [[-0.43974388  0.7021744   0.12219     0.22558677]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 120. State = [[-0.19040266  0.0933692   0.11705572  1.        ]]. Action = [[-0.23698139 -0.18512952  0.4305774   0.8649932 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 121. State = [[-0.26176405  0.02048255  0.12136845  1.        ]]. Action = [[ 0.30627632  0.86662436  0.46677864 -0.27926224]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 122. State = [[-0.26112244  0.09675409  0.12131403  1.        ]]. Action = [[ 0.9281206   0.927351    0.35370517 -0.12908691]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 123. State = [[-0.25751206  0.10759163  0.10889693  1.        ]]. Action = [[-0.37025762 -0.8468207   0.946785    0.91653585]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Current timestep = 124. State = [[-0.24660477  0.09487385  0.10941798  1.        ]]. Action = [[ 0.83254266 -0.90886813  0.02910948  0.6483455 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 125. State = [[-0.2273923   0.08841597  0.113516    1.        ]]. Action = [[0.22149086 0.41108418 0.78491116 0.9433613 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 126. State = [[-0.21081463  0.10191546  0.11736841  1.        ]]. Action = [[ 0.8431113   0.75650764 -0.6936863   0.8875828 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 127. State = [[-0.2632172   0.10431366  0.12107437  1.        ]]. Action = [[ 0.26182222 -0.58714956  0.73986506 -0.7370193 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 128. State = [[-0.25921208  0.11971498  0.10101774  1.        ]]. Action = [[ 0.2969463   0.34942174 -0.88393635  0.45287335]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 129. State = [[-0.25433025  0.13542269  0.07277641  1.        ]]. Action = [[-0.1378169   0.5231972  -0.38516837  0.87776613]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 130. State = [[-0.23978195  0.14802887  0.06867474  1.        ]]. Action = [[ 0.9500743 -0.1144039  0.841732   0.7409872]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 131. State = [[-0.2110068   0.1346168   0.07992288  1.        ]]. Action = [[ 0.7832531  -0.8261861   0.29571998  0.51131856]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 132. State = [[-0.19346452  0.13170628  0.08030859  1.        ]]. Action = [[ 0.24552107  0.69894516 -0.97547007  0.7428633 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 133. State = [[-0.18101583  0.15216583  0.07476465  1.        ]]. Action = [[0.13004506 0.78725994 0.95103574 0.6956146 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 134. State = [[-0.1736669   0.1713682   0.08598095  1.        ]]. Action = [[ 0.45045304 -0.8298649   0.11911786  0.55530405]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 135. State = [[-0.17334895  0.17282984  0.08681671  1.        ]]. Action = [[ 0.63335896 -0.8673759  -0.55047625  0.51285887]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 136. State = [[-0.17326094  0.17304118  0.08691011  1.        ]]. Action = [[ 8.6067748e-01 -9.9718219e-01  3.4843183e-01  2.7477741e-04]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 137. State = [[-0.16020513  0.17055996  0.09957196  1.        ]]. Action = [[ 0.7172929  -0.22070324  0.86054826  0.98311734]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 138. State = [[-0.14319879  0.16898416  0.1156824   1.        ]]. Action = [[ 0.5173423  -0.8195507   0.93725944 -0.29238874]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 139. State = [[-0.14430189  0.18005407  0.1261503   1.        ]]. Action = [[-0.4170555  0.6518816  0.496832   0.8070135]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 140. State = [[-0.1521166   0.18966742  0.13224845  1.        ]]. Action = [[-0.14447153 -0.21580529 -0.48375058  0.0769465 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 141. State = [[-0.1445324   0.18131237  0.13995066  1.        ]]. Action = [[ 0.77250457 -0.3791046   0.81517124  0.84806824]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 142. State = [[-0.12914634  0.18368885  0.14849761  1.        ]]. Action = [[ 0.5135373   0.742712   -0.44259822  0.60888183]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 143. State = [[-0.11434893  0.19353779  0.1550265   1.        ]]. Action = [[ 0.0974524  -0.06521368  0.7800932   0.38261247]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 144. State = [[-0.09779643  0.20493798  0.17274062  1.        ]]. Action = [[0.924376   0.70158315 0.20761728 0.820482  ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 145. State = [[-0.06935545  0.21374908  0.19422293  1.        ]]. Action = [[ 0.7438735  -0.29322731  0.79152524  0.96255064]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 145 is [False, True, False, False, False, True, False, True, False, True]
State prediction error at timestep 145 is tensor(0.0652, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 145 of 1
Current timestep = 146. State = [[-0.04235656  0.20378767  0.21579634  1.        ]]. Action = [[-0.139202   -0.6610399   0.40390277  0.2882806 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 146 is [False, True, False, False, False, True, False, True, False, True]
State prediction error at timestep 146 is tensor(0.0800, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 146 of 1
Current timestep = 147. State = [[-0.26211724 -0.06136255  0.11250498  1.        ]]. Action = [[-0.6134378  -0.35470843 -0.26331556 -0.61430305]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 148. State = [[-0.24772727 -0.11837408  0.12462658  1.        ]]. Action = [[ 0.58739567 -0.28679407  0.6275387  -0.261773  ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 149. State = [[-0.24819916 -0.13088255  0.11176081  1.        ]]. Action = [[-0.53049576  0.08310568  0.04351568  0.7674341 ]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Current timestep = 150. State = [[-0.2474215  -0.12454814  0.10428038  1.        ]]. Action = [[ 0.15859199  0.45306563 -0.7085483   0.93629956]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 151. State = [[-0.2451838  -0.1211047   0.08580595  1.        ]]. Action = [[-0.48646593  0.7322624   0.13958967  0.4976704 ]]. Reward = [0.]
Curr episode timestep = 2
Action ignored: Workspace boundary
Current timestep = 152. State = [[-0.24015696 -0.10889906  0.07717318  1.        ]]. Action = [[ 0.45086527  0.5824915  -0.90758353  0.29642344]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 153. State = [[-0.2624388   0.06476615  0.1218659   1.        ]]. Action = [[ 0.9525769   0.9813514   0.20560586 -0.40829146]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 154. State = [[-0.25419357 -0.1656725   0.12063067  1.        ]]. Action = [[ 0.63462806 -0.9167604   0.7768744  -0.37394512]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 155. State = [[-0.2423093  -0.17499979  0.11476317  1.        ]]. Action = [[0.8879149  0.71534467 0.9498867  0.930575  ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 156. State = [[-0.22393607 -0.17107888  0.12801065  1.        ]]. Action = [[ 0.08961999 -0.3875507   0.27787757  0.9359431 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 157. State = [[-0.21991873 -0.17279117  0.133106    1.        ]]. Action = [[-0.9107766  0.3085159  0.7689519  0.3730222]]. Reward = [0.]
Curr episode timestep = 2
Action ignored: Workspace boundary
Current timestep = 158. State = [[-0.21412899 -0.1807348   0.12837152  1.        ]]. Action = [[ 0.46727073 -0.53041124 -0.79710966  0.6294575 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 159. State = [[-0.21063986 -0.19242662  0.12288354  1.        ]]. Action = [[-0.89545774 -0.05620795  0.37026513  0.3885901 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 160. State = [[-0.21432403 -0.20683523  0.12165712  1.        ]]. Action = [[ 0.70995975 -0.74242604 -0.4574139   0.7096001 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 161. State = [[-0.21863171 -0.2138533   0.11257842  1.        ]]. Action = [[-0.93756425  0.6493571  -0.37468898  0.9683118 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 162. State = [[-0.22720769 -0.20216721  0.10184894  1.        ]]. Action = [[ 0.15953314  0.37670124 -0.3764435   0.6660739 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 163. State = [[-0.22807936 -0.193161    0.08463169  1.        ]]. Action = [[ 0.02703333 -0.05099374 -0.6504911   0.90336585]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 164. State = [[-0.23069292 -0.19162287  0.07001203  1.        ]]. Action = [[ 0.05955303 -0.09758127  0.30251908  0.48160124]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 165. State = [[-0.2209617  -0.19553106  0.07915591  1.        ]]. Action = [[ 0.6639596  -0.28001082  0.85624385  0.8569491 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 166. State = [[-0.20129047 -0.20509796  0.09310859  1.        ]]. Action = [[ 0.6465163  -0.41228414  0.0810895   0.8874998 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 167. State = [[-0.1899112  -0.22074026  0.101608    1.        ]]. Action = [[-0.32677454 -0.412727    0.31506205  0.9499123 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 168. State = [[-0.18456794 -0.21977071  0.11995091  1.        ]]. Action = [[0.4557464  0.78688073 0.83790994 0.9400375 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 169. State = [[-0.17075442 -0.21837762  0.14474498  1.        ]]. Action = [[ 0.53677654 -0.521213    0.3563305   0.9850079 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 170. State = [[-0.16157028 -0.21462308  0.16517407  1.        ]]. Action = [[-0.8381322   0.7812598   0.8122231   0.53236246]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 171. State = [[-0.1757414  -0.20931675  0.17894512  1.        ]]. Action = [[-0.19011104 -0.40810454 -0.5934845   0.68040085]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 172. State = [[-0.17217627 -0.20988888  0.18067135  1.        ]]. Action = [[0.87508   0.1199317 0.3580593 0.8839817]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 173. State = [[-0.25817075 -0.05998003  0.10754815  1.        ]]. Action = [[ 0.6996031  -0.23733431 -0.8757402  -0.13656771]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 174. State = [[-0.25874573 -0.06531759  0.0935247   1.        ]]. Action = [[-0.3663566   0.03216982  0.22097623  0.51270914]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Current timestep = 175. State = [[-0.24685761 -0.05466687  0.09998976  1.        ]]. Action = [[0.88625693 0.88599634 0.8156686  0.86467123]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 176. State = [[-0.26383102  0.09026921  0.1240011   1.        ]]. Action = [[ 0.186957    0.6765455   0.41314435 -0.354007  ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 177. State = [[-0.25399697  0.09370179  0.10474754  1.        ]]. Action = [[ 0.6203604 -0.497262  -0.5913377  0.7984264]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 178. State = [[-0.23767069  0.09684768  0.08559167  1.        ]]. Action = [[ 0.31103802  0.56537783 -0.30905652  0.67795205]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 179. State = [[-0.26529056  0.11457472  0.12064306  1.        ]]. Action = [[-0.36326182 -0.5923683   0.9864588  -0.26618505]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 180. State = [[-0.26245764  0.12624945  0.10827734  1.        ]]. Action = [[-0.5619618  -0.82951194 -0.786018    0.9187112 ]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Current timestep = 181. State = [[-0.24855857  0.13028663  0.11213034  1.        ]]. Action = [[0.8753209  0.24292684 0.56396794 0.746366  ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 182. State = [[-0.23364277  0.13456199  0.11713451  1.        ]]. Action = [[-0.8052335   0.6980519   0.9548917  -0.21877152]]. Reward = [0.]
Curr episode timestep = 2
Action ignored: Workspace boundary
Current timestep = 183. State = [[-0.23251334  0.13555107  0.11780643  1.        ]]. Action = [[-0.12684375  0.0205276   0.11368811  0.9856001 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 184. State = [[-0.23610026  0.12677053  0.11691674  1.        ]]. Action = [[-0.5342462  -0.8023394  -0.15290266  0.9713174 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 185. State = [[-0.23590742  0.11486227  0.12633172  1.        ]]. Action = [[0.4840032  0.05277383 0.9078206  0.93173087]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 186. State = [[-0.23400754  0.12612064  0.15420173  1.        ]]. Action = [[-0.09707737  0.85631216  0.8646543   0.36237288]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 187. State = [[-0.23676491  0.13967225  0.17054388  1.        ]]. Action = [[-0.01996756 -0.16050464 -0.48849744  0.7792163 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 188. State = [[-0.26759586  0.17180151  0.12556317  1.        ]]. Action = [[-0.35674816  0.07967353  0.7899803  -0.01039368]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 189. State = [[-0.26502433  0.19034001  0.11253776  1.        ]]. Action = [[-0.8304993  -0.42497218  0.5107609   0.9420929 ]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Current timestep = 190. State = [[-0.2594547   0.18635674  0.107256    1.        ]]. Action = [[ 0.51517713 -0.29751337 -0.45014858  0.58806515]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 191. State = [[-0.24782911  0.18381026  0.09564932  1.        ]]. Action = [[-0.2674451   0.28484118 -0.62545764  0.6232724 ]]. Reward = [0.]
Curr episode timestep = 2
Action ignored: Workspace boundary
Current timestep = 192. State = [[-0.23754476  0.17636931  0.09054426  1.        ]]. Action = [[ 0.6343987  -0.38696945 -0.3049127   0.92272985]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 193. State = [[-0.21322478  0.18205452  0.08756393  1.        ]]. Action = [[0.8588855  0.8856995  0.23763394 0.9737228 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 194. State = [[-0.19196236  0.2003055   0.09360725  1.        ]]. Action = [[0.1957041  0.33536243 0.38019896 0.8486483 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 195. State = [[-0.18059541  0.20475663  0.10602722  1.        ]]. Action = [[ 0.03178918 -0.35247564  0.64568305  0.8645253 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 196. State = [[-0.15947784  0.1898027   0.12142141  1.        ]]. Action = [[ 0.9462142  -0.79138905  0.5426415   0.5778723 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 197. State = [[-0.13773169  0.18148479  0.1445351   1.        ]]. Action = [[0.10073757 0.2654506  0.6343268  0.953243  ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 198. State = [[-0.13432194  0.19124165  0.17097199  1.        ]]. Action = [[-0.5051834   0.38289762  0.9256966   0.8751347 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 199. State = [[-0.13773891  0.19109945  0.20147227  1.        ]]. Action = [[ 0.16513216 -0.49105406  0.37705088  0.13986969]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 200. State = [[-0.14164434  0.19767983  0.20909424  1.        ]]. Action = [[-0.15414691  0.9425461  -0.29132038  0.7057705 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 201. State = [[-0.14610408  0.211024    0.20305014  1.        ]]. Action = [[ 0.697283    0.17463863 -0.855368    0.83279526]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 202. State = [[-0.129613    0.22927992  0.18274802  1.        ]]. Action = [[ 0.11765862  0.778996   -0.10582393  0.500818  ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 203. State = [[-0.11909956  0.24879408  0.18284689  1.        ]]. Action = [[0.32282972 0.26006484 0.42049623 0.22626543]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 204. State = [[-0.11308911  0.24650358  0.19358452  1.        ]]. Action = [[-0.6597695  -0.89645034  0.3157847   0.6283622 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 205. State = [[-0.11707951  0.22528462  0.18742539  1.        ]]. Action = [[-0.218876   -0.8517693  -0.83635706  0.8865013 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 206. State = [[-0.13070437  0.20313878  0.17159542  1.        ]]. Action = [[-0.674508   -0.49765432 -0.62290686  0.9255917 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 207. State = [[-0.15345697  0.19514167  0.15737464  1.        ]]. Action = [[-0.5771783   0.240103    0.44909453  0.44846487]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 208. State = [[-0.16877453  0.20017664  0.16576502  1.        ]]. Action = [[-0.42940366  0.24832237  0.40914154  0.93450165]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 209. State = [[-0.18735519  0.19952348  0.18776831  1.        ]]. Action = [[-0.8408304  -0.42875695  0.8878906   0.8418162 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 210. State = [[-0.2176873   0.18120018  0.19647503  1.        ]]. Action = [[-0.40308267 -0.62902033 -0.9022695   0.6092732 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 211. State = [[-0.23241813  0.16406387  0.1767536   1.        ]]. Action = [[ 0.17183745 -0.1750856  -0.5507261   0.57702005]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 212. State = [[-0.2426391   0.15355423  0.15700182  1.        ]]. Action = [[-0.5792364  -0.41928053 -0.9290541   0.5329392 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 213. State = [[-0.258576    0.14359553  0.13162099  1.        ]]. Action = [[-0.8795115   0.9407797   0.37499857  0.46577764]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 214. State = [[-0.2612982   0.14202634  0.12907456  1.        ]]. Action = [[-0.45606625  0.72257054 -0.0077942   0.95904446]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 215. State = [[-0.2509667   0.13099888  0.13687044  1.        ]]. Action = [[ 0.7612064 -0.5945852  0.795573   0.9263663]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 216. State = [[-0.23934454  0.1183764   0.14458503  1.        ]]. Action = [[-0.4341805  0.5832627 -0.9982476  0.7976053]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 217. State = [[-0.2357907   0.11739838  0.14658785  1.        ]]. Action = [[-0.8575049   0.9188175   0.24294996  0.16089082]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 218. State = [[-0.2356264   0.11715105  0.14664535  1.        ]]. Action = [[-0.7962988  -0.49716705 -0.31965524  0.7063627 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 219. State = [[-0.22702406  0.11446622  0.14910579  1.        ]]. Action = [[ 0.7614474  -0.11398017  0.09807146  0.82533574]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 220. State = [[-0.2078138   0.10487622  0.14824714  1.        ]]. Action = [[ 0.8340447  -0.24846727 -0.3912027   0.44739652]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 221. State = [[-0.19092755  0.09719482  0.14465365  1.        ]]. Action = [[ 0.7894113  -0.2643667  -0.88613874  0.5926373 ]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: No entry zone
Current timestep = 222. State = [[-0.1890076   0.09672441  0.1448986   1.        ]]. Action = [[0.89432    0.44842052 0.8967825  0.75496435]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: No entry zone
Current timestep = 223. State = [[-0.19228889  0.10749596  0.14335027  1.        ]]. Action = [[-0.35186064  0.73114085 -0.02677292  0.94472396]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 224. State = [[-0.19459711  0.11476267  0.14161406  1.        ]]. Action = [[ 0.7201538  -0.24614632 -0.3722645   0.49025595]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: No entry zone
Current timestep = 225. State = [[-0.19731992  0.10633866  0.14441164  1.        ]]. Action = [[-0.5422847  -0.8090746   0.37726355  0.6263335 ]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 226. State = [[-0.21496199  0.0946842   0.13664687  1.        ]]. Action = [[-0.9198125  -0.11425322 -0.9276625   0.3548373 ]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 227. State = [[-0.23400782  0.08629081  0.12613365  1.        ]]. Action = [[-0.21396488 -0.27016097 -0.16278899  0.8599435 ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 228. State = [[-0.24130817  0.08221297  0.12217396  1.        ]]. Action = [[-0.97270864  0.87412715 -0.42566097  0.9828737 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 229. State = [[-0.23806787  0.07304584  0.11381959  1.        ]]. Action = [[ 0.421515   -0.4665063  -0.6288771   0.71416783]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 230. State = [[-0.22620897  0.07642572  0.09163173  1.        ]]. Action = [[ 0.9716604   0.99122775 -0.67733186  0.6582711 ]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 231. State = [[-0.21028803  0.08182219  0.07680011  1.        ]]. Action = [[-0.18397272 -0.77585644  0.51168025  0.49934244]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 232. State = [[-0.26170498 -0.04079539  0.11559447  1.        ]]. Action = [[-0.00169414  0.80668473  0.7536843  -0.16557562]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 233. State = [[-0.25959378 -0.04596993  0.10774795  1.        ]]. Action = [[-0.09039026  0.1762476   0.86280596  0.89066947]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 234. State = [[-0.2563396  -0.04588656  0.11659864  1.        ]]. Action = [[-0.6796208  -0.15842628  0.44898367  0.85135436]]. Reward = [0.]
Curr episode timestep = 1
Action ignored: Workspace boundary
Current timestep = 235. State = [[-0.25628152 -0.05395402  0.11784381  1.        ]]. Action = [[ 0.15130126 -0.59486884 -0.01293284  0.704484  ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 236. State = [[-0.25019997 -0.0619182   0.13064165  1.        ]]. Action = [[0.5322882  0.19859314 0.97692263 0.98249507]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 237. State = [[-0.23568098 -0.04957889  0.15672605  1.        ]]. Action = [[0.6433587  0.8346727  0.36545575 0.89750075]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 238. State = [[-0.21128935 -0.02846335  0.17131953  1.        ]]. Action = [[0.6767708  0.46520686 0.13348627 0.22540331]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 239. State = [[-0.20404159 -0.01467979  0.17096685  1.        ]]. Action = [[-0.84666705  0.13337696 -0.7727952   0.53920877]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 240. State = [[-0.20579122 -0.00590892  0.16229123  1.        ]]. Action = [[ 0.65734637  0.3048309  -0.05436838  0.29680288]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 241. State = [[-0.19811802 -0.00629639  0.16059329  1.        ]]. Action = [[ 0.16319299 -0.5564064  -0.08758152  0.18427455]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 242. State = [[-0.1936297  -0.01017762  0.15701008  1.        ]]. Action = [[ 0.8307576  -0.10124379 -0.20627159  0.6028793 ]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 243. State = [[-0.19129127 -0.02635908  0.1637856   1.        ]]. Action = [[-0.15744305 -0.8931974   0.799814    0.19839978]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 244. State = [[-0.1947465  -0.03266306  0.18420199  1.        ]]. Action = [[-0.60227716  0.70517313  0.97724605  0.9160781 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 245. State = [[-0.20242509 -0.02635657  0.20830424  1.        ]]. Action = [[ 0.60286915 -0.85457754 -0.01204979  0.83392954]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: No entry zone
Current timestep = 246. State = [[-0.20326908 -0.03073478  0.21056741  1.        ]]. Action = [[ 0.1587789  -0.4075032   0.13700628  0.21341777]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 247. State = [[-0.205666   -0.02628778  0.22261758  1.        ]]. Action = [[-0.16966134  0.68859005  0.6852714   0.5214461 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 248. State = [[-0.20977831 -0.0165925   0.24052927  1.        ]]. Action = [[ 0.8596685   0.755599   -0.64023155 -0.0250088 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: No entry zone
Scene graph at timestep 248 is [True, False, False, False, True, False, True, False, False, True]
State prediction error at timestep 248 is tensor(0.0346, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 248 of 1
Current timestep = 249. State = [[-2.0811354e-01  4.7605866e-04  2.4185672e-01  1.0000000e+00]]. Action = [[ 0.342726    0.9836632  -0.13963503  0.73018765]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 249 is [True, False, False, False, True, False, True, False, False, True]
State prediction error at timestep 249 is tensor(0.0443, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 249 of 0
Current timestep = 250. State = [[-0.21386665  0.00934949  0.23939958  1.        ]]. Action = [[-0.8349263 -0.9921464 -0.5253091  0.8426633]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 250 is [True, False, False, False, True, False, True, False, False, True]
State prediction error at timestep 250 is tensor(0.0304, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 250 of -1
Current timestep = 251. State = [[-0.22693136 -0.02341859  0.22815317  1.        ]]. Action = [[ 0.01245129 -0.87708634 -0.5244285   0.6847789 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 251 is [True, False, False, False, True, False, True, False, False, True]
State prediction error at timestep 251 is tensor(0.0341, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 251 of -1
Current timestep = 252. State = [[-0.22107556 -0.04218535  0.21110356  1.        ]]. Action = [[ 0.8074553   0.01248813 -0.2837839   0.8377843 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 253. State = [[-0.21806143 -0.04970978  0.19255011  1.        ]]. Action = [[-0.88911986 -0.46633232 -0.7919412   0.76627684]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 254. State = [[-0.23877344 -0.05337273  0.1659566   1.        ]]. Action = [[-0.8690141   0.42005217 -0.70979893  0.11994183]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 255. State = [[-0.26060313 -0.04623127  0.14916417  1.        ]]. Action = [[-0.17607439  0.3357829   0.20613372  0.9198718 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 256. State = [[-0.26542816 -0.0293266   0.13819571  1.        ]]. Action = [[ 0.38296068  0.7122638  -0.89529055  0.90209746]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 257. State = [[-0.2646678  -0.01353159  0.11852064  1.        ]]. Action = [[-0.5894787  -0.39989793 -0.90490043  0.69604254]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 258. State = [[-0.2644578  -0.00891884  0.11704476  1.        ]]. Action = [[-0.3101945  -0.39550316  0.8683388   0.6728823 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 259. State = [[-0.25152096 -0.01939816  0.11508253  1.        ]]. Action = [[ 0.9001117  -0.848307   -0.24022138  0.30833638]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 260. State = [[-0.23167272 -0.03566645  0.09981578  1.        ]]. Action = [[ 0.47301877 -0.09272683 -0.9002444   0.5284246 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 261. State = [[-0.2075965  -0.04997568  0.06914856  1.        ]]. Action = [[ 0.94334126 -0.71256375 -0.649537    0.91395795]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 262. State = [[-0.25882626 -0.02418112  0.12149162  1.        ]]. Action = [[ 0.28493822 -0.6551977  -0.0083006  -0.01216483]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 263. State = [[-0.25960952 -0.03414161  0.10298185  1.        ]]. Action = [[ 0.04510546 -0.46602738 -0.4322452   0.9094392 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 264. State = [[-0.25837263 -0.06099941  0.09765985  1.        ]]. Action = [[-0.03145766 -0.9562284   0.7590213   0.31371439]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 265. State = [[-0.2551335  -0.08138343  0.1005407   1.        ]]. Action = [[ 0.31315076 -0.0656532  -0.5560988   0.8536701 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 266. State = [[-0.23933356 -0.07509162  0.09486932  1.        ]]. Action = [[ 0.8952639   0.82167435 -0.22745979  0.94958806]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 267. State = [[-0.21295336 -0.06984859  0.09526288  1.        ]]. Action = [[ 0.68989587 -0.421363    0.76090074  0.461545  ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 268. State = [[-0.19522722 -0.08699291  0.11545265  1.        ]]. Action = [[-0.23983467 -0.7773135   0.97162867  0.6949742 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 269. State = [[-0.19332416 -0.09141991  0.14514768  1.        ]]. Action = [[0.0689925  0.6998781  0.6002345  0.65783465]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 270. State = [[-0.1947003  -0.09237964  0.17294687  1.        ]]. Action = [[-0.6272106 -0.4557017  0.8463037  0.9636142]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 271. State = [[-0.2097478  -0.11106787  0.18988845  1.        ]]. Action = [[-0.47843945 -0.8296685  -0.37269098  0.67873824]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 272. State = [[-0.22429082 -0.11425202  0.19845079  1.        ]]. Action = [[-0.56517357  0.8599036   0.737931    0.8081355 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 273. State = [[-0.24588366 -0.11873648  0.2189499   1.        ]]. Action = [[-0.64735997 -0.93508     0.5604452   0.9244549 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 274. State = [[-0.2623925  -0.13746192  0.23608184  1.        ]]. Action = [[ 0.14381707 -0.3492604   0.12615407  0.42440498]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 274 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 274 is tensor(0.0572, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 274 of 1
Current timestep = 275. State = [[-0.26520178 -0.1426668   0.23995112  1.        ]]. Action = [[ 0.01246047  0.50519204 -0.3628844   0.9068388 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 275 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 275 is tensor(0.0611, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 275 of 1
Current timestep = 276. State = [[-0.25984463 -0.13766506  0.24237816  1.        ]]. Action = [[ 0.55838895 -0.16983163  0.6707592   0.90943635]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 276 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 276 is tensor(0.0578, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 276 of 1
Current timestep = 277. State = [[-0.24351737 -0.14639634  0.2600602   1.        ]]. Action = [[ 0.32366526 -0.6068026   0.7391393   0.43029737]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 277 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 277 is tensor(0.0520, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 277 of 1
Current timestep = 278. State = [[-0.23346846 -0.1600107   0.28128627  1.        ]]. Action = [[-9.6902370e-01 -5.8093446e-01 -1.3470167e-01 -9.4491243e-04]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Scene graph at timestep 278 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 278 is tensor(0.0427, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 278 of -1
Current timestep = 279. State = [[-0.23397179 -0.15855812  0.27397144  1.        ]]. Action = [[ 0.00741804  0.18065286 -0.98938453  0.48324728]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 279 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 279 is tensor(0.0553, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 279 of 0
Current timestep = 280. State = [[-0.22823821 -0.17010812  0.2707326   1.        ]]. Action = [[ 0.33480942 -0.95567745  0.86814     0.28259265]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 280 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 280 is tensor(0.0476, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 280 of -1
Current timestep = 281. State = [[-0.22781564 -0.19488378  0.2929033   1.        ]]. Action = [[-0.17328078 -0.4381078   0.9213815   0.9839959 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 281 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 281 is tensor(0.0549, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 281 of -1
Current timestep = 282. State = [[-0.2338282  -0.22309549  0.3214826   1.        ]]. Action = [[-0.3205167  -0.9177203   0.37938476  0.9426563 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 282 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 282 is tensor(0.0580, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 282 of -1
Current timestep = 283. State = [[-0.24336347 -0.24316595  0.33376175  1.        ]]. Action = [[-0.90647566 -0.21279359  0.36623526  0.6956036 ]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Scene graph at timestep 283 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 283 is tensor(0.0626, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 283 of -1
Current timestep = 284. State = [[-0.23427203 -0.24059118  0.34319633  1.        ]]. Action = [[0.5269642  0.25027406 0.6386504  0.73585033]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 284 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 284 is tensor(0.0778, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 284 of -1
Current timestep = 285. State = [[-0.21759942 -0.23462026  0.34990445  1.        ]]. Action = [[ 0.46709466  0.12047458 -0.99506176  0.7821872 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 285 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 285 is tensor(0.0720, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 285 of 1
Current timestep = 286. State = [[-0.20402594 -0.23301327  0.3280275   1.        ]]. Action = [[ 0.4436437  -0.2255103  -0.48193336  0.8807702 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 286 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 286 is tensor(0.0739, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 286 of 1
Current timestep = 287. State = [[-0.19384472 -0.2310017   0.31763485  1.        ]]. Action = [[-0.7844009  0.5875006  0.3544147  0.856483 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 287 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 287 is tensor(0.0695, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 287 of -1
Current timestep = 288. State = [[-0.19251403 -0.21040647  0.3278695   1.        ]]. Action = [[0.7911215 0.8111826 0.6087245 0.7120106]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 288 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 288 is tensor(0.0691, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 288 of 1
Current timestep = 289. State = [[-0.18698601 -0.17955133  0.33196115  1.        ]]. Action = [[-0.4775955   0.63591146 -0.82202286  0.6234182 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 289 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 289 is tensor(0.0580, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 289 of 1
Current timestep = 290. State = [[-0.19688822 -0.17436194  0.32765692  1.        ]]. Action = [[-0.04609311 -0.5945874   0.50171125  0.27171493]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 290 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 290 is tensor(0.0575, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 290 of -1
Current timestep = 291. State = [[-0.20334013 -0.18373731  0.341771    1.        ]]. Action = [[-0.34875488  0.07619452  0.76888204  0.7299442 ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 291 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 291 is tensor(0.0605, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 291 of -1
Current timestep = 292. State = [[-0.20352411 -0.17290902  0.36250302  1.        ]]. Action = [[0.5003207 0.7398753 0.5346322 0.5900111]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 292 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 292 is tensor(0.0626, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 292 of 1
Current timestep = 293. State = [[-0.19558981 -0.1572384   0.37780055  1.        ]]. Action = [[-0.10990411 -0.27938682 -0.5088376   0.869737  ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 293 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 293 is tensor(0.0680, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 293 of 0
Current timestep = 294. State = [[-0.20466566 -0.17776246  0.38294005  1.        ]]. Action = [[-0.35772455 -0.9835991   0.7198198   0.6114162 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 294 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 294 is tensor(0.0520, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 294 of -1
Current timestep = 295. State = [[-0.22393873 -0.2017741   0.39688876  1.        ]]. Action = [[-0.63302946 -0.07577467  0.25830734  0.7914815 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 295 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 295 is tensor(0.0650, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 295 of -1
Current timestep = 296. State = [[-0.23127368 -0.20719989  0.40421948  1.        ]]. Action = [[-0.7618831  -0.68262154 -0.5920135   0.20389009]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Scene graph at timestep 296 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 296 is tensor(0.0596, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 296 of -1
Current timestep = 297. State = [[-0.23394173 -0.19331355  0.39584225  1.        ]]. Action = [[-0.10520071  0.9011035  -0.85549396  0.662745  ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 297 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 297 is tensor(0.0542, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 297 of 0
Current timestep = 298. State = [[-0.2404586  -0.17573725  0.38772994  1.        ]]. Action = [[ 0.31091833 -0.7805457   0.9821801   0.84198916]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Scene graph at timestep 298 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 298 is tensor(0.0495, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 298 of -1
Current timestep = 299. State = [[-0.23785919 -0.18387775  0.3846485   1.        ]]. Action = [[ 0.5507214  -0.7644948  -0.11144662  0.9683111 ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 299 is [True, False, False, True, False, False, True, False, False, True]
State prediction error at timestep 299 is tensor(0.0522, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 299 of 0
Current timestep = 300. State = [[-0.22174954 -0.19393167  0.3689267   1.        ]]. Action = [[ 0.9920292  -0.13813347 -0.7620801   0.60787845]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 301. State = [[-0.20753108 -0.21159987  0.34987664  1.        ]]. Action = [[-0.74234295 -0.7675367  -0.05040109  0.76176274]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 302. State = [[-0.22081713 -0.24342965  0.3587513   1.        ]]. Action = [[-0.7307752  -0.85041785  0.83688664  0.730219  ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 303. State = [[-0.22357023 -0.25098172  0.3780429   1.        ]]. Action = [[0.7924905  0.7128055  0.76942396 0.55109966]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 304. State = [[-0.20557049 -0.23494905  0.38202143  1.        ]]. Action = [[ 0.8848407   0.46051908 -0.7604553   0.39142478]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 305. State = [[-0.18859276 -0.22569853  0.37413415  1.        ]]. Action = [[-0.36768317  0.16399145  0.821259    0.07318461]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 306. State = [[-0.18311848 -0.21910632  0.3659732   1.        ]]. Action = [[-0.09949046  0.28920174 -0.8962909   0.11700475]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 307. State = [[-0.1773911  -0.21725284  0.35666263  1.        ]]. Action = [[ 0.32110357 -0.11784381  0.472973    0.89356875]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 308. State = [[-0.2557347  -0.11892523  0.10300986  1.        ]]. Action = [[-0.8096842   0.6309469   0.96320975 -0.36028278]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 309. State = [[-0.25573796 -0.13174032  0.09064974  1.        ]]. Action = [[ 0.08555412 -0.05706465  0.3535738   0.7625165 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 310. State = [[-0.25416872 -0.1323498   0.09091517  1.        ]]. Action = [[-0.9237268  -0.46546686  0.07021046  0.04612005]]. Reward = [0.]
Curr episode timestep = 1
Action ignored: Workspace boundary
Current timestep = 311. State = [[-0.2539696  -0.13253506  0.09097062  1.        ]]. Action = [[-0.9059424  -0.28111243  0.19496214  0.5165479 ]]. Reward = [0.]
Curr episode timestep = 2
Action ignored: Workspace boundary
Current timestep = 312. State = [[-0.2435595  -0.142287    0.08443316  1.        ]]. Action = [[ 0.7680148  -0.60389054 -0.85288876  0.8420353 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 313. State = [[-0.23002252 -0.15547289  0.07112188  1.        ]]. Action = [[-0.58763367 -0.5334512   0.8138629   0.74780846]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: Workspace boundary
Current timestep = 314. State = [[-0.22003913 -0.15242891  0.06168166  1.        ]]. Action = [[ 0.6465659  0.265041  -0.7259001  0.8521445]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 315. State = [[-0.20109455 -0.15070207  0.0432194   1.        ]]. Action = [[ 0.36478937 -0.0483647  -0.10802042  0.48224783]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 316. State = [[-0.18421628 -0.14211722  0.03913002  1.        ]]. Action = [[0.6026728  0.6087545  0.21310103 0.8182651 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 317. State = [[-0.17165959 -0.13464166  0.03992378  1.        ]]. Action = [[ 0.43723214 -0.3338393  -0.06282079  0.8285636 ]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 318. State = [[-0.17031625 -0.13333304  0.03998094  1.        ]]. Action = [[ 0.25984216  0.678797   -0.91416544  0.457677  ]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 319. State = [[-0.17002136 -0.13296199  0.04002352  1.        ]]. Action = [[0.18767846 0.88606083 0.55725217 0.8117647 ]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 320. State = [[-0.17439611 -0.12344057  0.04317303  1.        ]]. Action = [[-0.7864356  0.7080395  0.5400493  0.9614229]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 321. State = [[-0.1814073  -0.10995951  0.04817024  1.        ]]. Action = [[ 0.37566662  0.4133296  -0.36449474  0.77668214]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 322. State = [[-0.18150361 -0.10876243  0.04960858  1.        ]]. Action = [[ 0.4197533  -0.02158213 -0.97646916  0.00269878]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 323. State = [[-0.18179104 -0.108698    0.05015629  1.        ]]. Action = [[ 0.75223684 -0.5693624  -0.9257716   0.889043  ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 324. State = [[-0.18022266 -0.12257328  0.06022874  1.        ]]. Action = [[ 0.22179401 -0.9406802   0.75590444  0.9356332 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 325. State = [[-0.17932138 -0.1346588   0.07669367  1.        ]]. Action = [[ 0.50666404 -0.37472022 -0.2524314   0.6244955 ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: No entry zone
Current timestep = 326. State = [[-0.18525124 -0.14840873  0.07004489  1.        ]]. Action = [[-0.32073832 -0.77728474 -0.95889544  0.6625354 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 327. State = [[-0.18826497 -0.15693232  0.06682435  1.        ]]. Action = [[-0.03474504  0.6020855   0.70765257  0.8575654 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 328. State = [[-0.19809122 -0.15011582  0.06268193  1.        ]]. Action = [[-0.6973367  0.2215854 -0.7792378  0.5929649]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 329. State = [[-0.20710707 -0.15670304  0.05671644  1.        ]]. Action = [[ 0.09828448 -0.8993732   0.05894029  0.33123672]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 330. State = [[-0.20787708 -0.16780253  0.05557758  1.        ]]. Action = [[ 0.6171737  -0.32166672 -0.63808    -0.28900087]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 331. State = [[-0.21967213 -0.16408357  0.05349191  1.        ]]. Action = [[-0.95516515  0.5765599  -0.00306737  0.87371993]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 332. State = [[-0.23595527 -0.16122794  0.04562385  1.        ]]. Action = [[ 0.523932   -0.3761264  -0.48626488  0.48877335]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 333. State = [[-0.24120793 -0.154199    0.03748603  1.        ]]. Action = [[-0.632361    0.7102759  -0.09193373  0.73424196]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 334. State = [[-0.24251837 -0.14825371  0.03469392  1.        ]]. Action = [[ 0.5824969  -0.3067702  -0.0865556   0.85617316]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 335. State = [[-0.23995905 -0.14795348  0.03424234  1.        ]]. Action = [[ 0.09202051 -0.22963583 -0.9363149   0.8103142 ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 336. State = [[-0.2437292  -0.13846703  0.0339096   1.        ]]. Action = [[-0.54167765  0.7794707   0.32392693  0.9663173 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 337. State = [[-0.24305248 -0.13333523  0.03385823  1.        ]]. Action = [[ 0.6025114  -0.46990383 -0.14528447  0.578714  ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 338. State = [[-0.2580276   0.00667752  0.12138095  1.        ]]. Action = [[ 0.5161004   0.862434    0.7639544  -0.05229104]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 339. State = [[-0.2591788   0.00759502  0.10747883  1.        ]]. Action = [[-0.40300727 -0.61833084 -0.52930707  0.603137  ]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Current timestep = 340. State = [[-0.25917572  0.00765568  0.10747571  1.        ]]. Action = [[-0.70955306 -0.7992349   0.61275065  0.6241665 ]]. Reward = [0.]
Curr episode timestep = 1
Action ignored: Workspace boundary
Current timestep = 341. State = [[-0.25291106  0.01883634  0.11123805  1.        ]]. Action = [[0.5031898 0.7610488 0.6380819 0.2868998]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 342. State = [[-0.24498215  0.03397014  0.1153636   1.        ]]. Action = [[-0.7042869  -0.5870386   0.71367764 -0.479819  ]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: Workspace boundary
Current timestep = 343. State = [[-0.23147325  0.04917261  0.12059803  1.        ]]. Action = [[0.9500052  0.91418743 0.20708835 0.88797736]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 344. State = [[-0.20907421  0.08057608  0.13344672  1.        ]]. Action = [[0.24684334 0.7625339  0.23694718 0.62363887]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 344 is [True, False, False, False, False, True, False, True, False, True]
State prediction error at timestep 344 is tensor(0.0226, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 344 of -1
Current timestep = 345. State = [[-0.19896095  0.10069167  0.14235164  1.        ]]. Action = [[ 0.6374955  -0.71293515  0.24948883  0.61284447]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Scene graph at timestep 345 is [True, False, False, False, False, True, False, True, False, True]
State prediction error at timestep 345 is tensor(0.0211, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 345 of -1
Current timestep = 346. State = [[-0.19642839  0.09926185  0.13934235  1.        ]]. Action = [[ 0.26666534 -0.15565741 -0.27274418  0.0150063 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 346 is [True, False, False, False, False, True, False, True, False, True]
State prediction error at timestep 346 is tensor(0.0216, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 346 of -1
Current timestep = 347. State = [[-0.18647823  0.08372257  0.1292459   1.        ]]. Action = [[ 0.37323523 -0.8815394  -0.71432644  0.65068865]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 347 is [True, False, False, False, False, True, False, True, False, True]
State prediction error at timestep 347 is tensor(0.0164, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 347 of -1
Current timestep = 348. State = [[-0.17736     0.06804745  0.11381174  1.        ]]. Action = [[-0.9213817   0.01999271  0.57575536  0.08741462]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 349. State = [[-0.18817316  0.06773149  0.1183299   1.        ]]. Action = [[0.6450945  0.41174555 0.16023791 0.8418751 ]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 350. State = [[-0.1902026   0.07825901  0.12881055  1.        ]]. Action = [[-0.12414426  0.71261764  0.81818616  0.16662562]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 350 is [True, False, False, False, False, True, False, True, False, True]
State prediction error at timestep 350 is tensor(0.0147, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 350 of -1
Current timestep = 351. State = [[-0.20587341  0.10274934  0.14629963  1.        ]]. Action = [[-0.504531    0.5902839  -0.40378428  0.57103133]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 351 is [True, False, False, False, False, True, False, True, False, True]
State prediction error at timestep 351 is tensor(0.0117, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 351 of -1
Current timestep = 352. State = [[-0.22545096  0.10434248  0.13579318  1.        ]]. Action = [[-0.66773736 -0.91120976 -0.84823     0.67871785]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 352 is [True, False, False, False, False, True, False, True, False, True]
State prediction error at timestep 352 is tensor(0.0102, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 352 of 0
Current timestep = 353. State = [[-0.24508376  0.09685008  0.12159476  1.        ]]. Action = [[0.05071092 0.81119573 0.5196929  0.72984695]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 353 is [True, False, False, False, False, True, False, True, False, True]
State prediction error at timestep 353 is tensor(0.0088, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 353 of -1
Current timestep = 354. State = [[-0.24573635  0.10337597  0.12559125  1.        ]]. Action = [[-0.10196292 -0.54671985 -0.06325704  0.49763465]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 354 is [True, False, False, False, False, True, False, True, False, True]
State prediction error at timestep 354 is tensor(0.0167, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 354 of 0
Current timestep = 355. State = [[-0.23507616  0.08534542  0.12965947  1.        ]]. Action = [[ 0.8710189  -0.6937728   0.12833762  0.9270961 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 356. State = [[-0.22205175  0.06133291  0.12854405  1.        ]]. Action = [[ 0.3118894  -0.74906623 -0.48782843  0.89238715]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 357. State = [[-0.26652643  0.14855029  0.12350661  1.        ]]. Action = [[-0.6581817 -0.5661814 -0.1023221 -0.1109271]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 358. State = [[-0.25349167  0.1782496   0.10638213  1.        ]]. Action = [[ 0.8964026   0.9208503  -0.3992864   0.15362644]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 359. State = [[-0.23749861  0.19057797  0.08817437  1.        ]]. Action = [[-0.03361505 -0.4005592  -0.41159344  0.20862854]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 360. State = [[-0.22639279  0.18960705  0.07349494  1.        ]]. Action = [[ 0.7435777   0.07866788 -0.7177158   0.79291964]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 361. State = [[-0.20109381  0.1771566   0.06196901  1.        ]]. Action = [[ 0.2943046  -0.8333591   0.9451616   0.81186485]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 362. State = [[-0.18135206  0.162361    0.07434854  1.        ]]. Action = [[ 0.81801724 -0.03565788  0.29741287  0.50812745]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 363. State = [[-0.26880926  0.15386857  0.10759442  1.        ]]. Action = [[-0.5764      0.7609509   0.8427104  -0.05995309]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 364. State = [[-0.25670955  0.15983947  0.0864336   1.        ]]. Action = [[ 0.7484369  -0.76997656 -0.7180821   0.7421433 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 365. State = [[-0.2393292   0.15337783  0.07583676  1.        ]]. Action = [[0.04122424 0.2792734  0.86397195 0.947098  ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 366. State = [[-0.22660525  0.1581831   0.0828674   1.        ]]. Action = [[ 0.61702263  0.27550352 -0.05145073  0.62267065]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 367. State = [[-0.21379869  0.16090286  0.08268978  1.        ]]. Action = [[ 0.25453424 -0.20279479 -0.44922888  0.7440795 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 368. State = [[-0.19353549  0.1527134   0.08789116  1.        ]]. Action = [[ 0.8480041  -0.4409485   0.9737085   0.84451485]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 369. State = [[-0.17221154  0.1446542   0.10097632  1.        ]]. Action = [[ 0.6867995  -0.5869946  -0.28795886  0.79031   ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 370. State = [[-0.16816343  0.14416045  0.10324961  1.        ]]. Action = [[ 0.7287712  -0.86353415 -0.5773423   0.7390027 ]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 371. State = [[-0.17462967  0.14604068  0.10173248  1.        ]]. Action = [[-0.90992737  0.00339544 -0.08649665  0.75185394]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 372. State = [[-0.18937875  0.1397668   0.10487293  1.        ]]. Action = [[-0.58903706 -0.46817422  0.48577738  0.5493809 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 373. State = [[-0.19740319  0.13794531  0.12184788  1.        ]]. Action = [[0.7685852  0.6173289  0.36182797 0.63790727]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 374. State = [[-0.19866914  0.15690748  0.13837475  1.        ]]. Action = [[-0.5935004   0.5852108   0.66532445  0.7057748 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 375. State = [[-0.2078878   0.17067814  0.15470786  1.        ]]. Action = [[ 0.67903006 -0.42369866  0.03587234  0.91674995]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: No entry zone
Current timestep = 376. State = [[-0.20441785  0.18498197  0.17022094  1.        ]]. Action = [[0.34432805 0.76339865 0.9777739  0.40034485]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 377. State = [[-0.201955    0.20676821  0.19145198  1.        ]]. Action = [[-0.07490748  0.3817904   0.02039719  0.30209565]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 378. State = [[-0.20346047  0.20656922  0.20978917  1.        ]]. Action = [[-0.6559296 -0.7282308  0.9445243  0.9021263]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 379. State = [[-0.22146744  0.20403299  0.22282067  1.        ]]. Action = [[-0.5904994   0.27675152 -0.9089944   0.84749675]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 380. State = [[-0.23618574  0.21415669  0.22085255  1.        ]]. Action = [[0.07637441 0.6768153  0.62789    0.93021977]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 381. State = [[-0.2418125   0.22660536  0.22394162  1.        ]]. Action = [[-0.755568   -0.4799366  -0.73691124  0.17014074]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 382. State = [[-0.24377055  0.2265913   0.21718562  1.        ]]. Action = [[-0.15773124 -0.12581635 -0.84382844  0.38337493]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 383. State = [[-0.2442542   0.23270479  0.21562797  1.        ]]. Action = [[0.16728818 0.48658705 0.8071431  0.84556866]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 384. State = [[-0.2441184   0.23967691  0.22096115  1.        ]]. Action = [[-0.5868752  0.8485    -0.8482866  0.7853478]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 385. State = [[-0.23244788  0.25031304  0.23142117  1.        ]]. Action = [[0.9570751 0.7867563 0.5083531 0.8646755]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 385 is [True, False, False, False, False, True, True, False, False, True]
State prediction error at timestep 385 is tensor(0.0075, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 385 of 1
Current timestep = 386. State = [[-0.22095396  0.27281028  0.25104263  1.        ]]. Action = [[-0.85181373  0.05328846  0.10276783  0.6211921 ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 386 is [True, False, False, False, False, True, True, False, False, True]
State prediction error at timestep 386 is tensor(0.0085, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 386 of -1
Current timestep = 387. State = [[-0.23219334  0.2800578   0.25212127  1.        ]]. Action = [[-0.63713217  0.40117884  0.11387217  0.53772473]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Scene graph at timestep 387 is [True, False, False, False, False, True, True, False, False, True]
State prediction error at timestep 387 is tensor(0.0073, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 387 of -1
Current timestep = 388. State = [[-0.23225725  0.2767534   0.26117206  1.        ]]. Action = [[-0.20774162 -0.27693117  0.6702051   0.7600868 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 388 is [True, False, False, False, False, True, True, False, False, True]
State prediction error at timestep 388 is tensor(0.0071, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 388 of 0
Current timestep = 389. State = [[-0.22961661  0.2663189   0.27576914  1.        ]]. Action = [[ 0.79454803 -0.21237898 -0.21943033  0.6022383 ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 389 is [True, False, False, False, False, True, True, False, False, True]
State prediction error at timestep 389 is tensor(0.0095, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 389 of 1
Current timestep = 390. State = [[-0.2278907   0.25317234  0.2879622   1.        ]]. Action = [[-0.7873134  -0.53892446  0.958967    0.7298329 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 390 is [True, False, False, False, False, True, True, False, False, True]
State prediction error at timestep 390 is tensor(0.0080, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 390 of 0
Current timestep = 391. State = [[-0.25972363  0.03959621  0.09908572  1.        ]]. Action = [[-0.45772898  0.6467022   0.18177474 -0.12153465]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 392. State = [[-0.24859577  0.0534756   0.07955905  1.        ]]. Action = [[ 0.92431545  0.5330682  -0.9573554   0.5185082 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 393. State = [[-0.22814682  0.06327365  0.05265179  1.        ]]. Action = [[-0.8911132   0.7858906  -0.796478    0.68833447]]. Reward = [0.]
Curr episode timestep = 1
Action ignored: Workspace boundary
Current timestep = 394. State = [[-0.22418962  0.06503744  0.04853068  1.        ]]. Action = [[-0.6817535   0.82363355 -0.61581546  0.7186742 ]]. Reward = [0.]
Curr episode timestep = 2
Action ignored: Workspace boundary
Current timestep = 395. State = [[-0.22037044  0.05730971  0.04831604  1.        ]]. Action = [[ 0.30639338 -0.6642695  -0.09699881  0.5254464 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 396. State = [[-0.21715547  0.04892925  0.04825777  1.        ]]. Action = [[ 0.5357146  -0.60010374 -0.75713843 -0.01560736]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: Workspace boundary
Current timestep = 397. State = [[-0.22356996  0.05947344  0.05392709  1.        ]]. Action = [[-0.85455453  0.91368854  0.9469433   0.9269271 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 398. State = [[-0.2345029   0.07714644  0.06125488  1.        ]]. Action = [[-0.5736049   0.47898054 -0.8235766   0.9141096 ]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: Workspace boundary
Current timestep = 399. State = [[-0.23207973  0.07265145  0.07208549  1.        ]]. Action = [[ 0.2847278  -0.3948536   0.76001847  0.6825279 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 400. State = [[-0.22707216  0.05276516  0.08767827  1.        ]]. Action = [[-0.22221076 -0.9282249  -0.2747097   0.77782035]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 401. State = [[-0.23656213  0.04866173  0.08716179  1.        ]]. Action = [[-0.60727006  0.72192526 -0.06451833  0.87891316]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 402. State = [[-0.25564015  0.06136609  0.09428245  1.        ]]. Action = [[-0.60122204  0.26969147  0.8756825   0.8551171 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 403. State = [[-0.263586    0.08203782  0.11015601  1.        ]]. Action = [[ 0.7250993   0.92676187 -0.1178143   0.6883521 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 404. State = [[-0.2610278   0.09571269  0.10690495  1.        ]]. Action = [[-0.0646075  -0.11915749 -0.6723349   0.30783367]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 405. State = [[-0.2514211   0.10273593  0.09433056  1.        ]]. Action = [[ 0.8622894   0.40103638 -0.51602036  0.6379776 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 406. State = [[-0.23667793  0.10682851  0.08387166  1.        ]]. Action = [[-0.29193956 -0.32276297  0.42182612  0.71329105]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 407. State = [[-0.24170697  0.09746612  0.08159328  1.        ]]. Action = [[-0.48898125 -0.51972264 -0.39401895  0.801005  ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 408. State = [[-0.24504265  0.07626764  0.07869015  1.        ]]. Action = [[-0.15612221 -0.95522565  0.00401509  0.5504334 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 409. State = [[-0.24401677  0.05128658  0.06977078  1.        ]]. Action = [[ 0.8034818  -0.34926844 -0.86870456  0.13677299]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 410. State = [[-0.23568757  0.03797978  0.05101675  1.        ]]. Action = [[-0.8997284   0.446818   -0.634805    0.93696356]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 411. State = [[-0.2361388   0.04632822  0.05258706  1.        ]]. Action = [[-0.37136614  0.68822694  0.5644554   0.8706465 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 412. State = [[-0.23875856  0.05503582  0.05429124  1.        ]]. Action = [[ 0.50006676 -0.5179964  -0.61193234  0.7137246 ]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 413. State = [[-0.23358591  0.04540956  0.05909084  1.        ]]. Action = [[ 0.29084945 -0.8242861   0.2948749   0.4181664 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 414. State = [[-0.2238591   0.02347829  0.07304417  1.        ]]. Action = [[ 0.27423692 -0.70999175  0.72105086  0.9562851 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 415. State = [[-0.21640562  0.0098999   0.08877414  1.        ]]. Action = [[ 0.7210436   0.07584047 -0.9694466   0.897472  ]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 416. State = [[-0.2205181   0.00912878  0.09124285  1.        ]]. Action = [[-0.5046537   0.23524594 -0.1857593   0.6679473 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 417. State = [[-0.22987969  0.01305253  0.08678853  1.        ]]. Action = [[ 0.0486542   0.19796717 -0.4574356   0.27318382]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 418. State = [[-0.26154682 -0.04545707  0.11879919  1.        ]]. Action = [[-0.56380016 -0.8037104  -0.29056895 -0.2585516 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 419. State = [[-0.26248118 -0.05001716  0.10600287  1.        ]]. Action = [[-0.6186531  -0.05933005 -0.08752835  0.22501218]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Current timestep = 420. State = [[-0.25648984 -0.04502836  0.10307991  1.        ]]. Action = [[ 0.5131484   0.47527874 -0.22155416  0.56137514]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 421. State = [[-0.24801745 -0.0413838   0.09632376  1.        ]]. Action = [[-0.28193122  0.2057457  -0.39956272  0.6096637 ]]. Reward = [0.]
Curr episode timestep = 2
Action ignored: Workspace boundary
Current timestep = 422. State = [[-0.23724775 -0.04479529  0.09705281  1.        ]]. Action = [[ 0.6163304  -0.42071497  0.10965037  0.86496127]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 423. State = [[-0.2284581  -0.04924959  0.09845284  1.        ]]. Action = [[-0.00402296 -0.05237967  0.1701628   0.6208923 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 424. State = [[-0.22892162 -0.03976563  0.10789196  1.        ]]. Action = [[-0.47768366  0.9221833   0.8834722   0.5716827 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 425. State = [[-0.25547284 -0.02326412  0.12290119  1.        ]]. Action = [[-0.68515474  0.54448044 -0.234967   -0.2520625 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 426. State = [[-0.24524051 -0.01757563  0.11611211  1.        ]]. Action = [[0.7135391  0.74556434 0.85195243 0.90751016]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 427. State = [[-0.23234056 -0.00974728  0.12423089  1.        ]]. Action = [[-0.51542324  0.7348362   0.2013346   0.09533775]]. Reward = [0.]
Curr episode timestep = 1
Action ignored: Workspace boundary
Current timestep = 428. State = [[-0.2312369  -0.0088655   0.12451997  1.        ]]. Action = [[-0.8041609   0.33704317 -0.67944     0.9449737 ]]. Reward = [0.]
Curr episode timestep = 2
Action ignored: Workspace boundary
Current timestep = 429. State = [[-2.1930455e-01  2.8962389e-04  1.2935126e-01  1.0000000e+00]]. Action = [[0.86414814 0.5573487  0.29399252 0.43599987]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 430. State = [[-0.20747253  0.00638937  0.1310569   1.        ]]. Action = [[-0.53043973 -0.43472075 -0.7828216   0.79936934]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 431. State = [[-0.21124478  0.00456092  0.12417353  1.        ]]. Action = [[ 0.88147545 -0.9340684  -0.09758443  0.7864567 ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 432. State = [[-0.21047202 -0.00646281  0.11704528  1.        ]]. Action = [[ 0.15395153 -0.6969749  -0.9091776   0.7108407 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 433. State = [[-0.21057172 -0.02090046  0.09837369  1.        ]]. Action = [[-0.28022355 -0.12238753  0.6092609   0.5683626 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 434. State = [[-0.21046753 -0.03495305  0.0999551   1.        ]]. Action = [[ 0.08396697 -0.5278964   0.00145841  0.8459954 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 435. State = [[-0.20543787 -0.03689482  0.10540363  1.        ]]. Action = [[0.5025151  0.6432649  0.4267652  0.25121522]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 436. State = [[-0.19230007 -0.03436746  0.11691405  1.        ]]. Action = [[ 0.4781375  -0.25588608  0.42799664  0.76354766]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 437. State = [[-0.18585323 -0.03478904  0.12247472  1.        ]]. Action = [[-0.30174595 -0.01637816 -0.69840354  0.8885822 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 438. State = [[-0.19801697 -0.03589534  0.11697152  1.        ]]. Action = [[-0.9523857  -0.0148164   0.36990905  0.11329901]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 439. State = [[-0.21982466 -0.03685203  0.11451421  1.        ]]. Action = [[-0.80306673 -0.03548265 -0.48555112  0.76905084]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 440. State = [[-0.25018042 -0.03176815  0.09992917  1.        ]]. Action = [[-0.63829684  0.45752656 -0.78444016  0.6962588 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 441. State = [[-0.26559997 -0.01466318  0.08668855  1.        ]]. Action = [[-0.0060159   0.71839833  0.29217565  0.65323687]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 442. State = [[-0.26959872  0.0129449   0.09053762  1.        ]]. Action = [[0.27193093 0.76315355 0.41943336 0.9306669 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 443. State = [[-0.26593044  0.04122819  0.08880664  1.        ]]. Action = [[ 0.43711376  0.69319177 -0.8510567   0.94806075]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 444. State = [[-0.25446653  0.06952383  0.08345889  1.        ]]. Action = [[0.35624218 0.94193316 0.6200378  0.72086406]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 445. State = [[-0.25165275  0.09531474  0.08140952  1.        ]]. Action = [[-0.18794775  0.2447077  -0.85123485  0.2883433 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 446. State = [[-0.24467544  0.11763658  0.06355073  1.        ]]. Action = [[ 0.724005   0.9423232 -0.6215745  0.7000122]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 447. State = [[-0.22902621  0.13767329  0.04690669  1.        ]]. Action = [[-0.6641288  -0.8025128  -0.41917032  0.7731838 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 448. State = [[-0.22089121  0.14866266  0.04234109  1.        ]]. Action = [[ 0.63545513  0.6489867  -0.25532562  0.86790943]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 449. State = [[-0.20815247  0.16271822  0.03523098  1.        ]]. Action = [[ 0.44319582  0.302132   -0.34838927  0.8702179 ]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 450. State = [[-0.19164492  0.16740884  0.03779437  1.        ]]. Action = [[0.91527927 0.07477379 0.2472713  0.5636418 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 451. State = [[-0.1619578   0.1810701   0.05257459  1.        ]]. Action = [[0.8974823  0.68851566 0.79984474 0.8098259 ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 452. State = [[-0.1394923   0.20667109  0.07305878  1.        ]]. Action = [[-0.14103293  0.68375444  0.47074163  0.27310014]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 453. State = [[-0.12800455  0.22648941  0.08373561  1.        ]]. Action = [[ 0.80864406  0.31698012 -0.32510626  0.24193108]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 454. State = [[-0.10307867  0.22906537  0.07512458  1.        ]]. Action = [[ 0.53614223 -0.33593512 -0.11736798  0.8058951 ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 455. State = [[-0.07725146  0.22284964  0.08054133  1.        ]]. Action = [[ 0.6134862  -0.1875068   0.56362176  0.42033565]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 455 is [False, True, False, False, False, True, False, True, False, True]
State prediction error at timestep 455 is tensor(0.0099, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 455 of -1
Current timestep = 456. State = [[-0.0609083   0.2336381   0.09532453  1.        ]]. Action = [[-0.3287598   0.8726485   0.19487941  0.6748185 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 456 is [False, True, False, False, False, True, False, True, False, True]
State prediction error at timestep 456 is tensor(0.0081, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 456 of -1
Current timestep = 457. State = [[-0.06436598  0.25083438  0.09673782  1.        ]]. Action = [[ 0.8428389  0.0773052 -0.7448359  0.8400047]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 457 is [False, True, False, False, False, True, False, True, False, True]
State prediction error at timestep 457 is tensor(0.0085, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 457 of -1
Current timestep = 458. State = [[-0.03322023  0.2596489   0.06969965  1.        ]]. Action = [[-0.30386066  0.8991859  -0.82766217  0.75930333]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Scene graph at timestep 458 is [False, True, False, False, False, True, False, True, False, True]
State prediction error at timestep 458 is tensor(0.0081, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 458 of -1
Current timestep = 459. State = [[-0.02369132  0.25584367  0.07324864  1.        ]]. Action = [[ 0.8970479  -0.17796195  0.1678474   0.853961  ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 459 is [False, True, False, False, False, True, False, True, False, True]
State prediction error at timestep 459 is tensor(0.0105, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 459 of -1
Current timestep = 460. State = [[0.00467611 0.2569963  0.07762928 1.        ]]. Action = [[0.4751563  0.8899169  0.63086593 0.6264682 ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Scene graph at timestep 460 is [False, True, False, False, False, True, False, True, False, True]
State prediction error at timestep 460 is tensor(0.0119, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 460 of -1
Current timestep = 461. State = [[0.01566268 0.2478902  0.08803575 1.        ]]. Action = [[ 0.83708405 -0.5110302   0.638762    0.6871985 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 461 is [False, True, False, False, False, True, False, True, False, True]
State prediction error at timestep 461 is tensor(0.0132, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 461 of 1
Current timestep = 462. State = [[0.02369033 0.24217638 0.09382568 1.        ]]. Action = [[-0.94929194  0.21960258 -0.75210357  0.76725364]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 462 is [False, True, False, False, False, True, False, True, False, True]
State prediction error at timestep 462 is tensor(0.0105, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 462 of -1
Current timestep = 463. State = [[0.01767118 0.247933   0.08775733 1.        ]]. Action = [[-0.35423815  0.01673448  0.86136127  0.770417  ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 463 is [False, True, False, False, False, True, False, True, False, True]
State prediction error at timestep 463 is tensor(0.0121, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 463 of 1
Current timestep = 464. State = [[0.01613479 0.26271167 0.11328074 1.        ]]. Action = [[0.20291877 0.70228195 0.84184337 0.9234998 ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 464 is [False, True, False, False, False, True, False, True, False, True]
State prediction error at timestep 464 is tensor(0.0112, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 464 of 1
Current timestep = 465. State = [[0.0127266  0.27468085 0.13313574 1.        ]]. Action = [[-0.87601596  0.7912705   0.79851687  0.79394007]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Scene graph at timestep 465 is [False, True, False, False, False, True, False, True, False, True]
State prediction error at timestep 465 is tensor(0.0092, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 465 of -1
Current timestep = 466. State = [[0.01692321 0.26487136 0.14508891 1.        ]]. Action = [[-0.2033993  -0.84734225  0.6811216   0.95773363]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 466 is [False, True, False, False, False, True, False, True, False, True]
State prediction error at timestep 466 is tensor(0.0125, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 466 of 1
Current timestep = 467. State = [[0.02522731 0.23917161 0.1700472  1.        ]]. Action = [[ 0.20615733 -0.77236986  0.30244613  0.6610267 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 467 is [False, True, False, False, False, True, False, True, False, True]
State prediction error at timestep 467 is tensor(0.0142, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 467 of 1
Current timestep = 468. State = [[0.0274654  0.22162299 0.18421784 1.        ]]. Action = [[0.23012352 0.18390882 0.5175221  0.41596425]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 468 is [False, True, False, False, False, True, False, True, False, True]
State prediction error at timestep 468 is tensor(0.0125, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 468 of 1
Current timestep = 469. State = [[0.02717218 0.22402768 0.20951803 1.        ]]. Action = [[-0.26952434  0.11707616  0.9615034   0.46165693]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 469 is [False, True, False, False, False, True, False, True, False, True]
State prediction error at timestep 469 is tensor(0.0113, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 469 of 1
Current timestep = 470. State = [[0.01606491 0.24018693 0.24521244 1.        ]]. Action = [[-0.4408067   0.7752361   0.5921724   0.60107493]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 470 is [False, True, False, False, False, True, True, False, False, True]
State prediction error at timestep 470 is tensor(0.0082, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 470 of 0
Current timestep = 471. State = [[-1.9201450e-04  2.5956103e-01  2.5161141e-01  1.0000000e+00]]. Action = [[ 0.08432651  0.12761211 -0.92956686  0.12075758]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 471 is [False, True, False, False, False, True, True, False, False, True]
State prediction error at timestep 471 is tensor(0.0099, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 471 of -1
Current timestep = 472. State = [[-0.00336902  0.25920013  0.23244378  1.        ]]. Action = [[-0.3603922  -0.1421895  -0.26644146  0.8445885 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 472 is [False, True, False, False, False, True, True, False, False, True]
State prediction error at timestep 472 is tensor(0.0052, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 472 of 0
Current timestep = 473. State = [[-0.00659176  0.2531317   0.21988158  1.        ]]. Action = [[ 0.15985394 -0.2891832  -0.6907475   0.7886528 ]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 474. State = [[-0.00643706  0.2500617   0.20376557  1.        ]]. Action = [[0.4470551  0.94314456 0.0664252  0.9160454 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 475. State = [[-0.00677059  0.2555179   0.19355011  1.        ]]. Action = [[ 0.885077    0.69146895 -0.875987    0.51891136]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 476. State = [[0.00645997 0.25319707 0.17880183 1.        ]]. Action = [[ 0.02488244 -0.9097948   0.8982258   0.7252276 ]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 477. State = [[0.01721778 0.23660222 0.18023601 1.        ]]. Action = [[ 0.9874172  -0.18123227 -0.86952555  0.66774535]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 478. State = [[0.0389972  0.21311331 0.15094647 1.        ]]. Action = [[-0.16178888 -0.9728243  -0.47107702  0.31685984]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 479. State = [[0.04530517 0.1960968  0.13355589 1.        ]]. Action = [[ 0.45619166  0.1861347  -0.729187    0.49667716]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 480. State = [[0.05311166 0.19710575 0.11243349 1.        ]]. Action = [[-0.45260918 -0.9576521   0.66232395  0.6480663 ]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: No entry zone
Current timestep = 481. State = [[0.0554744  0.18933225 0.09820543 1.        ]]. Action = [[-0.08897263 -0.5434441  -0.82665324  0.8322692 ]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 482. State = [[0.06264004 0.17216843 0.07433554 1.        ]]. Action = [[ 0.8368467  -0.46829122 -0.3206091   0.8415773 ]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 483. State = [[0.08173092 0.16022626 0.06372053 1.        ]]. Action = [[ 0.6806388  -0.18361795 -0.9254105   0.7344434 ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 484. State = [[0.08650322 0.15882514 0.06108775 1.        ]]. Action = [[ 0.9455106  -0.68355906 -0.66867864  0.6347301 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 485. State = [[0.0866451  0.15847315 0.06111335 1.        ]]. Action = [[ 0.7841917  -0.3189125   0.4749334   0.30789256]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 486. State = [[0.0842941  0.16264392 0.05756111 1.        ]]. Action = [[-0.21110022  0.3641323  -0.30099308  0.8905052 ]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 487. State = [[0.08324473 0.16643067 0.05169853 1.        ]]. Action = [[ 0.37050653  0.8937142  -0.4965253   0.76066494]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 488. State = [[0.08279192 0.17036387 0.05005169 1.        ]]. Action = [[-0.20118737  0.15741801 -0.11283332  0.19814837]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 489. State = [[0.08099037 0.1776212  0.05668721 1.        ]]. Action = [[-0.9080216   0.08229971  0.7761698   0.31616008]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 490. State = [[0.07017931 0.1838688  0.06714606 1.        ]]. Action = [[0.8945501  0.51602435 0.84469473 0.7825198 ]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 491. State = [[0.06870374 0.18463385 0.06929438 1.        ]]. Action = [[ 0.5962577   0.5788652  -0.8094972   0.77098334]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 492. State = [[0.06866028 0.18455985 0.06923446 1.        ]]. Action = [[0.67045975 0.11441505 0.47445416 0.7219033 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 493. State = [[0.06866028 0.18455985 0.06923446 1.        ]]. Action = [[ 0.78654504 -0.3111304  -0.10264623  0.9232857 ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 494. State = [[0.06866028 0.18455985 0.06923446 1.        ]]. Action = [[-0.1877662  -0.9697279   0.7917335   0.47055614]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: No entry zone
Current timestep = 495. State = [[0.06866028 0.18455985 0.06923446 1.        ]]. Action = [[ 0.7764809  -0.66726404 -0.96896774  0.664894  ]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 496. State = [[0.06689733 0.17958507 0.0744922  1.        ]]. Action = [[-0.46192575 -0.29547763  0.34504342  0.7831936 ]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 497. State = [[0.05398013 0.19014202 0.09787798 1.        ]]. Action = [[-0.5811086   0.79074407  0.9254637   0.5185987 ]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 498. State = [[0.03141672 0.20387277 0.11740609 1.        ]]. Action = [[ 0.9094405  -0.3553778   0.8416945   0.57934606]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 499. State = [[0.02966257 0.20306283 0.11715598 1.        ]]. Action = [[ 0.4117006  -0.14903492 -0.27599007  0.7771256 ]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 500. State = [[0.03084485 0.20307642 0.11801145 1.        ]]. Action = [[0.3115735  0.13092577 0.2503271  0.42494345]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 501. State = [[0.04189618 0.19256936 0.1347214  1.        ]]. Action = [[ 0.46013117 -0.8160705   0.9365554   0.62791455]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 502. State = [[0.05572501 0.172715   0.16837537 1.        ]]. Action = [[ 0.10936666 -0.23375684  0.8578057   0.90185213]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 503. State = [[0.05584345 0.16202849 0.20075019 1.        ]]. Action = [[-0.76661676 -0.18088478  0.7439456   0.5591788 ]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 504. State = [[0.0417194  0.16426028 0.22205661 1.        ]]. Action = [[-0.5173304   0.38157344  0.06220853  0.52607393]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 505. State = [[-0.25988796 -0.06087407  0.08603445  1.        ]]. Action = [[ 0.56555974  0.38168633 -0.6550039  -0.08737814]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 506. State = [[-0.24683353 -0.07905773  0.07223756  1.        ]]. Action = [[ 0.9539521  -0.8366897  -0.13202131  0.9445138 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 507. State = [[-0.23387688 -0.09487148  0.06775206  1.        ]]. Action = [[-0.4062546   0.36860812  0.49507928  0.6959572 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 508. State = [[-0.23687786 -0.09329748  0.06312526  1.        ]]. Action = [[-0.05126876 -0.02423209 -0.70912683  0.6996739 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 509. State = [[-0.23877291 -0.09184235  0.06004527  1.        ]]. Action = [[-0.69432974  0.22174096  0.28749728  0.75465536]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: Workspace boundary
Current timestep = 510. State = [[-0.23009785 -0.0816749   0.05994609  1.        ]]. Action = [[0.7257607  0.6950774  0.08916819 0.52629423]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 511. State = [[-0.22155187 -0.07043602  0.06157154  1.        ]]. Action = [[-0.19110751  0.18060362  0.45840192  0.83428466]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 512. State = [[-0.21939749 -0.05718773  0.07163204  1.        ]]. Action = [[0.1619345  0.6184815  0.74248207 0.7036768 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 513. State = [[-0.22082217 -0.05078827  0.09569342  1.        ]]. Action = [[-0.61995333 -0.47219414  0.56942296  0.8984475 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 514. State = [[-0.22644834 -0.04905028  0.11818737  1.        ]]. Action = [[-0.14160544  0.32317126  0.6477276   0.82382965]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 515. State = [[-0.2236781  -0.03482465  0.13787103  1.        ]]. Action = [[0.5790111  0.70441675 0.27962232 0.6846185 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 516. State = [[-0.21150205 -0.02326396  0.1547432   1.        ]]. Action = [[ 0.5819011  -0.17632109  0.62095654  0.9246571 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 517. State = [[-0.1971077  -0.02344734  0.16855586  1.        ]]. Action = [[ 0.91861176 -0.19826925 -0.9828046   0.43445873]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: No entry zone
Current timestep = 518. State = [[-0.1960984  -0.02349878  0.17184941  1.        ]]. Action = [[0.8999696  0.37956882 0.19492638 0.77524567]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: No entry zone
Current timestep = 519. State = [[-0.19358042 -0.01616677  0.1684824   1.        ]]. Action = [[ 0.39754748  0.4908185  -0.6499686   0.91078365]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 520. State = [[-0.18636078 -0.00772581  0.1636463   1.        ]]. Action = [[ 0.84686387 -0.47592694  0.73142266  0.8067204 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: No entry zone
Current timestep = 521. State = [[-0.19128571  0.00320713  0.1622894   1.        ]]. Action = [[-0.6711067   0.5123378   0.07518673  0.62975836]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 522. State = [[-1.9616619e-01 -7.2883855e-04  1.7159297e-01  1.0000000e+00]]. Action = [[-0.0492841  -0.90662867  0.947479    0.6514251 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 523. State = [[-0.20395762 -0.00131559  0.191294    1.        ]]. Action = [[-0.51991427  0.83085275  0.36287856  0.4031855 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 524. State = [[-0.25851092 -0.1460587   0.12710118  1.        ]]. Action = [[-0.14561355  0.11270046  0.8962257  -0.0391103 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 525. State = [[-0.25417784 -0.1544728   0.11916669  1.        ]]. Action = [[0.45434558 0.6784446  0.8445113  0.7739475 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 526. State = [[-0.24366716 -0.15571108  0.12314269  1.        ]]. Action = [[ 0.4345969  -0.72789323 -0.55659235  0.82385874]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 527. State = [[-0.23838799 -0.16083269  0.11730739  1.        ]]. Action = [[-0.41124552  0.1420207  -0.16394126  0.4875784 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 528. State = [[-0.24475618 -0.1606689   0.11613359  1.        ]]. Action = [[-0.4512545  -0.07623625  0.05721533  0.56819105]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 529. State = [[-0.24816014 -0.16130358  0.1156021   1.        ]]. Action = [[-0.8933202   0.74067736  0.4260397   0.71306074]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: Workspace boundary
Current timestep = 530. State = [[-0.23932956 -0.17467292  0.12220452  1.        ]]. Action = [[ 0.94703615 -0.82496184  0.7179823   0.5790063 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 531. State = [[-0.21900275 -0.18577604  0.14092945  1.        ]]. Action = [[0.5790248  0.37068892 0.9251989  0.918345  ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 532. State = [[-0.19275568 -0.19350737  0.17383553  1.        ]]. Action = [[ 0.86865675 -0.6372733   0.6613991   0.86843526]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 533. State = [[-0.16957572 -0.20271246  0.19108087  1.        ]]. Action = [[0.8153422  0.6490874  0.69218266 0.68598986]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 534. State = [[-0.16553022 -0.20472653  0.19405393  1.        ]]. Action = [[ 0.53481984  0.5647801  -0.31970853  0.9580214 ]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 535. State = [[-0.16460754 -0.20015635  0.19398783  1.        ]]. Action = [[ 0.0385381  0.4629401 -0.182495   0.1761694]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 536. State = [[-0.1678965  -0.20770775  0.19036272  1.        ]]. Action = [[-0.42845047 -0.8019312  -0.36416686  0.7103152 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 537. State = [[-0.17477949 -0.21564972  0.1795459   1.        ]]. Action = [[ 0.01175141  0.09670556 -0.9517038   0.93312955]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 538. State = [[-0.17533779 -0.22932133  0.15294077  1.        ]]. Action = [[ 0.21065474 -0.91855574 -0.3003024   0.7224785 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 539. State = [[-0.17949878 -0.26094955  0.14884618  1.        ]]. Action = [[-0.5476166 -0.6755164  0.5753734  0.8347292]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 540. State = [[-0.17866845 -0.28684577  0.15132412  1.        ]]. Action = [[ 0.6471211  -0.7143886  -0.28900456  0.7752671 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 541. State = [[-0.16312389 -0.29406554  0.1458356   1.        ]]. Action = [[ 0.7507796   0.49963772 -0.31253004  0.86321473]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 542. State = [[-0.1545798  -0.29330966  0.13392775  1.        ]]. Action = [[-0.49755406 -0.22578037 -0.33614278  0.8343159 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 543. State = [[-0.1656098  -0.28871146  0.12793155  1.        ]]. Action = [[-0.8790717   0.67371404  0.21374166  0.7834637 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 544. State = [[-0.17715585 -0.28336442  0.12533242  1.        ]]. Action = [[-0.6621382  -0.4854226   0.33723342  0.6617696 ]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 545. State = [[-0.17423853 -0.2733192   0.12033753  1.        ]]. Action = [[ 0.4585992   0.49045217 -0.54271847  0.83851945]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 546. State = [[-0.16300176 -0.25296834  0.12340274  1.        ]]. Action = [[0.22255266 0.7768214  0.86434233 0.75603545]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 547. State = [[-0.14919057 -0.24158879  0.13215084  1.        ]]. Action = [[ 0.92707896 -0.6003824  -0.1770156   0.4953394 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 548. State = [[-0.14186639 -0.24077356  0.12736657  1.        ]]. Action = [[-0.27073532  0.37392592 -0.61768883  0.9343095 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 549. State = [[-0.15186985 -0.24929783  0.11947119  1.        ]]. Action = [[-0.8564211  -0.8001776   0.09478188  0.88452053]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 550. State = [[-0.15379234 -0.2607602   0.12749574  1.        ]]. Action = [[ 0.6524222  -0.00201476  0.98768735  0.74838877]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 551. State = [[-0.26316103  0.022708    0.11136945  1.        ]]. Action = [[ 0.7573066   0.8068316   0.8821651  -0.01408678]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 552. State = [[-0.25348386  0.03599124  0.10155027  1.        ]]. Action = [[0.6766182  0.60048795 0.53761935 0.33849716]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 553. State = [[-0.24294761  0.04909416  0.10517243  1.        ]]. Action = [[-0.8814806  -0.13453877  0.9342766   0.73141   ]]. Reward = [0.]
Curr episode timestep = 1
Action ignored: Workspace boundary
Current timestep = 554. State = [[-0.24261105  0.04963717  0.10532328  1.        ]]. Action = [[-0.6567463   0.34100318  0.8167958   0.5431739 ]]. Reward = [0.]
Curr episode timestep = 2
Action ignored: Workspace boundary
Current timestep = 555. State = [[-0.24236116  0.04966655  0.10538159  1.        ]]. Action = [[-0.9624057  -0.8504727   0.18704176  0.9421351 ]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: Workspace boundary
Current timestep = 556. State = [[-0.24554771  0.04102571  0.10486093  1.        ]]. Action = [[-0.454543   -0.6595741  -0.04061633  0.899745  ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 557. State = [[-0.25030062  0.02176546  0.11237366  1.        ]]. Action = [[-0.43187368 -0.69202393  0.82823575  0.5651897 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 558. State = [[-0.25840935  0.00712511  0.12736629  1.        ]]. Action = [[-0.51618     0.31140983 -0.616532    0.6692337 ]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: Workspace boundary
Current timestep = 559. State = [[-0.26150686  0.00600578  0.12324217  1.        ]]. Action = [[ 0.10615993  0.18327105 -0.7322213   0.5831363 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 560. State = [[-0.2562697  -0.00571794  0.12577206  1.        ]]. Action = [[ 0.5678892  -0.9394856   0.95042145  0.94628656]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 561. State = [[-0.24866824 -0.03257861  0.13878936  1.        ]]. Action = [[-0.21314293 -0.75776917  0.23483253  0.6366463 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 562. State = [[-0.24979502 -0.04787413  0.14582558  1.        ]]. Action = [[-0.7986142  -0.5550254  -0.16032982  0.48179603]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: Workspace boundary
Current timestep = 563. State = [[-0.24573225 -0.03879943  0.15168014  1.        ]]. Action = [[0.3486383  0.8629122  0.41742027 0.6080409 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 564. State = [[-0.2343478  -0.02266744  0.1618012   1.        ]]. Action = [[ 0.4176731   0.32232475 -0.22699201  0.88567185]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 565. State = [[-0.2264933  -0.00573415  0.16259795  1.        ]]. Action = [[ 0.14503145  0.46576715 -0.0519399   0.7840717 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 566. State = [[-0.22498113 -0.00430395  0.15486342  1.        ]]. Action = [[-0.2857008  -0.6149385  -0.7261745   0.37184596]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 567. State = [[-0.21774042 -0.00790822  0.1442284   1.        ]]. Action = [[0.8288349  0.17059505 0.03520989 0.7993939 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 568. State = [[-0.20906085 -0.01563209  0.15006635  1.        ]]. Action = [[-0.868342   -0.50965816  0.95634794  0.46045446]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 569. State = [[-0.21333075 -0.01530043  0.17502008  1.        ]]. Action = [[0.3881353 0.5893972 0.9076247 0.7694056]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 570. State = [[-0.21453433 -0.01496917  0.19175221  1.        ]]. Action = [[-0.40358317 -0.50529885 -0.40552342  0.8519428 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 571. State = [[-0.2180928  -0.0327151   0.20059325  1.        ]]. Action = [[-0.1981802  -0.69625545  0.75730014  0.10268593]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 572. State = [[-0.21383785 -0.04947012  0.22411777  1.        ]]. Action = [[ 0.70912254 -0.13429475  0.7449378   0.7312211 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 573. State = [[-0.19435675 -0.05834927  0.25018826  1.        ]]. Action = [[ 0.8414893  -0.34452653  0.6264107   0.8544837 ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 573 is [True, False, False, False, True, False, True, False, False, True]
State prediction error at timestep 573 is tensor(0.0067, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 573 of 1
Current timestep = 574. State = [[-0.1614463  -0.07806355  0.2874733   1.        ]]. Action = [[ 0.9786377 -0.6548873  0.9315977  0.6402054]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 575. State = [[-0.1330541  -0.09976935  0.311237    1.        ]]. Action = [[ 0.79544723 -0.63087934 -0.06347525  0.43933272]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 576. State = [[-0.10601474 -0.12235653  0.32411462  1.        ]]. Action = [[ 0.40001738 -0.44888276  0.76477695  0.88275456]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 577. State = [[-0.09503628 -0.12126677  0.33071205  1.        ]]. Action = [[-0.03188914  0.79862905 -0.92614174  0.72199297]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 577 is [False, True, False, True, False, False, True, False, False, True]
State prediction error at timestep 577 is tensor(0.0024, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 577 of 1
Current timestep = 578. State = [[-0.07911747 -0.11324071  0.31896147  1.        ]]. Action = [[ 0.82527137 -0.2983706   0.3313316   0.33770788]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 578 is [False, True, False, True, False, False, True, False, False, True]
State prediction error at timestep 578 is tensor(0.0053, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 578 of 1
Current timestep = 579. State = [[-0.06337292 -0.119284    0.32672572  1.        ]]. Action = [[-0.46360826 -0.15997076  0.00113821  0.747926  ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 579 is [False, True, False, True, False, False, True, False, False, True]
State prediction error at timestep 579 is tensor(0.0039, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 579 of 1
Current timestep = 580. State = [[-0.07196672 -0.12003701  0.3225129   1.        ]]. Action = [[-0.55813915  0.41435838 -0.55264455  0.96684337]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 580 is [False, True, False, True, False, False, True, False, False, True]
State prediction error at timestep 580 is tensor(0.0019, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 580 of 1
Current timestep = 581. State = [[-0.07662904 -0.11121262  0.31884056  1.        ]]. Action = [[0.5678835  0.26469207 0.6798465  0.3133886 ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 581 is [False, True, False, True, False, False, True, False, False, True]
State prediction error at timestep 581 is tensor(0.0042, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 581 of 1
Current timestep = 582. State = [[-0.07327773 -0.09929654  0.32244655  1.        ]]. Action = [[-0.60638237  0.34681845 -0.60198504  0.23661685]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 582 is [False, True, False, True, False, False, True, False, False, True]
State prediction error at timestep 582 is tensor(0.0060, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 582 of 1
Current timestep = 583. State = [[-0.07651519 -0.08557554  0.30982116  1.        ]]. Action = [[ 0.957819    0.28485954 -0.2474662   0.7249956 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 583 is [False, True, False, True, False, False, True, False, False, True]
State prediction error at timestep 583 is tensor(0.0046, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 583 of 1
Current timestep = 584. State = [[-0.0684097  -0.06670414  0.29151446  1.        ]]. Action = [[-0.73489875  0.6895826  -0.83061856  0.4001869 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 584 is [False, True, False, True, False, False, True, False, False, True]
State prediction error at timestep 584 is tensor(0.0028, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 584 of 1
Current timestep = 585. State = [[-0.06582548 -0.05447205  0.28183448  1.        ]]. Action = [[ 0.9585991  -0.29607314  0.7069521   0.8634566 ]]. Reward = [0.]
Curr episode timestep = 33
Above hoop
Scene graph at timestep 585 is [False, True, False, False, True, False, True, False, False, True]
State prediction error at timestep 585 is tensor(0.0036, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 585 of 1
Current timestep = 586. State = [[-0.05835055 -0.06793309  0.28879496  1.        ]]. Action = [[-0.1261633  -0.73610425 -0.26968002  0.8980398 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 586 is [False, True, False, True, False, False, True, False, False, True]
State prediction error at timestep 586 is tensor(0.0025, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 586 of -1
Current timestep = 587. State = [[-0.05942336 -0.08373165  0.29033446  1.        ]]. Action = [[-0.2994902   0.06232989  0.55945945  0.609426  ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 587 is [False, True, False, True, False, False, True, False, False, True]
State prediction error at timestep 587 is tensor(0.0025, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 587 of -1
Current timestep = 588. State = [[-0.2619255  -0.03619959  0.1149018   1.        ]]. Action = [[ 0.15360498  0.3883363   0.68325853 -0.25345993]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 589. State = [[-0.26243687 -0.04021775  0.10160383  1.        ]]. Action = [[-0.31698525  0.04999411  0.6444323   0.7423835 ]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Current timestep = 590. State = [[-0.25494945 -0.03793654  0.09536592  1.        ]]. Action = [[ 0.67934823  0.3277893  -0.54106534  0.7478194 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 591. State = [[-0.24247617 -0.02792994  0.08062721  1.        ]]. Action = [[ 0.00336492  0.5479038  -0.05358523  0.77136636]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 592. State = [[-0.24101771 -0.02001985  0.07902727  1.        ]]. Action = [[-0.6953525   0.8283901  -0.20417869  0.44630527]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: Workspace boundary
Current timestep = 593. State = [[-0.23630874 -0.01445039  0.08667414  1.        ]]. Action = [[0.23881805 0.25556028 0.9809773  0.8202919 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 594. State = [[-0.23229007 -0.01418712  0.09492208  1.        ]]. Action = [[-0.1717717  -0.4635991  -0.48291993  0.8400272 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 595. State = [[-0.2210966  -0.00819406  0.1016031   1.        ]]. Action = [[0.9984913 0.7587273 0.7516539 0.5970423]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 596. State = [[-0.19148217  0.00161211  0.12157983  1.        ]]. Action = [[ 0.71189356 -0.0148232   0.84051394  0.86711836]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 597. State = [[-0.17212598  0.00345402  0.14023693  1.        ]]. Action = [[ 0.983222   -0.16697657  0.97142625  0.7696655 ]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 598. State = [[-1.7346369e-01 -3.6581387e-04  1.5441063e-01  1.0000000e+00]]. Action = [[-0.92356294 -0.29235214  0.84110546  0.86552024]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 599. State = [[-0.2001241  -0.01651645  0.16221939  1.        ]]. Action = [[-0.93906194 -0.82915    -0.948227    0.6149907 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 600. State = [[-0.23115163 -0.02256104  0.14633593  1.        ]]. Action = [[-0.7057232   0.535403   -0.5646129   0.51509225]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 601. State = [[-0.25208485 -0.02763727  0.13335858  1.        ]]. Action = [[-0.24733472 -0.64433795 -0.03416443  0.11097348]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 602. State = [[-0.2650887  -0.04543052  0.13044144  1.        ]]. Action = [[-0.33447874 -0.73261106  0.16515851  0.71147776]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 603. State = [[-0.27223438 -0.06085058  0.13043332  1.        ]]. Action = [[-0.7692258  -0.30210662  0.95870674  0.8051591 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 604. State = [[-0.27290553 -0.06353763  0.13084053  1.        ]]. Action = [[-0.55116254 -0.6286743   0.8119334   0.4363731 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 605. State = [[-0.27287602 -0.06377907  0.13089584  1.        ]]. Action = [[-0.3466633  -0.01360589 -0.4909407   0.58460665]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 606. State = [[-0.26933938 -0.07608551  0.12429851  1.        ]]. Action = [[ 0.58755636 -0.7676757  -0.7757309   0.666142  ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 607. State = [[-0.26643607 -0.09387538  0.11044264  1.        ]]. Action = [[-0.7768806  -0.10170913 -0.8230971   0.79317725]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 608. State = [[-0.26609808 -0.09555384  0.11028169  1.        ]]. Action = [[-0.21850938  0.69778085  0.15163684  0.8257512 ]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 609. State = [[-0.26596817 -0.09557069  0.11030006  1.        ]]. Action = [[-0.16933179 -0.6677026   0.05220759  0.8087363 ]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 610. State = [[-0.26346985 -0.10383559  0.11070616  1.        ]]. Action = [[ 0.15496898 -0.53028935  0.06049836  0.7822386 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 611. State = [[-0.25806412 -0.12829898  0.10350301  1.        ]]. Action = [[ 0.35684502 -0.9512575  -0.9257916   0.77862644]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 612. State = [[-0.2528429  -0.15736885  0.0712136   1.        ]]. Action = [[-0.09953475 -0.43939483 -0.65131754  0.69609284]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 613. State = [[-0.25203708 -0.16741788  0.06009918  1.        ]]. Action = [[-0.30306613  0.31344366  0.96178436  0.66233134]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 614. State = [[-0.2526264  -0.16654252  0.07520144  1.        ]]. Action = [[0.01284969 0.02421272 0.6637924  0.52421653]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 615. State = [[-0.25759    -0.15735869  0.10232526  1.        ]]. Action = [[-0.29746115  0.5328653   0.9613596   0.892972  ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 616. State = [[-0.2569134  -0.14315933  0.11768468  1.        ]]. Action = [[ 0.7330222   0.24725413 -0.88291615  0.5234046 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 617. State = [[-0.24685864 -0.12562162  0.11520337  1.        ]]. Action = [[0.20156503 0.6396694  0.5137775  0.79460275]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 618. State = [[-0.23818783 -0.11836974  0.12475014  1.        ]]. Action = [[ 0.3056903  -0.315417    0.58618724  0.34877872]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 619. State = [[-0.22034661 -0.12201966  0.13766754  1.        ]]. Action = [[ 0.82942176 -0.1933819  -0.2859972   0.5874057 ]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 620. State = [[-0.19250941 -0.11318464  0.14281447  1.        ]]. Action = [[0.8243047  0.7844362  0.15214956 0.69656205]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 621. State = [[-0.17175557 -0.10234092  0.14708431  1.        ]]. Action = [[ 0.55767536 -0.10758018  0.9631698   0.9129822 ]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: No entry zone
Current timestep = 622. State = [[-0.1718836  -0.10678991  0.15256184  1.        ]]. Action = [[-0.5906657  -0.4783187   0.63001657  0.80169654]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 623. State = [[-0.17970796 -0.11903542  0.16996762  1.        ]]. Action = [[-0.52673596 -0.18769985  0.7302387   0.8912113 ]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 624. State = [[-0.19076236 -0.13142768  0.18814106  1.        ]]. Action = [[-0.07748377 -0.46337795  0.14002609  0.9424584 ]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 625. State = [[-0.19671907 -0.12834577  0.19299965  1.        ]]. Action = [[-0.2841453   0.8006847  -0.09259409  0.6999347 ]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 626. State = [[-0.20744473 -0.11529105  0.20048738  1.        ]]. Action = [[-0.86930156  0.07706904  0.81987536  0.3992697 ]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 627. State = [[-0.22173685 -0.1187897   0.22644673  1.        ]]. Action = [[ 0.8257768  -0.6018187   0.40009618  0.8272176 ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 628. State = [[-0.21842304 -0.12066928  0.23131992  1.        ]]. Action = [[-0.1700638   0.46927798 -0.7007909   0.7008033 ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 629. State = [[-0.22568654 -0.12705144  0.21589771  1.        ]]. Action = [[-0.37651688 -0.720258   -0.95885956  0.9434936 ]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 630. State = [[-0.22703059 -0.12564102  0.20131744  1.        ]]. Action = [[0.18956506 0.68787956 0.6782949  0.62942874]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 631. State = [[-0.22522856 -0.11935116  0.20400518  1.        ]]. Action = [[ 0.21195138 -0.08449215 -0.1755116   0.7300451 ]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 632. State = [[-0.2257037  -0.12890732  0.20731233  1.        ]]. Action = [[-0.33616042 -0.6575669   0.43143606  0.50822675]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 633. State = [[-0.2365821  -0.15526421  0.22378956  1.        ]]. Action = [[-0.7966396 -0.9066615  0.9566655  0.8621063]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 634. State = [[-0.25841185 -0.18467303  0.25234175  1.        ]]. Action = [[-0.59910005 -0.5141792   0.20103717  0.64800406]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 635. State = [[-0.26986793 -0.18623073  0.269309    1.        ]]. Action = [[0.17138672 0.7899027  0.71534383 0.8486576 ]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 636. State = [[-0.26781157 -0.16946395  0.27790183  1.        ]]. Action = [[ 0.6413562   0.28984594 -0.9376064   0.6422639 ]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 637. State = [[-0.25944492 -0.16225177  0.26796252  1.        ]]. Action = [[-0.1589793   0.83010745  0.85666513  0.5425447 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 638. State = [[-0.24946028 -0.15075581  0.26054418  1.        ]]. Action = [[ 0.7765372   0.5819757  -0.5978369   0.64706135]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 639. State = [[-0.2226176 -0.1299346  0.2500433  1.       ]]. Action = [[0.66443574 0.4741869  0.5220834  0.41431272]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 640. State = [[-0.21520835 -0.11156158  0.24733354  1.        ]]. Action = [[-0.6218347   0.59116673 -0.69908595  0.71958876]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 641. State = [[-0.22786933 -0.10171001  0.2256154   1.        ]]. Action = [[-0.55333734 -0.06513977 -0.98370373  0.46263647]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 642. State = [[-0.24371764 -0.10699087  0.20001292  1.        ]]. Action = [[-0.57803124 -0.44140065 -0.15281528  0.6754204 ]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 643. State = [[-0.25507918 -0.12020244  0.1991296   1.        ]]. Action = [[ 0.17517173 -0.6721927   0.83777404  0.68209887]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 644. State = [[-0.25529188 -0.13679971  0.2178743   1.        ]]. Action = [[ 0.13296139 -0.20123994  0.8326787   0.74908257]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 645. State = [[-0.25755456 -0.14155376  0.23604041  1.        ]]. Action = [[-0.43191636  0.03034842  0.93866897  0.7764722 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 646. State = [[-0.25730392 -0.14220755  0.2370487   1.        ]]. Action = [[-0.62008244 -0.8394018  -0.48691082  0.23119366]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 647. State = [[-0.25745395 -0.1333628   0.24509957  1.        ]]. Action = [[-0.03211409  0.5946895   0.6075301   0.75727713]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 648. State = [[-0.2511736  -0.11484393  0.25188744  1.        ]]. Action = [[ 0.7649052   0.64517665 -0.852765    0.6472213 ]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 649. State = [[-0.23918784 -0.09313081  0.24849065  1.        ]]. Action = [[-0.32237518  0.61566186  0.6619154   0.60493743]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 650. State = [[-0.24615444 -0.06521835  0.24685341  1.        ]]. Action = [[-0.4897822  0.8182225 -0.7747934  0.9223726]]. Reward = [0.]
Curr episode timestep = 61
Scene graph at timestep 650 is [True, False, False, False, True, False, True, False, False, True]
State prediction error at timestep 650 is tensor(0.0088, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 650 of 1
Current timestep = 651. State = [[-0.25474486 -0.04572445  0.24247894  1.        ]]. Action = [[-0.66915554 -0.877294   -0.6486586   0.87030756]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 652. State = [[-0.25474486 -0.04572445  0.24247894  1.        ]]. Action = [[-0.5069244   0.85132754 -0.978904    0.50522935]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 653. State = [[-0.25419444 -0.03606845  0.24096745  1.        ]]. Action = [[ 0.273713    0.59564745 -0.1054306   0.66877747]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 654. State = [[-0.25346518 -0.02591104  0.23604867  1.        ]]. Action = [[-0.3532083   0.77186656  0.8458593   0.6409581 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 655. State = [[-0.2518762  -0.01240598  0.24279839  1.        ]]. Action = [[-0.03824925  0.6404002   0.895668    0.43210995]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 656. State = [[-0.24600023  0.01360913  0.25411347  1.        ]]. Action = [[ 0.5492059   0.66379976 -0.12113267  0.624051  ]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 657. State = [[-0.22783625  0.03930703  0.25864974  1.        ]]. Action = [[ 0.8607311   0.7457435  -0.05522496  0.1550405 ]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 658. State = [[-0.21189682  0.06385239  0.2622884   1.        ]]. Action = [[-0.45989227  0.36190128  0.49666727  0.8690505 ]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 659. State = [[-0.2525023  -0.17542085  0.1110576   1.        ]]. Action = [[-0.33717406 -0.04724836  0.98782253 -0.08969724]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 660. State = [[-0.24290766 -0.19282906  0.09337106  1.        ]]. Action = [[ 0.77579784  0.1521318  -0.39038527  0.6343539 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 661. State = [[-0.2170583  -0.19205056  0.07836243  1.        ]]. Action = [[ 0.90358067 -0.10511196 -0.35414642  0.23254848]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 662. State = [[-0.19231677 -0.18535884  0.05997061  1.        ]]. Action = [[ 0.509675   0.6016607 -0.7367595  0.828593 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 663. State = [[-0.1847692  -0.16660613  0.04409423  1.        ]]. Action = [[-0.83113     0.7647923   0.42049444  0.556425  ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 664. State = [[-0.19083701 -0.1531282   0.04319702  1.        ]]. Action = [[0.8022895 0.5774257 0.5778315 0.5192236]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 665. State = [[-0.19264865 -0.16463895  0.05256029  1.        ]]. Action = [[-0.22500181 -0.7825793   0.8558297   0.7285979 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 666. State = [[-0.19084395 -0.1786102   0.0767846   1.        ]]. Action = [[ 0.5398054  -0.33157325  0.66287637  0.8929012 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 667. State = [[-0.19224381 -0.18744838  0.1028372   1.        ]]. Action = [[-0.616009    0.01648629  0.6735332   0.44359922]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 668. State = [[-0.20336029 -0.19912593  0.1196173   1.        ]]. Action = [[-0.24208927 -0.6498789   0.00444114  0.484017  ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 669. State = [[-0.20943958 -0.21386255  0.13368464  1.        ]]. Action = [[-0.10128683 -0.09825265  0.9469192   0.76628685]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 670. State = [[-0.20297608 -0.2152202   0.15246285  1.        ]]. Action = [[ 0.85217714  0.05805564 -0.40404886  0.7344309 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 671. State = [[-0.19990928 -0.20290715  0.14426422  1.        ]]. Action = [[-0.24060285  0.72703266 -0.8503335   0.2653756 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 672. State = [[-0.20211254 -0.20259862  0.12149063  1.        ]]. Action = [[-0.11540878 -0.86241156 -0.9377945   0.46213174]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 673. State = [[-0.19725966 -0.2072579   0.08830018  1.        ]]. Action = [[ 0.72096443  0.42250776 -0.5998338   0.71153235]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 674. State = [[-0.17364523 -0.2132732   0.0649613   1.        ]]. Action = [[ 0.82979083 -0.67331845 -0.70993423  0.9001875 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 675. State = [[-0.15993546 -0.21517012  0.04732617  1.        ]]. Action = [[-0.6540867   0.72661424  0.29362047  0.80211663]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 676. State = [[-0.16203718 -0.21091609  0.04659348  1.        ]]. Action = [[-0.4437331   0.96485126 -0.78257674  0.6970569 ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 677. State = [[-0.16169159 -0.2098069   0.04648827  1.        ]]. Action = [[ 0.7867367  -0.145428   -0.7328586   0.90195835]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 678. State = [[-0.1614146  -0.20915452  0.04639371  1.        ]]. Action = [[-0.8129826   0.01870978 -0.6311583   0.5398946 ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 679. State = [[-0.1675527  -0.21315072  0.04533216  1.        ]]. Action = [[-0.4883911  -0.38166767 -0.07927471  0.8967831 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 680. State = [[-0.16801032 -0.22921509  0.05197309  1.        ]]. Action = [[ 0.63231754 -0.80314314  0.6659578   0.46734476]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 681. State = [[-0.16458319 -0.24034585  0.05916446  1.        ]]. Action = [[ 0.40231466 -0.06713414 -0.52955455  0.7568064 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 682. State = [[-0.16784172 -0.25098792  0.07130419  1.        ]]. Action = [[-0.52842814 -0.3364576   0.9782615   0.6837685 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 683. State = [[-0.17490819 -0.2475508   0.08684059  1.        ]]. Action = [[-0.11110002  0.91132724 -0.60017705  0.74578834]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 684. State = [[-0.17461793 -0.23566034  0.07822652  1.        ]]. Action = [[ 0.53972065 -0.20045978 -0.5840164   0.847075  ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 685. State = [[-0.1768564  -0.24508272  0.06449043  1.        ]]. Action = [[-0.34246707 -0.8994321  -0.38540804  0.6515535 ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 686. State = [[-0.18227303 -0.26196843  0.05498422  1.        ]]. Action = [[ 0.60247016  0.07369483 -0.8732731   0.8089224 ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 687. State = [[-0.1908745  -0.25898     0.04914501  1.        ]]. Action = [[-0.78107375  0.44421077 -0.46670675  0.4488052 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 688. State = [[-0.19021495 -0.25519338  0.04219851  1.        ]]. Action = [[0.7228401  0.06101859 0.6135762  0.8757248 ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 689. State = [[-0.17468534 -0.24150828  0.0529856   1.        ]]. Action = [[0.74232876 0.79256976 0.71848357 0.7252326 ]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 690. State = [[-0.1630059  -0.22483313  0.06793651  1.        ]]. Action = [[ 0.5499511  0.9842565 -0.7189371  0.6619165]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 691. State = [[-0.1535936  -0.23163174  0.08305867  1.        ]]. Action = [[ 0.4067061  -0.73711145  0.95627654  0.6261921 ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 692. State = [[-0.15261082 -0.24403563  0.10354312  1.        ]]. Action = [[-0.9234573   0.02308941 -0.00729281  0.842214  ]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 693. State = [[-0.17378385 -0.23542751  0.09959498  1.        ]]. Action = [[-0.89282364  0.94278073 -0.51415616  0.37712395]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 694. State = [[-0.19009437 -0.20632981  0.08491854  1.        ]]. Action = [[ 0.27672887  0.8875036  -0.8793088   0.11033642]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 695. State = [[-0.1990311  -0.17279354  0.06125422  1.        ]]. Action = [[-0.7302746   0.86362803 -0.7361088   0.39634633]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 696. State = [[-0.21501382 -0.15288083  0.04201159  1.        ]]. Action = [[ 0.8565326   0.4760306  -0.67167604  0.8654605 ]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 697. State = [[-0.20816068 -0.15256761  0.04186451  1.        ]]. Action = [[ 0.93726516 -0.25612104  0.33672976  0.30747783]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 698. State = [[-0.19391255 -0.16053577  0.0470896   1.        ]]. Action = [[ 0.2995925  -0.50142044  0.37208354  0.39538884]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 699. State = [[-0.18543848 -0.16043729  0.0602242   1.        ]]. Action = [[-0.25063378  0.4760692   0.71124697  0.7063489 ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 700. State = [[-0.18186803 -0.15856442  0.0743787   1.        ]]. Action = [[ 0.76841736  0.7438047  -0.07242167  0.62908435]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: No entry zone
Current timestep = 701. State = [[-0.18340202 -0.1423631   0.06897189  1.        ]]. Action = [[ 0.02723897  0.99637425 -0.803756    0.7922895 ]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 702. State = [[-0.18688948 -0.12239992  0.06408695  1.        ]]. Action = [[ 0.96091413 -0.12296259  0.5909183   0.7745197 ]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: No entry zone
Current timestep = 703. State = [[-0.187432   -0.11988138  0.06345886  1.        ]]. Action = [[ 0.7952455  -0.8927994   0.96431756  0.7012408 ]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: No entry zone
Current timestep = 704. State = [[-0.19274361 -0.11854377  0.05791663  1.        ]]. Action = [[-0.5153356   0.03438234 -0.3480307   0.29773593]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 705. State = [[-0.19611113 -0.10829283  0.05872846  1.        ]]. Action = [[0.07923257 0.63549066 0.9568994  0.9096613 ]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 706. State = [[-0.19582276 -0.09370387  0.06841245  1.        ]]. Action = [[ 0.8798864   0.42312038 -0.87113917  0.83125496]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 707. State = [[-0.1958161  -0.09248378  0.06866343  1.        ]]. Action = [[ 0.7443054   0.07360423 -0.8023403   0.51422584]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: No entry zone
Current timestep = 708. State = [[-0.19876133 -0.10666189  0.0721045   1.        ]]. Action = [[-0.23229289 -0.9160888   0.2887113   0.6985302 ]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 709. State = [[-0.19944239 -0.10787351  0.07833377  1.        ]]. Action = [[ 0.57578135  0.8093915  -0.3439139   0.7358148 ]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 710. State = [[-0.20043398 -0.10491233  0.07169989  1.        ]]. Action = [[-0.3812269 -0.5477981 -0.7157014  0.0879519]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 711. State = [[-0.21481536 -0.12352641  0.05690836  1.        ]]. Action = [[-0.940912  -0.8763573 -0.1356923  0.7518921]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 712. State = [[-0.21507318 -0.14838645  0.05261849  1.        ]]. Action = [[ 0.9598354  -0.46599638  0.19275296  0.51068294]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 713. State = [[-0.20974956 -0.15880175  0.0536382   1.        ]]. Action = [[-0.87546676  0.31518602 -0.7853773   0.42609358]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 714. State = [[-0.19873291 -0.1485822   0.05208072  1.        ]]. Action = [[ 0.78642464  0.7850845  -0.3140155   0.95621467]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 715. State = [[-0.18557957 -0.13700834  0.05035926  1.        ]]. Action = [[ 0.26564395 -0.6704128  -0.5128283   0.80285585]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 716. State = [[-0.17916894 -0.13558017  0.05600534  1.        ]]. Action = [[0.22775912 0.03167832 0.7961893  0.8447639 ]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 717. State = [[-0.17402178 -0.1358526   0.0633366   1.        ]]. Action = [[ 0.69801927 -0.63899     0.8521774   0.7020534 ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: No entry zone
Current timestep = 718. State = [[-0.17324828 -0.13596548  0.06454346  1.        ]]. Action = [[ 0.17148328  0.06709766 -0.9170531   0.7644391 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 719. State = [[-0.1743301  -0.13321987  0.06740298  1.        ]]. Action = [[-0.41046947  0.21427763  0.31233943  0.6128452 ]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 720. State = [[-0.18542834 -0.13150248  0.0705439   1.        ]]. Action = [[-0.9551751  -0.0089559  -0.04348308  0.37963367]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 721. State = [[-0.20312662 -0.13039671  0.0716567   1.        ]]. Action = [[ 0.94307446  0.14388704 -0.69770473  0.6849835 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: No entry zone
Current timestep = 722. State = [[-0.20884229 -0.11648347  0.06748088  1.        ]]. Action = [[-0.32931042  0.961354   -0.5892166   0.13963342]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 723. State = [[-0.2094888  -0.10781688  0.06085977  1.        ]]. Action = [[ 0.6777878  -0.7998723  -0.34628236  0.7952919 ]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 724. State = [[-0.20735882 -0.11296953  0.05494728  1.        ]]. Action = [[ 0.8880842  -0.6842486  -0.00327104  0.90445495]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: No entry zone
Current timestep = 725. State = [[-0.2068723  -0.1133027   0.05487566  1.        ]]. Action = [[ 0.948341   -0.07912612  0.6194986   0.76879   ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: No entry zone
Current timestep = 726. State = [[-0.21598904 -0.11752157  0.05744467  1.        ]]. Action = [[-0.994443   -0.00758845  0.581689    0.815536  ]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 727. State = [[-0.2371903  -0.12567765  0.05746924  1.        ]]. Action = [[-0.6413759  -0.3646772  -0.30682528  0.51105523]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 728. State = [[-0.24972703 -0.13722718  0.06333833  1.        ]]. Action = [[ 0.1214906  -0.38245475  0.7712562   0.64065886]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 729. State = [[-0.24782713 -0.15837765  0.08266972  1.        ]]. Action = [[ 0.62006545 -0.903457    0.5220101   0.85405195]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 730. State = [[-0.24354239 -0.17456487  0.09408353  1.        ]]. Action = [[-0.54541415  0.82464087 -0.5138451   0.7574158 ]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 731. State = [[-0.2320257  -0.1654408   0.08748847  1.        ]]. Action = [[ 0.97564757  0.78993475 -0.9594434   0.8315275 ]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 732. State = [[-0.21678159 -0.14863393  0.0769389   1.        ]]. Action = [[-0.28985846  0.42336905  0.3973912   0.81439614]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 733. State = [[-0.22461413 -0.15321767  0.07978756  1.        ]]. Action = [[-0.7993326  -0.7783536   0.35107195  0.73493874]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 734. State = [[-0.23853435 -0.17441235  0.08579811  1.        ]]. Action = [[-0.40938252 -0.6727381  -0.05849165  0.6404152 ]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 735. State = [[-0.24983853 -0.2019627   0.09491146  1.        ]]. Action = [[-0.1506322  -0.84637755  0.68117476  0.77795887]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 736. State = [[-0.25815028 -0.23597719  0.12207931  1.        ]]. Action = [[-0.28816915 -0.84168285  0.94318175  0.7333288 ]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 737. State = [[-0.26572266 -0.25592902  0.13891292  1.        ]]. Action = [[ 5.1045418e-04 -4.2381227e-02 -7.5731057e-01  7.1036637e-01]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 738. State = [[-0.268806   -0.26024276  0.13567524  1.        ]]. Action = [[-0.55807    -0.48038238 -0.05094308  0.6954491 ]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 739. State = [[-0.268064   -0.26787674  0.13027763  1.        ]]. Action = [[ 0.3570645  -0.5976187  -0.51594394  0.68133855]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 740. State = [[-0.26462862 -0.27983302  0.12070306  1.        ]]. Action = [[-0.92657465 -0.8714363  -0.03881627  0.87472534]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 741. State = [[-0.25391454 -0.28667355  0.12632371  1.        ]]. Action = [[ 0.65676844 -0.3358339   0.83455706  0.68467   ]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 742. State = [[-0.22999658 -0.29174992  0.12415341  1.        ]]. Action = [[ 0.9184716  -0.05394191 -0.9170257   0.846179  ]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 743. State = [[-0.20770699 -0.28711253  0.11414017  1.        ]]. Action = [[0.29166782 0.51392436 0.1569699  0.6501168 ]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 744. State = [[-0.1981149  -0.27242315  0.11213403  1.        ]]. Action = [[ 0.19100106  0.43108582 -0.02233237  0.59197116]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 745. State = [[-0.19457634 -0.2717785   0.1041588   1.        ]]. Action = [[ 0.02996707 -0.5986871  -0.89163345  0.72300315]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 746. State = [[-0.18255383 -0.28627998  0.09596031  1.        ]]. Action = [[ 0.28686118 -0.43037856  0.8108846   0.62173486]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 747. State = [[-0.17973857 -0.30003494  0.11267203  1.        ]]. Action = [[-0.5394825  -0.11405313  0.9064543   0.43010676]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 748. State = [[-0.18399622 -0.3075962   0.13193214  1.        ]]. Action = [[ 0.8628615  -0.3200755   0.29617047  0.7160264 ]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 749. State = [[-0.18794876 -0.30056402  0.14200352  1.        ]]. Action = [[-0.33784074  0.718724    0.5658523   0.5462408 ]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 750. State = [[-0.20003574 -0.27625182  0.14643407  1.        ]]. Action = [[-0.23108208  0.8380482  -0.8313294   0.7388575 ]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 751. State = [[-0.20323181 -0.26355526  0.13179061  1.        ]]. Action = [[ 0.55551016 -0.55416894 -0.9970827   0.66550434]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 752. State = [[-0.19904076 -0.26344135  0.11342801  1.        ]]. Action = [[-0.3095262   0.32704973  0.61202574  0.4812492 ]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 753. State = [[-0.19506058 -0.25113347  0.11054721  1.        ]]. Action = [[ 0.24163604  0.66037536 -0.5040315   0.6289027 ]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 754. State = [[-0.194922   -0.22842309  0.09941019  1.        ]]. Action = [[-0.1022414   0.66833043 -0.8934604   0.87780535]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 755. State = [[-0.20083107 -0.20828457  0.07396389  1.        ]]. Action = [[-0.5097344   0.44654846 -0.07872182  0.49858212]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 756. State = [[-0.19958201 -0.19383077  0.06888063  1.        ]]. Action = [[0.73065424 0.1565069  0.19609201 0.78787994]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 757. State = [[-0.19626    -0.1851643   0.06963447  1.        ]]. Action = [[-0.23711628  0.0910995   0.177266    0.7641792 ]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 758. State = [[-0.19821106 -0.17180914  0.06842362  1.        ]]. Action = [[-0.18042725  0.8162582  -0.24450207  0.8058977 ]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 759. State = [[-0.20758946 -0.1590244   0.06065833  1.        ]]. Action = [[-0.68149483 -0.31903505 -0.7619233   0.5303099 ]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 760. State = [[-0.23423614 -0.17061503  0.03898213  1.        ]]. Action = [[-0.86787176 -0.7107601  -0.34005517  0.77497184]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 761. State = [[-0.2536225   0.13045946  0.12583472  1.        ]]. Action = [[-0.85477656  0.95381236  0.44663596  0.5944054 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 762. State = [[-0.23911528  0.13443111  0.11458579  1.        ]]. Action = [[ 0.6975286  -0.7264272   0.45423186  0.92133117]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 763. State = [[-0.21500191  0.1205387   0.12212053  1.        ]]. Action = [[ 0.89009523 -0.2240395   0.19269514  0.8300791 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 764. State = [[-0.19406338  0.10385133  0.12320962  1.        ]]. Action = [[ 0.29139388 -0.6993612  -0.49396348  0.87552536]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 765. State = [[-0.18782948  0.08442199  0.11255646  1.        ]]. Action = [[-0.561597   -0.51015455 -0.12165767  0.16642797]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 766. State = [[-0.1923542   0.06074444  0.10331257  1.        ]]. Action = [[ 0.05292404 -0.84304315 -0.9682913   0.7929301 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 767. State = [[-0.19154218  0.02750793  0.07630291  1.        ]]. Action = [[-0.12066734 -0.93096346 -0.21126544  0.81625724]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 768. State = [[-0.19085589  0.01658791  0.05839331  1.        ]]. Action = [[ 0.30072927  0.62522316 -0.8668967   0.7458106 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 769. State = [[-0.19184677  0.01965203  0.03744612  1.        ]]. Action = [[ 0.4394629   0.45428777 -0.85752106  0.61238277]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: Workspace boundary
Current timestep = 770. State = [[-0.19860667  0.00718233  0.04002838  1.        ]]. Action = [[-0.9315672  -0.9100452   0.7002933   0.87879705]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 771. State = [[-0.19897583 -0.01413201  0.05808486  1.        ]]. Action = [[ 0.50144005 -0.49974263  0.9804282   0.79330397]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 772. State = [[-0.19200046 -0.02488824  0.07859906  1.        ]]. Action = [[ 0.10297358 -0.79277474 -0.8439042   0.66843295]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: Workspace boundary
Current timestep = 773. State = [[-0.20063654 -0.03470274  0.08850012  1.        ]]. Action = [[-0.83658534 -0.4326825   0.6812377   0.8023453 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 774. State = [[-0.21983533 -0.05707417  0.10660261  1.        ]]. Action = [[ 0.11031771 -0.8656327   0.05117047  0.6559193 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 775. State = [[-0.22520569 -0.07938567  0.1058158   1.        ]]. Action = [[-0.17053914 -0.07631993 -0.6745233   0.54384065]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 776. State = [[-0.23249975 -0.08362602  0.10624541  1.        ]]. Action = [[-0.60900575  0.14807057  0.87846136  0.54723334]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 777. State = [[-0.2469885  -0.08131711  0.11824592  1.        ]]. Action = [[-0.86393595  0.6746104  -0.1195178   0.3629501 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 778. State = [[-0.2403556  -0.09527716  0.12894817  1.        ]]. Action = [[ 0.7808963  -0.9791348   0.73788786  0.618963  ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 779. State = [[-0.23863769 -0.11232688  0.13861865  1.        ]]. Action = [[-0.58189213  0.13644814 -0.5403047   0.82983947]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 780. State = [[-0.25116366 -0.1099744   0.1303355   1.        ]]. Action = [[-0.5632283   0.22725737 -0.5883185   0.844085  ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 781. State = [[-0.25499883 -0.11068509  0.11973234  1.        ]]. Action = [[ 0.9019531  -0.30493867 -0.21954703  0.8251648 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 782. State = [[-0.24268177 -0.1277086   0.12074401  1.        ]]. Action = [[ 0.00565279 -0.77924174  0.9898834   0.26507616]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 783. State = [[-0.24113992 -0.15821773  0.12900205  1.        ]]. Action = [[-0.33229113 -0.92156875 -0.38228327  0.6827668 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 784. State = [[-0.23614472 -0.17407466  0.12577948  1.        ]]. Action = [[ 0.89233744  0.2432487  -0.26624435  0.89348114]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 785. State = [[-0.22852334 -0.18126395  0.12655196  1.        ]]. Action = [[-0.5101334  -0.47437716  0.61891484  0.84762526]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 786. State = [[-0.23006311 -0.1855791   0.13900869  1.        ]]. Action = [[-0.17847097  0.38928723  0.66885674  0.74497616]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 787. State = [[-0.23627463 -0.17567237  0.15303165  1.        ]]. Action = [[-0.18458462  0.5427873  -0.08052671  0.37847555]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 788. State = [[-0.23127668 -0.15180409  0.15720175  1.        ]]. Action = [[0.94797695 0.81850135 0.3409747  0.8325887 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 789. State = [[-0.22303662 -0.14054954  0.1735998   1.        ]]. Action = [[-0.35617185 -0.4151104   0.78222346  0.65276647]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 790. State = [[-0.21431299 -0.14310957  0.19479895  1.        ]]. Action = [[ 0.82684267 -0.07207239 -0.06247538  0.81017184]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 791. State = [[-0.20298484 -0.12977825  0.19137864  1.        ]]. Action = [[ 0.16598046  0.9620061  -0.83869714  0.5932224 ]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 792. State = [[-0.20454362 -0.12237727  0.17822415  1.        ]]. Action = [[-0.90363157 -0.4486971  -0.02379686  0.43693256]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 793. State = [[-0.21750648 -0.11666448  0.1687341   1.        ]]. Action = [[-0.15537953  0.66483784 -0.58102864  0.3506217 ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 794. State = [[-0.22063152 -0.10631195  0.15574932  1.        ]]. Action = [[ 0.27960813  0.11051929 -0.19953322  0.6962879 ]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 795. State = [[-0.21957518 -0.08865438  0.15129894  1.        ]]. Action = [[-0.15164834  0.8092346   0.43101668  0.6516496 ]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 796. State = [[-0.21560477 -0.0615485   0.14878799  1.        ]]. Action = [[ 0.61807823  0.5527692  -0.5037726   0.38278222]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 797. State = [[-0.21175745 -0.04817544  0.14433111  1.        ]]. Action = [[-0.3900249   0.09790969  0.01545751  0.70930696]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 798. State = [[-0.20535438 -0.03639494  0.14649795  1.        ]]. Action = [[0.69986403 0.41711533 0.16717935 0.2182926 ]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 799. State = [[-0.18850838 -0.03008106  0.15433282  1.        ]]. Action = [[ 0.56342816 -0.15008843  0.60722184  0.91033673]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 800. State = [[-0.17930222 -0.01532598  0.1553542   1.        ]]. Action = [[-0.13652223  0.96826434 -0.6300164   0.71953654]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 801. State = [[-0.17893283  0.01812097  0.15316622  1.        ]]. Action = [[0.00486732 0.9393878  0.48149276 0.48467684]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 802. State = [[-0.17986412  0.04023385  0.15654917  1.        ]]. Action = [[0.96561944 0.06313908 0.48948634 0.8171065 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: No entry zone
Current timestep = 803. State = [[-0.18013135  0.04296103  0.1569085   1.        ]]. Action = [[ 0.46938324 -0.9148849  -0.34489197  0.7583823 ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: No entry zone
Current timestep = 804. State = [[-0.18091622  0.03365247  0.1522725   1.        ]]. Action = [[-0.2590332  -0.68728775 -0.5804648   0.69647527]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 805. State = [[-0.18374449  0.02410191  0.14671217  1.        ]]. Action = [[ 0.3232355   0.35126388 -0.20096087  0.49790895]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: No entry zone
Current timestep = 806. State = [[-0.18373063  0.02348229  0.14672613  1.        ]]. Action = [[ 0.61924267 -0.05447203 -0.6930441   0.8427496 ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: No entry zone
Current timestep = 807. State = [[-0.18363403  0.02329335  0.14678985  1.        ]]. Action = [[ 0.98447096  0.17969227 -0.9744197   0.22927558]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: No entry zone
Current timestep = 808. State = [[-0.18370429  0.02322073  0.14677012  1.        ]]. Action = [[0.546844   0.06323612 0.6779616  0.49784613]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: No entry zone
Current timestep = 809. State = [[-0.18370429  0.02322073  0.14677012  1.        ]]. Action = [[ 0.35865355 -0.16486007 -0.5807302   0.34694552]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: No entry zone
Current timestep = 810. State = [[-0.1848931   0.01712934  0.14334781  1.        ]]. Action = [[-0.13277191 -0.3557974  -0.2937184   0.66115415]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 811. State = [[-0.18424405  0.0211716   0.141876    1.        ]]. Action = [[0.2975453  0.72515607 0.55541277 0.7365078 ]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 812. State = [[-0.18064377  0.03018342  0.1448021   1.        ]]. Action = [[ 0.36281967 -0.19341117  0.7000866   0.5740726 ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: No entry zone
Current timestep = 813. State = [[-0.18374367  0.02157567  0.15675679  1.        ]]. Action = [[-0.7044556  -0.6373155   0.93285847  0.7507613 ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 814. State = [[-0.19952439  0.01964268  0.16895618  1.        ]]. Action = [[-0.47395706  0.4808439  -0.6674238   0.58534646]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 815. State = [[-0.21120434  0.01277842  0.17230786  1.        ]]. Action = [[-0.2882117  -0.8445002   0.7637608   0.64911366]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 816. State = [[-0.228218   -0.01544333  0.17951006  1.        ]]. Action = [[-0.5395403  -0.92910767 -0.49222577  0.76688504]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 817. State = [[-0.23839611 -0.0460288   0.18038112  1.        ]]. Action = [[ 0.10358274 -0.8763105   0.12393403  0.69721746]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 818. State = [[-0.23464385 -0.07882398  0.18344775  1.        ]]. Action = [[ 0.26928818 -0.7333026  -0.01124424  0.7956755 ]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 819. State = [[-0.23080277 -0.08916372  0.18241352  1.        ]]. Action = [[ 0.11045086  0.5622275  -0.1537016   0.63622594]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 820. State = [[-0.23927967 -0.08159076  0.1702435   1.        ]]. Action = [[-0.6468665   0.22447717 -0.85141325  0.88344383]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 821. State = [[-0.25180084 -0.0678601   0.14857712  1.        ]]. Action = [[-0.40659273  0.55953085 -0.1908474   0.74456024]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 822. State = [[-0.25542736 -0.05902253  0.14831021  1.        ]]. Action = [[ 0.63600445 -0.20073837  0.88812304  0.69928885]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 823. State = [[-0.24868788 -0.07227912  0.15674245  1.        ]]. Action = [[ 0.18151355 -0.8816468  -0.11305678  0.5394001 ]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 824. State = [[-0.23798056 -0.08019202  0.1545389   1.        ]]. Action = [[ 0.74612427  0.45608783 -0.4416896   0.8766459 ]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 825. State = [[-0.22432725 -0.07323272  0.14416268  1.        ]]. Action = [[ 0.12078702  0.08435369 -0.4014094   0.8128228 ]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 826. State = [[-0.21792321 -0.07203636  0.13560748  1.        ]]. Action = [[-0.96113306 -0.5383621  -0.81572753  0.66708255]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 827. State = [[-0.20712174 -0.06396242  0.13032003  1.        ]]. Action = [[ 0.91273713  0.37080777 -0.8615947   0.48191535]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 828. State = [[-0.19164416 -0.05582006  0.11333478  1.        ]]. Action = [[-0.5967493   0.15593326  0.71289897  0.8463342 ]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 829. State = [[-0.19264185 -0.05421245  0.1146418   1.        ]]. Action = [[0.58577824 0.41256332 0.81031597 0.8829732 ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: No entry zone
Current timestep = 830. State = [[-0.19288857 -0.05383855  0.11458863  1.        ]]. Action = [[0.9496639  0.20245636 0.27810097 0.6760688 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: No entry zone
Current timestep = 831. State = [[-0.203481   -0.04979683  0.10659643  1.        ]]. Action = [[-0.7818537   0.3070321  -0.88895684  0.60892725]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 832. State = [[-0.20962319 -0.05016189  0.10325129  1.        ]]. Action = [[ 0.66428757 -0.41873592  0.84052086  0.7673466 ]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 833. State = [[-0.20626095 -0.05299746  0.10956912  1.        ]]. Action = [[0.9428257  0.6917789  0.73278844 0.7004367 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: No entry zone
Current timestep = 834. State = [[-0.20239139 -0.05246212  0.1113743   1.        ]]. Action = [[0.25908864 0.16221571 0.12266982 0.8316959 ]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 835. State = [[-0.19701588 -0.05324893  0.10755148  1.        ]]. Action = [[ 0.17898452 -0.1578821  -0.733875    0.6321802 ]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 836. State = [[-0.1927032  -0.04663683  0.10069349  1.        ]]. Action = [[ 0.0971384   0.49379182 -0.14415997  0.6169293 ]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 837. State = [[-0.19181821 -0.03830868  0.0992009   1.        ]]. Action = [[ 0.64096    -0.51906663 -0.03787577  0.86662436]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: No entry zone
Current timestep = 838. State = [[-0.18547605 -0.04732652  0.10222085  1.        ]]. Action = [[ 0.35731125 -0.7554462   0.5108323   0.62597907]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 839. State = [[-0.18249576 -0.05204991  0.11316364  1.        ]]. Action = [[-0.77274066  0.48460078  0.7544894   0.82706165]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 840. State = [[-0.18879376 -0.04856635  0.1275275   1.        ]]. Action = [[0.59770036 0.7286842  0.1790297  0.8460208 ]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: No entry zone
Current timestep = 841. State = [[-0.18821974 -0.04825703  0.1303835   1.        ]]. Action = [[ 0.8323171  -0.22823668 -0.9582144   0.31880546]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: No entry zone
Current timestep = 842. State = [[-0.19707918 -0.05444038  0.1366025   1.        ]]. Action = [[-0.7130834  -0.3665213   0.46736896  0.6413497 ]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 843. State = [[-0.2224131 -0.0479482  0.1557421  1.       ]]. Action = [[-0.7354526   0.82691     0.74118066  0.41974878]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 844. State = [[-0.25079426 -0.04673281  0.18488884  1.        ]]. Action = [[-0.84703845 -0.7094444   0.8844526   0.43352175]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 845. State = [[-0.26917198 -0.04440808  0.20878446  1.        ]]. Action = [[0.40911222 0.60637486 0.08773363 0.73560834]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 846. State = [[-0.26957443 -0.03497242  0.21159147  1.        ]]. Action = [[ 0.23899436  0.12233472 -0.320171    0.6316304 ]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 847. State = [[-0.2559501  -0.04292157  0.20722277  1.        ]]. Action = [[ 0.9851332 -0.8084815 -0.6282915  0.3092208]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 848. State = [[-0.2336916  -0.05475064  0.19365852  1.        ]]. Action = [[-0.32383537 -0.30088615  0.69501114  0.622188  ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 849. State = [[-0.21792479 -0.05351108  0.19483724  1.        ]]. Action = [[0.94456315 0.24722219 0.00255048 0.71234226]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 850. State = [[-0.19330749 -0.03896954  0.19215176  1.        ]]. Action = [[0.4192047  0.78567886 0.10572016 0.4386915 ]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 851. State = [[-0.18603685 -0.02553319  0.20324615  1.        ]]. Action = [[-0.42055064 -0.05872673  0.8983711   0.7559011 ]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 852. State = [[-0.18537447 -0.0101567   0.216001    1.        ]]. Action = [[0.18716288 0.7994118  0.06919849 0.3504057 ]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 853. State = [[-1.8120936e-01  8.9557446e-04  2.3066719e-01  1.0000000e+00]]. Action = [[ 0.030303   -0.2538221   0.7215214   0.29249096]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 854. State = [[-1.774726e-01 -7.353531e-04  2.452785e-01  1.000000e+00]]. Action = [[ 0.47386932 -0.23454028 -0.9678082   0.15614629]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: No entry zone
Current timestep = 855. State = [[-0.1754439 -0.0011841  0.2485918  1.       ]]. Action = [[ 0.42854393 -0.8350747  -0.6397882   0.5315325 ]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: No entry zone
Current timestep = 856. State = [[-0.16880426  0.00937557  0.24989766  1.        ]]. Action = [[ 0.6674206   0.67406523 -0.12033516  0.5998429 ]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 857. State = [[-0.155408    0.01461988  0.2566492   1.        ]]. Action = [[ 0.3172226  -0.42739475  0.17437756  0.68787503]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 858. State = [[-0.1481177   0.02411178  0.2651833   1.        ]]. Action = [[-0.09410805  0.773515    0.5297787   0.5652274 ]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 859. State = [[-0.14093731  0.04224546  0.2722138   1.        ]]. Action = [[ 0.3591758   0.43926883 -0.2945032   0.91521955]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 860. State = [[-0.14215428  0.03487508  0.26997858  1.        ]]. Action = [[-0.9093653  -0.9721943   0.04836023  0.7860856 ]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 861. State = [[-0.1514962   0.02211941  0.26449206  1.        ]]. Action = [[-0.02145755 -0.08066612 -0.6891852   0.8447943 ]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 862. State = [[-0.1580279   0.02441742  0.26261982  1.        ]]. Action = [[-0.25040978  0.3445176   0.50064707  0.5965748 ]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 863. State = [[-0.26176667 -0.01539783  0.10981362  1.        ]]. Action = [[-0.6360767 -0.3752842  0.4190507  0.8098545]]. Reward = [0.]
Curr episode timestep = 101
Current timestep = 864. State = [[-0.26071167 -0.01211197  0.09854362  1.        ]]. Action = [[0.22564745 0.6220763  0.30084372 0.6564604 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 865. State = [[-0.25560886  0.00595796  0.1001095   1.        ]]. Action = [[0.18414533 0.7064066  0.12393582 0.68005204]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 866. State = [[-0.2423125   0.01022869  0.0959335   1.        ]]. Action = [[ 0.78608406 -0.8548703  -0.85690683  0.6784785 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 867. State = [[-0.22344773  0.00451566  0.08591143  1.        ]]. Action = [[0.07801545 0.3923465  0.7415056  0.6182976 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 868. State = [[-0.22226866  0.01598472  0.10145413  1.        ]]. Action = [[-0.65556735  0.6406882   0.97568035  0.8263533 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 869. State = [[-0.2362425   0.04368317  0.11543163  1.        ]]. Action = [[-0.41907895  0.76033187 -0.97328967  0.35385442]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 870. State = [[-0.24772511  0.05488039  0.10047839  1.        ]]. Action = [[ 0.1357553  -0.2770118  -0.6496407   0.58157563]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 871. State = [[-0.24953078  0.05369373  0.08443186  1.        ]]. Action = [[-0.8847167  -0.5042767  -0.01457733  0.77498126]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: Workspace boundary
Current timestep = 872. State = [[-0.2428645   0.05511878  0.09151432  1.        ]]. Action = [[0.37564492 0.1294254  0.9070678  0.6093806 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 873. State = [[-0.23785758  0.05616606  0.0990224   1.        ]]. Action = [[-0.5831951   0.49392235  0.445881    0.703141  ]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: Workspace boundary
Current timestep = 874. State = [[-0.23039195  0.052013    0.0947044   1.        ]]. Action = [[ 0.59068894 -0.33360702 -0.73716235  0.5598388 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 875. State = [[-0.20847186  0.05503152  0.08417883  1.        ]]. Action = [[ 0.84590435  0.48722458 -0.3320219   0.4569528 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 876. State = [[-0.19831027  0.06754673  0.06638917  1.        ]]. Action = [[-0.29268456  0.44538772 -0.8862689   0.69241   ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 877. State = [[-0.19582757  0.07575349  0.04569242  1.        ]]. Action = [[ 0.6665449  -0.70830745  0.22807729  0.65617156]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: No entry zone
Current timestep = 878. State = [[-0.1925526   0.0767845   0.04535662  1.        ]]. Action = [[ 0.12487495 -0.17284375  0.42942786  0.5106107 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 879. State = [[-0.18917091  0.07654063  0.04647636  1.        ]]. Action = [[ 0.5475763   0.3544581  -0.37447578  0.6207979 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 880. State = [[-0.18438755  0.06688938  0.051899    1.        ]]. Action = [[ 0.13791144 -0.5499597   0.48520255  0.8521867 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 881. State = [[-0.17844777  0.05563191  0.06882027  1.        ]]. Action = [[-0.10666955 -0.11961609  0.6540587   0.7687888 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 882. State = [[-0.18432991  0.05170828  0.0768197   1.        ]]. Action = [[-0.58178234  0.00783205 -0.7430265   0.6887193 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 883. State = [[-0.20299569  0.04864978  0.07948032  1.        ]]. Action = [[-0.8629332  -0.16306919  0.8495498   0.78812003]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 884. State = [[-0.21363376  0.05633732  0.09977072  1.        ]]. Action = [[0.68714106 0.72221255 0.6307268  0.49935913]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 885. State = [[-0.21851866  0.05382307  0.11789561  1.        ]]. Action = [[-0.9170846  -0.93597364  0.49122977  0.7012975 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 886. State = [[-0.2313029   0.03944979  0.14276873  1.        ]]. Action = [[-0.04800743 -0.01665902  0.82469785  0.7734096 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 887. State = [[-0.23188972  0.02936367  0.17069937  1.        ]]. Action = [[ 0.13714409 -0.5541151   0.58847547  0.42666936]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 888. State = [[-0.22324482  0.02387248  0.19331238  1.        ]]. Action = [[0.8075981  0.3760438  0.45739663 0.7817254 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 889. State = [[-0.2092526   0.01918006  0.21036878  1.        ]]. Action = [[ 0.1216464 -0.4954158  0.4900987  0.7118299]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 890. State = [[-0.20654272  0.01630441  0.23522177  1.        ]]. Action = [[-0.17711186  0.21005404  0.890453    0.819626  ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 891. State = [[-0.19970152  0.0095558   0.26735875  1.        ]]. Action = [[ 0.694376   -0.50465846  0.70495987  0.6795242 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 892. State = [[-0.18528844  0.00141848  0.28830191  1.        ]]. Action = [[ 0.9288075  -0.85368556 -0.9168562   0.6826277 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: No entry zone
Current timestep = 893. State = [[-0.1791788   0.00622642  0.29970375  1.        ]]. Action = [[0.17488647 0.38177335 0.6207788  0.82425   ]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 894. State = [[-0.1762608   0.00806221  0.30650106  1.        ]]. Action = [[-0.4212258  -0.2993511  -0.7376142   0.81242895]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 895. State = [[-0.1776682   0.00551455  0.29215923  1.        ]]. Action = [[ 0.62867117  0.1087817  -0.97375476  0.7534548 ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 896. State = [[-0.16025516  0.0010687   0.2753076   1.        ]]. Action = [[ 0.8828522  -0.34583658  0.48689592  0.51614165]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 897. State = [[-0.1372861   0.00887917  0.27178523  1.        ]]. Action = [[ 0.55298984  0.87749934 -0.47493666  0.8167412 ]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 898. State = [[-0.1155089   0.02111446  0.25642455  1.        ]]. Action = [[ 0.48170328 -0.01370758 -0.42113996  0.7754705 ]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 899. State = [[-0.10223842  0.02324207  0.24705045  1.        ]]. Action = [[-0.8260792 -0.6641291 -0.756809   0.5675614]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: No entry zone
Current timestep = 900. State = [[-0.10219499  0.0235832   0.2467001   1.        ]]. Action = [[-0.1754443  -0.07758677 -0.48234558  0.6710392 ]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: No entry zone
Current timestep = 901. State = [[-0.10219993  0.02378953  0.24660675  1.        ]]. Action = [[ 0.8206785  -0.54057676 -0.9091315   0.79787016]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: No entry zone
Current timestep = 902. State = [[-0.10219873  0.02385888  0.24659416  1.        ]]. Action = [[ 0.06773877  0.5553868  -0.22804326  0.70907795]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: No entry zone
Current timestep = 903. State = [[-0.10219754  0.02392823  0.24658155  1.        ]]. Action = [[-0.8328991  -0.85644805 -0.43723643  0.04105508]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: No entry zone
Current timestep = 904. State = [[-0.08911793  0.01075541  0.25199035  1.        ]]. Action = [[ 0.9064393  -0.8811003   0.29549623  0.269104  ]]. Reward = [0.]
Curr episode timestep = 40
Above hoop
Scene graph at timestep 904 is [False, True, False, False, True, False, True, False, False, True]
State prediction error at timestep 904 is tensor(0.0018, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 904 of 1
Current timestep = 905. State = [[-0.05612255  0.00412979  0.2677214   1.        ]]. Action = [[0.94311357 0.70172524 0.73849833 0.6669016 ]]. Reward = [0.]
Curr episode timestep = 41
Above hoop
Scene graph at timestep 905 is [False, True, False, False, True, False, True, False, False, True]
State prediction error at timestep 905 is tensor(0.0022, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 905 of -1
Current timestep = 906. State = [[-0.02788183  0.02842047  0.27899128  1.        ]]. Action = [[ 0.5623746   0.71791446 -0.8326338   0.6989305 ]]. Reward = [0.]
Curr episode timestep = 42
Above hoop
Scene graph at timestep 906 is [False, True, False, False, True, False, True, False, False, True]
State prediction error at timestep 906 is tensor(0.0026, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 906 of -1
Current timestep = 907. State = [[6.8081147e-04 5.6667808e-02 2.5820804e-01 1.0000000e+00]]. Action = [[0.17239809 0.84564173 0.51449466 0.702718  ]]. Reward = [0.]
Curr episode timestep = 43
Above hoop
Scene graph at timestep 907 is [False, True, False, False, True, False, True, False, False, True]
State prediction error at timestep 907 is tensor(0.0014, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 907 of -1
Current timestep = 908. State = [[0.00293963 0.06226239 0.27386856 1.        ]]. Action = [[-0.47576767 -0.8971575   0.14693642  0.92656493]]. Reward = [0.]
Curr episode timestep = 44
Above hoop
Scene graph at timestep 908 is [False, True, False, False, True, False, True, False, False, True]
State prediction error at timestep 908 is tensor(0.0002, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 908 of -1
Current timestep = 909. State = [[-0.00675614  0.03970473  0.26986513  1.        ]]. Action = [[-0.93143785 -0.4929793  -0.6617236   0.5719838 ]]. Reward = [0.]
Curr episode timestep = 45
Above hoop
Scene graph at timestep 909 is [False, True, False, False, True, False, True, False, False, True]
State prediction error at timestep 909 is tensor(0.0003, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 909 of 0
Current timestep = 910. State = [[-0.0151269   0.02219657  0.26752365  1.        ]]. Action = [[ 0.79969406 -0.3500796   0.8237469   0.59325147]]. Reward = [0.]
Curr episode timestep = 46
Above hoop
Scene graph at timestep 910 is [False, True, False, False, True, False, True, False, False, True]
State prediction error at timestep 910 is tensor(0.0004, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 910 of 0
Current timestep = 911. State = [[-0.00803078  0.00855735  0.27543613  1.        ]]. Action = [[-0.0997836  -0.3883952  -0.5997505   0.77339506]]. Reward = [0.]
Curr episode timestep = 47
Above hoop
Scene graph at timestep 911 is [False, True, False, False, True, False, True, False, False, True]
State prediction error at timestep 911 is tensor(0.0003, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 911 of 0
Current timestep = 912. State = [[-0.00521242 -0.01186004  0.27817243  1.        ]]. Action = [[ 0.51131535 -0.8372093   0.32434618  0.677901  ]]. Reward = [0.]
Curr episode timestep = 48
Above hoop
Current timestep = 913. State = [[-0.00260306 -0.01987589  0.27488244  1.        ]]. Action = [[-0.10816193  0.65477514 -0.44604826  0.7979697 ]]. Reward = [0.]
Curr episode timestep = 49
Above hoop
Current timestep = 914. State = [[ 0.00263722 -0.00342565  0.26379582  1.        ]]. Action = [[ 0.66019154  0.624588   -0.1705572   0.8774451 ]]. Reward = [0.]
Curr episode timestep = 50
Above hoop
Current timestep = 915. State = [[0.01856164 0.00381944 0.26308876 1.        ]]. Action = [[-0.03684568 -0.25486737  0.66248095  0.6628691 ]]. Reward = [0.]
Curr episode timestep = 51
Above hoop
Current timestep = 916. State = [[ 2.1079978e-02 -7.5865589e-04  2.7773732e-01  1.0000000e+00]]. Action = [[-0.33242786 -0.24652386  0.5626259   0.8427448 ]]. Reward = [0.]
Curr episode timestep = 52
Above hoop
Current timestep = 917. State = [[ 1.8222563e-02 -3.7975729e-04  2.8019863e-01  1.0000000e+00]]. Action = [[-0.13627493  0.29516673 -0.8228775   0.7764344 ]]. Reward = [0.]
Curr episode timestep = 53
Above hoop
Current timestep = 918. State = [[0.01608388 0.01111704 0.27068815 1.        ]]. Action = [[ 0.3334322   0.49127018 -0.13467443  0.7926396 ]]. Reward = [0.]
Curr episode timestep = 54
Above hoop
Current timestep = 919. State = [[0.02007829 0.00781619 0.26167595 1.        ]]. Action = [[ 0.9012432  -0.80475706 -0.7012609   0.22304904]]. Reward = [0.]
Curr episode timestep = 55
Above hoop
Current timestep = 920. State = [[0.04468563 0.00558687 0.23345163 1.        ]]. Action = [[ 0.51149774  0.51757    -0.36176962  0.72817016]]. Reward = [0.]
Curr episode timestep = 56
Above hoop
Current timestep = 921. State = [[0.07029702 0.00758227 0.235532   1.        ]]. Action = [[ 0.39234257 -0.3766663   0.927423    0.61775136]]. Reward = [0.]
Curr episode timestep = 57
Above hoop
Current timestep = 922. State = [[0.07967468 0.00425348 0.25036582 1.        ]]. Action = [[ 0.45675623 -0.28641248 -0.48068607  0.7707226 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: No entry zone
Above hoop
Current timestep = 923. State = [[0.08095402 0.00351141 0.25147954 1.        ]]. Action = [[ 0.6189861  -0.23607028  0.8974217   0.8445442 ]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 924. State = [[0.08108021 0.00321477 0.25153115 1.        ]]. Action = [[-0.26863277  0.63560796 -0.5597975   0.6150576 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: No entry zone
Current timestep = 925. State = [[0.07884469 0.0130087  0.25180003 1.        ]]. Action = [[-0.37462676  0.66701746  0.02342796  0.5844469 ]]. Reward = [0.]
Curr episode timestep = 61
Above hoop
Current timestep = 926. State = [[0.07681742 0.0214505  0.2517921  1.        ]]. Action = [[-0.44566286  0.6756661  -0.6622684   0.8571656 ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: No entry zone
Above hoop
Current timestep = 927. State = [[0.07659866 0.02240972 0.251792   1.        ]]. Action = [[ 0.82385063 -0.7395324  -0.6429752   0.568159  ]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Action ignored: No entry zone
Above hoop
Current timestep = 928. State = [[0.07659866 0.02240972 0.251792   1.        ]]. Action = [[0.675889  0.8515303 0.694132  0.8327315]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Above hoop
Current timestep = 929. State = [[0.07659866 0.02240972 0.251792   1.        ]]. Action = [[ 0.14894736 -0.077115   -0.9220131   0.7858088 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: No entry zone
Above hoop
Current timestep = 930. State = [[0.07659866 0.02240972 0.251792   1.        ]]. Action = [[ 0.8274007  -0.78357345 -0.71753156  0.6270704 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Action ignored: No entry zone
Above hoop
Current timestep = 931. State = [[0.07900649 0.01342708 0.2568998  1.        ]]. Action = [[ 0.20459771 -0.6164372   0.42342114  0.858956  ]]. Reward = [0.]
Curr episode timestep = 67
Above hoop
Current timestep = 932. State = [[7.939173e-02 9.442509e-04 2.671775e-01 1.000000e+00]]. Action = [[-0.82765716 -0.28035557 -0.04324126  0.64776826]]. Reward = [0.]
Curr episode timestep = 68
Above hoop
Current timestep = 933. State = [[ 0.07637949 -0.00648208  0.27176034  1.        ]]. Action = [[ 0.57459104  0.4126054  -0.86413735  0.6828966 ]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Action ignored: No entry zone
Above hoop
Current timestep = 934. State = [[ 0.06910291 -0.01190277  0.2872652   1.        ]]. Action = [[-0.9661063  -0.19390398  0.7924893   0.66143477]]. Reward = [0.]
Curr episode timestep = 70
Above hoop
Current timestep = 935. State = [[ 0.04540144 -0.01432109  0.30333796  1.        ]]. Action = [[0.8902023  0.14702034 0.14441872 0.608464  ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Above hoop
Current timestep = 936. State = [[ 0.03407813 -0.03221448  0.31879047  1.        ]]. Action = [[-0.9073758  -0.97543633  0.7432331   0.2089448 ]]. Reward = [0.]
Curr episode timestep = 72
Above hoop
Current timestep = 937. State = [[ 0.00216696 -0.05682482  0.35138318  1.        ]]. Action = [[-0.87270916 -0.25410235  0.9599502   0.8337853 ]]. Reward = [0.]
Curr episode timestep = 73
Above hoop
Current timestep = 938. State = [[-0.02953401 -0.06433647  0.37541744  1.        ]]. Action = [[-0.11992443 -0.02330345 -0.01323932  0.9043684 ]]. Reward = [0.]
Curr episode timestep = 74
Above hoop
Current timestep = 939. State = [[-0.0361437  -0.06658217  0.38102803  1.        ]]. Action = [[0.86092377 0.37548363 0.9844892  0.74649394]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Scene graph at timestep 939 is [False, True, False, True, False, False, True, False, False, True]
State prediction error at timestep 939 is tensor(0.0005, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 939 of -1
Current timestep = 940. State = [[-0.04243501 -0.05877046  0.38939968  1.        ]]. Action = [[-0.6311965   0.5004051   0.4829352   0.60910225]]. Reward = [0.]
Curr episode timestep = 76
Above hoop
Current timestep = 941. State = [[-0.05926543 -0.04046617  0.3904395   1.        ]]. Action = [[ 0.534498    0.48591232 -0.587514    0.7108836 ]]. Reward = [0.]
Curr episode timestep = 77
Above hoop
Current timestep = 942. State = [[-0.0629641  -0.01918553  0.38454756  1.        ]]. Action = [[-0.5689775   0.7860637   0.09318662  0.89687395]]. Reward = [0.]
Curr episode timestep = 78
Above hoop
Current timestep = 943. State = [[-0.06897139 -0.00307719  0.38301313  1.        ]]. Action = [[ 0.11509061 -0.17285466 -0.21905631  0.46248472]]. Reward = [0.]
Curr episode timestep = 79
Above hoop
Current timestep = 944. State = [[-0.07500602 -0.00735415  0.37969503  1.        ]]. Action = [[-0.7075928  -0.27992588 -0.11364287  0.86443424]]. Reward = [0.]
Curr episode timestep = 80
Above hoop
Current timestep = 945. State = [[-0.08438989 -0.02386691  0.35835415  1.        ]]. Action = [[ 0.5535152  -0.7403127  -0.9915637   0.78716147]]. Reward = [0.]
Curr episode timestep = 81
Above hoop
Current timestep = 946. State = [[-0.07659245 -0.04364726  0.3301868   1.        ]]. Action = [[ 0.8946197  -0.3822183  -0.7596744   0.78611696]]. Reward = [0.]
Curr episode timestep = 82
Above hoop
Current timestep = 947. State = [[-0.05847488 -0.04255556  0.31121162  1.        ]]. Action = [[0.26191616 0.8681288  0.52899003 0.78889024]]. Reward = [0.]
Curr episode timestep = 83
Above hoop
Current timestep = 948. State = [[-0.05599491 -0.02168735  0.31778634  1.        ]]. Action = [[-0.7013854   0.54692245  0.29297078  0.5296848 ]]. Reward = [0.]
Curr episode timestep = 84
Above hoop
Current timestep = 949. State = [[-5.7212479e-02 -3.2141269e-04  3.3081794e-01  1.0000000e+00]]. Action = [[0.36252224 0.3829229  0.8206978  0.52409124]]. Reward = [0.]
Curr episode timestep = 85
Above hoop
Current timestep = 950. State = [[-0.05500141  0.00212778  0.35477695  1.        ]]. Action = [[ 0.17389643 -0.3535391   0.7149645   0.62944555]]. Reward = [0.]
Curr episode timestep = 86
Above hoop
Current timestep = 951. State = [[-0.0453036  -0.00145802  0.37384158  1.        ]]. Action = [[ 0.92085624 -0.00892454  0.00221062  0.575014  ]]. Reward = [0.]
Curr episode timestep = 87
Above hoop
Current timestep = 952. State = [[-0.03114948 -0.00120052  0.3805047   1.        ]]. Action = [[-0.08382279 -0.11944884  0.87161183  0.86988235]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Above hoop
Current timestep = 953. State = [[-0.03192681 -0.00949453  0.37579477  1.        ]]. Action = [[-0.34557205 -0.5251631  -0.5747757   0.5545459 ]]. Reward = [0.]
Curr episode timestep = 89
Above hoop
Current timestep = 954. State = [[-0.02830807 -0.00667844  0.36215776  1.        ]]. Action = [[ 0.938004   0.7182032 -0.9508465  0.9188788]]. Reward = [0.]
Curr episode timestep = 90
Above hoop
Current timestep = 955. State = [[-0.01353009 -0.0080563   0.32630825  1.        ]]. Action = [[-0.62751585 -0.7181128  -0.4322095   0.8971033 ]]. Reward = [0.]
Curr episode timestep = 91
Above hoop
Current timestep = 956. State = [[-0.00725586 -0.01036933  0.3115502   1.        ]]. Action = [[ 0.9358746   0.37491286 -0.9138473   0.8631412 ]]. Reward = [0.]
Curr episode timestep = 92
Above hoop
Current timestep = 957. State = [[ 0.0152221  -0.01707261  0.27582544  1.        ]]. Action = [[ 0.9466338  -0.5063741  -0.26852834  0.5208086 ]]. Reward = [0.]
Curr episode timestep = 93
Above hoop
Current timestep = 958. State = [[ 0.04018548 -0.03426336  0.27270827  1.        ]]. Action = [[-0.5344529 -0.4650377  0.9203775  0.7821028]]. Reward = [0.]
Curr episode timestep = 94
Above hoop
Current timestep = 959. State = [[ 0.04015355 -0.057016    0.28446794  1.        ]]. Action = [[ 0.16933155 -0.8871186  -0.19877481  0.6475682 ]]. Reward = [0.]
Curr episode timestep = 95
Above hoop
Current timestep = 960. State = [[ 0.04345131 -0.07144639  0.2847935   1.        ]]. Action = [[ 0.32492423  0.21317935 -0.0520401   0.73229337]]. Reward = [0.]
Curr episode timestep = 96
Scene graph at timestep 960 is [False, True, False, True, False, False, True, False, False, True]
State prediction error at timestep 960 is tensor(0.0002, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 960 of 0
Current timestep = 961. State = [[ 0.04622897 -0.05812082  0.27429315  1.        ]]. Action = [[ 0.23101532  0.9117291  -0.768319    0.4507333 ]]. Reward = [0.]
Curr episode timestep = 97
Above hoop
Current timestep = 962. State = [[ 0.05544624 -0.03024515  0.26739225  1.        ]]. Action = [[-0.6510786   0.9277837   0.64733255  0.8759134 ]]. Reward = [0.]
Curr episode timestep = 98
Above hoop
Current timestep = 963. State = [[ 0.04989364 -0.00654415  0.27366188  1.        ]]. Action = [[-0.6160495   0.21950567 -0.8432286   0.6372297 ]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: No entry zone
Above hoop
Current timestep = 964. State = [[0.04462975 0.00751007 0.28225228 1.        ]]. Action = [[-0.7814202   0.725265    0.47590852  0.3358115 ]]. Reward = [0.]
Curr episode timestep = 100
Above hoop
Current timestep = 965. State = [[-0.26240665 -0.12522225  0.10196459  1.        ]]. Action = [[0.5336808  0.4154787  0.98533523 0.68042934]]. Reward = [0.]
Curr episode timestep = 101
Above hoop
Current timestep = 966. State = [[-0.26051816 -0.14827181  0.08157281  1.        ]]. Action = [[ 0.37757826 -0.6978751  -0.9444378   0.80932426]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 967. State = [[-0.24748345 -0.17552821  0.04934461  1.        ]]. Action = [[ 0.7867522 -0.7643542 -0.6178763  0.5156958]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 968. State = [[-0.22992162 -0.19347186  0.03006777  1.        ]]. Action = [[-0.91090584  0.48652077 -0.67805624  0.71080136]]. Reward = [0.]
Curr episode timestep = 2
Action ignored: Workspace boundary
Current timestep = 969. State = [[-0.22851177 -0.19413286  0.02978156  1.        ]]. Action = [[-0.9913599   0.6801784   0.15437996  0.87109876]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: Workspace boundary
Current timestep = 970. State = [[-0.22799169 -0.19434245  0.0296574   1.        ]]. Action = [[ 0.8998611  -0.7992526  -0.9436815   0.84775174]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: Workspace boundary
Current timestep = 971. State = [[-0.22803847 -0.207779    0.03474737  1.        ]]. Action = [[-0.08660156 -0.81110567  0.7557905   0.8672352 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 972. State = [[-0.22711733 -0.22474346  0.0397007   1.        ]]. Action = [[ 0.72174454 -0.54513323 -0.95699966  0.6452532 ]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: Workspace boundary
Current timestep = 973. State = [[-0.22634453 -0.22650403  0.04152815  1.        ]]. Action = [[ 0.3468076   0.6250191  -0.40951014  0.79023623]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: Workspace boundary
Current timestep = 974. State = [[-0.22985117 -0.22213784  0.0410918   1.        ]]. Action = [[-0.35715258  0.5070996  -0.10228467  0.46853077]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 975. State = [[-0.2332847  -0.21802978  0.04033706  1.        ]]. Action = [[ 0.7848846  -0.26525688 -0.51816773  0.79282   ]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: Workspace boundary
Current timestep = 976. State = [[-0.24099015 -0.22150214  0.04574431  1.        ]]. Action = [[-0.6411062  -0.27597344  0.6194184   0.60319126]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 977. State = [[-0.25255844 -0.22152217  0.0567917   1.        ]]. Action = [[-0.45667624  0.16683435 -0.78726476  0.68945575]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: Workspace boundary
Current timestep = 978. State = [[-0.25496528 -0.22166277  0.05763163  1.        ]]. Action = [[-0.8059511 -0.4372437 -0.6024364  0.6063957]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Current timestep = 979. State = [[-0.25342566 -0.216189    0.057969    1.        ]]. Action = [[0.28241038 0.5345806  0.07805383 0.63957024]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 980. State = [[-0.25117832 -0.21170068  0.05804076  1.        ]]. Action = [[-0.32625782  0.44068193 -0.88257277  0.6983923 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 981. State = [[-0.25024533 -0.21013893  0.05790008  1.        ]]. Action = [[ 0.1875298  -0.64938456 -0.9210205   0.6502662 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 982. State = [[-0.25055096 -0.21347146  0.05785117  1.        ]]. Action = [[ 0.06605625 -0.4358921  -0.3072405   0.5538161 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 983. State = [[-0.25076318 -0.215092    0.05785202  1.        ]]. Action = [[-0.8847773  -0.78844464  0.16985464  0.22696996]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 984. State = [[-0.2507755  -0.2151847   0.05785207  1.        ]]. Action = [[-0.61590827 -0.07248223 -0.83228236  0.5485759 ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 985. State = [[-0.24197896 -0.21258321  0.06015408  1.        ]]. Action = [[0.7734494 0.2898203 0.3451779 0.5388081]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 986. State = [[-0.23233858 -0.21259941  0.06370873  1.        ]]. Action = [[-0.48189306  0.7952012  -0.929547    0.4547721 ]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 987. State = [[-0.22951351 -0.21237692  0.06402896  1.        ]]. Action = [[-0.84355855 -0.8545356   0.08091962  0.67294717]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 988. State = [[-0.22479595 -0.20691207  0.06735735  1.        ]]. Action = [[0.2551068  0.36588347 0.27947903 0.60535526]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 989. State = [[-0.2244303  -0.21165238  0.08144609  1.        ]]. Action = [[-0.83292276 -0.6351643   0.5852661   0.47500193]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 990. State = [[-0.23042855 -0.23000713  0.09516928  1.        ]]. Action = [[ 0.30872035 -0.8742507   0.07131195  0.700202  ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 991. State = [[-0.23194587 -0.24632521  0.09630643  1.        ]]. Action = [[-0.8004779  -0.66981894  0.6067419   0.5835862 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 992. State = [[-0.23653014 -0.2450947   0.0926377   1.        ]]. Action = [[-0.5182472   0.351058   -0.6516436   0.73064256]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 993. State = [[-0.23550886 -0.24429405  0.08471981  1.        ]]. Action = [[ 0.76093435 -0.36572587 -0.47467947  0.6768067 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 994. State = [[-0.21618254 -0.25611037  0.06627537  1.        ]]. Action = [[ 0.78530025 -0.5694497  -0.932568    0.63747334]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 995. State = [[-0.20243628 -0.25825182  0.03861237  1.        ]]. Action = [[-0.28648782  0.7755203  -0.2429738   0.76298296]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 996. State = [[-0.19116822 -0.26165828  0.0317352   1.        ]]. Action = [[ 0.8902675  -0.95433253 -0.16091597  0.7704525 ]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 997. State = [[-0.16256396 -0.2831941   0.0341952   1.        ]]. Action = [[ 0.90237045 -0.50327253  0.977612    0.45370197]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 998. State = [[-0.14000636 -0.29569134  0.04485957  1.        ]]. Action = [[ 0.6345296  -0.6297709   0.13153458  0.44911695]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 999. State = [[-0.13581318 -0.29787612  0.04662061  1.        ]]. Action = [[-0.7580167   0.130126   -0.54578716  0.7548535 ]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 1000. State = [[-0.13555026 -0.29801422  0.04671048  1.        ]]. Action = [[ 0.9291961  -0.66283554  0.63310504  0.4271953 ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 1001. State = [[-0.1354164  -0.2980931   0.04678367  1.        ]]. Action = [[ 0.72865427  0.2690196  -0.42061943  0.69654846]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 1002. State = [[-0.1239596  -0.29897177  0.04637623  1.        ]]. Action = [[ 0.9837241  -0.0688951  -0.34000838  0.8151159 ]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 1003. State = [[-0.10503652 -0.30392173  0.04631526  1.        ]]. Action = [[ 0.954602   -0.18129027 -0.6253285   0.04995215]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 1004. State = [[-0.1068484  -0.3014145   0.04602763  1.        ]]. Action = [[-0.6756371   0.367841    0.24389505  0.80006945]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 1005. State = [[-0.10851239 -0.30026132  0.04546877  1.        ]]. Action = [[ 0.50118864 -0.78022826  0.7815839   0.7032862 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 1006. State = [[-0.11774555 -0.30306014  0.05328944  1.        ]]. Action = [[-0.85387945 -0.00344867  0.84982467  0.6892141 ]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 1007. State = [[-0.13484004 -0.29797718  0.07066851  1.        ]]. Action = [[ 0.30567646  0.5285325  -0.97025967  0.75205064]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 1008. State = [[-0.13828997 -0.29645252  0.07316655  1.        ]]. Action = [[ 0.07849467 -0.72571945 -0.2998783   0.67255104]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 1009. State = [[-0.1513772  -0.30179644  0.08015066  1.        ]]. Action = [[-0.9472778  -0.15027887  0.56266594  0.62888026]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 1010. State = [[-0.16050273 -0.29540086  0.10360875  1.        ]]. Action = [[0.8402746  0.5226095  0.69674015 0.5289664 ]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 1011. State = [[-0.15808246 -0.27865702  0.12199918  1.        ]]. Action = [[-0.57998174  0.6030694   0.20452929  0.6562766 ]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 1012. State = [[-0.1751387  -0.27063447  0.13775344  1.        ]]. Action = [[-0.9150819  -0.13299     0.69950914  0.7377019 ]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 1013. State = [[-0.19734238 -0.26437756  0.15159605  1.        ]]. Action = [[-0.09053433  0.0843786  -0.2540536   0.49044943]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 1014. State = [[-0.20915893 -0.2535431   0.15532698  1.        ]]. Action = [[-0.82201946  0.7753928   0.5097766   0.678036  ]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 1015. State = [[-0.24053949 -0.25261986  0.16821696  1.        ]]. Action = [[-0.59016424 -0.9195969   0.04997861  0.44115853]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 1016. State = [[-0.25004396 -0.25270817  0.17517127  1.        ]]. Action = [[0.26854455 0.81432927 0.3174554  0.47049868]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 1017. State = [[-0.2533484  -0.25669655  0.1854779   1.        ]]. Action = [[-0.35892808 -0.8880278   0.3079096   0.693964  ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 1018. State = [[-0.26538083 -0.26159385  0.1848572   1.        ]]. Action = [[-0.2546314  0.4091766 -0.9818527  0.6017126]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 1019. State = [[-0.27650526 -0.2545662   0.174753    1.        ]]. Action = [[-0.13282692 -0.2171709  -0.00188392  0.8029225 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 1020. State = [[-0.27855328 -0.25314093  0.17373194  1.        ]]. Action = [[-0.4521773  -0.8869103  -0.5071834   0.90363646]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 1021. State = [[-0.2790571  -0.2528363   0.17357054  1.        ]]. Action = [[-0.09288585  0.1435889  -0.2865064   0.8190274 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 1022. State = [[-0.27933505 -0.2526041   0.17345221  1.        ]]. Action = [[-0.3906442   0.646935    0.08659339  0.6190907 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 1023. State = [[-0.27529463 -0.25443175  0.17488188  1.        ]]. Action = [[ 0.36470222 -0.23351353  0.24349308  0.6387758 ]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 1024. State = [[-0.2618271  -0.2633698   0.18046057  1.        ]]. Action = [[ 0.59411    -0.48960412  0.368716    0.8447659 ]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 1025. State = [[-0.25248772 -0.26771173  0.17879866  1.        ]]. Action = [[ 0.11834288  0.22742319 -0.6732757   0.603179  ]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 1026. State = [[-0.24883048 -0.2671281   0.16990522  1.        ]]. Action = [[-0.7151053   0.52044654 -0.72985214  0.49370027]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 1027. State = [[-0.23482843 -0.27285075  0.1763033   1.        ]]. Action = [[ 0.8149433  -0.40953088  0.87426174  0.6698855 ]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 1028. State = [[-0.21703808 -0.28190774  0.18650042  1.        ]]. Action = [[-0.88279665 -0.41356385  0.5480931   0.6481502 ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 1029. State = [[-0.21985567 -0.27249393  0.18873583  1.        ]]. Action = [[-0.76092136  0.9178574   0.05783904  0.77817154]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 1030. State = [[-0.22911175 -0.24433465  0.19281542  1.        ]]. Action = [[0.13588274 0.9737158  0.12853658 0.8048185 ]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 1031. State = [[-0.25256988 -0.07149737  0.12226466  1.        ]]. Action = [[ 0.5663202   0.72392213  0.8989928  -0.08943897]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 1032. State = [[-0.24531831 -0.09110548  0.10766552  1.        ]]. Action = [[ 0.6486075  -0.8246702  -0.17475182  0.7754364 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1033. State = [[-0.23299138 -0.12048624  0.09535883  1.        ]]. Action = [[ 0.22292233 -0.64364564 -0.56507236  0.5065863 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1034. State = [[-0.218465  -0.1488744  0.0795359  1.       ]]. Action = [[ 0.5209124  -0.8524435  -0.20983136  0.83205247]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1035. State = [[-0.19813581 -0.1620232   0.06354529  1.        ]]. Action = [[ 0.81900907  0.2871287  -0.94043994  0.5900128 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1036. State = [[-0.17929986 -0.1629521   0.03888218  1.        ]]. Action = [[ 0.6022191  -0.14462411 -0.9082883   0.5231744 ]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1037. State = [[-0.16368541 -0.17673376  0.04489334  1.        ]]. Action = [[ 0.78052485 -0.8816678   0.88320065  0.8786795 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1038. State = [[-0.15268461 -0.19432947  0.06153744  1.        ]]. Action = [[-0.8803625  -0.03363681  0.6533072   0.52038383]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1039. State = [[-0.1577087  -0.19877681  0.07101669  1.        ]]. Action = [[ 0.6222651  -0.01216102 -0.6399349   0.54777336]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1040. State = [[-0.16303185 -0.19831371  0.0739213   1.        ]]. Action = [[-0.98073405  0.2084651   0.8246194   0.93424463]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1041. State = [[-0.18903778 -0.21133524  0.08135177  1.        ]]. Action = [[-0.959219   -0.9507533  -0.33304322  0.5966642 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1042. State = [[-0.21524446 -0.21944167  0.0874061   1.        ]]. Action = [[-0.7947419   0.64899004  0.8159938   0.6204498 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1043. State = [[-0.2454274  -0.20622706  0.09680939  1.        ]]. Action = [[-0.68782353  0.39325917 -0.46823478  0.59974265]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1044. State = [[-0.25618875 -0.19815479  0.09322076  1.        ]]. Action = [[ 0.85538495 -0.1176542   0.10265732  0.6136682 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1045. State = [[-0.24899274 -0.19020753  0.08630273  1.        ]]. Action = [[ 0.22571933  0.30354    -0.97227734  0.37494946]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 1046. State = [[-0.23641138 -0.17462443  0.06304219  1.        ]]. Action = [[ 0.5566119   0.56279254 -0.54462576  0.5367129 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 1047. State = [[-0.22568668 -0.16406055  0.04936492  1.        ]]. Action = [[-0.04006875  0.7111664  -0.7881185   0.89436734]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 1048. State = [[-0.21754123 -0.15797825  0.05101011  1.        ]]. Action = [[0.48625755 0.3459221  0.5466521  0.728812  ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 1049. State = [[-0.20194311 -0.15561359  0.0655752   1.        ]]. Action = [[ 0.44034433 -0.21414375  0.9036554   0.65835667]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 1050. State = [[-0.19425005 -0.14531337  0.07954125  1.        ]]. Action = [[-0.15855724  0.7671418  -0.5435529   0.7687726 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 1051. State = [[-0.1956285  -0.14304174  0.07004092  1.        ]]. Action = [[ 0.05935133 -0.8619488  -0.8632827   0.5995691 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 1052. State = [[-0.19034272 -0.1524198   0.05144523  1.        ]]. Action = [[ 0.7062609  -0.7138583  -0.90309125  0.7378702 ]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1053. State = [[-0.18701455 -0.15720719  0.05123345  1.        ]]. Action = [[ 0.10615039 -0.19630247  0.34508216  0.6877558 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 1054. State = [[-0.18634361 -0.16142808  0.0520399   1.        ]]. Action = [[ 0.5228368   0.602157   -0.08528513  0.7137232 ]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: No entry zone
Current timestep = 1055. State = [[-0.19281982 -0.16107781  0.06105217  1.        ]]. Action = [[-0.90233773  0.36025     0.8640702   0.79329085]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 1056. State = [[-0.21289079 -0.1722424   0.07899128  1.        ]]. Action = [[-0.49068612 -0.8767444   0.18379307  0.79563594]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 1057. State = [[-0.23228286 -0.1818806   0.08469978  1.        ]]. Action = [[-0.7565367   0.35672212  0.10138285  0.7843504 ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 1058. State = [[-0.24124679 -0.17559892  0.08998714  1.        ]]. Action = [[ 0.6716466   0.1702193  -0.07097638  0.5043378 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 1059. State = [[-0.23097672 -0.16938964  0.09118295  1.        ]]. Action = [[0.6594827  0.24743986 0.13105345 0.71968985]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 1060. State = [[-0.21995614 -0.15918487  0.10061285  1.        ]]. Action = [[0.18489552 0.27812934 0.62060964 0.7134639 ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 1061. State = [[-0.2173023  -0.1526737   0.11894592  1.        ]]. Action = [[-0.64835864  0.01364434  0.42741966  0.51764894]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 1062. State = [[-0.22622208 -0.14782745  0.12580289  1.        ]]. Action = [[-0.38353992  0.298483   -0.43796808  0.677894  ]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 1063. State = [[-0.22295286 -0.12977992  0.1260641   1.        ]]. Action = [[0.8920839  0.8046497  0.3063059  0.86190116]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 1064. State = [[-0.20775177 -0.11204442  0.139413    1.        ]]. Action = [[ 0.5156245  -0.12711334  0.88004947  0.8014369 ]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 1065. State = [[-0.20270064 -0.11083135  0.15474394  1.        ]]. Action = [[-0.50862336  0.06049907 -0.35110235  0.4944806 ]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 1066. State = [[-0.2048206  -0.11021955  0.15405974  1.        ]]. Action = [[ 0.96065784  0.77692616 -0.58131754  0.831604  ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: No entry zone
Current timestep = 1067. State = [[-0.20190305 -0.11415939  0.14954463  1.        ]]. Action = [[ 0.56719255 -0.43526435 -0.54448116  0.53728807]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 1068. State = [[-0.19434178 -0.11504327  0.14532371  1.        ]]. Action = [[-0.07191396  0.26992106  0.48922467  0.679867  ]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 1069. State = [[-0.19327536 -0.11446012  0.14666404  1.        ]]. Action = [[ 0.9038869  -0.8723239  -0.5320494   0.84539676]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: No entry zone
Current timestep = 1070. State = [[-0.1933253  -0.11447144  0.14665988  1.        ]]. Action = [[0.77413607 0.06315732 0.32053924 0.7273941 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: No entry zone
Current timestep = 1071. State = [[-0.19613543 -0.11289078  0.14488     1.        ]]. Action = [[-0.37286246  0.15495408 -0.39394712  0.88440824]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 1072. State = [[-0.20170124 -0.09575887  0.13429831  1.        ]]. Action = [[ 0.02753544  0.9303299  -0.80588573  0.742394  ]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 1073. State = [[-0.20611182 -0.07329302  0.12115736  1.        ]]. Action = [[-0.06853664  0.29355764  0.3044517   0.7417543 ]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 1074. State = [[-0.20814224 -0.05396166  0.12324508  1.        ]]. Action = [[-0.07994086  0.60194683  0.29718125  0.16172576]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 1075. State = [[-0.21948409 -0.02798694  0.11711798  1.        ]]. Action = [[-0.68805915  0.74239373 -0.8794981   0.54181695]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 1076. State = [[-2.1940419e-01  2.2123834e-04  1.1344765e-01  1.0000000e+00]]. Action = [[0.96836615 0.7773428  0.74927056 0.779762  ]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 1077. State = [[-0.19387874  0.01131326  0.12985     1.        ]]. Action = [[ 0.87363374 -0.5242715   0.6842766   0.58818066]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 1078. State = [[-0.1737192   0.00536681  0.14426658  1.        ]]. Action = [[ 0.87112176 -0.7239824  -0.8424604   0.4828589 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: No entry zone
Current timestep = 1079. State = [[-0.17794248  0.00471729  0.14459196  1.        ]]. Action = [[-0.7608167   0.01017892 -0.01513398  0.90801454]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 1080. State = [[-0.1858897   0.0184455   0.15879686  1.        ]]. Action = [[-0.16893     0.90661454  0.9502983   0.67472684]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 1081. State = [[-0.20340064  0.03231238  0.17382003  1.        ]]. Action = [[-0.894033   -0.2565518  -0.4578727   0.35828066]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 1082. State = [[-0.22815698  0.04401501  0.16597597  1.        ]]. Action = [[-0.41694885  0.87558556 -0.54402155  0.7393215 ]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 1083. State = [[-0.24533612  0.07213838  0.1638719   1.        ]]. Action = [[-0.5032568   0.5609653   0.51946187  0.45064175]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 1084. State = [[-0.25898042  0.08951408  0.15909126  1.        ]]. Action = [[-0.19156778  0.21323681 -0.93882805  0.520069  ]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 1085. State = [[-0.2602393   0.10272562  0.15087478  1.        ]]. Action = [[0.57722926 0.51211345 0.5474851  0.7959573 ]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 1086. State = [[-0.25770915  0.11135712  0.15338756  1.        ]]. Action = [[-0.65056837 -0.92780495  0.1079011   0.5080254 ]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 1087. State = [[-0.25732407  0.11217668  0.15365958  1.        ]]. Action = [[-0.6159912  -0.33323896  0.5471237   0.58239055]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 1088. State = [[-0.24556996  0.11518599  0.15979947  1.        ]]. Action = [[0.8437563  0.10208249 0.4776628  0.7089007 ]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 1089. State = [[-0.23186408  0.12922412  0.16457953  1.        ]]. Action = [[ 0.03714895  0.70506907 -0.40998667  0.6450677 ]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 1090. State = [[-0.23594597  0.13036692  0.15599094  1.        ]]. Action = [[-0.48813576 -0.72160876 -0.55151796  0.7703004 ]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 1091. State = [[-0.23073824  0.12071083  0.15388718  1.        ]]. Action = [[ 0.586118   -0.12866443  0.76075757  0.19500387]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 1092. State = [[-0.21178202  0.10228341  0.17440997  1.        ]]. Action = [[ 0.7134721 -0.8323879  0.9733969  0.5149455]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 1093. State = [[-0.20261376  0.09019182  0.20141268  1.        ]]. Action = [[-0.6384789   0.08013403  0.4149629   0.70330906]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 1094. State = [[-0.20193286  0.0725003   0.21891971  1.        ]]. Action = [[ 0.3708135  -0.9641101   0.31401348  0.6773567 ]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 1095. State = [[-0.20665433  0.05011293  0.240578    1.        ]]. Action = [[-0.84871    -0.32645118  0.9559704   0.6222693 ]]. Reward = [0.]
Curr episode timestep = 63
Scene graph at timestep 1095 is [True, False, False, False, True, False, True, False, False, True]
State prediction error at timestep 1095 is tensor(0.0051, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1095 of 1
Current timestep = 1096. State = [[-0.22348846  0.04577554  0.26827994  1.        ]]. Action = [[-0.23054636  0.5329757  -0.39459336  0.66449654]]. Reward = [0.]
Curr episode timestep = 64
Scene graph at timestep 1096 is [True, False, False, False, True, False, True, False, False, True]
State prediction error at timestep 1096 is tensor(0.0055, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1096 of -1
Current timestep = 1097. State = [[-0.24016353  0.05318864  0.2602286   1.        ]]. Action = [[-0.7703353  -0.18570781 -0.41325623  0.8785589 ]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 1098. State = [[-0.24798511  0.06067773  0.25585842  1.        ]]. Action = [[0.6700386  0.6911154  0.4758618  0.56178117]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 1099. State = [[-0.2486122   0.06934021  0.25540814  1.        ]]. Action = [[-0.22384512 -0.18481779 -0.50768596  0.80897546]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 1100. State = [[-0.24266219  0.06218115  0.24931009  1.        ]]. Action = [[ 0.66121495 -0.45741618 -0.1120702   0.47457564]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 1101. State = [[-0.23646502  0.04982818  0.2540392   1.        ]]. Action = [[-0.4732393  -0.41738987  0.9603176   0.5872357 ]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 1102. State = [[-0.23715986  0.04202418  0.26582834  1.        ]]. Action = [[ 0.32319832  0.13219464 -0.0448885   0.5346515 ]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 1103. State = [[-0.23808293  0.03648806  0.27352962  1.        ]]. Action = [[-0.2062974  -0.37292933  0.5360689   0.7340872 ]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 1104. State = [[-0.24055108  0.03460934  0.28090796  1.        ]]. Action = [[ 0.07674336  0.40599394 -0.41064095  0.43066788]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 1105. State = [[-0.23556057  0.02933918  0.2869509   1.        ]]. Action = [[ 0.3755412  -0.629839    0.6626148   0.54270697]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 1106. State = [[-0.21907753  0.02690002  0.29685694  1.        ]]. Action = [[ 0.75606024  0.39007187 -0.22135282  0.41239154]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 1107. State = [[-0.19226095  0.02533226  0.29507157  1.        ]]. Action = [[ 0.9608636 -0.3880396 -0.1613096  0.712698 ]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 1108. State = [[-0.16480677  0.03124791  0.3012085   1.        ]]. Action = [[0.38640547 0.7113259  0.733438   0.5182922 ]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 1109. State = [[-0.14538856  0.04074316  0.32509038  1.        ]]. Action = [[ 0.3534925  -0.11889613  0.7337222   0.5986794 ]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 1110. State = [[-0.12936677  0.03149797  0.33463368  1.        ]]. Action = [[ 0.84724    -0.61076516 -0.7837866   0.79946876]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 1111. State = [[-0.10836803  0.01663657  0.3105578   1.        ]]. Action = [[ 0.09951937 -0.17159176 -0.76318336  0.78980756]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 1112. State = [[-0.09685886  0.01983319  0.28748903  1.        ]]. Action = [[ 0.32326102  0.4166515  -0.69331837  0.79840183]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 1113. State = [[-0.0808287   0.02874472  0.26180002  1.        ]]. Action = [[ 0.75527024  0.20045722 -0.9722867   0.78958225]]. Reward = [0.]
Curr episode timestep = 81
Above hoop
Current timestep = 1114. State = [[-0.06018204  0.03406158  0.23479587  1.        ]]. Action = [[-0.8328642  -0.8317699  -0.9501499   0.59090006]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: No entry zone
Above hoop
Current timestep = 1115. State = [[-0.04952638  0.04227014  0.23983628  1.        ]]. Action = [[0.37928987 0.46821165 0.73654985 0.72055197]]. Reward = [0.]
Curr episode timestep = 83
Above hoop
Current timestep = 1116. State = [[-0.04032813  0.03484271  0.2569262   1.        ]]. Action = [[-0.31173348 -0.9018489   0.45163035  0.764174  ]]. Reward = [0.]
Curr episode timestep = 84
Above hoop
Current timestep = 1117. State = [[-0.03933005  0.00721469  0.27713677  1.        ]]. Action = [[ 0.02733946 -0.93088233  0.73763597  0.53325915]]. Reward = [0.]
Curr episode timestep = 85
Above hoop
Current timestep = 1118. State = [[-0.0404177 -0.0108589  0.2866276  1.       ]]. Action = [[ 0.15266573  0.06661701 -0.824658    0.7380223 ]]. Reward = [0.]
Curr episode timestep = 86
Above hoop
Current timestep = 1119. State = [[-0.03818784 -0.01058305  0.2819687   1.        ]]. Action = [[0.08736014 0.19383919 0.5013107  0.8149147 ]]. Reward = [0.]
Curr episode timestep = 87
Above hoop
Current timestep = 1120. State = [[-0.2700886   0.14464991  0.12841924  1.        ]]. Action = [[ 0.71327627 -0.578884   -0.8594415  -0.03577536]]. Reward = [1000.]
Curr episode timestep = 88
Above hoop
Current timestep = 1121. State = [[-0.26273224  0.15993159  0.1170568   1.        ]]. Action = [[ 0.4583465  -0.12406588  0.131464    0.88937056]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1122. State = [[-0.2565764   0.16179955  0.11486173  1.        ]]. Action = [[-0.011985    0.27045584 -0.3075192   0.7090744 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1123. State = [[-0.25440586  0.1644897   0.10852501  1.        ]]. Action = [[-0.7260807  -0.9409561  -0.14661276  0.50424147]]. Reward = [0.]
Curr episode timestep = 2
Action ignored: Workspace boundary
Current timestep = 1124. State = [[-0.2504443   0.18057638  0.111789    1.        ]]. Action = [[0.26755762 0.95017684 0.3637277  0.5875695 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1125. State = [[-0.24749495  0.21240121  0.120191    1.        ]]. Action = [[-0.00855815  0.8165498   0.35463834  0.7736845 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1126. State = [[-0.23975052  0.22319642  0.12175626  1.        ]]. Action = [[ 0.5741894  -0.49243635 -0.73860925  0.6887884 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1127. State = [[-0.22114736  0.22886139  0.10281099  1.        ]]. Action = [[ 0.560694    0.7332344  -0.3209598   0.49287045]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1128. State = [[-0.1991395   0.23294827  0.08463362  1.        ]]. Action = [[ 0.66214204 -0.47389054 -0.8350591   0.70282936]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1129. State = [[-0.17449877  0.23578133  0.06077399  1.        ]]. Action = [[ 0.6413758  0.4425714 -0.1429621  0.6180172]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1130. State = [[-0.15477547  0.25329414  0.05665109  1.        ]]. Action = [[0.1086154 0.6178849 0.2500199 0.6383326]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1131. State = [[-0.14854877  0.26585153  0.06149884  1.        ]]. Action = [[ 0.50268376 -0.71663135 -0.75326777  0.6631315 ]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: Workspace boundary
Current timestep = 1132. State = [[-0.14582197  0.2683124   0.0617988   1.        ]]. Action = [[ 0.6444192   0.05725312 -0.9025657   0.5341661 ]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: Workspace boundary
Current timestep = 1133. State = [[-0.1508085   0.26911375  0.05694     1.        ]]. Action = [[-0.42430443 -0.0243631  -0.5475509   0.18701899]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1134. State = [[-0.1565314   0.26980814  0.04349199  1.        ]]. Action = [[ 0.708539   -0.25196767 -0.66592646  0.7777991 ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Current timestep = 1135. State = [[-0.15686856  0.2701095   0.04322066  1.        ]]. Action = [[ 0.91113544 -0.6786468  -0.82790494  0.79805017]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 1136. State = [[-0.14292505  0.2549391   0.04782964  1.        ]]. Action = [[ 0.8881558  -0.9277719   0.44477046  0.05888987]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 1137. State = [[-0.11647736  0.22611474  0.05689976  1.        ]]. Action = [[ 0.859252   -0.84621006  0.06664276  0.625474  ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 1138. State = [[-0.09980521  0.20958805  0.06022196  1.        ]]. Action = [[ 0.31706524 -0.592024   -0.64516234  0.41285813]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 1139. State = [[-0.09638416  0.20678113  0.06064367  1.        ]]. Action = [[-0.07854712  0.709648   -0.86719084  0.5123745 ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 1140. State = [[-0.08921991  0.19213693  0.06301811  1.        ]]. Action = [[ 0.19782388 -0.9037532   0.09073794  0.20529604]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 1141. State = [[-0.08249874  0.17670058  0.06355892  1.        ]]. Action = [[ 0.9226868  -0.538226   -0.9263656   0.22968304]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 1142. State = [[-0.08106926  0.17402585  0.06355818  1.        ]]. Action = [[ 0.9042454  -0.8819737  -0.56170714 -0.2069242 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: No entry zone
Current timestep = 1143. State = [[-0.0809274   0.17370391  0.0635567   1.        ]]. Action = [[ 0.8536267  -0.98245615 -0.69517726  0.6463165 ]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: No entry zone
Current timestep = 1144. State = [[-0.08085961  0.17357622  0.06355667  1.        ]]. Action = [[ 0.9627981  -0.84728134 -0.7696126   0.1285963 ]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1145. State = [[-0.08085961  0.17357622  0.06355667  1.        ]]. Action = [[ 0.9706626  -0.9346764  -0.8263675  -0.13112235]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1146. State = [[-0.0809404   0.1735673   0.06355263  1.        ]]. Action = [[ 0.9804158  -0.91528386 -0.79504544 -0.00312978]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1147. State = [[-0.08096797  0.17356424  0.06355125  1.        ]]. Action = [[ 0.957029   -0.89126056 -0.8805844  -0.21251398]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1148. State = [[-0.08096797  0.17356424  0.06355125  1.        ]]. Action = [[ 0.9662168  -0.9502883  -0.85023284 -0.4132526 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1149. State = [[-0.08096797  0.17356424  0.06355125  1.        ]]. Action = [[ 0.9380089  -0.93273246 -0.97565466 -0.04797083]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1150. State = [[-0.08096797  0.17356424  0.06355125  1.        ]]. Action = [[ 0.98302245 -0.8516571  -0.953777   -0.17687792]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1151. State = [[-0.08107803  0.17355208  0.06354585  1.        ]]. Action = [[ 0.90702295 -0.9146198  -0.9183725  -0.11814314]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1152. State = [[-0.08107803  0.17355208  0.06354585  1.        ]]. Action = [[ 0.801649   -0.9817834  -0.830976   -0.15152925]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1153. State = [[-0.08107803  0.17355208  0.06354585  1.        ]]. Action = [[ 0.9510809  -0.83114266 -0.9790734  -0.20209336]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1154. State = [[-0.08107803  0.17355208  0.06354585  1.        ]]. Action = [[ 0.92193425 -0.620438   -0.9708877   0.07925344]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1155. State = [[-0.08107803  0.17355208  0.06354585  1.        ]]. Action = [[ 0.98483074 -0.9012329  -0.80563647 -0.10456681]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1156. State = [[-0.08107803  0.17355208  0.06354585  1.        ]]. Action = [[ 0.8133029  -0.9330209  -0.9013829  -0.02161235]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1157. State = [[-0.08107803  0.17355208  0.06354585  1.        ]]. Action = [[ 0.95017076 -0.17076737 -0.96782035  0.02345717]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 1158. State = [[-0.08107803  0.17355208  0.06354585  1.        ]]. Action = [[ 0.74126005 -0.42181736 -0.98722    -0.1031093 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1159. State = [[-0.0811881   0.17353994  0.06354053  1.        ]]. Action = [[ 0.82071924 -0.773472   -0.94773465  0.07453406]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1160. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9741647  -0.86915314 -0.8594304  -0.10495442]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1161. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9836521  -0.9361132  -0.9841153  -0.01822686]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1162. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.8684772  -0.9554522  -0.7324958  -0.18132794]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1163. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 9.6486306e-01 -9.6082348e-01 -9.3844545e-01  7.0846081e-04]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1164. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9893811  -0.7928198  -0.85840505 -0.04338902]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1165. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.760515   -0.9866115  -0.9817115  -0.11056983]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1166. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9057691  -0.91764134 -0.9435299  -0.09435081]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1167. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.91747236 -0.8413955  -0.85634655 -0.12283826]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1168. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.7012129  -0.8952246  -0.3842913  -0.04029149]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: No entry zone
Current timestep = 1169. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.94154453 -0.9130492  -0.7710374  -0.12139893]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1170. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.95506287 -0.8562486  -0.98428935 -0.14717108]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1171. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.8222408  -0.8300297  -0.87764037 -0.14124453]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1172. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9508574 -0.7420161 -0.8544685 -0.0635947]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1173. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.71235657 -0.93653923 -0.95326465 -0.10543501]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1174. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.81679416 -0.8914241  -0.8583439  -0.17375839]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1175. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9269941  -0.9038831  -0.80956143 -0.10157561]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1176. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.943442   -0.78670835 -0.97112584 -0.17919129]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1177. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9756038  -0.90792304 -0.8689907  -0.06887472]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1178. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.983268   -0.84714043 -0.97994196 -0.07468313]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1179. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.92943525 -0.8006436  -0.9527938  -0.1450243 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1180. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9821904  -0.3282863  -0.8042439  -0.12439805]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1181. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9793427  -0.7459355  -0.50719315 -0.19001639]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: No entry zone
Current timestep = 1182. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.94664645 -0.82909906 -0.85069406 -0.05269867]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1183. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.94097626 -0.8709515  -0.943437   -0.09201837]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1184. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9017346  -0.90664583 -0.91923827  0.01854026]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1185. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9907963 -0.8896133 -0.6403517 -0.1863038]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: No entry zone
Current timestep = 1186. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.84815    -0.87836474 -0.95121706 -0.11943257]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1187. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.8966292  -0.92966145 -0.9267829  -0.21096921]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1188. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9490881  -0.79026246 -0.97547925 -0.16003895]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1189. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 8.9538479e-01 -7.2480136e-01 -8.9750683e-01 -3.7133694e-04]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1190. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9171004  -0.680024   -0.9909135  -0.02956569]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1191. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9524095  -0.8291261  -0.9765647  -0.08739567]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1192. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.89663124 -0.81090486 -0.97455174 -0.14859432]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1193. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9479933  -0.7443763  -0.9105115  -0.01634252]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1194. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.993775   -0.80145097 -0.9536925  -0.04679507]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1195. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9715712  -0.8653728  -0.96336776 -0.00735331]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1196. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.92100453 -0.64604765 -0.95333123 -0.00162005]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1197. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9742472  -0.75724345 -0.97726566  0.07197523]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1198. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.97969556 -0.58835465 -0.97649705 -0.08334649]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1199. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9176092  -0.7618847  -0.92821056  0.02253067]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1200. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9624702  -0.8475821  -0.93100727  0.01208234]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1201. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.98508275 -0.7345987  -0.9839193   0.00419295]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1202. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9737787  -0.3087693  -0.7827464   0.02085721]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1203. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9305444  -0.76996654 -0.9025683   0.03384423]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1204. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.65077806 -0.90001106 -0.9713396   0.07027328]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1205. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.8784087  -0.768851   -0.98954827  0.04795468]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1206. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.8315959  -0.7237029  -0.87611055  0.10670829]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1207. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9841783  -0.6571678  -0.94954705  0.09692609]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1208. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.8402512  -0.7981796  -0.6508654   0.07184076]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: No entry zone
Current timestep = 1209. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.78727126 -0.66200167 -0.94909203  0.15446079]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1210. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.964187   -0.5837825  -0.9129009   0.12427425]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1211. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.95440316 -0.62631994 -0.98588455 -0.00932842]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1212. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.62452435 -0.5885919  -0.9716824   0.01447725]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1213. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.86749077 -0.63058615 -0.62889737  0.12722659]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: No entry zone
Current timestep = 1214. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.86277616 -0.71820474 -0.9692029   0.00752449]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1215. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.982947   -0.8070412  -0.9327296   0.04149306]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1216. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9301443  -0.8313135  -0.77254975  0.04954541]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1217. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.96153045 -0.74898976 -0.92087156  0.03995705]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1218. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9005513  -0.66743755 -0.9859543  -0.01717466]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1219. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9596734  -0.8950096  -0.9631982   0.00211799]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1220. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.9259411  -0.8509924  -0.92721075 -0.02266043]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1221. State = [[-0.08129817  0.17352778  0.06353532  1.        ]]. Action = [[ 0.82052875 -0.7734723  -0.9518344   0.00716317]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1222. State = [[-0.26383147 -0.01233698  0.11185298  1.        ]]. Action = [[ 0.9175751  -0.86719066 -0.9749119  -0.0582397 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1223. State = [[-0.25385362 -0.12699415  0.12041597  1.        ]]. Action = [[ 0.8800013  -0.8760054  -0.97449434 -0.01696962]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1224. State = [[-0.25248536 -0.12731099  0.12288024  1.        ]]. Action = [[ 0.84908366 -0.85266894 -0.96091413 -0.04695404]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1225. State = [[-0.2625251   0.15105166  0.12591147  1.        ]]. Action = [[ 0.7625003  -0.6824712  -0.9767011  -0.00759733]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1226. State = [[-0.2594826   0.03086374  0.11984789  1.        ]]. Action = [[ 0.9359505  -0.7867954  -0.98599356 -0.01309538]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1227. State = [[-0.2683107   0.1166054   0.12280551  1.        ]]. Action = [[ 0.92748976 -0.8644311  -0.88394594 -0.12064159]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1228. State = [[-0.25710958  0.11920933  0.10379788  1.        ]]. Action = [[ 0.79884696 -0.7773503  -0.98704493  0.01623583]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1229. State = [[-0.2661886   0.07051023  0.12069743  1.        ]]. Action = [[ 0.92198443 -0.8732614  -0.9287652  -0.1089713 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1230. State = [[-0.25412345  0.06759774  0.10109674  1.        ]]. Action = [[ 0.91504693 -0.8664973  -0.91561437  0.00595737]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1231. State = [[-0.22241053  0.04191628  0.06688038  1.        ]]. Action = [[ 0.9752743  -0.93849    -0.8995111   0.01174247]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1232. State = [[-0.19911899  0.02326429  0.04035139  1.        ]]. Action = [[ 0.83849764 -0.7041232  -0.97569203 -0.00234145]]. Reward = [0.]
Curr episode timestep = 2
Action ignored: Workspace boundary
Current timestep = 1233. State = [[-0.19549842  0.01979978  0.03793165  1.        ]]. Action = [[ 0.93897426 -0.49774432 -0.9902795   0.02856994]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1234. State = [[-0.195474    0.01904233  0.03799618  1.        ]]. Action = [[ 0.9273057  -0.71934396 -0.91679037  0.06427848]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1235. State = [[-0.195474    0.01904233  0.03799618  1.        ]]. Action = [[ 0.90921366 -0.469437   -0.9148924  -0.07464141]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1236. State = [[-0.19537859  0.01871194  0.03803736  1.        ]]. Action = [[ 0.9610121  -0.6434935  -0.91445184  0.02675653]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1237. State = [[-0.19537516  0.01828848  0.0380767   1.        ]]. Action = [[ 0.80775905 -0.5248825  -0.9964269  -0.00678641]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1238. State = [[-0.19537461  0.01821783  0.03808329  1.        ]]. Action = [[ 0.94843197 -0.45142168 -0.9854883   0.03576016]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1239. State = [[-0.19537461  0.01821783  0.03808329  1.        ]]. Action = [[ 0.83869743 -0.76584876 -0.9701287   0.11567736]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1240. State = [[-0.19514927  0.01822986  0.03812867  1.        ]]. Action = [[ 0.70663035 -0.6489471  -0.95667773  0.09530818]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1241. State = [[-0.19487941  0.01824384  0.03814456  1.        ]]. Action = [[ 0.9297452  -0.7678728  -0.9380153   0.04663587]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1242. State = [[-0.19478963  0.01824775  0.03808515  1.        ]]. Action = [[-0.3428555  -0.69687605 -0.9011686   0.10646963]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Current timestep = 1243. State = [[-0.19478963  0.01824775  0.03808515  1.        ]]. Action = [[ 0.84670174 -0.7101025  -0.94494885  0.14203906]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1244. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.8895143  -0.8114054  -0.9346575   0.11047363]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1245. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.8258493  -0.9387906  -0.9700353   0.10844898]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1246. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.89459145 -0.8446153  -0.9726951   0.06427479]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1247. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.89558005 -0.2665403  -0.97408867  0.09098995]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1248. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.7772995  -0.60834986 -0.9656917   0.14313304]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1249. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.9540076  -0.5887492  -0.88926804  0.17309177]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1250. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.9320197  -0.407789   -0.9863281   0.18775666]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1251. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.88917136 -0.6796278  -0.8889244   0.1013881 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1252. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.90369    -0.7001637  -0.9936472   0.13485265]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1253. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.88967025 -0.8341895  -0.86674964  0.15105712]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1254. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.98548424 -0.43690252 -0.9767084   0.22567213]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1255. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.76209843 -0.5860224  -0.94397855  0.1661942 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1256. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.8150369  -0.6311581  -0.89113575  0.17426944]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1257. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.9322691  -0.8097122  -0.98032576  0.14400077]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1258. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.8471234  -0.8102715  -0.9223418   0.13173318]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1259. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.8411567  -0.7847117  -0.9568114   0.12299109]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1260. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.85707784 -0.5985174  -0.9041798   0.07481146]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1261. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.81233966 -0.4559195  -0.978788    0.24916089]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1262. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.84502184 -0.7965253  -0.9520217   0.15003753]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1263. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.8334886  -0.745389   -0.87844414  0.01503134]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1264. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.5986141  -0.6596352  -0.9716166  -0.00335789]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1265. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.8523705  -0.5778544  -0.80891883  0.09495008]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1266. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.6034112  -0.60418487 -0.97157544  0.07512093]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1267. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.92624426 -0.6857955  -0.9869639   0.06682158]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1268. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.83746386 -0.773709   -0.91590035  0.08413005]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1269. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.9488013  -0.8637347  -0.9751945   0.17990255]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1270. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.35713625 -0.47838515 -0.9613653   0.07250881]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 1271. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.9560387  -0.8790193  -0.9547746  -0.04216617]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1272. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.8426167  -0.7372447  -0.9578652   0.02238059]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1273. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.6628308  -0.6792002  -0.9621191   0.08446753]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1274. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.8110018  -0.7135551  -0.98335075  0.06713986]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1275. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.6026809  -0.7040104  -0.90835935  0.04354846]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1276. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.9574497  -0.63460964 -0.96871835  0.14367187]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1277. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.89565384 -0.741059   -0.97258055  0.04211962]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1278. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.7815734  -0.7531616  -0.90688837  0.0468179 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1279. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.7311685  -0.74949616 -0.70672596  0.02140427]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1280. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.7917311  -0.49371517 -0.9934417  -0.02091211]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1281. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.9506259  -0.85923547 -0.99232477  0.04233146]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1282. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.6956196  -0.88789666 -0.3996591   0.14777255]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1283. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.9433141  -0.34885752 -0.84585005  0.1318978 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1284. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.8870399  -0.46761286 -0.9512392   0.11842334]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1285. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.48367262 -0.4737472  -0.7695185   0.03153396]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 1286. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.08896554 -0.5085035  -0.9616548   0.03569543]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 1287. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.80898166 -0.54689217 -0.95650846  0.14750457]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1288. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.8132024  -0.47475314 -0.96774995  0.11186433]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1289. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.9651524  -0.1482166  -0.99387234  0.21906614]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1290. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.58451104 -0.5331346  -0.98471606  0.2159226 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1291. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.765062   -0.44584692 -0.99583083  0.05083787]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1292. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.84103477 -0.4439969  -0.98868865  0.07395649]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1293. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.87690735 -0.2268678  -0.89286983  0.11192524]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1294. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.36170125 -0.6676288  -0.9544133   0.03562558]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 1295. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.43407845 -0.40960985 -0.8982383   0.12064028]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 1296. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.71489    -0.5338522  -0.98214006  0.05530107]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1297. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.8041328  -0.7497426  -0.91651607  0.13118589]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1298. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.93106246 -0.6640235  -0.7129085   0.17759955]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1299. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.8455365  -0.33669913 -0.9224291   0.09851813]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1300. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.81862617 -0.5990379  -0.95813024  0.14929056]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1301. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.3187424  -0.80044    -0.8753201   0.07743537]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 1302. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.6455258  -0.63428164 -0.92624414  0.10135961]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1303. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.713421   -0.5865405  -0.99227273  0.20668697]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1304. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.20246947 -0.710456   -0.90658516  0.02612042]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 1305. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.7771325  -0.5855739  -0.9798342   0.20599985]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1306. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.64616954 -0.4907452  -0.9568106   0.0994432 ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1307. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.8133385  -0.54172987 -0.90497935  0.11168313]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1308. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.88379645 -0.73481333 -0.97433704  0.06838512]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1309. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.8792305  -0.69931626 -0.8838533   0.14890909]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1310. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.8273438  -0.75108856 -0.95903194  0.05320728]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1311. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.7334571 -0.6371691 -0.89508    0.0743959]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1312. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.88369465 -0.68170255 -0.9870785   0.01772702]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1313. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.8457444  -0.6341791  -0.98799944  0.11702371]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1314. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.9523696  -0.5215093  -0.9239867   0.04988706]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1315. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.8318548  -0.6588132  -0.9361844   0.13891995]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1316. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.8568289  -0.49462557 -0.872337    0.15599537]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1317. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.46462893 -0.7785893  -0.8188856   0.1257832 ]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 1318. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.64145195 -0.43047845 -0.9736823   0.14847612]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1319. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.86601496 -0.44584113 -0.9646967   0.06254196]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1320. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.93867326 -0.6083733  -0.9601115   0.2076534 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1321. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.89100456 -0.6672982  -0.74779284  0.18031168]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1322. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.5950949  -0.6775325  -0.94345903  0.09821248]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1323. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.7049923  -0.48470163 -0.95977855  0.19127047]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1324. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.7402638  -0.39665574 -0.7934743   0.28928208]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1325. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.8920764  -0.53032637 -0.9672056   0.21126473]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1326. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.7691231  -0.28749776 -0.70965177  0.25620735]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1327. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.8137033  -0.08029103 -0.87492913  0.19994605]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1328. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.5003729  -0.5551705  -0.9598718   0.17636383]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 1329. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[ 0.73697615 -0.7819119  -0.8904018   0.19028556]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1330. State = [[-0.19471453  0.01825176  0.03810034  1.        ]]. Action = [[-0.4062817  -0.33180904 -0.9027382   0.1579082 ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 1331. State = [[-0.2638402   0.08021732  0.12125814  1.        ]]. Action = [[ 0.8749552  -0.65851885 -0.93194896  0.15578127]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1332. State = [[-0.253551    0.08382931  0.10158571  1.        ]]. Action = [[ 0.8580146  -0.37655652 -0.9974535   0.16186512]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1333. State = [[-0.23320635  0.07265127  0.06350862  1.        ]]. Action = [[ 0.33176148 -0.54264563 -0.96834695  0.04960299]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1334. State = [[-0.22271487  0.0639399   0.03593099  1.        ]]. Action = [[ 0.46755886 -0.5380453  -0.8235846   0.07164931]]. Reward = [0.]
Curr episode timestep = 2
Action ignored: Workspace boundary
Current timestep = 1335. State = [[-0.22033828  0.06191204  0.03398097  1.        ]]. Action = [[ 0.8893976  -0.3277793  -0.94057775  0.18642735]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: Workspace boundary
Current timestep = 1336. State = [[-0.22028399  0.06128057  0.03387654  1.        ]]. Action = [[ 0.90819275 -0.6647592  -0.67375135  0.16444027]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: Workspace boundary
Current timestep = 1337. State = [[-0.22002523  0.06124095  0.03392123  1.        ]]. Action = [[ 0.85607195 -0.5478767  -0.98641497  0.1307497 ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: Workspace boundary
Current timestep = 1338. State = [[-0.22002523  0.06124095  0.03392123  1.        ]]. Action = [[ 0.7937224  -0.6073123  -0.87917817  0.20877743]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: Workspace boundary
Current timestep = 1339. State = [[-0.22002523  0.06124095  0.03392123  1.        ]]. Action = [[ 0.26038337 -0.6724408  -0.9714734   0.17127264]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: Workspace boundary
Current timestep = 1340. State = [[-0.22002523  0.06124095  0.03392123  1.        ]]. Action = [[ 0.8079246  -0.5003278  -0.63778967  0.15463758]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: Workspace boundary
Current timestep = 1341. State = [[-0.22002523  0.06124095  0.03392123  1.        ]]. Action = [[ 0.7789873  -0.5827346  -0.9705344   0.09344792]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: Workspace boundary
Current timestep = 1342. State = [[-0.22002523  0.06124095  0.03392123  1.        ]]. Action = [[ 0.44191408 -0.62400365 -0.97073865  0.16079187]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: Workspace boundary
Current timestep = 1343. State = [[-0.22002523  0.06124095  0.03392123  1.        ]]. Action = [[ 0.6386813  -0.7485081  -0.97079045  0.14341128]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: Workspace boundary
Current timestep = 1344. State = [[-0.22002523  0.06124095  0.03392123  1.        ]]. Action = [[ 0.6923325  -0.6427442  -0.91204125  0.08706129]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Current timestep = 1345. State = [[-0.22002523  0.06124095  0.03392123  1.        ]]. Action = [[ 0.78018165 -0.38913357 -0.9819581   0.07503045]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Current timestep = 1346. State = [[-0.22002523  0.06124095  0.03392123  1.        ]]. Action = [[ 0.74184227 -0.74921036 -0.92622834  0.20465362]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 1347. State = [[-0.22002523  0.06124095  0.03392123  1.        ]]. Action = [[ 0.6583004  -0.68053687 -0.99788517  0.10953784]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 1348. State = [[-0.22002523  0.06124095  0.03392123  1.        ]]. Action = [[ 0.6134685  -0.71695507 -0.9693889   0.03199196]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 1349. State = [[-0.22002523  0.06124095  0.03392123  1.        ]]. Action = [[ 0.13439965 -0.5710031  -0.98218006  0.11429799]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 1350. State = [[-0.22002523  0.06124095  0.03392123  1.        ]]. Action = [[ 0.714746   -0.39150685 -0.95635635  0.12315369]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 1351. State = [[-0.21987565  0.06125977  0.03394776  1.        ]]. Action = [[ 0.86152506 -0.43185258 -0.8461052   0.18282056]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 1352. State = [[-0.2198006   0.06126921  0.03396109  1.        ]]. Action = [[ 0.54150033 -0.38037455 -0.9088974   0.17425239]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 1353. State = [[-0.2198006   0.06126921  0.03396109  1.        ]]. Action = [[ 0.64053345 -0.3198949  -0.97899985  0.20523083]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 1354. State = [[-0.2198006   0.06126921  0.03396109  1.        ]]. Action = [[ 0.4830023  -0.17075068 -0.5306724   0.19845998]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 1355. State = [[-0.2198006   0.06126921  0.03396109  1.        ]]. Action = [[ 0.8692422 -0.4669119 -0.6404811  0.0296607]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 1356. State = [[-0.2198006   0.06126921  0.03396109  1.        ]]. Action = [[ 0.27242982 -0.03279394 -0.7060438   0.04813099]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 1357. State = [[-0.2198006   0.06126921  0.03396109  1.        ]]. Action = [[ 0.3210435  -0.22709787 -0.99062276  0.21154702]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 1358. State = [[-0.2198006   0.06126921  0.03396109  1.        ]]. Action = [[ 0.27046704 -0.00326657 -0.9657482   0.1306423 ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 1359. State = [[-0.2198006   0.06126921  0.03396109  1.        ]]. Action = [[ 0.3349781  -0.273852   -0.9565937   0.16816068]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 1360. State = [[-0.21972556  0.06127865  0.03397442  1.        ]]. Action = [[ 0.86111283 -0.4189843  -0.935266    0.16490662]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 1361. State = [[-0.21957093  0.06129811  0.03400194  1.        ]]. Action = [[ 0.66534686 -0.6653431  -0.89501345  0.13843179]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 1362. State = [[-0.21957093  0.06129811  0.03400194  1.        ]]. Action = [[ 0.679121   -0.47100568 -0.69574535  0.07085276]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 1363. State = [[-0.21957093  0.06129811  0.03400194  1.        ]]. Action = [[ 0.7140807  -0.5429444  -0.95821023  0.12780523]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 1364. State = [[-0.21957093  0.06129811  0.03400194  1.        ]]. Action = [[ 0.87219477 -0.70724726 -0.90245605  0.1357534 ]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 1365. State = [[-0.21957093  0.06129811  0.03400194  1.        ]]. Action = [[ 0.6481397  -0.3774333  -0.77377445  0.17357445]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 1366. State = [[-0.21957093  0.06129811  0.03400194  1.        ]]. Action = [[ 0.8018756  -0.5917514  -0.95214784  0.19125724]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 1367. State = [[-0.21957093  0.06129811  0.03400194  1.        ]]. Action = [[ 0.7393918  -0.4091426  -0.9357451   0.11994267]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 1368. State = [[-0.21957093  0.06129811  0.03400194  1.        ]]. Action = [[ 0.73654056 -0.652316   -0.9744393   0.17419374]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 1369. State = [[-0.21957093  0.06129811  0.03400194  1.        ]]. Action = [[ 0.8071486  -0.6764967  -0.94309956  0.05678558]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 1370. State = [[-0.21957093  0.06129811  0.03400194  1.        ]]. Action = [[ 0.7285552  -0.615814   -0.7963625   0.06425464]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 1371. State = [[-0.21957093  0.06129811  0.03400194  1.        ]]. Action = [[ 0.5178988  -0.49387378 -0.6793188   0.15430284]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 1372. State = [[-0.21957093  0.06129811  0.03400194  1.        ]]. Action = [[ 0.62111044 -0.45729434 -0.87309235  0.24023902]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 1373. State = [[-0.21957093  0.06129811  0.03400194  1.        ]]. Action = [[ 0.81005716 -0.48877144 -0.97482437  0.24209833]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 1374. State = [[-0.21957093  0.06129811  0.03400194  1.        ]]. Action = [[ 0.61532235 -0.14503694 -0.9531009   0.1595335 ]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 1375. State = [[-0.21957093  0.06129811  0.03400194  1.        ]]. Action = [[-0.52000505 -0.09669149 -0.8769923   0.22555947]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 1376. State = [[-0.21957093  0.06129811  0.03400194  1.        ]]. Action = [[ 0.6777415  -0.46378732 -0.87940407  0.21684718]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 1377. State = [[-0.21957093  0.06129811  0.03400194  1.        ]]. Action = [[-0.29296923 -0.47022164 -0.8672332   0.28954685]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 1378. State = [[-0.21957093  0.06129811  0.03400194  1.        ]]. Action = [[ 0.5676539   0.37708163 -0.95680535  0.07421207]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 1379. State = [[-0.21957093  0.06129811  0.03400194  1.        ]]. Action = [[ 0.85630727  0.29967546 -0.773704    0.30107093]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 1380. State = [[-0.21957093  0.06129811  0.03400194  1.        ]]. Action = [[ 0.60217106 -0.03808862 -0.7112121   0.2556045 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 1381. State = [[-0.21957093  0.06129811  0.03400194  1.        ]]. Action = [[ 0.48291254 -0.16473132 -0.8633913   0.20833087]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 1382. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[-0.03850043 -0.31023562 -0.8355697   0.28009844]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 1383. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.3844509  -0.4604882  -0.7562195   0.22047794]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 1384. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.338336   -0.08761877 -0.6994307   0.22541893]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 1385. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.67502     0.0659678  -0.8627172   0.20082176]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 1386. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.3501401  -0.49773806 -0.9719721   0.21034849]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 1387. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.70510757 -0.35213315 -0.9564919   0.14899135]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 1388. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.7181071  -0.44480622 -0.79728675  0.14908302]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 1389. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.30124974 -0.48137867 -0.98176897  0.15276241]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 1390. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.16187572 -0.24944979 -0.88584995  0.18673813]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 1391. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.5158056  -0.6182086  -0.96879786  0.16924202]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 1392. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.76702833 -0.7409258  -0.8608835   0.18335581]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 1393. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.45518708 -0.25343835 -0.8384625   0.15910816]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 1394. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.75602853 -0.2657132  -0.9230402   0.23485398]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 1395. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.40489912 -0.40311623 -0.9767621   0.11974728]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 1396. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.5622504  -0.22313195 -0.9140847   0.24067914]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 1397. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.55898225 -0.74539834 -0.88234824  0.15908432]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 1398. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.7073389  -0.29517663 -0.7947049   0.12944722]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 1399. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.19616544 -0.57408196 -0.9391857   0.21800447]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 1400. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.46842217 -0.5546849  -0.97523975  0.23683774]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 1401. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.8095403  -0.20089018 -0.8586402   0.24539971]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 1402. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.608397   -0.281677   -0.87068427  0.18700373]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 1403. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.5699637  -0.21440107 -0.871609    0.20481479]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 1404. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.87557244 -0.49893534 -0.84876657  0.16708171]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 1405. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.497033   -0.11264604 -0.9236138   0.21976852]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 1406. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.62386274 -0.38366348 -0.93959516  0.18940365]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 1407. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.6926578  -0.4882654  -0.1931991   0.22531676]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 1408. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.4710822  -0.2071687  -0.8508298   0.25328362]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 1409. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.20333922 -0.49811172 -0.9678618   0.18926072]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 1410. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[-0.14001888 -0.37396514 -0.97392726  0.17106295]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 1411. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.21406841 -0.4239167  -0.9571927   0.24712276]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 1412. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.504428   -0.26506186 -0.51742023  0.1592269 ]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 1413. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.64711857 -0.19913685 -0.87785316  0.2187376 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 1414. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.38547778 -0.3828665  -0.912893    0.19190824]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 1415. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.73434377 -0.5349805  -0.7734576   0.32505667]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 1416. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.26012003 -0.2994383  -0.95795524  0.24720657]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 1417. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.53678596 -0.59582275 -0.9088207   0.25896573]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 1418. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.621742   -0.09123671 -0.98294026  0.33519888]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 1419. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.36112     0.03925014 -0.9467767   0.18738592]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 1420. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.18597674 -0.4919803  -0.45248568  0.26340032]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 1421. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[-0.00954354 -0.59822446 -0.82127666  0.27439046]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 1422. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.6639991  -0.48949128 -0.7039725   0.1941129 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 1423. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 3.7882459e-01 -5.6350231e-04 -8.7422937e-01  2.2821999e-01]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 1424. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.8006964  -0.4217819  -0.26708174  0.27129102]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 1425. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.5594301  -0.41296637 -0.7458857   0.23486447]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 1426. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[-0.00668919 -0.25841433 -0.8788015   0.25473535]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 1427. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.49829614 -0.29792082 -0.91983217  0.2538967 ]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 1428. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.8500949  -0.02985042 -0.92305166  0.3705455 ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 1429. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.47716093 -0.1399678  -0.9588236   0.21357608]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 1430. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.7325145  -0.5659835  -0.94547874  0.19888675]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 1431. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.46860516 -0.24587941 -0.8526377   0.2692895 ]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 1432. State = [[-0.2194959   0.06130755  0.03401531  1.        ]]. Action = [[ 0.39374948 -0.3411929  -0.48374957  0.25003457]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 1433. State = [[-0.26355314  0.09076634  0.1206928   1.        ]]. Action = [[ 0.45037127 -0.4475357  -0.93618023  0.16612172]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 1434. State = [[-0.2593867   0.09426548  0.10000912  1.        ]]. Action = [[ 0.25722098 -0.5330933  -0.96828914  0.2604401 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1435. State = [[-0.24690911  0.08395928  0.06472434  1.        ]]. Action = [[ 0.6377833  -0.32528996 -0.7394911   0.16996753]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1436. State = [[-0.2361086   0.07730868  0.03540928  1.        ]]. Action = [[-0.18698645 -0.07865912 -0.6400819   0.33659565]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1437. State = [[-0.23720305  0.07381082  0.0184849   1.        ]]. Action = [[ 0.4581126  -0.12420118 -0.89885217  0.33240795]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: Workspace boundary
Current timestep = 1438. State = [[-0.23583117  0.07281105  0.01634827  1.        ]]. Action = [[ 0.68660474 -0.10723144 -0.98984     0.3179356 ]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: Workspace boundary
Current timestep = 1439. State = [[-0.23570037  0.07249514  0.01637864  1.        ]]. Action = [[ 0.52889276 -0.28150505 -0.9760034   0.2467326 ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: Workspace boundary
Current timestep = 1440. State = [[-0.23570037  0.07249514  0.01637864  1.        ]]. Action = [[ 0.12366176 -0.24602515 -0.91263074  0.33310926]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: Workspace boundary
Current timestep = 1441. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.4476813  -0.06336302 -0.91666573  0.23186207]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: Workspace boundary
Current timestep = 1442. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.46824884 -0.12309313 -0.9213967   0.2865348 ]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: Workspace boundary
Current timestep = 1443. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.44937682 -0.41827387 -0.81416184  0.25856686]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: Workspace boundary
Current timestep = 1444. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.54653513 -0.20015079 -0.86027     0.40463138]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: Workspace boundary
Current timestep = 1445. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.37988067 -0.24117517 -0.72337204  0.365108  ]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: Workspace boundary
Current timestep = 1446. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.34722638 -0.14627147 -0.9849481   0.21750486]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Current timestep = 1447. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.76185536 -0.4935528  -0.9723796   0.34577453]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Current timestep = 1448. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.8040261  -0.39402282 -0.80650115  0.20555961]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 1449. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.6395049  -0.16486359 -0.58590406  0.31701827]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 1450. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[-0.0510208  -0.37739587 -0.9636719   0.26777518]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 1451. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.7067661   0.177917   -0.94202834  0.32341492]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 1452. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.28618097 -0.7020707  -0.6181338   0.355322  ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 1453. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.29998982 -0.10069638 -0.9106564   0.29334867]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 1454. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.63771296 -0.47306705 -0.9187762   0.30055094]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 1455. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.23488736 -0.20483452 -0.8363671   0.24732816]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 1456. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.86031294  0.46909332 -0.87788135  0.41009927]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 1457. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.7780905  -0.0227387  -0.52057874  0.35199904]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 1458. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.3688773  -0.28824604 -0.343199    0.22289324]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 1459. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.67065    -0.36676788 -0.82529134  0.30356908]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 1460. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.6927366   0.21320844 -0.9668896   0.29692626]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 1461. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.00168777 -0.03226435 -0.33353066 -0.0927211 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 1462. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.4967507   0.10073495 -0.8123896   0.13164604]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 1463. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.72361743 -0.20852661 -0.7807369   0.28551698]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 1464. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 9.2330933e-01 -3.8665533e-04 -8.9861560e-01  2.5012219e-01]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 1465. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.0818156  -0.68658423 -0.47795147  0.43546772]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 1466. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.73044765 -0.34334445 -0.6457918   0.34034932]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 1467. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.38324142  0.1439538  -0.6960632   0.4214406 ]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 1468. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.14695692 -0.2890073  -0.759858    0.22833252]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 1469. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.08454871 -0.50181097 -0.91508996  0.16499329]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 1470. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[-0.32919115  0.11985958 -0.91911274  0.3429278 ]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 1471. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.5373571  -0.20491397 -0.96634525  0.30413198]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 1472. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.35125077  0.19453466 -0.79607934  0.18832183]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 1473. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.4926989   0.06024158 -0.61469704  0.33547103]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 1474. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.50180364  0.32712245 -0.6360533   0.28119802]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 1475. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.15281272 -0.24187505 -0.5274759   0.3448211 ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 1476. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.0411191  -0.11284107 -0.8827376   0.24844646]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 1477. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.41362154 -0.4540714  -0.9765135   0.20665193]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 1478. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.053563   -0.2373401  -0.96034276  0.2677865 ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 1479. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.8314979  -0.15755832 -0.9751785   0.2672317 ]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 1480. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.42088747 -0.3244834  -0.82331926  0.2436117 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 1481. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.49227858  0.0029285  -0.7317058   0.11701453]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 1482. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.23915517 -0.07936889 -0.9048517   0.3483827 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 1483. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[-0.09320801 -0.03138977 -0.6924739   0.19743896]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 1484. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.54032516  0.22170866 -0.90238714  0.31036282]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 1485. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[-0.36758018  0.23414648 -0.9796142   0.2911315 ]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 1486. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.10692585  0.17509127 -0.59487903  0.34324992]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 1487. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.1311295  -0.06523538 -0.9445487   0.37984967]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 1488. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.17371178  0.20451319 -0.7469354   0.19632351]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 1489. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.40997362  0.01309752 -0.8684963   0.36592555]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 1490. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.20477057 -0.28665113 -0.56284213  0.41945958]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 1491. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.55081606 -0.2976448  -0.89322895  0.41488826]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 1492. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.17693448  0.04022181 -0.84444654  0.2778126 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 1493. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.28432465 -0.19632554 -0.38423252  0.10693455]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 1494. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.4245261   0.08991063 -0.9449258   0.4251356 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 1495. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.07763445 -0.24968225 -0.6129353   0.19021308]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 1496. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[-0.06844187 -0.05555749 -0.94348764  0.42846966]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 1497. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.70848787  0.06955659 -0.9494779   0.36789358]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 1498. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.2896589   0.15376139 -0.30792755  0.40130424]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 1499. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[-0.13669944  0.02113712 -0.88073385  0.31225157]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 1500. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.6837193   0.40724647 -0.73791206  0.49689817]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 1501. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.48681498 -0.5207695  -0.78072304  0.34550405]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 1502. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.39538324 -0.3155455  -0.8619224   0.21640885]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 1503. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.79739356  0.32568502 -0.7362945   0.24806511]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 1504. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.7648189  -0.09956205 -0.22718143  0.45620835]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 1505. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.28485823 -0.4191097  -0.6592967   0.36556745]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 1506. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[-0.28500295  0.3687389  -0.7267948   0.23056138]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 1507. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[-0.00999939 -0.20900846 -0.8488009   0.4908619 ]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 1508. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.5056186  -0.13732153 -0.19805682  0.35853958]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 1509. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.80383515 -0.4985752  -0.7325528   0.39436555]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 1510. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.33413982  0.27973604 -0.9034659   0.46267593]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 1511. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.52502155  0.08898878 -0.6857047   0.5557653 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 1512. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.60301447  0.40324473 -0.86308134  0.2240293 ]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 1513. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.16450298 -0.1825167  -0.5048599   0.4489305 ]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 1514. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 0.2626679  -0.41216743 -0.44303846  0.07360756]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 1515. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[-0.01987851  0.29863596 -0.9486009   0.461066  ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 1516. State = [[-0.23567592  0.07228149  0.01639386  1.        ]]. Action = [[ 2.1541119e-04 -1.6922951e-03  2.2317290e-02  3.6822248e-01]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 1517. State = [[-0.2355258   0.07230449  0.01641499  1.        ]]. Action = [[ 0.39889348  0.29206312 -0.4906423   0.4399954 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 1518. State = [[-0.2355258   0.07230449  0.01641499  1.        ]]. Action = [[ 0.22579944  0.47047067 -0.1994707   0.40760565]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 1519. State = [[-0.2355258   0.07230449  0.01641499  1.        ]]. Action = [[-0.37199473 -0.02275521 -0.6713497   0.604928  ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 1520. State = [[-0.2355258   0.07230449  0.01641499  1.        ]]. Action = [[-0.48140597  0.08575308 -0.81073725  0.44783998]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 1521. State = [[-0.2355258   0.07230449  0.01641499  1.        ]]. Action = [[ 0.13680518 -0.14964592 -0.9732411   0.3897276 ]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 1522. State = [[-0.2355258   0.07230449  0.01641499  1.        ]]. Action = [[ 0.31665456 -0.3326676  -0.94411874  0.39980626]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 1523. State = [[-0.2355258   0.07230449  0.01641499  1.        ]]. Action = [[-0.45966774 -0.38780534 -0.9806917   0.48874295]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 1524. State = [[-0.2355258   0.07230449  0.01641499  1.        ]]. Action = [[-0.01552886  0.6421877  -0.82190704  0.33516622]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 1525. State = [[-0.2355258   0.07230449  0.01641499  1.        ]]. Action = [[ 0.28890312  0.33249736 -0.781325    0.50661874]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 1526. State = [[-0.2355258   0.07230449  0.01641499  1.        ]]. Action = [[-0.06878233  0.13165021 -0.8442799   0.5862787 ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 1527. State = [[-0.23567948  0.06686974  0.01674156  1.        ]]. Action = [[-0.3214029 -0.3728075  0.3102076  0.3188721]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 1528. State = [[-0.23676959  0.0693126   0.02223703  1.        ]]. Action = [[-0.10932034  0.57891226  0.53883076  0.6878301 ]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 1529. State = [[-0.23856995  0.07684004  0.02846319  1.        ]]. Action = [[-0.12182301  0.32152283 -0.89248574  0.39193654]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 1530. State = [[-0.24036847  0.0792049   0.03050328  1.        ]]. Action = [[-0.14933944  0.08264303  0.1291982   0.501789  ]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 1531. State = [[-0.2429962   0.08063148  0.03394583  1.        ]]. Action = [[ 0.42118466  0.08462596 -0.8509074   0.29103613]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 1532. State = [[-0.24497369  0.08034552  0.0340545   1.        ]]. Action = [[ 0.5530181   0.50196385 -0.42099178  0.44269812]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 1533. State = [[-0.24494694  0.08035372  0.03405955  1.        ]]. Action = [[ 0.32124424  0.49740243 -0.9466399   0.50451887]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 1534. State = [[-0.24494694  0.08035372  0.03405955  1.        ]]. Action = [[-0.00774598  0.66625595 -0.52817106  0.32676554]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 1535. State = [[-0.25205988 -0.07454233  0.12116706  1.        ]]. Action = [[-0.2211324  -0.06622803 -0.09236103  0.5285803 ]]. Reward = [0.]
Curr episode timestep = 101
Current timestep = 1536. State = [[-0.24628235 -0.0907088   0.10092133  1.        ]]. Action = [[ 0.6218159  -0.5040124  -0.9104491   0.26071286]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1537. State = [[-0.22917572 -0.10792376  0.06747209  1.        ]]. Action = [[ 0.53944755 -0.36478406 -0.811693    0.2843839 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1538. State = [[-0.2150407  -0.11641292  0.04481503  1.        ]]. Action = [[ 0.28520215 -0.16581595 -0.80239683  0.21752071]]. Reward = [0.]
Curr episode timestep = 2
Action ignored: Workspace boundary
Current timestep = 1539. State = [[-0.21290241 -0.11708385  0.04289596  1.        ]]. Action = [[ 0.46890128 -0.290114   -0.7219558   0.22935128]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: Workspace boundary
Current timestep = 1540. State = [[-0.21237226 -0.11724482  0.04296931  1.        ]]. Action = [[ 0.26681137 -0.51830673 -0.90694624  0.28466177]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: Workspace boundary
Current timestep = 1541. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.17934358 -0.21059668 -0.92443824  0.3191979 ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: Workspace boundary
Current timestep = 1542. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.5001731  -0.26937312 -0.6121707   0.20769048]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: Workspace boundary
Current timestep = 1543. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.28952217 -0.38570672 -0.7993526   0.17889369]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: Workspace boundary
Current timestep = 1544. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.37502742 -0.08365434 -0.90675956  0.17404139]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: Workspace boundary
Current timestep = 1545. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.45855272 -0.27898228 -0.4601481   0.23634076]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: Workspace boundary
Current timestep = 1546. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.26296914 -0.3481977  -0.789446    0.23503458]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: Workspace boundary
Current timestep = 1547. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.4401362  -0.29980063 -0.5879875   0.22833395]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: Workspace boundary
Current timestep = 1548. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.5815592  -0.17707545 -0.9079408   0.22620177]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Current timestep = 1549. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.25146008 -0.2836197  -0.8710872   0.2031281 ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Current timestep = 1550. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.59235823 -0.57735336 -0.7268881   0.30635858]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 1551. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.09524941 -0.60520977 -0.8723585   0.22480857]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 1552. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.32122827 -0.4160112  -0.8001167   0.31804705]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 1553. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.49844038 -0.19657171 -0.9023218   0.216326  ]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 1554. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.54750264 -0.23512948 -0.6789281   0.25651383]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 1555. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.54051113 -0.1816026  -0.9150699   0.29920268]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 1556. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.26450598 -0.21907258 -0.94601315  0.17462456]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 1557. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.15828669 -0.22005194 -0.9248919   0.26420975]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 1558. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.45621705 -0.39331806 -0.866654    0.19551313]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 1559. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.3313868  -0.24720013 -0.92609507  0.14834416]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 1560. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.5141132  -0.4123788  -0.81229794  0.12807024]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 1561. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.43350434 -0.30365777 -0.9453547   0.2518735 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 1562. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.32883954 -0.54034835 -0.96691865  0.22453535]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 1563. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.3725171  -0.16545314 -0.8812157   0.2190665 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 1564. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.4339739  -0.3037948  -0.73833233  0.1990602 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 1565. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.44521487 -0.13552654 -0.9505626   0.3153304 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 1566. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.13112211  0.06783319 -0.8465677   0.24490058]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 1567. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.45535135 -0.12238532 -0.945368    0.24470711]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 1568. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.38768792 -0.15181756 -0.6115549   0.24076617]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 1569. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.32477677 -0.22823358 -0.41020405  0.29934597]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 1570. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.31343293 -0.2692256  -0.84722203  0.23492157]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 1571. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.5726875  -0.2786584  -0.7275691   0.21152675]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 1572. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.29401755 -0.44556403 -0.754935    0.25186467]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 1573. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.4206357  -0.56534785 -0.81716937  0.17885995]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 1574. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.41640687 -0.14934266 -0.8987213   0.19594765]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 1575. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.28077126 -0.5861681  -0.80410033  0.24308777]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 1576. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.35986054 -0.20950615 -0.80930567  0.28761983]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 1577. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.3904686  -0.13646305 -0.9309145   0.26220214]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 1578. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.42795348 -0.54549617 -0.7813852   0.25521076]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 1579. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.2563784  -0.43115163 -0.64037997  0.30349648]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 1580. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.20757103 -0.5419159  -0.79995364  0.28654206]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 1581. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.35374093  0.01804078 -0.8328793   0.28802907]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 1582. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.259547   -0.31520367 -0.3979534   0.2641008 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 1583. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.154145   -0.35745668 -0.7245282   0.26554823]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 1584. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.649775    0.24122405 -0.8711146   0.10172379]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 1585. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.48651505 -0.5111385  -0.82144874  0.19308162]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 1586. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.3547187  -0.18678254 -0.68999994  0.23852992]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 1587. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.35422337 -0.25546116 -0.7544074   0.2409426 ]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 1588. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.5188911  -0.48211443 -0.8688271   0.26793337]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 1589. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.5223024  -0.50202984 -0.7250755   0.21573794]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 1590. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.3484167  -0.43709874 -0.8832434   0.2426579 ]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 1591. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.4812721  -0.481363   -0.7894006   0.25547028]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 1592. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.60683966 -0.1514638  -0.78757304  0.25451076]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 1593. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.6203799  -0.18538117 -0.93586427  0.24563825]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 1594. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.33268845 -0.25466716 -0.94807005  0.23062396]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 1595. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.51776934 -0.2975998  -0.80333656  0.25151622]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 1596. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.3596065  -0.30117172 -0.8142468   0.26358235]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 1597. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.5859163  -0.07762527 -0.89143974  0.2980162 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 1598. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.48942125 -0.44418472 -0.79318005  0.35679066]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 1599. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.48936963 -0.40108    -0.585024    0.22279894]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 1600. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.6120584  -0.00595528 -0.7666339   0.21875703]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 1601. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.32899952 -0.40222955 -0.90815485  0.18715906]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 1602. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.45179546 -0.02048546 -0.88052297  0.26605463]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 1603. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.06713903 -0.15363157 -0.8694545   0.27885795]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 1604. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.39202905 -0.18001223 -0.7002916   0.27124858]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 1605. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.35783672 -0.51002437 -0.67703545  0.24857414]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 1606. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.21581793 -0.25085223 -0.85746914  0.35639954]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 1607. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.32935107 -0.2706082  -0.57864356  0.33348072]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 1608. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.4365909  -0.32273066 -0.8111913   0.23338068]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 1609. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.5034857  -0.29997754 -0.9339904   0.29911923]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 1610. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.35630488 -0.15725952 -0.6862191   0.25983655]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 1611. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.50087714 -0.37658757 -0.89279765  0.28825283]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 1612. State = [[-0.21229766 -0.11726055  0.04297975  1.        ]]. Action = [[ 0.5343065  -0.16588724 -0.32388043  0.2754748 ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 1613. State = [[-0.20781471 -0.12379148  0.04090774  1.        ]]. Action = [[ 0.32937872 -0.39197284 -0.18313098  0.29864514]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 1614. State = [[-0.20127916 -0.131021    0.03476807  1.        ]]. Action = [[ 0.44713354 -0.28182185 -0.9553025   0.37362194]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 1615. State = [[-0.20124175 -0.13127112  0.03465148  1.        ]]. Action = [[ 0.06414366 -0.28210902 -0.6128778   0.34829485]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 1616. State = [[-0.20124175 -0.13127112  0.03465148  1.        ]]. Action = [[ 0.5179517  -0.11399686 -0.45533     0.29061794]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 1617. State = [[-0.20123924 -0.13132282  0.0346515   1.        ]]. Action = [[ 0.7714839  -0.33709764 -0.55473685  0.2896644 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1618. State = [[-0.20116559 -0.13133994  0.03466248  1.        ]]. Action = [[ 0.48765576 -0.29511988 -0.8896045   0.18527806]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 1619. State = [[-0.20116559 -0.13133994  0.03466248  1.        ]]. Action = [[ 0.68194616 -0.37821507 -0.6225285   0.3034556 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1620. State = [[-0.20116559 -0.13133994  0.03466248  1.        ]]. Action = [[ 0.39008105 -0.3823427  -0.6832625   0.14424944]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 1621. State = [[-0.20116559 -0.13133994  0.03466248  1.        ]]. Action = [[ 0.56275964 -0.52497536 -0.21772444  0.32954514]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 1622. State = [[-0.20101725 -0.1313744   0.03468462  1.        ]]. Action = [[ 0.6836784  -0.36971653 -0.60891837  0.17681587]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1623. State = [[-0.20094308 -0.13139164  0.03469571  1.        ]]. Action = [[ 0.36584604 -0.51147485 -0.55464184  0.30029488]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 1624. State = [[-0.20094308 -0.13139164  0.03469571  1.        ]]. Action = [[ 0.3636706  -0.55207825 -0.8867168   0.20500302]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 1625. State = [[-0.20094308 -0.13139164  0.03469571  1.        ]]. Action = [[ 0.4971069  -0.35437226 -0.93007183  0.19973326]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 1626. State = [[-0.20094308 -0.13139164  0.03469571  1.        ]]. Action = [[ 0.61597323 -0.5960775  -0.861785    0.24885404]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 1627. State = [[-0.20094308 -0.13139164  0.03469571  1.        ]]. Action = [[ 0.6146573  -0.21159184 -0.9588987   0.3154533 ]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 1628. State = [[-0.20094308 -0.13139164  0.03469571  1.        ]]. Action = [[ 0.24995995 -0.3975991  -0.8003752   0.30562377]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 1629. State = [[-0.20094308 -0.13139164  0.03469571  1.        ]]. Action = [[ 0.66426015 -0.3300737  -0.8712967   0.2709427 ]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 1630. State = [[-0.20094308 -0.13139164  0.03469571  1.        ]]. Action = [[ 0.30902696 -0.31674135 -0.72246027  0.27686405]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 1631. State = [[-0.20094308 -0.13139164  0.03469571  1.        ]]. Action = [[ 0.5249703  -0.33562195 -0.8915285   0.27809143]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 1632. State = [[-0.20094308 -0.13139164  0.03469571  1.        ]]. Action = [[ 0.61589384 -0.02445155 -0.7748558   0.284037  ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 1633. State = [[-0.20094308 -0.13139164  0.03469571  1.        ]]. Action = [[ 0.21422076 -0.32889068 -0.7447047   0.21505034]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 1634. State = [[-0.20094308 -0.13139164  0.03469571  1.        ]]. Action = [[ 0.6849853  -0.43673742 -0.8390895   0.27019536]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1635. State = [[-0.20094308 -0.13139164  0.03469571  1.        ]]. Action = [[ 0.6511097  -0.33876568 -0.8123101   0.22809744]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 1636. State = [[-0.20094308 -0.13139164  0.03469571  1.        ]]. Action = [[ 0.4063667  -0.3214913  -0.96240973  0.28689075]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 1637. State = [[-0.2560507  -0.17011923  0.11991102  1.        ]]. Action = [[ 0.42782474 -0.6688408  -0.9259742   0.18494523]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 1638. State = [[-0.25240242 -0.19446608  0.09976953  1.        ]]. Action = [[ 0.5156746  -0.44644833 -0.9284513   0.20976937]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1639. State = [[-0.23615627 -0.20836967  0.06381142  1.        ]]. Action = [[ 0.47887146 -0.30749226 -0.96831584  0.20781755]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1640. State = [[-0.22455673 -0.21674214  0.03624043  1.        ]]. Action = [[ 0.5737312  -0.61165804 -0.80816376  0.3270173 ]]. Reward = [0.]
Curr episode timestep = 2
Action ignored: Workspace boundary
Current timestep = 1641. State = [[-0.22278392 -0.21713033  0.03314621  1.        ]]. Action = [[ 0.6516135  -0.6647931  -0.74078065  0.30172372]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: Workspace boundary
Current timestep = 1642. State = [[-0.22232133 -0.21696208  0.03313558  1.        ]]. Action = [[ 0.51703715 -0.480408   -0.9162841   0.27339256]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: Workspace boundary
Current timestep = 1643. State = [[-0.22229105 -0.21690166  0.0331266   1.        ]]. Action = [[ 0.49880898 -0.5260219  -0.9585378   0.27887595]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: Workspace boundary
Current timestep = 1644. State = [[-0.22218908 -0.21680798  0.03309089  1.        ]]. Action = [[ 0.44947612 -0.5042899  -0.86764467  0.36569953]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: Workspace boundary
Current timestep = 1645. State = [[-0.22218908 -0.21680798  0.03309089  1.        ]]. Action = [[ 0.41269183 -0.47887385 -0.6013688   0.29373324]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: Workspace boundary
Current timestep = 1646. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.40907335 -0.63664913 -0.69286984  0.26387072]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: Workspace boundary
Current timestep = 1647. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.43490005 -0.47247517 -0.9368001   0.22442293]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: Workspace boundary
Current timestep = 1648. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.41499388 -0.645304   -0.81018984  0.29128003]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: Workspace boundary
Current timestep = 1649. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.33864844 -0.5177883  -0.8215808   0.24753296]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: Workspace boundary
Current timestep = 1650. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.56280136 -0.6765047  -0.8360899   0.18182933]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Current timestep = 1651. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.30606806 -0.54662985 -0.8432869   0.28823054]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Current timestep = 1652. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.08556306 -0.5508905  -0.86327773  0.25359428]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 1653. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.54785335 -0.36961687 -0.8449426   0.31385016]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 1654. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.6445513  -0.5350512  -0.72495955  0.35298014]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 1655. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.3399999  -0.79584205 -0.5764584   0.3502978 ]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 1656. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.56504846 -0.7691735  -0.6460613   0.26502383]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 1657. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.5282241  -0.33837378 -0.9687182   0.34502387]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 1658. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.2945435  -0.20500976 -0.71949774  0.28855324]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 1659. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.2792306  -0.4644003  -0.6914503   0.20326662]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 1660. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.66141343 -0.23353505 -0.9304837   0.24763834]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 1661. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.52971697 -0.01991051 -0.968724    0.3953848 ]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 1662. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.6340598  -0.31461173 -0.7764187   0.3175347 ]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 1663. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.57295156 -0.44571668 -0.669164    0.32050395]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 1664. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.59975314 -0.4365728  -0.26847017  0.17131329]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 1665. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.16820383 -0.44879186 -0.95975846  0.34443104]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 1666. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.18909729 -0.5630025  -0.7848875   0.23337007]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 1667. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.25371397 -0.50003356 -0.9275939   0.27584577]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 1668. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.2816007  -0.24184012 -0.95195687  0.2956897 ]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 1669. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.5036508  -0.46967328 -0.36400962  0.2611835 ]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 1670. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.6383207  -0.7086435  -0.50470215  0.21589017]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 1671. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.3661306  -0.5790502  -0.27521253  0.34168828]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 1672. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.31462348 -0.4006716  -0.78218156  0.2971846 ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 1673. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.49370396 -0.1336407  -0.23718876  0.4178605 ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 1674. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.3615588  -0.3867119  -0.8761656   0.33572555]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 1675. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.43073976 -0.28090727 -0.71552044  0.34250975]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 1676. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.537467   -0.46600378 -0.93130535  0.43597806]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 1677. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.6608038  -0.11011624 -0.87448895  0.3866483 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 1678. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.60201347 -0.41539013 -0.6229853   0.29822838]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 1679. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.48790026 -0.08966088 -0.62814707  0.32129407]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 1680. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.44782495 -0.51819885 -0.88461095  0.22569323]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 1681. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.53008556 -0.49187917 -0.5842935   0.33454037]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 1682. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.541914   -0.70663214 -0.92038304  0.38156164]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 1683. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.6485963  -0.76103204 -0.8051678   0.29876077]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 1684. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.6478561  -0.6644805  -0.63256836  0.32069516]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 1685. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.51912487 -0.7069951  -0.86814976  0.2945826 ]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 1686. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.26916778 -0.72063035 -0.90896136  0.2748654 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 1687. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.4946282 -0.7814234 -0.9299491  0.2688688]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 1688. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.5840323  -0.41081023 -0.7254197   0.30898428]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 1689. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.5779214  -0.586166   -0.8836968   0.20236182]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 1690. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.734215   -0.42480862 -0.4613843   0.27208662]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 1691. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.64140296 -0.57009816 -0.9394857   0.2624699 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 1692. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.39815414 -0.44679272 -0.30781114  0.30416715]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 1693. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.60753214 -0.64042085 -0.91028816  0.313362  ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 1694. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.13914454 -0.16584778 -0.80323815  0.20044541]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 1695. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.23097026 -0.7549631  -0.37228012  0.32899475]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 1696. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.78813386 -0.3143428  -0.93612885  0.3627125 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 1697. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.6800426  -0.6190114  -0.7426091   0.38197958]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 1698. State = [[-0.22212853 -0.2166871   0.03307301  1.        ]]. Action = [[ 0.5176444  -0.54561037 -0.6758264   0.34892893]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 1699. State = [[-0.21580939 -0.22159101  0.0330846   1.        ]]. Action = [[ 0.46293473 -0.3632996  -0.0655753   0.5415592 ]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 1700. State = [[-0.19867826 -0.23663075  0.03155797  1.        ]]. Action = [[ 0.63011336 -0.5549793  -0.08880758  0.3152821 ]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 1701. State = [[-0.18658124 -0.2489333   0.0257867   1.        ]]. Action = [[ 0.76917756 -0.55761456 -0.7717417   0.27035832]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 1702. State = [[-0.17760336 -0.2565961   0.02533863  1.        ]]. Action = [[ 0.5409107  -0.44265634  0.14430201  0.3787508 ]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 1703. State = [[-0.15572216 -0.27371305  0.03242216  1.        ]]. Action = [[ 0.58508945 -0.48195422  0.46797907  0.3356111 ]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 1704. State = [[-0.1396108  -0.28574842  0.03927851  1.        ]]. Action = [[ 0.6433066  -0.7798126  -0.6815863   0.22591877]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 1705. State = [[-0.13774483 -0.28733635  0.04000191  1.        ]]. Action = [[ 0.5273335 -0.8065033 -0.983603   0.1033206]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 1706. State = [[-0.13693398 -0.28788054  0.04029107  1.        ]]. Action = [[ 0.45270133 -0.7789001  -0.8347749   0.24645936]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 1707. State = [[-0.136559   -0.2879529   0.04049344  1.        ]]. Action = [[ 0.627987   -0.7817733  -0.937062    0.28033483]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 1708. State = [[-0.13664274 -0.28798878  0.04049956  1.        ]]. Action = [[ 0.62001157 -0.830752   -0.9346291   0.24524975]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 1709. State = [[-0.13650833 -0.28803343  0.0406135   1.        ]]. Action = [[ 0.7432575  -0.7402731  -0.92676926  0.24347436]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 1710. State = [[-0.13620988 -0.2881724   0.04073698  1.        ]]. Action = [[ 0.59091973 -0.81811297 -0.8716507   0.19922912]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 1711. State = [[-0.13601243 -0.28826946  0.04080191  1.        ]]. Action = [[ 0.67633605 -0.86745715 -0.99029917  0.17544436]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 1712. State = [[-0.13567986 -0.28841162  0.04098175  1.        ]]. Action = [[ 0.7359326  -0.8504859  -0.95370936  0.16970217]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 1713. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.57835245 -0.8539621  -0.9061549   0.18112504]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 1714. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.72866845 -0.85652375 -0.8777531   0.23973143]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 1715. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.7147385  -0.79757893 -0.94006264  0.25120556]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 1716. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.7153903  -0.81401616 -0.90667737  0.2106452 ]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 1717. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.6227164  -0.6725746  -0.8783411   0.22779155]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 1718. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.6478746  -0.70512724 -0.9443477   0.22226119]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 1719. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.45060825 -0.824967   -0.9474705   0.26163602]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 1720. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.7585447  -0.77878    -0.9134728   0.17324114]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 1721. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.56794167 -0.5295277  -0.91424096  0.1776011 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 1722. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.5271926  -0.701315   -0.86860234  0.25596523]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 1723. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.6216264  -0.55914843 -0.9584049   0.31025767]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 1724. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.44547522 -0.561864   -0.9652897   0.24836946]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 1725. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.32188118 -0.7971326  -0.80718887  0.26652133]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 1726. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.37054563 -0.48545778 -0.41448212  0.29934442]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 1727. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.6638557  -0.37863564 -0.8699944   0.26695728]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 1728. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.7163142  -0.72936535 -0.12922895  0.18907022]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 1729. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.72104526 -0.7892079  -0.89268947  0.21703422]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 1730. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.59316134 -0.85474616  0.21530974  0.19802272]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 1731. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.5060179  -0.5331627  -0.7707604   0.20860255]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 1732. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.7841934  -0.9305632  -0.8670322   0.15119886]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 1733. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.5647993  -0.83892184 -0.96144605  0.18690062]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 1734. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.6107589  -0.9021208  -0.88773483  0.3165027 ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 1735. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.56141686 -0.8464095  -0.90465486  0.26159668]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 1736. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.6780839  -0.7396907  -0.89529324  0.23828149]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 1737. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.7846894  -0.89207    -0.90265477  0.290509  ]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 1738. State = [[-0.13530956 -0.28859168  0.04111054  1.        ]]. Action = [[ 0.5180565  -0.79786694 -0.925063    0.2823341 ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 1739. State = [[-0.25669566 -0.1128707   0.11016339  1.        ]]. Action = [[ 0.6948236  -0.86178416 -0.9471562   0.26303434]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 1740. State = [[-0.24947776 -0.12725158  0.09769698  1.        ]]. Action = [[ 0.6654813  -0.17662412  0.5106149   0.42349386]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1741. State = [[-0.23855087 -0.12404995  0.09856922  1.        ]]. Action = [[ 0.21628737  0.52144766 -0.35007787  0.47645628]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1742. State = [[-0.22697353 -0.11274503  0.08955804  1.        ]]. Action = [[ 0.56255126  0.1969459  -0.8373033   0.48709798]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1743. State = [[-0.20699961 -0.10825031  0.06513239  1.        ]]. Action = [[ 0.44894707  0.00154483 -0.46651697  0.51426864]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1744. State = [[-0.19616425 -0.10873704  0.0521304   1.        ]]. Action = [[ 0.45806515  0.47114396 -0.7389205   0.5783739 ]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: Workspace boundary
Current timestep = 1745. State = [[-0.18921475 -0.09943613  0.0469003   1.        ]]. Action = [[ 0.37827396  0.5606134  -0.38441575  0.41475463]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1746. State = [[-0.17620799 -0.09121233  0.04093295  1.        ]]. Action = [[ 0.38294327 -0.0825156   0.10902953  0.45161104]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1747. State = [[-0.16910109 -0.09032489  0.04136098  1.        ]]. Action = [[ 0.66042376  0.18245709 -0.8396279   0.4691924 ]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1748. State = [[-0.16744986 -0.0900421   0.04023257  1.        ]]. Action = [[ 0.22482824  0.43200982 -0.0711323   0.46451426]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 1749. State = [[-0.16701788 -0.08990059  0.03973056  1.        ]]. Action = [[ 0.6893189   0.1424582  -0.17565238  0.37841594]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 1750. State = [[-0.16702022 -0.08976153  0.03919087  1.        ]]. Action = [[ 0.6899713   0.5306313  -0.18426049  0.3800969 ]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 1751. State = [[-0.16688691 -0.08978477  0.03910224  1.        ]]. Action = [[ 0.5656452  -0.15644419 -0.5517893   0.27023423]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1752. State = [[-0.16688691 -0.08978477  0.03910224  1.        ]]. Action = [[ 0.42911887 -0.47944933 -0.35871243  0.35711944]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1753. State = [[-0.16693132 -0.08970527  0.03900857  1.        ]]. Action = [[0.61961436 0.148139   0.4599315  0.26778758]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: No entry zone
Current timestep = 1754. State = [[-0.1669612  -0.0897      0.03896371  1.        ]]. Action = [[ 0.75624275 -0.27823603 -0.7568057   0.3792976 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1755. State = [[-0.1669612  -0.0897      0.03896371  1.        ]]. Action = [[ 0.78154993 -0.26344538 -0.8932873   0.2853365 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1756. State = [[-0.1669612  -0.0897      0.03896371  1.        ]]. Action = [[ 0.42767715 -0.331648   -0.3607635   0.32377553]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1757. State = [[-0.1669612  -0.0897      0.03896371  1.        ]]. Action = [[ 0.37019038 -0.55179137 -0.35708404  0.19701827]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1758. State = [[-0.1669612  -0.0897      0.03896371  1.        ]]. Action = [[ 0.64324594 -0.30116117  0.24529755  0.32073677]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: No entry zone
Current timestep = 1759. State = [[-0.16688693 -0.08971301  0.03897877  1.        ]]. Action = [[ 0.66243243 -0.5887985  -0.8639485   0.34223366]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1760. State = [[-0.16688693 -0.08971301  0.03897877  1.        ]]. Action = [[ 0.5688778   0.06079674 -0.5873486   0.22986412]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1761. State = [[-0.16688693 -0.08971301  0.03897877  1.        ]]. Action = [[ 0.57189536  0.00666821 -0.39250708  0.33034015]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1762. State = [[-0.16688693 -0.08971301  0.03897877  1.        ]]. Action = [[ 0.45186317  0.24475813 -0.22689629  0.36715484]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: No entry zone
Current timestep = 1763. State = [[-0.16688693 -0.08971301  0.03897877  1.        ]]. Action = [[ 0.5535655   0.03538823 -0.74370134  0.42480302]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1764. State = [[-0.16688693 -0.08971301  0.03897877  1.        ]]. Action = [[ 0.5447035  -0.33616984 -0.6167393   0.41972923]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1765. State = [[-0.16688693 -0.08971301  0.03897877  1.        ]]. Action = [[ 0.63522196  0.29238045 -0.12324393  0.32132185]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: No entry zone
Current timestep = 1766. State = [[-0.16688693 -0.08971301  0.03897877  1.        ]]. Action = [[ 0.73390007  0.02841306 -0.20839983  0.38576472]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: No entry zone
Current timestep = 1767. State = [[-0.16688693 -0.08971301  0.03897877  1.        ]]. Action = [[ 0.24423242 -0.01653296 -0.44330037  0.3488642 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1768. State = [[-0.16688693 -0.08971301  0.03897877  1.        ]]. Action = [[ 0.5307503   0.30213714 -0.6369311   0.39961255]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1769. State = [[-0.16688693 -0.08971301  0.03897877  1.        ]]. Action = [[ 0.6364331  -0.42313683 -0.06303757  0.29247618]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: No entry zone
Current timestep = 1770. State = [[-0.16691652 -0.08970779  0.03893432  1.        ]]. Action = [[ 0.5906005  -0.12099713 -0.39249682  0.31052625]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1771. State = [[-0.16691652 -0.08970779  0.03893432  1.        ]]. Action = [[ 0.68182445  0.06762099 -0.46771646  0.3551525 ]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1772. State = [[-0.16691652 -0.08970779  0.03893432  1.        ]]. Action = [[ 0.27396667 -0.16649085 -0.9040589   0.38075364]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1773. State = [[-0.16691652 -0.08970779  0.03893432  1.        ]]. Action = [[ 0.53856325 -0.55790323 -0.3981259   0.33392584]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1774. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.5475899  -0.17132366 -0.86292815  0.31134915]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1775. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.47338295 -0.07710612 -0.6188255   0.2709005 ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1776. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.3378476  -0.5262386  -0.24047029  0.3782606 ]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: No entry zone
Current timestep = 1777. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.71476066 -0.07367641 -0.7983275   0.3741417 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1778. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.74238586 -0.04537445 -0.84607375  0.41698313]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1779. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.73108363 -0.5980022  -0.01774496  0.4017241 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: No entry zone
Current timestep = 1780. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.6309314  -0.2771088  -0.88049644  0.455423  ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1781. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.56134176 -0.44681174 -0.26770592  0.39668798]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1782. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.6044569   0.09278631 -0.77374697  0.40924323]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1783. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[0.7243401  0.27258027 0.04461312 0.45871127]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: No entry zone
Current timestep = 1784. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.7279403  -0.6727302  -0.19378424  0.47997856]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: No entry zone
Current timestep = 1785. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.5997509  -0.5049349   0.5679884   0.50873494]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: No entry zone
Current timestep = 1786. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[0.64991665 0.6738111  0.6369078  0.3826971 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: No entry zone
Current timestep = 1787. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[0.6098782  0.36091256 0.3590529  0.24607038]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: No entry zone
Current timestep = 1788. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.5004399  -0.5328449  -0.22056806  0.5280638 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: No entry zone
Current timestep = 1789. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.47700262 -0.2305538   0.34709978  0.41909313]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: No entry zone
Current timestep = 1790. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.61384475 -0.48899323  0.48271775  0.29671645]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: No entry zone
Current timestep = 1791. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.42191803  0.00231719 -0.56131434  0.23962581]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1792. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.6023197  -0.8299809  -0.48006248  0.40597034]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1793. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.6758423  -0.6403166   0.08005059  0.2661382 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: No entry zone
Current timestep = 1794. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.4545462  -0.3994665  -0.43609756  0.41362047]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1795. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.7711096  -0.3286909  -0.40105855  0.2432524 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1796. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.18825126 -0.6387722  -0.5341533   0.2073251 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1797. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.7044288  -0.48734212 -0.19634032  0.26865125]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: No entry zone
Current timestep = 1798. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.5569184  -0.44678682 -0.57952195  0.3030504 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1799. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.25802398 -0.5160514  -0.48136425  0.28238523]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1800. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.5096357  -0.39658302  0.28925002  0.39532483]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: No entry zone
Current timestep = 1801. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.51976717 -0.29056883 -0.51881135  0.4142344 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1802. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.7242286  -0.01987678  0.654366    0.34186828]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: No entry zone
Current timestep = 1803. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.69653535 -0.02847958 -0.3339346   0.57956886]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1804. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.76760316 -0.41006994 -0.32827395  0.41979802]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1805. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.8749435  -0.09851128  0.7522038   0.40572798]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: No entry zone
Current timestep = 1806. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.7748978  -0.27591485  0.12374091  0.3960079 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: No entry zone
Current timestep = 1807. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.41244888 -0.47118336  0.22798586  0.35615408]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: No entry zone
Current timestep = 1808. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.588125   -0.46919018 -0.24301827  0.2984972 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: No entry zone
Current timestep = 1809. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.7855375  -0.3332628   0.44776046  0.4566375 ]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: No entry zone
Current timestep = 1810. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.5902281  -0.16721827 -0.27322805  0.38879025]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1811. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.5768025  -0.49707192  0.26517653  0.40306377]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: No entry zone
Current timestep = 1812. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.6866001  -0.5927524  -0.18010187  0.4163022 ]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: No entry zone
Current timestep = 1813. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.72575355 -0.63320553  0.53425395  0.3088076 ]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: No entry zone
Current timestep = 1814. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.46484494 -0.5663855  -0.04264194  0.37189186]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: No entry zone
Current timestep = 1815. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.5699148  -0.6528116  -0.72013897  0.3944    ]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1816. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.7409594  -0.54317707 -0.6319803   0.32182443]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1817. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.8324928  -0.6952788  -0.37040114  0.17806876]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1818. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.4460237  -0.54370886 -0.65702325  0.38371623]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1819. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.81201017 -0.39073718  0.19068539  0.2571392 ]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: No entry zone
Current timestep = 1820. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.6652801  -0.24933738 -0.09899306  0.4375881 ]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: No entry zone
Current timestep = 1821. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.7817384  -0.5768413   0.4720391   0.41699696]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: No entry zone
Current timestep = 1822. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.5806782  -0.64606357 -0.7419994   0.31372523]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1823. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.7973622  -0.4883343  -0.01758176  0.35309756]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: No entry zone
Current timestep = 1824. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.29547608 -0.7568306   0.54124165  0.3756969 ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: No entry zone
Current timestep = 1825. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.74792755 -0.19374317  0.59293723  0.36815214]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: No entry zone
Current timestep = 1826. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.72831964 -0.4020372  -0.25255203  0.18579912]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1827. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.6377487  -0.60754645 -0.3857699   0.36665356]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1828. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.73432016 -0.6401082   0.43032694  0.30417633]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: No entry zone
Current timestep = 1829. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.84616816 -0.31015575  0.20999777  0.47855306]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: No entry zone
Current timestep = 1830. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[0.87367463 0.2865163  0.44584215 0.47533703]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: No entry zone
Current timestep = 1831. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.74122655 -0.09976876 -0.26679432  0.57871675]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1832. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.7127538  -0.2523396   0.77098715  0.52472043]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: No entry zone
Current timestep = 1833. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.798908   -0.5890659  -0.37890244  0.41612983]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1834. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.41000152 -0.6755263   0.52864766  0.3833109 ]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: No entry zone
Current timestep = 1835. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.8241439  -0.62627447 -0.08909005  0.46387696]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: No entry zone
Current timestep = 1836. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.60007703 -0.46517128  0.6382487   0.44915235]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: No entry zone
Current timestep = 1837. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.7075205  -0.3361013   0.75375605  0.2333324 ]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: No entry zone
Current timestep = 1838. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.66088367 -0.35462582  0.38935816  0.37197113]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: No entry zone
Current timestep = 1839. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.68667436 -0.8256699   0.08569336  0.4587462 ]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: No entry zone
Current timestep = 1840. State = [[-0.16694611 -0.08970257  0.03888988  1.        ]]. Action = [[ 0.76277506 -0.39355242  0.4504211   0.3788669 ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: No entry zone
Current timestep = 1841. State = [[-0.25389823 -0.09478696  0.11162087  1.        ]]. Action = [[ 0.8864398  -0.81421125 -0.25299335  0.41419935]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 1842. State = [[-0.24315974 -0.11398716  0.10182004  1.        ]]. Action = [[ 0.83649766 -0.57609344  0.3458464   0.58252585]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1843. State = [[-0.21929333 -0.13253719  0.111624    1.        ]]. Action = [[ 0.88481545 -0.44700927  0.7603588   0.5566678 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1844. State = [[-0.1871114  -0.15373683  0.12691636  1.        ]]. Action = [[ 0.7266576  -0.7118757  -0.11803651  0.39057362]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1845. State = [[-0.16041929 -0.18149537  0.13077033  1.        ]]. Action = [[ 0.7609048  -0.7536364  -0.15853417  0.37279558]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1846. State = [[-0.13002248 -0.21279976  0.12668979  1.        ]]. Action = [[ 0.841156  -0.882537  -0.1398359  0.2720461]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1847. State = [[-0.10121132 -0.24494444  0.11887395  1.        ]]. Action = [[ 0.8100116  -0.843244   -0.5609942   0.25041342]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1848. State = [[-0.0702508  -0.27893755  0.09937796  1.        ]]. Action = [[ 0.8367348  -0.950296   -0.60703415  0.29985452]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 1848 is [False, True, False, True, False, False, False, True, False, True]
State prediction error at timestep 1848 is tensor(0.0014, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1848 of -1
Current timestep = 1849. State = [[-0.03503126 -0.3075145   0.07616177  1.        ]]. Action = [[ 0.9115784  -0.94540644  0.13987446  0.1879524 ]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: Workspace boundary
Scene graph at timestep 1849 is [False, True, False, True, False, False, False, True, False, True]
State prediction error at timestep 1849 is tensor(0.0019, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1849 of -1
Current timestep = 1850. State = [[-0.03503126 -0.3075145   0.07616177  1.        ]]. Action = [[ 0.9503374  -0.96493745 -0.12717831  0.34812832]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: Workspace boundary
Scene graph at timestep 1850 is [False, True, False, True, False, False, False, True, False, True]
State prediction error at timestep 1850 is tensor(0.0014, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1850 of -1
Current timestep = 1851. State = [[-0.03503126 -0.3075145   0.07616177  1.        ]]. Action = [[ 0.9517033  -0.9529203  -0.01065344  0.2690029 ]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: Workspace boundary
Scene graph at timestep 1851 is [False, True, False, True, False, False, False, True, False, True]
State prediction error at timestep 1851 is tensor(0.0014, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1851 of -1
Current timestep = 1852. State = [[-0.0350642  -0.3075807   0.07617282  1.        ]]. Action = [[ 0.9368324  -0.96139675 -0.34624326  0.2925403 ]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: Workspace boundary
Scene graph at timestep 1852 is [False, True, False, True, False, False, False, True, False, True]
State prediction error at timestep 1852 is tensor(0.0012, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1852 of -1
Current timestep = 1853. State = [[-0.0350642  -0.3075807   0.07617282  1.        ]]. Action = [[ 0.909585   -0.9502894  -0.42249936  0.36468267]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: Workspace boundary
Scene graph at timestep 1853 is [False, True, False, True, False, False, False, True, False, True]
State prediction error at timestep 1853 is tensor(0.0008, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1853 of -1
Current timestep = 1854. State = [[-0.0350642  -0.3075807   0.07617282  1.        ]]. Action = [[ 0.894212   -0.9731095  -0.50043666  0.33881795]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Scene graph at timestep 1854 is [False, True, False, True, False, False, False, True, False, True]
State prediction error at timestep 1854 is tensor(0.0010, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1854 of -1
Current timestep = 1855. State = [[-0.0350642  -0.3075807   0.07617282  1.        ]]. Action = [[ 0.94600296 -0.9223469  -0.19153666  0.2797619 ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Scene graph at timestep 1855 is [False, True, False, True, False, False, False, True, False, True]
State prediction error at timestep 1855 is tensor(0.0016, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1855 of -1
Current timestep = 1856. State = [[-0.0350642  -0.3075807   0.07617282  1.        ]]. Action = [[ 0.9244516  -0.9473578   0.01678348  0.34420228]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Scene graph at timestep 1856 is [False, True, False, True, False, False, False, True, False, True]
State prediction error at timestep 1856 is tensor(0.0018, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1856 of -1
Current timestep = 1857. State = [[-0.0350642  -0.3075807   0.07617282  1.        ]]. Action = [[ 0.9415852  -0.9459831  -0.19525367  0.31853056]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Scene graph at timestep 1857 is [False, True, False, True, False, False, False, True, False, True]
State prediction error at timestep 1857 is tensor(0.0018, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1857 of -1
Current timestep = 1858. State = [[-0.03502768 -0.30759516  0.07614685  1.        ]]. Action = [[ 0.8648219  -0.95726466 -0.07677197  0.30893576]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Scene graph at timestep 1858 is [False, True, False, True, False, False, False, True, False, True]
State prediction error at timestep 1858 is tensor(0.0019, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1858 of -1
Current timestep = 1859. State = [[-0.03502768 -0.30759516  0.07614685  1.        ]]. Action = [[ 0.8524649  -0.9579073  -0.02897584  0.30233717]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Scene graph at timestep 1859 is [False, True, False, True, False, False, False, True, False, True]
State prediction error at timestep 1859 is tensor(0.0019, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1859 of -1
Current timestep = 1860. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.84052193 -0.9630778  -0.2980101   0.29743147]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Scene graph at timestep 1860 is [False, True, False, True, False, False, False, True, False, True]
State prediction error at timestep 1860 is tensor(0.0020, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1860 of -1
Current timestep = 1861. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.83842516 -0.97600657 -0.00138444  0.15446663]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Scene graph at timestep 1861 is [False, True, False, True, False, False, False, True, False, True]
State prediction error at timestep 1861 is tensor(0.0027, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 1861 of -1
Current timestep = 1862. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.8867985  -0.9745836   0.04051113  0.23523712]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 1863. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.5803268  -0.96544135  0.31934416  0.26923406]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 1864. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.8943188  -0.96907914 -0.5731107   0.3453226 ]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 1865. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.8854213  -0.9486888   0.2496059   0.18107498]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 1866. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.83076715 -0.97338974  0.02012539  0.32885063]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 1867. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.87492704 -0.94152856 -0.12819761  0.3764472 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 1868. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.9421277  -0.95706403 -0.19398403  0.15370703]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 1869. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.9578023  -0.96185726 -0.36981547  0.2960472 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 1870. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.84402    -0.96868616 -0.32000613  0.3211199 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 1871. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.8118746  -0.9610735   0.15318751  0.26172042]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 1872. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.8993908  -0.91911256 -0.45405138  0.29736602]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 1873. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.7655177  -0.96426463 -0.6979652   0.24759257]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 1874. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.87401974 -0.9501654  -0.57327324  0.21695578]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 1875. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.8780632  -0.9631166  -0.59769976  0.30710542]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 1876. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.8634119  -0.93749166 -0.25949287  0.36703277]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 1877. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.9330741  -0.95858234 -0.26044708  0.28446388]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 1878. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.8461249  -0.95876867 -0.26838827  0.25722122]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 1879. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.8805671  -0.9402246  -0.59203017  0.2435242 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 1880. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.8692069  -0.96603614 -0.13445592  0.18511236]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 1881. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.9389622  -0.9493746  -0.06679642  0.2092793 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 1882. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.71227336 -0.9646581  -0.4017371   0.1799978 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 1883. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.89945173 -0.98068154 -0.59988153  0.2923355 ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 1884. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.8333037  -0.9470803  -0.21398205  0.27790403]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 1885. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.82715964 -0.97869194 -0.43257517  0.17685819]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 1886. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.9420295  -0.95275426 -0.6082853   0.29537177]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 1887. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.71944225 -0.95518756 -0.3836674   0.27024603]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 1888. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.94018054 -0.96541506 -0.14945906  0.29691684]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 1889. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.80451965 -0.951902   -0.0968256   0.25043035]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 1890. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.97006106 -0.93815523 -0.25822103  0.27693224]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 1891. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.7435417  -0.9642606   0.02998316  0.30755913]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 1892. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.9015496  -0.9554999  -0.29915994  0.37188148]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 1893. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.8281294 -0.9683876 -0.4864753  0.3099631]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 1894. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.895697   -0.9094503  -0.2887566   0.26054227]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 1895. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.8383999  -0.9574003   0.48412037  0.23713934]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 1896. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.8304548  -0.9634442  -0.61845887  0.2921046 ]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 1897. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.914603   -0.9348145  -0.70667946  0.23407853]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 1898. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.8818326  -0.93068284 -0.7474473   0.18779492]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 1899. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.81304336 -0.95890236 -0.8144827   0.23195958]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 1900. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.8714547  -0.95384616 -0.87985957  0.2749648 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 1901. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.7961247  -0.96996653 -0.777686    0.14918971]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 1902. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.8808181  -0.9272076  -0.75478214  0.2575215 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 1903. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.71102417 -0.91618955 -0.65708154  0.14113355]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 1904. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.84643245 -0.911693   -0.6519677   0.18086243]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 1905. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.79120636 -0.9396062  -0.76172584  0.19032538]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 1906. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.8434341  -0.9622657  -0.8651841   0.20558965]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 1907. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.9268472  -0.92473036 -0.80967367  0.12581289]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 1908. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.85072935 -0.95116836 -0.7003109   0.14257157]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 1909. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.7749088  -0.9218261  -0.8848222   0.08448887]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 1910. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.67099106 -0.96142393 -0.7903091   0.09399998]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 1911. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.8200451  -0.92609525 -0.7741313   0.18150699]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 1912. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.64878154 -0.9467014  -0.6170517   0.1533544 ]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 1913. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.771757   -0.9232831  -0.6975039   0.14108944]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 1914. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.7292373  -0.9208049  -0.6937034   0.16614163]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 1915. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.7896161  -0.9070603  -0.39016783  0.08287454]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 1916. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.8776078  -0.91003066 -0.7246621   0.16713238]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 1917. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.8473973  -0.95414364 -0.5517543   0.16787577]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 1918. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.7016034  -0.9424196  -0.5022869   0.16197646]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 1919. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.8356631  -0.94322765 -0.7950175   0.13079011]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 1920. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.845875   -0.94678724 -0.7952581   0.14117253]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 1921. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.5994897  -0.9459134  -0.81291574  0.10803151]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 1922. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.71215165 -0.94948554 -0.7792885   0.13553643]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 1923. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.83519125 -0.94692516 -0.73764396  0.1842364 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 1924. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.720796   -0.9419789  -0.85661703  0.10018802]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 1925. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.7059543  -0.9488559  -0.7814618   0.10538244]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 1926. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.6289736  -0.89938164 -0.8534368   0.14702487]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 1927. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.79671526 -0.9189797  -0.9169942   0.21949077]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 1928. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.7086606  -0.922117   -0.74311715  0.12908089]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 1929. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.6215842  -0.9297228  -0.7521647   0.09654963]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 1930. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.43364477 -0.9052344  -0.69887054  0.13947451]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 1931. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.7195029  -0.87652093 -0.8123874   0.10385668]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 1932. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.7946788  -0.94582385 -0.51625097  0.16665137]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 1933. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.75994897 -0.88010526 -0.6870441   0.11785841]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 1934. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.7011657  -0.915411   -0.87558687  0.12149215]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 1935. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.64427924 -0.89826554 -0.7448572   0.11887813]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 1936. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.78144455 -0.9439737  -0.67723984  0.09626281]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 1937. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.75116396 -0.92064357 -0.8501892   0.11205363]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 1938. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.6040083  -0.9258878  -0.83064127  0.09669185]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 1939. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.50852513 -0.8919859  -0.82759863  0.03729367]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 1940. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.67729354 -0.8516353  -0.7606952   0.08438718]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 1941. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.72141814 -0.88463676 -0.8601643   0.09227431]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 1942. State = [[-0.03505204 -0.3075854   0.07608597  1.        ]]. Action = [[ 0.77491844 -0.91915923 -0.8285733   0.10734308]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 1943. State = [[-0.2701893   0.15188725  0.11739554  1.        ]]. Action = [[ 0.6679218  -0.88226205 -0.74940574  0.15430462]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 1944. State = [[-0.26485267  0.17670545  0.10655788  1.        ]]. Action = [[0.20068026 0.53176427 0.16267371 0.32630658]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1945. State = [[-0.26037863  0.19233952  0.10847092  1.        ]]. Action = [[ 0.28298604  0.38202918 -0.05496889  0.3540157 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1946. State = [[-0.25184187  0.21085703  0.10524583  1.        ]]. Action = [[ 0.23850894  0.6077242  -0.02606684  0.4601748 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1947. State = [[-0.24662292  0.23208985  0.10294704  1.        ]]. Action = [[ 0.09179318  0.47047925 -0.09625888  0.38511348]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1948. State = [[-0.23884577  0.24775235  0.09723793  1.        ]]. Action = [[ 0.35546124  0.3142283  -0.19154173  0.34429932]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1949. State = [[-0.23028748  0.25888866  0.08792126  1.        ]]. Action = [[ 0.10100293  0.26531482 -0.3903432   0.3448063 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1950. State = [[-0.2231481   0.27205536  0.08216182  1.        ]]. Action = [[0.16712165 0.3443148  0.2229929  0.32288408]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1951. State = [[-0.21862891  0.28462994  0.08921549  1.        ]]. Action = [[-0.02007306  0.24128687  0.13198781  0.31641185]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1952. State = [[-0.22135152  0.28986254  0.08811649  1.        ]]. Action = [[ 0.00125933  0.12999392 -0.4862585   0.21658468]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1953. State = [[-0.21653725  0.2955242   0.0735354   1.        ]]. Action = [[ 0.04379261  0.1222918  -0.5637802   0.2029984 ]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: Workspace boundary
Current timestep = 1954. State = [[-0.21629508  0.29676625  0.07199717  1.        ]]. Action = [[ 0.01648498  0.26674068 -0.81351084  0.21821785]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: Workspace boundary
Current timestep = 1955. State = [[-0.21660411  0.29646695  0.07137799  1.        ]]. Action = [[-0.03230393  0.21778166 -0.31101775  0.22444057]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: Workspace boundary
Current timestep = 1956. State = [[-0.21669994  0.2964182   0.07114899  1.        ]]. Action = [[ 0.1695348   0.03595269 -0.6219757   0.27558422]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Current timestep = 1957. State = [[-0.2178892   0.29498523  0.06519686  1.        ]]. Action = [[ 0.09158182 -0.06324291 -0.56177384  0.2051301 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 1958. State = [[-0.21265966  0.29568264  0.05217342  1.        ]]. Action = [[ 0.13668668  0.29807806 -0.62403196  0.35464764]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 1959. State = [[-0.21122758  0.29536211  0.04896014  1.        ]]. Action = [[ 0.149737    0.19637632 -0.34007603  0.2570883 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 1960. State = [[-0.21059199  0.29510683  0.0488076   1.        ]]. Action = [[-0.01541829  0.12959349 -0.42847955  0.23717654]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 1961. State = [[-0.20903513  0.2955966   0.04888195  1.        ]]. Action = [[ 0.17359936  0.16491604 -0.03407341  0.2604438 ]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 1962. State = [[-0.20895328  0.29561898  0.04869856  1.        ]]. Action = [[ 0.20459151  0.3180207  -0.29193372  0.29219174]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 1963. State = [[-0.20874096  0.29565668  0.04875097  1.        ]]. Action = [[ 0.10099876  0.35514843 -0.35173124  0.332124  ]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 1964. State = [[-0.20874096  0.29565668  0.04875097  1.        ]]. Action = [[ 0.13488865  0.45048845 -0.1733228   0.32100296]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 1965. State = [[-0.20887284  0.29570773  0.04875766  1.        ]]. Action = [[ 0.11959648  0.15365732 -0.20125306  0.39515805]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 1966. State = [[-0.20887284  0.29570773  0.04875766  1.        ]]. Action = [[ 0.0521853   0.23169875 -0.14331532  0.37660694]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 1967. State = [[-0.20868039  0.2958085   0.04876415  1.        ]]. Action = [[ 0.10732543  0.34570515 -0.4661408   0.31211376]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 1968. State = [[-0.20868039  0.2958085   0.04876415  1.        ]]. Action = [[0.13403678 0.2626443  0.14491391 0.29124975]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 1969. State = [[-0.2086062   0.29559362  0.048713    1.        ]]. Action = [[-0.08276159  0.19283473 -0.25096     0.32220626]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 1970. State = [[-0.2085135   0.29543206  0.04875498  1.        ]]. Action = [[ 0.049348    0.19310999 -0.46868455  0.21148193]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 1971. State = [[-0.20840085  0.29534698  0.04880489  1.        ]]. Action = [[-0.08182645  0.2051127  -0.40519643  0.2124635 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 1972. State = [[-0.20799945  0.29545054  0.04888051  1.        ]]. Action = [[ 0.04569268  0.23757136 -0.7546251   0.29660285]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 1973. State = [[-0.20805457  0.2953726   0.04880806  1.        ]]. Action = [[ 0.08144712  0.06983411 -0.52110445  0.31090355]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 1974. State = [[-0.20804705  0.29527205  0.04881561  1.        ]]. Action = [[ 0.06243217  0.06368864 -0.73933256  0.27249098]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 1975. State = [[-0.20805246  0.29515514  0.04882581  1.        ]]. Action = [[ 0.09984791 -0.0045653  -0.5954685   0.21705174]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 1976. State = [[-0.20813769  0.2951561   0.04883364  1.        ]]. Action = [[-0.00723755  0.00343418 -0.4037627   0.28877544]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 1977. State = [[-0.20813769  0.2951561   0.04883364  1.        ]]. Action = [[-0.02104062  0.01978409 -0.792797    0.28648508]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 1978. State = [[-0.20813769  0.2951561   0.04883364  1.        ]]. Action = [[-0.04351687 -0.03302193 -0.7631298   0.23256874]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 1979. State = [[-0.20818388  0.29520658  0.04883368  1.        ]]. Action = [[ 0.05655658 -0.04856873 -0.5654605   0.23758256]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 1980. State = [[-0.20778769  0.29490548  0.04875337  1.        ]]. Action = [[ 0.11656988 -0.02863449 -0.06189191  0.2438078 ]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 1981. State = [[-0.20639251  0.29471847  0.04872271  1.        ]]. Action = [[-0.13460958  0.3713374  -0.1166898   0.26675284]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 1982. State = [[-0.20646851  0.2946792   0.0485522   1.        ]]. Action = [[ 0.13726151  0.2216183  -0.33806026  0.2685392 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 1983. State = [[-0.20646851  0.2946792   0.0485522   1.        ]]. Action = [[ 0.20988512  0.28247166 -0.23755759  0.25731087]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 1984. State = [[-0.20646851  0.2946792   0.0485522   1.        ]]. Action = [[ 0.1817987   0.3604374  -0.34462798  0.3002243 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 1985. State = [[-0.20646851  0.2946792   0.0485522   1.        ]]. Action = [[ 0.32127213  0.27193403 -0.34383023  0.26561832]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 1986. State = [[-0.20646851  0.2946792   0.0485522   1.        ]]. Action = [[-0.01508111  0.13137078 -0.25084805  0.28455245]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 1987. State = [[-0.20646851  0.2946792   0.0485522   1.        ]]. Action = [[ 0.19325984  0.3124832  -0.46267277  0.23493707]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 1988. State = [[-0.20646851  0.2946792   0.0485522   1.        ]]. Action = [[ 0.12149608  0.29122317 -0.23617476  0.30801117]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 1989. State = [[-0.20646851  0.2946792   0.0485522   1.        ]]. Action = [[ 0.21905804  0.1540786  -0.25379562  0.3146701 ]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 1990. State = [[-0.20646851  0.2946792   0.0485522   1.        ]]. Action = [[0.13958955 0.07802856 0.05906391 0.36639178]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 1991. State = [[-0.20646851  0.2946792   0.0485522   1.        ]]. Action = [[ 0.1462928   0.13713074 -0.64344525  0.35483575]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 1992. State = [[-0.20646851  0.2946792   0.0485522   1.        ]]. Action = [[ 0.07101786  0.12970924 -0.593209    0.29481137]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 1993. State = [[-0.20646851  0.2946792   0.0485522   1.        ]]. Action = [[ 0.14400315  0.058357   -0.7869543   0.32066226]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 1994. State = [[-0.20646851  0.2946792   0.0485522   1.        ]]. Action = [[-0.01240087  0.02836871 -0.36855173  0.3112223 ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 1995. State = [[-0.20646851  0.2946792   0.0485522   1.        ]]. Action = [[-0.05656683  0.0717274  -0.7877146   0.26447606]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 1996. State = [[-0.20646851  0.2946792   0.0485522   1.        ]]. Action = [[ 0.11967206  0.10127163 -0.6174829   0.22783935]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 1997. State = [[-0.20646851  0.2946792   0.0485522   1.        ]]. Action = [[-0.04725033  0.05652237 -0.82821697  0.22824073]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 1998. State = [[-0.20646851  0.2946792   0.0485522   1.        ]]. Action = [[ 0.11330771  0.02469063 -0.596992    0.29657567]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 1999. State = [[-0.20646851  0.2946792   0.0485522   1.        ]]. Action = [[ 0.00213087  0.14006126 -0.43595833  0.2391746 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 2000. State = [[-0.20646851  0.2946792   0.0485522   1.        ]]. Action = [[ 0.00345004  0.11166668 -0.7554303   0.32288468]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 2001. State = [[-0.20646851  0.2946792   0.0485522   1.        ]]. Action = [[-0.07560754  0.19114387 -0.4196999   0.33864927]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 2002. State = [[-0.20646851  0.2946792   0.0485522   1.        ]]. Action = [[ 0.01441765  0.22548509 -0.69658023  0.253335  ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 2003. State = [[-0.20646851  0.2946792   0.0485522   1.        ]]. Action = [[-0.01542437  0.45486295 -0.3745172   0.33935666]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 2004. State = [[-0.20646851  0.2946792   0.0485522   1.        ]]. Action = [[ 0.01914048  0.3749647  -0.12245089  0.25506914]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 2005. State = [[-0.20646851  0.2946792   0.0485522   1.        ]]. Action = [[ 0.1557554   0.15869284 -0.61556095  0.3406744 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 2006. State = [[-0.20646851  0.2946792   0.0485522   1.        ]]. Action = [[ 0.01184964  0.18870974 -0.3601191   0.33493674]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 2007. State = [[-0.20649458  0.29466572  0.04849371  1.        ]]. Action = [[ 0.08155107  0.08208621 -0.18757081  0.24680221]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 2008. State = [[-0.20652044  0.29465237  0.04843577  1.        ]]. Action = [[ 0.00743103  0.24730742 -0.4988954   0.30715883]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 2009. State = [[-0.20652044  0.29465237  0.04843577  1.        ]]. Action = [[ 0.01895285  0.02626216 -0.19779515  0.3143685 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 2010. State = [[-0.20652044  0.29465237  0.04843577  1.        ]]. Action = [[ 0.2650602   0.16354525 -0.49440777  0.24621141]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 2011. State = [[-0.20652044  0.29465237  0.04843577  1.        ]]. Action = [[ 0.2688179   0.09226453 -0.2401821   0.26705015]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 2012. State = [[-0.20652044  0.29465237  0.04843577  1.        ]]. Action = [[ 0.26468492 -0.05406767 -0.6318616   0.2380898 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 2013. State = [[-0.20652044  0.29465237  0.04843577  1.        ]]. Action = [[ 0.24445868  0.08878338 -0.83359915  0.30648458]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 2014. State = [[-0.20652044  0.29465237  0.04843577  1.        ]]. Action = [[ 0.18974483 -0.07329011 -0.74496937  0.28270328]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 2015. State = [[-0.20652044  0.29465237  0.04843577  1.        ]]. Action = [[ 0.23554456  0.04554951 -0.63204     0.2500013 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 2016. State = [[-0.20652044  0.29465237  0.04843577  1.        ]]. Action = [[ 0.26370966  0.09520864 -0.41013336  0.28142428]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 2017. State = [[-0.20652044  0.29465237  0.04843577  1.        ]]. Action = [[ 0.2753123  -0.04521626 -0.7928666   0.3203839 ]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 2018. State = [[-0.20654653  0.29463887  0.04837729  1.        ]]. Action = [[ 0.05449092  0.07441878 -0.86942023  0.31705487]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 2019. State = [[-0.20654653  0.29463887  0.04837729  1.        ]]. Action = [[ 0.0587436   0.01107371 -0.7300931   0.24600244]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 2020. State = [[-0.20654653  0.29463887  0.04837729  1.        ]]. Action = [[ 0.00528169 -0.00822353 -0.79853487  0.29288197]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 2021. State = [[-0.20654653  0.29463887  0.04837729  1.        ]]. Action = [[ 0.01553202  0.05651248 -0.3418321   0.33260977]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 2022. State = [[-0.20654653  0.29463887  0.04837729  1.        ]]. Action = [[ 0.06559193  0.1164434  -0.5684507   0.26754344]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 2023. State = [[-0.20654653  0.29463887  0.04837729  1.        ]]. Action = [[ 0.00440919  0.05485141 -0.68351114  0.30429697]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 2024. State = [[-0.20654653  0.29463887  0.04837729  1.        ]]. Action = [[-0.06049669  0.08111179 -0.58486617  0.27293873]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 2025. State = [[-0.20654653  0.29463887  0.04837729  1.        ]]. Action = [[-0.22256786  0.20480001 -0.6190254   0.2375412 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 2026. State = [[-0.20654653  0.29463887  0.04837729  1.        ]]. Action = [[-0.00274724  0.2151649  -0.4265504   0.32527244]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 2027. State = [[-0.20654653  0.29463887  0.04837729  1.        ]]. Action = [[-0.2184084   0.22397876 -0.41028625  0.328596  ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 2028. State = [[-0.20654653  0.29463887  0.04837729  1.        ]]. Action = [[ 0.0661931   0.0506258  -0.6428133   0.20884049]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 2029. State = [[-0.20740737  0.29411304  0.04554668  1.        ]]. Action = [[ 0.07249665 -0.02162206 -0.36341232  0.28651416]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 2030. State = [[-0.20654428  0.2937699   0.03646671  1.        ]]. Action = [[-0.00374508 -0.01330614 -0.65405667  0.23040533]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 2031. State = [[-0.20648216  0.2934518   0.03634851  1.        ]]. Action = [[-0.17656934  0.0969646  -0.8425038   0.24376488]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 2032. State = [[-0.20648216  0.2934518   0.03634851  1.        ]]. Action = [[-0.00335366 -0.0710603  -0.7078542   0.20462847]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 2033. State = [[-0.20648216  0.2934518   0.03634851  1.        ]]. Action = [[ 0.05098653 -0.16533208 -0.64729923  0.16599059]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 2034. State = [[-0.20648216  0.2934518   0.03634851  1.        ]]. Action = [[-0.12803614 -0.24850154 -0.8809495   0.32136333]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 2035. State = [[-0.20648216  0.2934518   0.03634851  1.        ]]. Action = [[ 0.04979706 -0.19535697 -0.86337805  0.25992608]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 2036. State = [[-0.20648216  0.2934518   0.03634851  1.        ]]. Action = [[ 0.00680149 -0.17580152 -0.70365715  0.26274085]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 2037. State = [[-0.2064487   0.29338434  0.03635142  1.        ]]. Action = [[ 0.05592632 -0.08521867 -0.8228999   0.21924412]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 2038. State = [[-0.2064487   0.29338434  0.03635142  1.        ]]. Action = [[ 0.06537378 -0.08477676 -0.87443626  0.23520064]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 2039. State = [[-0.2064487   0.29338434  0.03635142  1.        ]]. Action = [[ 0.05966747  0.01693571 -0.7711989   0.23394823]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 2040. State = [[-0.2064487   0.29338434  0.03635142  1.        ]]. Action = [[ 0.16663456 -0.06570965 -0.7676778   0.27762485]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 2041. State = [[-0.2064487   0.29338434  0.03635142  1.        ]]. Action = [[ 0.03655064 -0.02926707 -0.8370677   0.22735298]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 2042. State = [[-0.20639761  0.29333782  0.03636828  1.        ]]. Action = [[-0.07944822  0.01617897 -0.813544    0.2872212 ]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 2043. State = [[-0.20638204  0.29324988  0.03635725  1.        ]]. Action = [[ 0.05613542 -0.03770584 -0.8681746   0.2748928 ]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 2044. State = [[-0.20638204  0.29324988  0.03635725  1.        ]]. Action = [[ 0.1573615  -0.02065074 -0.5542733   0.27174008]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 2045. State = [[-0.2670956   0.04433328  0.1130932   1.        ]]. Action = [[-0.01697266  0.03010798 -0.69266504  0.25925052]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 2046. State = [[-0.2608068   0.05983953  0.10397115  1.        ]]. Action = [[0.35341465 0.63040686 0.6037364  0.44130778]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 2047. State = [[-0.25171173  0.08454999  0.11145823  1.        ]]. Action = [[0.3344785  0.6463766  0.30388498 0.47005057]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 2048. State = [[-0.2428298   0.10657088  0.12228758  1.        ]]. Action = [[0.01222658 0.34537077 0.3086747  0.3848977 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 2049. State = [[-0.23852491  0.11794662  0.12797806  1.        ]]. Action = [[ 0.16584969  0.1528176  -0.06319648  0.3529848 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 2050. State = [[-0.2333632   0.12174799  0.12664212  1.        ]]. Action = [[ 0.14082098  0.13562953 -0.41496736  0.31464565]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 2051. State = [[-0.22867982  0.12400577  0.11928806  1.        ]]. Action = [[ 0.15283716 -0.04958552 -0.33481675  0.25133407]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 2052. State = [[-0.22562651  0.12483767  0.10726362  1.        ]]. Action = [[ 0.22090137 -0.02694064 -0.6138293   0.29071236]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 2053. State = [[-0.21414672  0.12773222  0.08918522  1.        ]]. Action = [[ 0.20121121  0.14711809 -0.24940819  0.24317253]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 2054. State = [[-0.20564564  0.13007098  0.07698569  1.        ]]. Action = [[ 0.28672206  0.12824571 -0.43893123  0.27336133]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 2055. State = [[-0.1969113   0.13531299  0.06172178  1.        ]]. Action = [[ 0.10090292  0.19834328 -0.29293215  0.3518213 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 2056. State = [[-0.18887049  0.14398673  0.04833592  1.        ]]. Action = [[ 0.32061255  0.2613672  -0.44526052  0.24248433]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 2057. State = [[-0.18150288  0.15042724  0.03726048  1.        ]]. Action = [[ 0.22877765  0.1365012  -0.5181099   0.27026093]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: Workspace boundary
Current timestep = 2058. State = [[-0.1807925   0.15098822  0.03742559  1.        ]]. Action = [[ 0.22578979  0.11672664 -0.45580882  0.24460435]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Current timestep = 2059. State = [[-0.18058173  0.15104453  0.03749398  1.        ]]. Action = [[ 0.05194223  0.24752462 -0.50167656  0.1758728 ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Current timestep = 2060. State = [[-0.18058173  0.15104453  0.03749398  1.        ]]. Action = [[ 0.25504112  0.23728347 -0.61334133  0.1871804 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 2061. State = [[-0.18058173  0.15104453  0.03749398  1.        ]]. Action = [[ 0.37539554  0.21187055 -0.66310495  0.16657364]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 2062. State = [[-0.18058173  0.15104453  0.03749398  1.        ]]. Action = [[ 0.40702212  0.12010837 -0.46881747  0.15178001]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 2063. State = [[-0.18058173  0.15104453  0.03749398  1.        ]]. Action = [[ 0.32068396  0.10985589 -0.635547    0.29058373]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 2064. State = [[-0.18058173  0.15104453  0.03749398  1.        ]]. Action = [[ 0.20522678  0.03903615 -0.74073774  0.20497549]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 2065. State = [[-0.18058173  0.15104453  0.03749398  1.        ]]. Action = [[ 0.37611175  0.1582098  -0.77164084  0.13753128]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 2066. State = [[-0.18058173  0.15104453  0.03749398  1.        ]]. Action = [[ 0.17543292  0.0391469  -0.53716266  0.208274  ]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 2067. State = [[-0.18058173  0.15104453  0.03749398  1.        ]]. Action = [[ 0.01254475  0.28647768 -0.6687643   0.20326757]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 2068. State = [[-0.18058173  0.15104453  0.03749398  1.        ]]. Action = [[ 0.17530608  0.12922907 -0.66627824  0.19154239]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 2069. State = [[-0.18058173  0.15104453  0.03749398  1.        ]]. Action = [[ 0.13706183  0.14549422 -0.37491107  0.14913452]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 2070. State = [[-0.18058173  0.15104453  0.03749398  1.        ]]. Action = [[-0.0312109   0.0959326  -0.43647474  0.16838598]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 2071. State = [[-0.18058173  0.15104453  0.03749398  1.        ]]. Action = [[ 0.24651802  0.04481626 -0.56995195  0.2007376 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 2072. State = [[-0.18058173  0.15104453  0.03749398  1.        ]]. Action = [[ 0.19369602  0.05938756 -0.6102643   0.18246472]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 2073. State = [[-0.18058173  0.15104453  0.03749398  1.        ]]. Action = [[ 0.21979594  0.15270543 -0.36445224  0.20225573]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 2074. State = [[-0.18058173  0.15104453  0.03749398  1.        ]]. Action = [[ 0.37774205  0.08985436 -0.6049962   0.2090683 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 2075. State = [[-0.18058173  0.15104453  0.03749398  1.        ]]. Action = [[ 0.20717382 -0.05356085 -0.34726834  0.21278083]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 2076. State = [[-0.17855076  0.15158457  0.037063    1.        ]]. Action = [[ 0.19164729  0.06649971 -0.14042366  0.20510435]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 2077. State = [[-0.17463373  0.15292177  0.03206879  1.        ]]. Action = [[ 0.19618893  0.06415057 -0.61849385  0.16512394]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 2078. State = [[-0.17473723  0.15288073  0.03162062  1.        ]]. Action = [[ 0.29178345  0.06332183 -0.5286796   0.21029842]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 2079. State = [[-0.17473723  0.15288073  0.03162062  1.        ]]. Action = [[ 0.124457    0.07609785 -0.5496804   0.29887676]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 2080. State = [[-0.17473723  0.15288073  0.03162062  1.        ]]. Action = [[ 0.05150139  0.01685011 -0.32454634  0.17331803]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 2081. State = [[-0.17473723  0.15288073  0.03162062  1.        ]]. Action = [[ 0.00697839  0.18141413 -0.4962955   0.19255292]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 2082. State = [[-0.17482692  0.15285711  0.03146438  1.        ]]. Action = [[ 0.21741176  0.14559388 -0.55529684  0.25923717]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 2083. State = [[-0.17537066  0.15553114  0.0315451   1.        ]]. Action = [[ 0.01945794  0.20155072 -0.01028848  0.21660638]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 2084. State = [[-0.17565133  0.15888518  0.03183031  1.        ]]. Action = [[ 0.18225443  0.18811393 -0.3730644   0.22182882]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 2085. State = [[-0.17586786  0.15965033  0.03185897  1.        ]]. Action = [[ 0.23094904  0.14993298 -0.6967543   0.19154024]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 2086. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.15617466  0.24711406 -0.45905197  0.2617128 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 2087. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.11606705  0.10380757 -0.5970654   0.14888906]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 2088. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.17135572  0.18082929 -0.60502285  0.20983481]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 2089. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.06791532  0.20476604 -0.38878     0.20759404]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 2090. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.25713336  0.05294967 -0.5425977   0.27693152]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 2091. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.11684     0.20350552 -0.65450704  0.20883238]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 2092. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.02358055  0.00372481 -0.14685947  0.14718628]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 2093. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.23789608  0.07576954 -0.6378175   0.17288172]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 2094. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.13138568  0.04647422 -0.55733365  0.21066022]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 2095. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.14262497  0.00134265 -0.5971009   0.21250677]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 2096. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.37921286  0.04391479 -0.83004296  0.15795028]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 2097. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.25297904  0.05015969 -0.7904154   0.18721426]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 2098. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.2801025   0.14064705 -0.6654157   0.21372926]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 2099. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.16417742  0.28733575 -0.40848023  0.24433804]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 2100. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.10583556  0.00376797 -0.6142839   0.22997046]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 2101. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.30403185  0.2728678  -0.35375094  0.250538  ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 2102. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.33727074  0.1640073  -0.65602314  0.17625594]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 2103. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.14127874  0.2278676  -0.6541965   0.20201612]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 2104. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.06986082  0.04747891 -0.6022688   0.2112621 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 2105. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.02740312  0.08779168 -0.6308402   0.17703462]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 2106. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.25787735  0.1365546  -0.5698683   0.29244316]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 2107. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.16764009 -0.06712604 -0.5262311   0.25515747]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 2108. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.13016164  0.04165912 -0.42846406  0.22080779]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 2109. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.12076342 -0.05675662 -0.46608108  0.23039567]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 2110. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.21307826 -0.06063497 -0.5875421   0.16575623]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 2111. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.08524001  0.10800719 -0.43478805  0.20822716]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 2112. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.15899038  0.00919008 -0.5405181   0.23822892]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 2113. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.2233442   0.00229681 -0.6354966   0.27257133]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 2114. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.22115266  0.04286921 -0.5080833   0.23507261]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 2115. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.25924814  0.20992184 -0.7753089   0.24859858]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 2116. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.29924417  0.22641289 -0.6984392   0.22548223]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 2117. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.16192245  0.1126343  -0.6306439   0.25106442]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 2118. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.3763584   0.07595134 -0.39967835  0.23212707]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 2119. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.3937528   0.23086798 -0.4374565   0.2093972 ]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 2120. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.3850143   0.15166748 -0.69725096  0.17532313]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 2121. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.3025936   0.22251701 -0.33734202  0.18704498]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 2122. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.08139277  0.10661256 -0.5102966   0.18452168]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 2123. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.3244971   0.22229564 -0.53687847  0.2797742 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 2124. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.27041757  0.22798443 -0.7380334   0.21220267]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 2125. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.25686336  0.11578131 -0.59856     0.22647917]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 2126. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.10089338  0.14039636 -0.5496303   0.23393595]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 2127. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.33125854  0.23747563 -0.70189124  0.24719405]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 2128. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.18442655  0.15653753 -0.6895421   0.23114562]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 2129. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.09979641  0.1678356  -0.67733747  0.2922536 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 2130. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.19220448  0.12299299 -0.6867465   0.29192424]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 2131. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.10936248  0.15951872 -0.6079737   0.29463124]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 2132. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.18140328 -0.15596223 -0.6298943   0.26162136]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 2133. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.28823233  0.12797785 -0.2529683   0.23959863]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 2134. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.33122635  0.17395353 -0.38297707  0.2525773 ]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 2135. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.272779    0.1184237  -0.4480487   0.23368728]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 2136. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.2650088   0.0119673  -0.6182019   0.24424958]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 2137. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.25938463  0.11916173 -0.5908359   0.25291955]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 2138. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.23208785 -0.0945968  -0.6954814   0.23545432]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 2139. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.38013232  0.07153261 -0.59436053  0.17711926]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 2140. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.48360598 -0.08079779 -0.28576434  0.19873011]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 2141. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.24301946  0.05344057 -0.42707813  0.21606934]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 2142. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.22436655  0.18438649 -0.72747767  0.22023153]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 2143. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.17280841  0.14039934 -0.6735104   0.14420795]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 2144. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.23993814  0.11452484 -0.12723601  0.19914126]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 2145. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.3390869   0.05471599 -0.7409306   0.19229305]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 2146. State = [[-0.17590047  0.15970464  0.03185898  1.        ]]. Action = [[ 0.33789754  0.04689789 -0.7067168   0.1940924 ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 2147. State = [[-0.26073316 -0.01616734  0.11553184  1.        ]]. Action = [[ 0.4691      0.19888282 -0.46029407  0.1658771 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 2148. State = [[-0.25412506 -0.01791708  0.10775237  1.        ]]. Action = [[0.54998374 0.24082434 0.76684    0.5045309 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 2149. State = [[-0.2362724  -0.01019535  0.12315351  1.        ]]. Action = [[0.65864694 0.47111773 0.6868944  0.70445156]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 2150. State = [[-0.21203205  0.00657404  0.1444166   1.        ]]. Action = [[0.6123731  0.4828155  0.3427626  0.34894967]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 2151. State = [[-0.191284    0.01565743  0.14840557  1.        ]]. Action = [[ 0.44844985 -0.14551502 -0.7341084   0.11338186]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 2152. State = [[-0.2542919  -0.0696689   0.12167802  1.        ]]. Action = [[ 0.42338252  0.0484339  -0.565823   -0.02714026]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 2153. State = [[-0.249987   -0.07745951  0.11469547  1.        ]]. Action = [[0.3942423  0.11285937 0.90676963 0.5874462 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 2154. State = [[-0.23658739 -0.07800362  0.13341558  1.        ]]. Action = [[0.63973594 0.03944468 0.76042366 0.76645684]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 2155. State = [[-0.21600613 -0.07468837  0.16031398  1.        ]]. Action = [[0.5157504  0.2746241  0.63386726 0.63269925]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 2156. State = [[-0.19605711 -0.07184265  0.17794769  1.        ]]. Action = [[ 0.3792392  -0.06949657 -0.02259219  0.26526046]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 2157. State = [[-0.18738683 -0.07113829  0.18236317  1.        ]]. Action = [[ 0.6098454  -0.5410511  -0.52403635  0.14649785]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 2158. State = [[-0.18632035 -0.07042264  0.18267834  1.        ]]. Action = [[ 0.58814514 -0.22584903 -0.8124342   0.11640739]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 2159. State = [[-0.18579106 -0.07030497  0.18290827  1.        ]]. Action = [[ 0.5834311  -0.28408515 -0.8762992   0.13989043]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 2160. State = [[-0.18344902 -0.07533187  0.17557311  1.        ]]. Action = [[ 0.31139064 -0.37718135 -0.8378675   0.02808905]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 2161. State = [[-0.174641   -0.0788352   0.16270383  1.        ]]. Action = [[ 0.46070838 -0.5891859  -0.6915769   0.1264931 ]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 2162. State = [[-0.17433824 -0.07905442  0.16241176  1.        ]]. Action = [[ 0.23671067 -0.48246884 -0.8329051   0.12448418]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 2163. State = [[-0.17433824 -0.07905442  0.16241176  1.        ]]. Action = [[ 0.40355194 -0.42708087 -0.8653273   0.12387168]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 2164. State = [[-0.17433824 -0.07905442  0.16241176  1.        ]]. Action = [[ 0.3908981  -0.38908398 -0.8650862  -0.00111234]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: No entry zone
Current timestep = 2165. State = [[-0.17433824 -0.07905442  0.16241176  1.        ]]. Action = [[ 0.2140361  -0.44099915 -0.6403803   0.18123758]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: No entry zone
Current timestep = 2166. State = [[-0.17433824 -0.07905442  0.16241176  1.        ]]. Action = [[ 0.43294287 -0.30056268 -0.8813419   0.068784  ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: No entry zone
Current timestep = 2167. State = [[-0.17433824 -0.07905442  0.16241176  1.        ]]. Action = [[ 0.43368912 -0.22157216 -0.7784725   0.1424588 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: No entry zone
Current timestep = 2168. State = [[-0.17433824 -0.07905442  0.16241176  1.        ]]. Action = [[ 0.651505   -0.5415025  -0.77193004  0.1166954 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: No entry zone
Current timestep = 2169. State = [[-0.17433824 -0.07905442  0.16241176  1.        ]]. Action = [[ 0.23538017 -0.5701322  -0.7134894   0.12167692]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: No entry zone
Current timestep = 2170. State = [[-0.17433824 -0.07905442  0.16241176  1.        ]]. Action = [[ 0.5846151 -0.6524589 -0.7682977  0.1713258]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: No entry zone
Current timestep = 2171. State = [[-0.17433824 -0.07905442  0.16241176  1.        ]]. Action = [[ 0.5210023  -0.27262884 -0.75070524  0.16405582]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: No entry zone
Current timestep = 2172. State = [[-0.17433824 -0.07905442  0.16241176  1.        ]]. Action = [[ 0.5250102  -0.31998873 -0.84485906  0.04103172]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: No entry zone
Current timestep = 2173. State = [[-0.17433824 -0.07905442  0.16241176  1.        ]]. Action = [[ 0.50434494 -0.5073622  -0.2219404   0.16246438]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: No entry zone
Current timestep = 2174. State = [[-0.17433824 -0.07905442  0.16241176  1.        ]]. Action = [[ 0.46832323 -0.28250325 -0.597351    0.14055264]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: No entry zone
Current timestep = 2175. State = [[-0.17433824 -0.07905442  0.16241176  1.        ]]. Action = [[ 0.57467234 -0.40106565 -0.8602788   0.12201762]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: No entry zone
Current timestep = 2176. State = [[-0.17433824 -0.07905442  0.16241176  1.        ]]. Action = [[ 0.48706055 -0.40163028 -0.8382488   0.1343751 ]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: No entry zone
Current timestep = 2177. State = [[-0.17433824 -0.07905442  0.16241176  1.        ]]. Action = [[ 0.6549833  -0.24760067 -0.9231501   0.18206906]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: No entry zone
Current timestep = 2178. State = [[-0.17433824 -0.07905442  0.16241176  1.        ]]. Action = [[ 0.63849735 -0.44678503 -0.8221038   0.18017077]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: No entry zone
Current timestep = 2179. State = [[-0.17433824 -0.07905442  0.16241176  1.        ]]. Action = [[ 0.55555797 -0.5786772  -0.80496067  0.14451194]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: No entry zone
Current timestep = 2180. State = [[-0.17435557 -0.07905286  0.162367    1.        ]]. Action = [[ 0.5972569  -0.34108186 -0.9204879   0.15359163]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: No entry zone
Current timestep = 2181. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.5172193  -0.408652   -0.84496874  0.1846745 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: No entry zone
Current timestep = 2182. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.5596912  -0.49148595 -0.83210915  0.10276818]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: No entry zone
Current timestep = 2183. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.30456495 -0.45628548 -0.9237142   0.19077611]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: No entry zone
Current timestep = 2184. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.47564602 -0.5965229  -0.6946214   0.17595959]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: No entry zone
Current timestep = 2185. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.35839534 -0.63171554 -0.8783197   0.08692563]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: No entry zone
Current timestep = 2186. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.35324252 -0.514197   -0.809874    0.05282557]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: No entry zone
Current timestep = 2187. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.5435772  -0.5712593  -0.7973972   0.11477196]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: No entry zone
Current timestep = 2188. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.2956028  -0.4032929  -0.8028356   0.13720179]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: No entry zone
Current timestep = 2189. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.5339788  -0.40526915 -0.9243094   0.19643068]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: No entry zone
Current timestep = 2190. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.46606994 -0.47958195 -0.82251793  0.14238179]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: No entry zone
Current timestep = 2191. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.44994092 -0.3665285  -0.81950665  0.1792016 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: No entry zone
Current timestep = 2192. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.56540275 -0.21286285 -0.8858962   0.22719216]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: No entry zone
Current timestep = 2193. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.5763762  -0.22975665 -0.7808932   0.08534372]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: No entry zone
Current timestep = 2194. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.5605171  -0.34267366 -0.8676204   0.15716004]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: No entry zone
Current timestep = 2195. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.33721447 -0.24902898 -0.511999    0.16428518]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: No entry zone
Current timestep = 2196. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.30469537 -0.28396195 -0.86473256  0.17915046]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: No entry zone
Current timestep = 2197. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.42815018 -0.30127668 -0.6655149   0.21178341]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: No entry zone
Current timestep = 2198. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.33348227 -0.44228697 -0.57858455  0.14498627]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: No entry zone
Current timestep = 2199. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.24375474 -0.3432191  -0.84492594  0.2299037 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: No entry zone
Current timestep = 2200. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.51144385 -0.46984065 -0.8960917   0.10662615]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: No entry zone
Current timestep = 2201. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.3234837  -0.21805876 -0.86040777  0.05595088]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: No entry zone
Current timestep = 2202. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.38018906 -0.2908392  -0.84675676  0.1859231 ]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: No entry zone
Current timestep = 2203. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.6540346  -0.30624592 -0.7741125   0.03832233]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: No entry zone
Current timestep = 2204. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.43245244 -0.49578553 -0.9572172   0.16535449]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: No entry zone
Current timestep = 2205. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.65235925 -0.49957347 -0.9261337   0.21447575]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: No entry zone
Current timestep = 2206. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.5850818  -0.2461757  -0.8610078   0.14774406]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: No entry zone
Current timestep = 2207. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.44303727 -0.45917946 -0.8494045   0.09090126]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: No entry zone
Current timestep = 2208. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.4763142  -0.3583405  -0.52853644  0.10512066]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: No entry zone
Current timestep = 2209. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.49521804 -0.2871486  -0.91061497  0.12592077]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: No entry zone
Current timestep = 2210. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.4584682  -0.5115222  -0.92676413  0.17250848]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: No entry zone
Current timestep = 2211. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.67197967 -0.47537172 -0.79070944  0.17920113]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: No entry zone
Current timestep = 2212. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.39700663 -0.48371738 -0.68615115  0.22130811]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: No entry zone
Current timestep = 2213. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.47352755 -0.6118788  -0.9282585   0.10442162]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: No entry zone
Current timestep = 2214. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.55759203 -0.6322996  -0.8837948   0.22875714]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: No entry zone
Current timestep = 2215. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.45626616 -0.24894404 -0.8893328   0.22340345]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: No entry zone
Current timestep = 2216. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.59396446 -0.34099615 -0.697643    0.05630004]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: No entry zone
Current timestep = 2217. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.31792343 -0.21827781 -0.84747255  0.17103589]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: No entry zone
Current timestep = 2218. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.597157    0.00977671 -0.72616845  0.1921438 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: No entry zone
Current timestep = 2219. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.53557897 -0.2698623  -0.62346715  0.18995655]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: No entry zone
Current timestep = 2220. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.45564878 -0.21402061 -0.61485237  0.24443305]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: No entry zone
Current timestep = 2221. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.44319534 -0.45487887 -0.8709906   0.15278745]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: No entry zone
Current timestep = 2222. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.36053216 -0.25555074 -0.7866029   0.26798058]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: No entry zone
Current timestep = 2223. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.36005354 -0.2370956  -0.810812    0.17083025]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: No entry zone
Current timestep = 2224. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.12428033 -0.31891847 -0.6808207   0.20590138]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: No entry zone
Current timestep = 2225. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.5166203  -0.3643434  -0.74480885  0.1901201 ]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: No entry zone
Current timestep = 2226. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.1205771  -0.45918643 -0.6146494   0.19563973]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: No entry zone
Current timestep = 2227. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.47286427 -0.5723761  -0.74852324  0.20873606]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: No entry zone
Current timestep = 2228. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.7184378  -0.52922666 -0.92588294  0.17159593]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: No entry zone
Current timestep = 2229. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.43513536 -0.4027977  -0.8305292   0.08264232]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: No entry zone
Current timestep = 2230. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.1987791  -0.3286283  -0.6277743   0.16164255]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: No entry zone
Current timestep = 2231. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.5365442  -0.47157222 -0.87922806  0.26812243]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: No entry zone
Current timestep = 2232. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.3388381  -0.21244311 -0.46788764  0.3428017 ]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: No entry zone
Current timestep = 2233. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.58587503 -0.14122933 -0.7071986   0.26981747]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: No entry zone
Current timestep = 2234. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.43497872 -0.37871397  0.04999912  0.27134454]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: No entry zone
Current timestep = 2235. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.43427944 -0.47658104  0.02522242  0.27781737]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: No entry zone
Current timestep = 2236. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.5525863  -0.23606646 -0.35143536  0.21924543]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: No entry zone
Current timestep = 2237. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.4629706  -0.28076375 -0.33646238  0.44097757]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: No entry zone
Current timestep = 2238. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.55482304 -0.01837605 -0.5926497   0.3649627 ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: No entry zone
Current timestep = 2239. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.12626839 -0.2815562  -0.2571026   0.3661834 ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: No entry zone
Current timestep = 2240. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.5213382  -0.11779946 -0.01410401  0.26164174]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: No entry zone
Current timestep = 2241. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.63893473 -0.02879083 -0.02677333  0.33682442]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: No entry zone
Current timestep = 2242. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.3599732  -0.44469655  0.1997236   0.4490242 ]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: No entry zone
Current timestep = 2243. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.6225929  -0.33358306 -0.42848676  0.4211098 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: No entry zone
Current timestep = 2244. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.5620954  -0.11302716  0.1021663   0.40829098]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: No entry zone
Current timestep = 2245. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.43094313 -0.34175164 -0.34488142  0.4329276 ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: No entry zone
Current timestep = 2246. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.62224615 -0.30525804  0.12947345  0.41902328]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: No entry zone
Current timestep = 2247. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.2892592  -0.08068633  0.55687225  0.42828107]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: No entry zone
Current timestep = 2248. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.5125799  -0.14193535 -0.03998649  0.5224414 ]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: No entry zone
Current timestep = 2249. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.36496747 -0.36932063  0.50235736  0.52286065]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: No entry zone
Current timestep = 2250. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.62274647 -0.5418936   0.28146815  0.51956487]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: No entry zone
Current timestep = 2251. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.5801277  -0.15381831 -0.30971766  0.54997563]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: No entry zone
Current timestep = 2252. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[ 0.56233084 -0.08873034  0.7350414   0.5863066 ]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: No entry zone
Current timestep = 2253. State = [[-0.17428586 -0.07906203  0.1623947   1.        ]]. Action = [[0.7108141  0.11152256 0.6244745  0.56571007]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: No entry zone
Current timestep = 2254. State = [[-0.2544433  -0.17065075  0.12394003  1.        ]]. Action = [[0.35857213 0.16137123 0.456707   0.5593488 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: No entry zone
Current timestep = 2255. State = [[-0.24341445 -0.19507362  0.11871669  1.        ]]. Action = [[ 0.84140205 -0.41078907  0.99659944  0.99874496]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 2256. State = [[-0.21958274 -0.21371101  0.14254509  1.        ]]. Action = [[ 0.5669873  -0.73671037  0.98764586  0.9929831 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 2257. State = [[-0.19431432 -0.23976085  0.18101986  1.        ]]. Action = [[ 0.6163573  -0.6211888   0.9838972   0.98293877]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 2258. State = [[-0.16733724 -0.26348105  0.22054994  1.        ]]. Action = [[ 0.71326065 -0.46215343  0.96698165  0.9247453 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 2259. State = [[-0.1417182  -0.2869308   0.24296242  1.        ]]. Action = [[ 0.64602816 -0.7044917  -0.31949222  0.7533963 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 2260. State = [[-0.12825786 -0.29951113  0.24567598  1.        ]]. Action = [[ 0.5959921  -0.7395182  -0.14464724  0.799842  ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: Workspace boundary
Current timestep = 2261. State = [[-0.1281782  -0.30028826  0.24606408  1.        ]]. Action = [[ 0.5237278  -0.81849116 -0.50898075  0.6352885 ]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: Workspace boundary
Current timestep = 2262. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.5603316  -0.63332963  0.6259259   0.6373435 ]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: Workspace boundary
Current timestep = 2263. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.80399513 -0.6740939   0.1978575   0.7000487 ]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: Workspace boundary
Current timestep = 2264. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.7144489  -0.71011925 -0.02191174  0.75353193]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: Workspace boundary
Current timestep = 2265. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.51552844 -0.7686146  -0.65450954  0.6431916 ]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: Workspace boundary
Current timestep = 2266. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.5012591 -0.7329374  0.1482501  0.6754005]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: Workspace boundary
Current timestep = 2267. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.738462   -0.7110498   0.34694958  0.73465395]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Current timestep = 2268. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.7613325  -0.82618785  0.07626998  0.7115189 ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Current timestep = 2269. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.82117844 -0.7969082  -0.56141776  0.6005995 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 2270. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.67464113 -0.77119905 -0.92674     0.7124522 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 2271. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.83967984 -0.8701964  -0.42317826  0.745173  ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 2272. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.6718247  -0.59190845  0.6806716   0.7298484 ]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 2273. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.62351024 -0.75755715 -0.1967712   0.72159505]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 2274. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.8316144 -0.799308   0.8502928  0.7904141]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 2275. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.5643593  -0.74477065  0.07551205  0.76183796]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 2276. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.7145966  -0.7346327   0.5100968   0.76533675]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 2277. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.874274   -0.71789676  0.67094946  0.78536844]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 2278. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.83052874 -0.79252    -0.17203403  0.8340831 ]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 2279. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.8295808  -0.7868889   0.71028423  0.8207991 ]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 2280. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.8251163  -0.8682724  -0.09279782  0.80887985]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 2281. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.6311976  -0.8151408   0.32781458  0.8608384 ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 2282. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.72582984 -0.85399675 -0.43750107  0.92957664]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 2283. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.9119785  -0.8520184   0.57205963  0.84353495]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 2284. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.9449427  -0.83237237 -0.5188843   0.8846874 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 2285. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.8094721  -0.73431116  0.34229767  0.9257517 ]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 2286. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.80433536 -0.94350016 -0.1790806   0.8539326 ]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 2287. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.9000156  -0.76906043  0.9310446   0.7988012 ]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 2288. State = [[-0.12814105 -0.30023098  0.24605098  1.        ]]. Action = [[ 0.9058707  -0.78943145  0.9379027   0.89460444]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 2289. State = [[-0.12805225 -0.3002628   0.2461327   1.        ]]. Action = [[ 0.9060285  -0.7969451   0.97426105  0.9167454 ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 2290. State = [[-0.12806042 -0.30023387  0.24616954  1.        ]]. Action = [[ 0.7942443  -0.8589436   0.88080597  0.8416755 ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 2291. State = [[-0.12806042 -0.30023387  0.24616954  1.        ]]. Action = [[ 0.9388466  -0.9395362   0.7863718   0.88819695]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 2292. State = [[-0.12806042 -0.30023387  0.24616954  1.        ]]. Action = [[ 0.88144684 -0.92633504  0.8316567   0.9379605 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 2293. State = [[-0.12806042 -0.30023387  0.24616954  1.        ]]. Action = [[ 0.9614545  -0.94789857  0.835407    0.8995216 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 2294. State = [[-0.12806042 -0.30023387  0.24616954  1.        ]]. Action = [[ 0.8774785  -0.97291344  0.91585827  0.8642918 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 2295. State = [[-0.12806042 -0.30023387  0.24616954  1.        ]]. Action = [[ 0.9871297  -0.9305341   0.84701586  0.9107466 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 2296. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.9725728  -0.94098634  0.87789094  0.8806107 ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 2297. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.9359422 -0.9447635  0.8360183  0.9287014]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 2298. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.97623825 -0.991551    0.3630191   0.8910246 ]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 2299. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.91762066 -0.95725906  0.9457413   0.8946953 ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 2300. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.9346647  -0.91912824  0.9707825   0.8920727 ]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 2301. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.9593799  -0.98395586 -0.04075521  0.8433037 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 2302. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.9468851  -0.97713333  0.8990841   0.9419799 ]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 2303. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.9692646 -0.9313634  0.6933341  0.9401102]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 2304. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.9783279  -0.9723373   0.94549716  0.95359635]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 2305. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.9431952  -0.9094672   0.90463614  0.9064864 ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 2306. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.9758856  -0.9740001   0.51578903  0.9411737 ]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 2307. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.95072675 -0.9829904   0.8966044   0.9396658 ]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 2308. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.95645285 -0.98398346  0.99337244  0.9018606 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 2309. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.97038734 -0.93925333  0.9234035   0.93189645]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 2310. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.95294833 -0.9954603   0.7178471   0.9384582 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 2311. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.9856919  -0.95418227  0.8290266   0.9439039 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 2312. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.9822631  -0.96114546  0.7174437   0.90795624]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 2313. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.84739363 -0.9394762   0.6895975   0.9093163 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 2314. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.8736012  -0.93600595  0.6134242   0.94871235]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 2315. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.98730254 -0.9923864   0.9223738   0.95584846]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 2316. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.90420556 -0.99338996  0.6550708   0.86911476]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 2317. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.9036288  -0.91431963  0.8285148   0.9596908 ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 2318. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.9482603  -0.9082811   0.78411174  0.96823406]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 2319. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.93284154 -0.96165025  0.8908701   0.9046893 ]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 2320. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.9637444  -0.91531664  0.67456794  0.9355681 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 2321. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.9064996 -0.7563982  0.7009126  0.8773041]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 2322. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.9807012  -0.96574104  0.83012104  0.91541266]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 2323. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.966419   -0.93205434  0.84413576  0.92469144]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 2324. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.95768714 -0.7968624   0.8701217   0.9226699 ]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 2325. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.84449816 -0.91656995  0.86907494  0.9588381 ]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 2326. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.80384564 -0.86262333  0.2897308   0.9185939 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 2327. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.10494459 -0.5662189   0.9275992   0.9252747 ]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 2328. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.783339   -0.9770111   0.49010003  0.9507458 ]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 2329. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.9194932 -0.6842388 -0.3663888  0.920465 ]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 2330. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.80737066 -0.9403126   0.83930564  0.90149486]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 2331. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.95169663 -0.7155536   0.4645089   0.8997731 ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 2332. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.94556093 -0.8348159   0.9672518   0.8688235 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 2333. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.95668316 -0.80853814  0.45982814  0.8561269 ]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 2334. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.8899127  -0.7314357   0.89191294  0.8905339 ]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 2335. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.9142399  -0.96901196  0.6722486   0.90119076]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 2336. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.8687022 -0.4514172  0.8345995  0.8848742]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 2337. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.620788  -0.5333395  0.8069358  0.8695681]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 2338. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.9653003  -0.5758242   0.75229466  0.9258342 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 2339. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.58564997 -0.9490866   0.612479    0.9416189 ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 2340. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.8724518  -0.71249056  0.34274173  0.7914572 ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 2341. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.9126712  -0.7524577   0.46743226  0.9305905 ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 2342. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.5878496  -0.7730002  -0.09463805  0.808663  ]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 2343. State = [[-0.12800547 -0.30025876  0.24621122  1.        ]]. Action = [[ 0.68223786 -0.23335111  0.7717117   0.90190244]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 2344. State = [[-0.115624   -0.3031531   0.25831783  1.        ]]. Action = [[ 0.80422556 -0.04983062  0.84967613  0.8933296 ]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 2345. State = [[-0.09756855 -0.30822942  0.27836066  1.        ]]. Action = [[ 0.89068043 -0.69574463  0.79038715  0.8748405 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 2346. State = [[-0.08628283 -0.30533767  0.28402817  1.        ]]. Action = [[0.7459688  0.16769767 0.21850586 0.70726085]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 2347. State = [[-0.06944133 -0.30684423  0.28813964  1.        ]]. Action = [[ 0.8723333  -0.37436914 -0.4326235   0.67328   ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 2348. State = [[-0.06223573 -0.3037761   0.28423813  1.        ]]. Action = [[ 0.4587009   0.0735625  -0.5723313   0.55232406]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 2349. State = [[-0.04574432 -0.30084532  0.2649203   1.        ]]. Action = [[ 0.6806023  -0.06986618 -0.77687943  0.479396  ]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 2350. State = [[-0.02546784 -0.30161598  0.23283479  1.        ]]. Action = [[ 0.23394287  0.12891746 -0.9014825   0.38391006]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 2351. State = [[-0.00638195 -0.29957658  0.20227253  1.        ]]. Action = [[ 0.7402816  -0.01470613 -0.76071894  0.3416829 ]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 2352. State = [[ 0.01658685 -0.30072096  0.1685121   1.        ]]. Action = [[ 0.5725517  -0.15241778 -0.91730374  0.3310207 ]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 2353. State = [[ 0.0396564  -0.30422595  0.13203534  1.        ]]. Action = [[ 0.53851104 -0.07800984 -0.7692619   0.19035304]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 2354. State = [[ 0.05349069 -0.30691567  0.09662489  1.        ]]. Action = [[-0.16600555  0.00251698 -0.9211422   0.28272128]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 2355. State = [[ 0.06102961 -0.30812746  0.0724779   1.        ]]. Action = [[ 0.4671961  -0.22865695 -0.9499891   0.26799345]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 2356. State = [[-0.26393813 -0.02366221  0.10960838  1.        ]]. Action = [[ 0.35426176 -0.06501907 -0.7563643   0.3830707 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 2357. State = [[-0.25252336 -0.03856576  0.10408768  1.        ]]. Action = [[ 0.95902276 -0.7435706   0.9868846   0.9347241 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 2358. State = [[-0.22107716 -0.06710844  0.1297817   1.        ]]. Action = [[ 0.9932668  -0.77880573  0.98592544  0.9805434 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 2359. State = [[-0.18086064 -0.09736329  0.16860136  1.        ]]. Action = [[ 0.9371698  -0.7220635   0.96984696  0.962098  ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 2360. State = [[-0.15719143 -0.11443353  0.19209842  1.        ]]. Action = [[ 0.9350848  -0.19771147  0.9768579   0.7884133 ]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: No entry zone
Current timestep = 2361. State = [[-0.15245588 -0.11770956  0.19668739  1.        ]]. Action = [[ 0.8690138  -0.57128525  0.8119807   0.72113216]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 2362. State = [[-0.15243606 -0.11805906  0.19692698  1.        ]]. Action = [[ 0.8185873  -0.34558725  0.7223158   0.79702926]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 2363. State = [[-0.15217856 -0.11817311  0.19709176  1.        ]]. Action = [[ 0.92901623 -0.2566107   0.7349913   0.6864346 ]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 2364. State = [[-0.15217856 -0.11817311  0.19709176  1.        ]]. Action = [[ 0.9049051  -0.52560085  0.8471285   0.82077694]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 2365. State = [[-0.14266662 -0.12602504  0.21024212  1.        ]]. Action = [[ 0.57547903 -0.49387336  0.92636824  0.69572556]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 2366. State = [[-0.12869406 -0.13659564  0.23015708  1.        ]]. Action = [[ 0.8629372  -0.7048732   0.23178458  0.604859  ]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 2367. State = [[-0.125705   -0.1377033   0.23290262  1.        ]]. Action = [[ 0.71026385 -0.13447195  0.04411757  0.52874625]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 2368. State = [[-0.12581247 -0.13795416  0.23294973  1.        ]]. Action = [[ 0.7748662  -0.34861928  0.00557745  0.5828905 ]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: No entry zone
Current timestep = 2369. State = [[-0.11464765 -0.14720574  0.24294083  1.        ]]. Action = [[ 0.8492105  -0.5964612   0.53081846  0.6483407 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 2370. State = [[-0.08954772 -0.16138083  0.25979704  1.        ]]. Action = [[ 0.8265641  -0.2640369  -0.05686194  0.45092463]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 2371. State = [[-0.07004737 -0.16787039  0.261791    1.        ]]. Action = [[ 0.5947689  -0.33120036 -0.7683653   0.3164692 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: No entry zone
Current timestep = 2372. State = [[-0.06459275 -0.17301516  0.2594386   1.        ]]. Action = [[ 0.60930586 -0.25384426 -0.6440176   0.12237442]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 2373. State = [[-0.04669035 -0.18312095  0.23454972  1.        ]]. Action = [[ 0.41788113 -0.2511134  -0.838314    0.225775  ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 2374. State = [[-0.02573504 -0.19477691  0.20447087  1.        ]]. Action = [[ 0.66374874 -0.34774065 -0.8422287   0.08729029]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 2375. State = [[-0.00624899 -0.2077639   0.1701696   1.        ]]. Action = [[ 0.15926516 -0.30037057 -0.89136547  0.10398376]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 2376. State = [[ 0.00835037 -0.21453348  0.13554369  1.        ]]. Action = [[ 0.3366301  -0.05075288 -0.736048    0.1691804 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 2377. State = [[ 0.02329657 -0.21722086  0.10734084  1.        ]]. Action = [[ 0.6612705  -0.13341177 -0.86594033  0.19149351]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 2378. State = [[ 0.04218324 -0.22266361  0.07004257  1.        ]]. Action = [[ 0.21054149 -0.14664996 -0.71183795  0.21594143]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 2379. State = [[ 0.05592781 -0.22753751  0.04835051  1.        ]]. Action = [[ 0.7400143  -0.09748274 -0.8447709   0.25379837]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 2380. State = [[ 0.05746445 -0.22839528  0.0461075   1.        ]]. Action = [[ 0.57218003 -0.08730787 -0.46713483  0.3495338 ]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 2381. State = [[ 0.0574893  -0.2284077   0.04610809  1.        ]]. Action = [[ 0.5826602  -0.02987623 -0.83554167  0.3286655 ]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 2382. State = [[ 0.0574893  -0.2284077   0.04610809  1.        ]]. Action = [[ 0.25777328 -0.01558858 -0.5889549   0.37157226]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 2383. State = [[ 0.05747289 -0.22847076  0.04612573  1.        ]]. Action = [[ 0.4188887  -0.19923323 -0.6223271   0.3199619 ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 2384. State = [[ 0.05747289 -0.22847076  0.04612573  1.        ]]. Action = [[ 0.59646606 -0.0019049  -0.6466042   0.2335639 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 2385. State = [[ 0.05747289 -0.22847076  0.04612573  1.        ]]. Action = [[ 0.42105675 -0.09664071 -0.75592655  0.3121699 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 2386. State = [[ 0.06346823 -0.22797209  0.042799    1.        ]]. Action = [[ 0.6274767   0.03746831 -0.26776636  0.4067564 ]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 2387. State = [[ 0.07791161 -0.22736965  0.0328871   1.        ]]. Action = [[ 0.43705714 -0.1318714  -0.9101225   0.30153704]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 2388. State = [[ 0.08200017 -0.22674368  0.03295441  1.        ]]. Action = [[ 0.29767108  0.0133841  -0.7938713   0.26345754]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 2389. State = [[ 0.08191395 -0.22674163  0.0327911   1.        ]]. Action = [[ 0.44107103 -0.17235124 -0.93252033  0.16346228]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 2390. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.57157505 -0.20138752 -0.53834987  0.23919165]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 2391. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.19644451 -0.08858085 -0.71580905  0.15987074]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 2392. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.5137913  -0.01640719 -0.86858517  0.25437737]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 2393. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.36280525 -0.25079554 -0.8950815   0.19059646]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 2394. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.5280572  -0.21163845 -0.8397811   0.28841686]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 2395. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.70617974 -0.21213341 -0.9233525   0.23417127]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 2396. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.37559915 -0.13657856 -0.86581814  0.16360545]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 2397. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.21591437  0.01605165 -0.80732954  0.25175846]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 2398. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.58595467 -0.13785511 -0.78873426  0.08659601]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 2399. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.46386838 -0.32972765 -0.9471889   0.18191087]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 2400. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.56566525 -0.43156785 -0.86202776  0.16441405]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 2401. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.59144664 -0.24068558 -0.7735165   0.17204618]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 2402. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.5859866  -0.47532976 -0.8019822   0.12880385]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 2403. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.19705153 -0.25425518 -0.88104457  0.21841073]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 2404. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.49103403 -0.29293108 -0.91418266  0.17802513]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 2405. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.53326106 -0.06618315 -0.8649016   0.10693216]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 2406. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.39252174 -0.35928756 -0.9065825   0.19504917]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 2407. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.6218941  -0.33685648 -0.79724354  0.13150954]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 2408. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.36368585 -0.35520214 -0.8521519   0.19420719]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 2409. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.2811234  -0.35247815 -0.8266281   0.17597616]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 2410. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[-0.01437855 -0.24431843 -0.8580059   0.15991402]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 2411. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.25178266 -0.46137822 -0.8443188   0.17332137]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 2412. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.45654333 -0.21645534 -0.88368285  0.16954803]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 2413. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.58622026 -0.2603804  -0.9278689   0.08236051]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 2414. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.06096315 -0.04567343 -0.8799446   0.12503338]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 2415. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.19485056  0.05901992 -0.77126044  0.08554459]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 2416. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.4866972  -0.19076449 -0.78621936  0.14990902]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 2417. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.29706478 -0.2821536  -0.8950009   0.13813138]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 2418. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.47830224 -0.21682608 -0.8221951   0.11053443]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 2419. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.47074378 -0.24943775 -0.838732    0.08409369]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 2420. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.61138415 -0.37828475 -0.87511444  0.06060541]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 2421. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.5749283  -0.43357253 -0.94770575  0.08981538]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 2422. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.44753397 -0.479334   -0.87209314  0.12227058]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 2423. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.55336237 -0.6822254  -0.85563755  0.00750422]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 2424. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.19032156 -0.57654643 -0.8037486   0.11462307]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 2425. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.602918   -0.5793358  -0.8469956   0.02695656]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 2426. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.65939677 -0.4281608  -0.7664231   0.15900207]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 2427. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.38982058 -0.32339776 -0.89666766  0.03770614]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 2428. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.59666276 -0.24836767 -0.81426966  0.13294923]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 2429. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.67148495 -0.37542903 -0.8208893   0.04975402]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 2430. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.593812   -0.10052663 -0.8082184   0.09971488]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 2431. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.4439056 -0.2840128 -0.6991712  0.0481925]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 2432. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.59890556 -0.3703738  -0.88087666  0.08840823]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 2433. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.5430912  -0.5337908  -0.9291344   0.10124159]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 2434. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.7681159  -0.2768963  -0.8233037   0.09223294]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 2435. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.44432473 -0.44719666 -0.8264391   0.11815357]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 2436. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.53802824 -0.46634305 -0.870029    0.05830622]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 2437. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.48479474 -0.5271566  -0.7972517   0.14547324]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 2438. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.43396926 -0.5052517  -0.9055138   0.07368922]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 2439. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.53290725 -0.5006914  -0.84356433  0.09496987]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 2440. State = [[ 0.08185332 -0.22673027  0.03264654  1.        ]]. Action = [[ 0.6908982  -0.35356724 -0.80605894  0.06342816]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 2441. State = [[ 0.08179788 -0.22671276  0.03257257  1.        ]]. Action = [[ 0.53115225 -0.45850384 -0.6461375   0.05318069]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 2442. State = [[ 0.08176769 -0.2267071   0.03250064  1.        ]]. Action = [[ 0.5233768  -0.46073246 -0.7033679   0.0662818 ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 2443. State = [[ 0.08169255 -0.22667158  0.03249659  1.        ]]. Action = [[ 0.6129967  -0.34253407 -0.80472076  0.07752192]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 2444. State = [[ 0.08169255 -0.22667158  0.03249659  1.        ]]. Action = [[ 0.37903762 -0.5128274  -0.8106012   0.08642697]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 2445. State = [[ 0.08169255 -0.22667158  0.03249659  1.        ]]. Action = [[ 0.6530075  -0.5147407  -0.7203792   0.09119117]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 2446. State = [[ 0.08169255 -0.22667158  0.03249659  1.        ]]. Action = [[ 0.70870245 -0.41972238 -0.79873586  0.04131222]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 2447. State = [[ 0.08169255 -0.22667158  0.03249659  1.        ]]. Action = [[ 0.7023797  -0.47626638 -0.77457947  0.05824101]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 2448. State = [[ 0.08169255 -0.22667158  0.03249659  1.        ]]. Action = [[ 0.58950305 -0.51726925 -0.8555109   0.07571125]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 2449. State = [[ 0.08169255 -0.22667158  0.03249659  1.        ]]. Action = [[ 0.6877279  -0.42232347 -0.8834797   0.09426045]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 2450. State = [[ 0.08169255 -0.22667158  0.03249659  1.        ]]. Action = [[ 0.19039059 -0.54664785 -0.87223196  0.09929514]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 2451. State = [[ 0.08169255 -0.22667158  0.03249659  1.        ]]. Action = [[ 0.6328161  -0.6445415  -0.6541481   0.05322433]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 2452. State = [[ 0.08169255 -0.22667158  0.03249659  1.        ]]. Action = [[ 0.54489505 -0.32886785 -0.86588037  0.05432057]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 2453. State = [[ 0.08166236 -0.22666591  0.03242468  1.        ]]. Action = [[ 0.533968   -0.57652205 -0.826652    0.05821872]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 2454. State = [[ 0.08166236 -0.22666591  0.03242468  1.        ]]. Action = [[ 0.5134654  -0.45416307 -0.6169913   0.02529228]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 2455. State = [[ 0.08166236 -0.22666591  0.03242468  1.        ]]. Action = [[ 0.49846053 -0.6212285  -0.73823255  0.01157045]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 2456. State = [[ 0.08166236 -0.22666591  0.03242468  1.        ]]. Action = [[ 0.5277102 -0.5461962 -0.669768  -0.0108875]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 2457. State = [[ 0.08166236 -0.22666591  0.03242468  1.        ]]. Action = [[ 0.646744   -0.39927655 -0.8553337   0.03507388]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 2458. State = [[-0.26235798 -0.07173236  0.11001775  1.        ]]. Action = [[ 0.65073395 -0.46759403 -0.8286564   0.01815999]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 2459. State = [[-0.25051907 -0.09295476  0.10398333  1.        ]]. Action = [[ 0.9907491  -0.87311286  0.9994242   0.9215057 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 2460. State = [[-0.2189826  -0.12140588  0.13052613  1.        ]]. Action = [[ 0.9727371  -0.6352528   0.95875096  0.95650923]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 2461. State = [[-0.18290482 -0.14864433  0.15992238  1.        ]]. Action = [[ 0.8344921  -0.75781494  0.47570002  0.9382987 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 2462. State = [[-0.16054788 -0.16605812  0.17692284  1.        ]]. Action = [[ 0.80367815 -0.5038537   0.97807515  0.94117665]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: No entry zone
Current timestep = 2463. State = [[-0.15760118 -0.16794674  0.17916761  1.        ]]. Action = [[ 0.6800178  -0.18753868  0.9632976   0.82522345]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 2464. State = [[-0.1462419  -0.17658408  0.19081436  1.        ]]. Action = [[ 0.70530796 -0.49425858  0.76933026  0.8968675 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 2465. State = [[-0.12050102 -0.19268902  0.21754372  1.        ]]. Action = [[ 0.7711439  -0.35016358  0.7014015   0.68565166]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 2466. State = [[-0.09509155 -0.20847397  0.239931    1.        ]]. Action = [[ 0.5916364  -0.44956183  0.06324995  0.5327194 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 2467. State = [[-0.07175414 -0.22158445  0.24248205  1.        ]]. Action = [[ 0.6969739  -0.27032816 -0.3861019   0.27498245]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 2468. State = [[-0.05070789 -0.23360248  0.2289159   1.        ]]. Action = [[ 0.7572396  -0.4175077  -0.88039327  0.2248429 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 2469. State = [[-0.0253257  -0.25130612  0.197041    1.        ]]. Action = [[ 0.6343919  -0.46400523 -0.8149093   0.08342946]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 2470. State = [[ 5.3736527e-04 -2.6743999e-01  1.6417611e-01  1.0000000e+00]]. Action = [[ 0.6171123  -0.3628568  -0.74160826  0.13120306]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 2471. State = [[ 0.0271012  -0.2811608   0.13311361  1.        ]]. Action = [[ 0.64261055 -0.35393006 -0.6432513   0.12400615]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 2472. State = [[ 0.04910894 -0.29657054  0.10397901  1.        ]]. Action = [[ 0.45683002 -0.4140373  -0.76585305  0.1178304 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 2473. State = [[ 0.06760955 -0.306618    0.08250584  1.        ]]. Action = [[ 0.4880799  -0.3718778  -0.61582667  0.12468183]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 2474. State = [[ 0.07477394 -0.3097327   0.08013456  1.        ]]. Action = [[ 0.3337921  -0.4418952  -0.82925755  0.14493322]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 2475. State = [[ 0.07807588 -0.31041747  0.07893903  1.        ]]. Action = [[ 0.4911995  -0.25861204 -0.9103668   0.1003629 ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 2476. State = [[ 0.07807588 -0.31041747  0.07893903  1.        ]]. Action = [[ 0.709507   -0.5476174  -0.7274545   0.10482574]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 2477. State = [[ 0.07807588 -0.31041747  0.07893903  1.        ]]. Action = [[ 0.45232165 -0.45942068 -0.8211647   0.15466046]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 2478. State = [[ 0.07807588 -0.31041747  0.07893903  1.        ]]. Action = [[ 0.55827403 -0.43667454 -0.904437    0.09496641]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 2479. State = [[ 0.07805078 -0.31040993  0.07886557  1.        ]]. Action = [[ 0.5095843  -0.48206723 -0.83970356  0.04075396]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 2480. State = [[ 0.07805078 -0.31040993  0.07886557  1.        ]]. Action = [[ 0.6609695  -0.4918812  -0.9204706   0.05098748]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 2481. State = [[ 0.07805078 -0.31040993  0.07886557  1.        ]]. Action = [[ 0.50429153 -0.39784074 -0.8480748   0.05340254]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 2482. State = [[ 0.07805078 -0.31040993  0.07886557  1.        ]]. Action = [[ 0.4507656  -0.515193   -0.844092    0.06982398]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 2483. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.40668845 -0.42985058 -0.8722269   0.06941688]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 2484. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.6284237  -0.54614747 -0.9528361   0.06753492]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 2485. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.59822893 -0.50572485 -0.8999348   0.03553319]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 2486. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.47073698 -0.40488273 -0.91252905  0.06358588]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 2487. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.49873912 -0.51379335 -0.87222624  0.02398467]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 2488. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.44375467 -0.41962886 -0.90370613  0.07864094]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 2489. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.7093923  -0.4016626  -0.92180246  0.10702038]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 2490. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.52097034 -0.41567922 -0.8786707   0.06774449]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 2491. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.38208568 -0.44657075 -0.7336011   0.03565145]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 2492. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.62395835 -0.33215523 -0.88174033  0.09726071]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 2493. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.391693   -0.592334   -0.80212635  0.0510174 ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 2494. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.36900508 -0.46928525 -0.8426571   0.06995523]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 2495. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.25114918 -0.36358106 -0.82783335  0.11837256]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 2496. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.5819349  -0.26829422 -0.82523596  0.09834111]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 2497. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.73497176 -0.47032845 -0.89860976  0.09314656]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 2498. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.5075767  -0.40552437 -0.8566926   0.06723392]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 2499. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.6685829  -0.45221484 -0.82030666  0.06209385]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 2500. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.5483353  -0.42967892 -0.8165205   0.05462897]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 2501. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.4799112  -0.38463938 -0.7888359   0.09856474]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 2502. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.59050965 -0.4391048  -0.8212092   0.06091702]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 2503. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.6534436  -0.403561   -0.84758645  0.06555307]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 2504. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.40753496 -0.42335153 -0.82802975  0.04858184]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 2505. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.60660255 -0.37689126 -0.8632169   0.07548785]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 2506. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.5543556  -0.4311378  -0.9056863   0.11545289]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 2507. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.6559136  -0.4792772  -0.88113695  0.0831064 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 2508. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.61741185 -0.45535773 -0.88590753  0.10711217]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 2509. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.7156173  -0.53310794 -0.8760774   0.07911015]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 2510. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.5788431  -0.53257513 -0.7218144   0.05654728]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 2511. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.5395905  -0.46276975 -0.8970144   0.01457417]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 2512. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.58304286 -0.45334387 -0.83207124  0.08095694]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 2513. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.6798899  -0.51661056 -0.7412587   0.05486333]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 2514. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.47425008 -0.5120234  -0.7790495   0.04766738]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 2515. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.6762017  -0.5206429  -0.8467526   0.07925749]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 2516. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.6515783 -0.6402952 -0.7557238  0.0658164]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 2517. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.39652824 -0.5355393  -0.628277    0.04934835]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 2518. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.5252079  -0.51787055 -0.8786861   0.06075644]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 2519. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.6145227  -0.7039162  -0.7298542   0.07461441]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 2520. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.47993398 -0.50708824 -0.8224266   0.10168827]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 2521. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.64503264 -0.54506135 -0.7910885   0.10781288]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 2522. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.7002175  -0.54314715 -0.6890529   0.04490376]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 2523. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.7005191  -0.5770671  -0.7480577   0.07498658]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 2524. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.668514   -0.51195365 -0.76317185  0.08266282]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 2525. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.6973338  -0.46496946 -0.70073414  0.0771811 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 2526. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.5669973  -0.43672407 -0.8282602   0.08752668]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 2527. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.62650347 -0.5540473  -0.856774    0.08285391]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 2528. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.62263525 -0.550696   -0.77326083  0.07070518]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 2529. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.57312846 -0.47773862 -0.74770445  0.06050503]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 2530. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.5800531  -0.5490327  -0.7530527   0.04140162]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 2531. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.6633178  -0.53731847 -0.73715234  0.0523361 ]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 2532. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.5862231  -0.61161    -0.90610754  0.05888772]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 2533. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.5035975  -0.598995   -0.8854689   0.09144747]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 2534. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.7891679  -0.49445128 -0.821696    0.03665388]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 2535. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.44622147 -0.51522964 -0.8901059   0.02946711]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 2536. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.40986562 -0.5346935  -0.80655557  0.07317877]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 2537. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.67369795 -0.5148122  -0.634991    0.0950917 ]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 2538. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.5618541  -0.5320238  -0.732442    0.05873716]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 2539. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.6096871  -0.5940861  -0.7906726   0.08028448]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 2540. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.5128406  -0.48811126 -0.8487066   0.10029685]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 2541. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.48208022 -0.59227884 -0.8749038   0.09560084]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 2542. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.4280697  -0.5599523  -0.79250884  0.10157418]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 2543. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.43873954 -0.531658   -0.8252373   0.11427927]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 2544. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.6407461  -0.5253077  -0.8383287   0.11021543]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 2545. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.47177732 -0.455451   -0.76736945  0.04923785]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 2546. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.65026855 -0.42651248 -0.6634039   0.09925151]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 2547. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.60909903 -0.54969776 -0.7728705   0.09080708]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 2548. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.51189363 -0.4906429  -0.67274666  0.08149195]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 2549. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.44415498 -0.49418366 -0.66252434  0.09937537]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 2550. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.67705154 -0.43808198 -0.7360928   0.07987654]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 2551. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.6773534  -0.53989667 -0.7976227   0.09785104]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 2552. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.4697485  -0.45767748 -0.77296233  0.07295692]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 2553. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.4268098  -0.53840697 -0.8054868   0.03336513]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 2554. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.4041319  -0.50797313 -0.79952914  0.07829463]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 2555. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.56709385 -0.5704472  -0.7799995   0.02054989]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 2556. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.524619   -0.60879177 -0.6934285   0.03079581]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 2557. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.57527554 -0.6023228  -0.8286791   0.0664165 ]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 2558. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.5411341  -0.5996652  -0.7641926   0.06558776]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 2559. State = [[ 0.07797886 -0.31036857  0.07886136  1.        ]]. Action = [[ 0.49237013 -0.5565978  -0.86229503  0.10528302]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 2560. State = [[-0.2709324   0.17444299  0.11320142  1.        ]]. Action = [[ 0.37431908 -0.5972953  -0.78836185  0.07738149]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 2561. State = [[-0.24937059  0.180492    0.10785467  1.        ]]. Action = [[ 0.9686961 -0.9731846  0.9801736  0.9016371]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 2562. State = [[-0.21712296  0.14910756  0.13408475  1.        ]]. Action = [[ 0.9950383 -0.9510299  0.9689498  0.9026582]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 2563. State = [[-0.1782467   0.11692318  0.17181714  1.        ]]. Action = [[ 0.979723   -0.8450505   0.96963906  0.7805761 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 2564. State = [[-0.15551402  0.09941601  0.19644323  1.        ]]. Action = [[ 0.9617002 -0.8399185  0.6837355  0.4581461]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: No entry zone
Current timestep = 2565. State = [[-0.15183826  0.0976686   0.20000753  1.        ]]. Action = [[ 0.86359835 -0.7137399   0.4773383   0.29696715]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 2566. State = [[-0.15124346  0.09699394  0.20081589  1.        ]]. Action = [[ 0.93611455 -0.34293944  0.35063386  0.2350825 ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 2567. State = [[-0.1509567   0.09622892  0.2010978   1.        ]]. Action = [[ 0.82113004 -0.8231007   0.5913179   0.29413915]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 2568. State = [[-0.1509219   0.09595252  0.20114778  1.        ]]. Action = [[ 0.9045708  -0.6553587   0.4510982   0.10131335]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 2569. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.94077444 -0.81746703 -0.16057378  0.23102522]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 2570. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.9572449  -0.81567526  0.17403495  0.2575817 ]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 2571. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.9596982  -0.7157538  -0.03378361  0.18746269]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 2572. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.88553834 -0.77007496  0.4536053   0.30215907]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: No entry zone
Current timestep = 2573. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.76210177 -0.78138286  0.35412014 -0.03547162]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: No entry zone
Current timestep = 2574. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.9503286  -0.84282225  0.59509814  0.21896577]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: No entry zone
Current timestep = 2575. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.8952725  -0.8472285   0.40167522  0.17272663]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: No entry zone
Current timestep = 2576. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.93879163 -0.8669282   0.44473433  0.2281903 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: No entry zone
Current timestep = 2577. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.8245112  -0.7633478   0.12164748  0.24794698]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: No entry zone
Current timestep = 2578. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.7060889  -0.7125551   0.39439023  0.32583022]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: No entry zone
Current timestep = 2579. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.82725406 -0.75894755  0.64452696  0.2536614 ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: No entry zone
Current timestep = 2580. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.8379493  -0.8199876  -0.19175428  0.22167647]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: No entry zone
Current timestep = 2581. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.9184799  -0.7675079   0.43725872  0.06800997]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: No entry zone
Current timestep = 2582. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.82160544 -0.7516982  -0.02234071  0.23673797]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: No entry zone
Current timestep = 2583. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.92409945 -0.8712707   0.2819867   0.31194425]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: No entry zone
Current timestep = 2584. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.91466665 -0.62189764  0.7365725   0.25046825]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: No entry zone
Current timestep = 2585. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.7724738 -0.8908878  0.2526989  0.0569315]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: No entry zone
Current timestep = 2586. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.9175348  -0.9030552   0.6287385   0.32035136]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: No entry zone
Current timestep = 2587. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.7545607  -0.5889106   0.30442524  0.30708396]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: No entry zone
Current timestep = 2588. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.87965727 -0.79159284  0.35943806  0.02644956]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: No entry zone
Current timestep = 2589. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.8735337  -0.8459422  -0.15632439  0.298195  ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: No entry zone
Current timestep = 2590. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.9218185  -0.8632522   0.34258413  0.2638402 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: No entry zone
Current timestep = 2591. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.9397249  -0.72626114  0.49218237  0.1933167 ]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: No entry zone
Current timestep = 2592. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.8953047  -0.81854975 -0.1781758   0.13495457]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: No entry zone
Current timestep = 2593. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.89206815 -0.7572986   0.03876829  0.21357417]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: No entry zone
Current timestep = 2594. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.9156699  -0.7651195   0.5261593   0.36289358]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: No entry zone
Current timestep = 2595. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.80956054 -0.43354434  0.31427467  0.1809907 ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: No entry zone
Current timestep = 2596. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.87043715 -0.7004772   0.4444766   0.19114983]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: No entry zone
Current timestep = 2597. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.9188888 -0.9034389  0.5375309  0.3353231]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: No entry zone
Current timestep = 2598. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.88781786 -0.73893005  0.6668973   0.29737973]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: No entry zone
Current timestep = 2599. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.81549656 -0.86217576  0.5905397   0.42264485]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: No entry zone
Current timestep = 2600. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.94105697 -0.5669347   0.6994479   0.30524302]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: No entry zone
Current timestep = 2601. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.96208787 -0.7617651   0.23623538  0.33265388]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: No entry zone
Current timestep = 2602. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.9446267  -0.88100636  0.485811    0.2655108 ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: No entry zone
Current timestep = 2603. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.92018914 -0.8848344   0.535043    0.3356217 ]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: No entry zone
Current timestep = 2604. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.94877577 -0.65643966  0.5483508   0.31278217]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: No entry zone
Current timestep = 2605. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.9113877  -0.854237    0.7599298   0.22178483]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: No entry zone
Current timestep = 2606. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.8581896  -0.5735059   0.68568516  0.2706113 ]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: No entry zone
Current timestep = 2607. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.82247066 -0.88198465  0.2837603   0.26532912]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: No entry zone
Current timestep = 2608. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.80710065 -0.8709865   0.50595355  0.07043087]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: No entry zone
Current timestep = 2609. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.97123456 -0.80566335  0.4694134   0.27078676]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: No entry zone
Current timestep = 2610. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.93608665 -0.6853663   0.71677315  0.3418591 ]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: No entry zone
Current timestep = 2611. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.849965   -0.7523454   0.2921462   0.22992516]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: No entry zone
Current timestep = 2612. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.9399419  -0.6621059   0.71164966  0.20662355]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: No entry zone
Current timestep = 2613. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.91366863 -0.67578095  0.10375237  0.3692199 ]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: No entry zone
Current timestep = 2614. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.8643069  -0.86762094  0.69207394  0.32567954]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: No entry zone
Current timestep = 2615. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.918221   -0.79304475  0.5100877   0.05791891]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: No entry zone
Current timestep = 2616. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.8889704  -0.6442283   0.33887804  0.14605951]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: No entry zone
Current timestep = 2617. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.8911252  -0.50496113  0.64351034  0.30390942]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: No entry zone
Current timestep = 2618. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.88979435 -0.8680245   0.23914838  0.31478608]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: No entry zone
Current timestep = 2619. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.9361615  -0.7809548   0.42077506  0.3667029 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: No entry zone
Current timestep = 2620. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.8766817  -0.48567712  0.18957913  0.27934027]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: No entry zone
Current timestep = 2621. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.8563926  -0.43908346  0.3518877   0.3407209 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: No entry zone
Current timestep = 2622. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.7504419  -0.77234286  0.58081126  0.18023086]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: No entry zone
Current timestep = 2623. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.79664207 -0.7088803  -0.10906875  0.43436813]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: No entry zone
Current timestep = 2624. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.8878572  -0.4794364   0.19568813  0.11190128]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: No entry zone
Current timestep = 2625. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.9370593  -0.6827037   0.50148165  0.2861588 ]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: No entry zone
Current timestep = 2626. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.92163396 -0.7985796   0.5527663   0.3266034 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: No entry zone
Current timestep = 2627. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.9504839  -0.73489106  0.53483987  0.38832796]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: No entry zone
Current timestep = 2628. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.9201969  -0.8908186   0.6216736   0.12974823]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: No entry zone
Current timestep = 2629. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.8583646  -0.4871502   0.29638195  0.13410568]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: No entry zone
Current timestep = 2630. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.9012867  -0.4386974  -0.08245921  0.23758948]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: No entry zone
Current timestep = 2631. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.8402474  -0.65489346  0.37002027  0.17387855]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: No entry zone
Current timestep = 2632. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.80665135 -0.50183874  0.5269098   0.14368856]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: No entry zone
Current timestep = 2633. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.9126916  -0.8270924  -0.03898001  0.17543662]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: No entry zone
Current timestep = 2634. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.85270953 -0.89251107  0.44695067  0.17415237]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: No entry zone
Current timestep = 2635. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.84635746 -0.8166322   0.11318743  0.26935172]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: No entry zone
Current timestep = 2636. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.86562467 -0.515269    0.5419934   0.37593675]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: No entry zone
Current timestep = 2637. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.86671066 -0.5319099   0.3733945   0.2697636 ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: No entry zone
Current timestep = 2638. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.9014702  -0.6732949   0.21794009  0.38957572]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: No entry zone
Current timestep = 2639. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.8712859  -0.6731687   0.1872083   0.24043286]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: No entry zone
Current timestep = 2640. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.94021773 -0.29073972 -0.11326504  0.25632882]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: No entry zone
Current timestep = 2641. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.88999677 -0.81668717  0.02551425  0.19713831]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: No entry zone
Current timestep = 2642. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.94615805 -0.55523896  0.65049267  0.24549103]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: No entry zone
Current timestep = 2643. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.8112031  -0.62744844 -0.03322047  0.21217775]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: No entry zone
Current timestep = 2644. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.91268134 -0.4593395   0.45773363  0.32858336]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: No entry zone
Current timestep = 2645. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.9204743  -0.24304724  0.30448866  0.2785083 ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: No entry zone
Current timestep = 2646. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.9568602  -0.0877918   0.3689854   0.17896843]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: No entry zone
Current timestep = 2647. State = [[-0.15089531  0.09574065  0.20118615  1.        ]]. Action = [[ 0.67661476 -0.5559901  -0.09727502  0.3214972 ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: No entry zone
Current timestep = 2648. State = [[-0.15098417  0.09575625  0.20119771  1.        ]]. Action = [[ 0.92287827 -0.70030355  0.5582708   0.19398141]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: No entry zone
Current timestep = 2649. State = [[-0.15098417  0.09575625  0.20119771  1.        ]]. Action = [[ 0.802331   -0.87808746  0.04248703  0.29396236]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: No entry zone
Current timestep = 2650. State = [[-0.15098417  0.09575625  0.20119771  1.        ]]. Action = [[ 0.79288137 -0.5852315   0.3081379   0.36007214]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: No entry zone
Current timestep = 2651. State = [[-0.15098417  0.09575625  0.20119771  1.        ]]. Action = [[ 0.7450259  -0.2950356   0.23208189  0.3646053 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: No entry zone
Current timestep = 2652. State = [[-0.15098417  0.09575625  0.20119771  1.        ]]. Action = [[ 0.56111956 -0.5434399  -0.04399616  0.34928322]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: No entry zone
Current timestep = 2653. State = [[-0.15098417  0.09575625  0.20119771  1.        ]]. Action = [[0.8689461  0.19311678 0.31705213 0.3358245 ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: No entry zone
Current timestep = 2654. State = [[-0.15098417  0.09575625  0.20119771  1.        ]]. Action = [[ 0.7489662  -0.34714478  0.17502522  0.29974878]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: No entry zone
Current timestep = 2655. State = [[-0.1510949   0.09575488  0.20119268  1.        ]]. Action = [[ 0.94670653 -0.09424669  0.43294024  0.1540327 ]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: No entry zone
Current timestep = 2656. State = [[-0.15112253  0.09575453  0.20119143  1.        ]]. Action = [[ 0.66903496 -0.6299101   0.23915756  0.30011535]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: No entry zone
Current timestep = 2657. State = [[-0.15120564  0.09575351  0.20118771  1.        ]]. Action = [[ 0.73895335 -0.7027521   0.22517943  0.40701056]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: No entry zone
Current timestep = 2658. State = [[-0.15120564  0.09575351  0.20118771  1.        ]]. Action = [[ 0.6568103  -0.58030826  0.03836703  0.24782848]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: No entry zone
Current timestep = 2659. State = [[-0.15120564  0.09575351  0.20118771  1.        ]]. Action = [[ 0.8421428  -0.18259126  0.14383173  0.24795341]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: No entry zone
Current timestep = 2660. State = [[-0.15120564  0.09575351  0.20118771  1.        ]]. Action = [[ 0.9051956  -0.42262286 -0.21732426  0.34605026]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: No entry zone
Current timestep = 2661. State = [[-0.15120564  0.09575351  0.20118771  1.        ]]. Action = [[ 0.6172923  -0.42925566 -0.10986316  0.40037572]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: No entry zone
Current timestep = 2662. State = [[-0.25815612 -0.12846719  0.11847928  1.        ]]. Action = [[ 0.8850025  -0.5884344   0.18845499  0.420686  ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: No entry zone
Current timestep = 2663. State = [[-0.2479391  -0.15399103  0.11306881  1.        ]]. Action = [[ 0.88039494 -0.73098266  0.96800935  0.86929834]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 2664. State = [[-0.23766726 -0.17891996  0.13664964  1.        ]]. Action = [[-0.33548635 -0.55260265  0.96014977  0.98587656]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 2665. State = [[-0.22452357 -0.19258234  0.17237136  1.        ]]. Action = [[ 0.99504113 -0.18918383  0.97917306  0.99872553]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 2666. State = [[-0.19105132 -0.20524997  0.2114571   1.        ]]. Action = [[ 0.9574394  -0.42988837  0.9199245   0.988541  ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 2667. State = [[-0.15467252 -0.22164674  0.24935775  1.        ]]. Action = [[ 0.90204966 -0.27200115  0.9407191   0.98295975]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 2668. State = [[-0.12514344 -0.22480537  0.28089875  1.        ]]. Action = [[0.42603815 0.34755528 0.50544333 0.9376596 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 2669. State = [[-0.10484385 -0.22310027  0.29560047  1.        ]]. Action = [[ 0.53335357 -0.02613419 -0.22633672  0.7454736 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 2670. State = [[-0.09407739 -0.22326861  0.28600547  1.        ]]. Action = [[ 0.3047005  -0.13577205 -0.83919674  0.4035058 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 2671. State = [[-0.08056867 -0.22575861  0.2612659   1.        ]]. Action = [[ 0.33591795 -0.03754818 -0.7865878   0.4163499 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 2672. State = [[-0.06838701 -0.22893438  0.2328941   1.        ]]. Action = [[ 0.4002571  -0.19260907 -0.85207385  0.3701223 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 2673. State = [[-0.05260021 -0.22839327  0.20228845  1.        ]]. Action = [[ 0.28301692  0.27230012 -0.6492819   0.5391458 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 2674. State = [[-0.03942129 -0.22348338  0.1767518   1.        ]]. Action = [[ 0.5153687   0.06017804 -0.8242678   0.5093539 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 2675. State = [[-0.02338277 -0.22461815  0.14807932  1.        ]]. Action = [[ 0.17702615 -0.18929154 -0.29412115  0.5488293 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 2676. State = [[-0.00883216 -0.22842105  0.13289751  1.        ]]. Action = [[ 0.50376654 -0.07498139 -0.3136139   0.4451052 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 2677. State = [[ 0.00965433 -0.23353986  0.11856365  1.        ]]. Action = [[ 0.5444455  -0.26851457 -0.33727622  0.5509435 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 2678. State = [[ 0.02456702 -0.24328524  0.10118919  1.        ]]. Action = [[ 0.25387168 -0.3896109  -0.56327766  0.3277979 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 2679. State = [[ 0.03418922 -0.25208232  0.07819346  1.        ]]. Action = [[ 0.20298183 -0.11936539 -0.70423996  0.3432238 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 2680. State = [[ 0.04343248 -0.25664145  0.05105438  1.        ]]. Action = [[ 0.28192878 -0.09890652 -0.6963964   0.44213498]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 2681. State = [[ 0.05451816 -0.26050314  0.02994959  1.        ]]. Action = [[ 0.3846867   0.05734634 -0.64491177  0.45302963]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 2682. State = [[ 0.05727572 -0.26102525  0.02789111  1.        ]]. Action = [[ 0.5568757  -0.10872108 -0.25738728  0.44934928]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 2683. State = [[ 0.05660689 -0.26482642  0.02791582  1.        ]]. Action = [[-0.08206213 -0.16651708  0.08975399  0.44405782]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 2684. State = [[ 0.05566012 -0.2685037   0.02866709  1.        ]]. Action = [[ 0.36137533  0.06569338 -0.24364501  0.5334611 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 2685. State = [[ 0.05521589 -0.2698861   0.02898434  1.        ]]. Action = [[-0.12981606 -0.16075778 -0.73279715  0.59097826]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 2686. State = [[ 0.05516123 -0.27050263  0.02911463  1.        ]]. Action = [[ 0.62098324 -0.34678727 -0.2106514   0.35581136]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 2687. State = [[ 0.05513978 -0.27056584  0.02912842  1.        ]]. Action = [[-0.1674065  -0.10296011 -0.3148526   0.4229468 ]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 2688. State = [[ 0.05513978 -0.27056584  0.02912842  1.        ]]. Action = [[-0.40367293 -0.28279722 -0.15143365  0.54901326]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 2689. State = [[ 0.05513978 -0.27056584  0.02912842  1.        ]]. Action = [[ 0.14855981 -0.15229523 -0.14282829  0.6195302 ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 2690. State = [[ 0.05513978 -0.27056584  0.02912842  1.        ]]. Action = [[-0.6523732  -0.1674053  -0.42899036  0.5892153 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 2691. State = [[ 0.05513978 -0.27056584  0.02912842  1.        ]]. Action = [[ 0.4340893  -0.46538746 -0.38671398  0.5917157 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 2692. State = [[ 0.05376234 -0.27600813  0.0300247   1.        ]]. Action = [[-0.3344226  -0.227916    0.07369387  0.5215478 ]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 2693. State = [[ 0.05294028 -0.27933535  0.03063584  1.        ]]. Action = [[-0.7710457  -0.05553031 -0.37290788  0.5464628 ]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 2694. State = [[ 0.05010258 -0.28042167  0.02952527  1.        ]]. Action = [[-0.471112    0.12595081  0.0101409   0.5431378 ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 2695. State = [[ 0.04611478 -0.28832644  0.0308205   1.        ]]. Action = [[-0.12237203 -0.32392967  0.20057225  0.73930526]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 2696. State = [[ 0.04430476 -0.29392377  0.03295784  1.        ]]. Action = [[ 0.14865708 -0.08100116 -0.20617199  0.8645253 ]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 2697. State = [[ 0.03812556 -0.29916412  0.03334619  1.        ]]. Action = [[-0.55143803 -0.14760756  0.05938971  0.657001  ]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 2698. State = [[ 0.02860356 -0.29838073  0.03746417  1.        ]]. Action = [[-0.30992275  0.45579016  0.30364656  0.83344316]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 2699. State = [[ 0.0198373  -0.28318936  0.05814348  1.        ]]. Action = [[-0.26833642  0.67815685  0.86843634  0.8695135 ]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 2700. State = [[-0.00108176 -0.26222607  0.08923056  1.        ]]. Action = [[-0.90815747  0.3355      0.68918204  0.90544987]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 2701. State = [[-0.02669144 -0.24745248  0.11450227  1.        ]]. Action = [[-0.398789    0.28524566  0.37690318  0.9341743 ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 2702. State = [[-0.04032511 -0.23035553  0.13733722  1.        ]]. Action = [[-0.04197168  0.5965607   0.7417879   0.97382116]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 2703. State = [[-0.05690856 -0.20760629  0.1644656   1.        ]]. Action = [[-0.8850364   0.55246675  0.6619189   0.9380574 ]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 2704. State = [[-0.07095321 -0.18377468  0.19840483  1.        ]]. Action = [[0.69366515 0.46174598 0.8983381  0.93369496]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 2705. State = [[-0.06806896 -0.17271449  0.21805622  1.        ]]. Action = [[-0.24356544  0.3704393   0.49330115  0.8027439 ]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: No entry zone
Current timestep = 2706. State = [[-0.06803202 -0.17101339  0.21901064  1.        ]]. Action = [[ 0.62907887  0.71549094 -0.20696396  0.83198595]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: No entry zone
Current timestep = 2707. State = [[-0.0729425  -0.16077928  0.22655463  1.        ]]. Action = [[-0.72213966  0.6225705   0.45580375  0.81105673]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 2708. State = [[-0.08589165 -0.14515552  0.2418328   1.        ]]. Action = [[0.22543764 0.08748531 0.21309912 0.8309642 ]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 2709. State = [[-0.08116265 -0.13366328  0.2524692   1.        ]]. Action = [[0.5823885  0.44215667 0.49843776 0.7907891 ]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 2710. State = [[-0.07797333 -0.1191342   0.26910055  1.        ]]. Action = [[-0.32766736  0.24572098  0.5294684   0.76374865]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 2711. State = [[-0.07910135 -0.11173493  0.2862953   1.        ]]. Action = [[0.2668941  0.09787416 0.2480048  0.64717627]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 2712. State = [[-0.07200062 -0.11198672  0.29475874  1.        ]]. Action = [[ 0.430071   -0.30619365  0.07675648  0.6220436 ]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 2713. State = [[-0.0726034  -0.12004264  0.29439232  1.        ]]. Action = [[-0.48136473 -0.2934398  -0.55525964  0.52447164]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 2714. State = [[-0.0732088  -0.12283784  0.28612873  1.        ]]. Action = [[ 0.4640988   0.2349019  -0.23520684  0.598438  ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 2715. State = [[-0.0706474  -0.11893712  0.2793722   1.        ]]. Action = [[ 0.15881586  0.14203453 -0.08220786  0.7127868 ]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 2716. State = [[-0.06663137 -0.11196304  0.27059475  1.        ]]. Action = [[-0.06478953  0.32045436 -0.35483432  0.66795516]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 2717. State = [[-0.06009523 -0.10347265  0.26220763  1.        ]]. Action = [[ 0.36191154  0.18543935 -0.15988934  0.38240337]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 2718. State = [[-0.0513811  -0.08930523  0.24927701  1.        ]]. Action = [[ 0.11156762  0.568053   -0.54483825  0.6789458 ]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 2719. State = [[-0.04922468 -0.07902081  0.23763715  1.        ]]. Action = [[ 0.5155984   0.35028982 -0.7073544   0.57586765]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: No entry zone
Current timestep = 2720. State = [[-0.04921806 -0.07740119  0.2366742   1.        ]]. Action = [[ 0.61524415  0.00711322 -0.2516123   0.67388415]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: No entry zone
Current timestep = 2721. State = [[-0.04928822 -0.0772799   0.23606776  1.        ]]. Action = [[ 0.1044693   0.10674131 -0.14723116  0.59210265]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: No entry zone
Current timestep = 2722. State = [[-0.04921909 -0.07730603  0.23600833  1.        ]]. Action = [[ 0.56801486 -0.16632283 -0.3236649   0.49448872]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: No entry zone
Current timestep = 2723. State = [[-0.04919265 -0.07731457  0.23600835  1.        ]]. Action = [[ 0.61847234  0.03773355 -0.6813804   0.5598239 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: No entry zone
Current timestep = 2724. State = [[-0.04911359 -0.07734011  0.2360084   1.        ]]. Action = [[ 0.7775724   0.11628127 -0.486297    0.5940962 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: No entry zone
Current timestep = 2725. State = [[-0.04914322 -0.07734186  0.2358312   1.        ]]. Action = [[ 0.05881679 -0.0732975  -0.46954715  0.46419883]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: No entry zone
Current timestep = 2726. State = [[-0.04793961 -0.07598606  0.23662148  1.        ]]. Action = [[0.02609324 0.08377624 0.11692846 0.4861977 ]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 2727. State = [[-0.04759131 -0.07451316  0.23699665  1.        ]]. Action = [[ 0.60877943 -0.16619706 -0.2874354   0.5726321 ]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: No entry zone
Current timestep = 2728. State = [[-0.04761703 -0.07409555  0.23701653  1.        ]]. Action = [[ 0.6036246  -0.15460259 -0.60522854  0.38652182]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: No entry zone
Current timestep = 2729. State = [[-0.04761703 -0.07409555  0.23701653  1.        ]]. Action = [[ 0.56724215 -0.08600402 -0.43422562  0.3874557 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: No entry zone
Current timestep = 2730. State = [[-0.04761703 -0.07409555  0.23701653  1.        ]]. Action = [[ 0.48615718  0.06085134 -0.6239182   0.43415606]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: No entry zone
Current timestep = 2731. State = [[-0.04761703 -0.07409555  0.23701653  1.        ]]. Action = [[-0.09074956 -0.27781737 -0.5658351   0.534456  ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: No entry zone
Current timestep = 2732. State = [[-0.04761703 -0.07409555  0.23701653  1.        ]]. Action = [[ 0.65488505 -0.04064876 -0.64672476  0.53137946]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: No entry zone
Current timestep = 2733. State = [[-0.04761703 -0.07409555  0.23701653  1.        ]]. Action = [[ 0.3623085   0.13218069 -0.38419825  0.48003113]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: No entry zone
Current timestep = 2734. State = [[-0.04761703 -0.07409555  0.23701653  1.        ]]. Action = [[ 0.281471   -0.07622993 -0.76640123  0.6151942 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: No entry zone
Current timestep = 2735. State = [[-0.04761703 -0.07409555  0.23701653  1.        ]]. Action = [[ 0.3514285  -0.09606206 -0.79516625  0.5225785 ]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: No entry zone
Current timestep = 2736. State = [[-0.04761703 -0.07409555  0.23701653  1.        ]]. Action = [[ 0.507635   -0.41104817 -0.7595753   0.42614973]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: No entry zone
Current timestep = 2737. State = [[-0.04761703 -0.07409555  0.23701653  1.        ]]. Action = [[ 0.09713161 -0.24504143 -0.15455359  0.37508702]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: No entry zone
Current timestep = 2738. State = [[-0.04761703 -0.07409555  0.23701653  1.        ]]. Action = [[ 0.5066525  -0.41672236 -0.54675555  0.51663375]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: No entry zone
Current timestep = 2739. State = [[-0.04761703 -0.07409555  0.23701653  1.        ]]. Action = [[ 0.15668654  0.03169799 -0.50969565  0.5969765 ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: No entry zone
Current timestep = 2740. State = [[-0.04761703 -0.07409555  0.23701653  1.        ]]. Action = [[ 0.76541173 -0.10549653 -0.45325243  0.5324197 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: No entry zone
Current timestep = 2741. State = [[-0.04761703 -0.07409555  0.23701653  1.        ]]. Action = [[ 0.64178824  0.02310061 -0.2034542   0.59124875]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: No entry zone
Current timestep = 2742. State = [[-0.04761703 -0.07409555  0.23701653  1.        ]]. Action = [[ 0.403466   -0.13028926 -0.5474892   0.53709507]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: No entry zone
Current timestep = 2743. State = [[-0.04761703 -0.07409555  0.23701653  1.        ]]. Action = [[ 0.28397822 -0.24865341 -0.50196713  0.40298128]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: No entry zone
Current timestep = 2744. State = [[-0.04761703 -0.07409555  0.23701653  1.        ]]. Action = [[ 0.13299584  0.01448023 -0.20354086  0.5700288 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: No entry zone
Current timestep = 2745. State = [[-0.04761703 -0.07409555  0.23701653  1.        ]]. Action = [[ 0.5442889   0.32502627 -0.5875843   0.44271088]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: No entry zone
Current timestep = 2746. State = [[-0.04761703 -0.07409555  0.23701653  1.        ]]. Action = [[ 0.14134371 -0.00798845 -0.479792    0.4625951 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: No entry zone
Current timestep = 2747. State = [[-0.04761703 -0.07409555  0.23701653  1.        ]]. Action = [[ 0.5163429  -0.13605273 -0.33410764  0.5314009 ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: No entry zone
Current timestep = 2748. State = [[-0.04761703 -0.07409555  0.23701653  1.        ]]. Action = [[-0.22620356  0.09583771 -0.45468056  0.47796392]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: No entry zone
Current timestep = 2749. State = [[-0.04761703 -0.07409555  0.23701653  1.        ]]. Action = [[ 0.30377102 -0.3889364  -0.33833528  0.4727018 ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: No entry zone
Current timestep = 2750. State = [[-0.04761703 -0.07409555  0.23701653  1.        ]]. Action = [[ 0.0055728  -0.30663204 -0.1453796   0.5330256 ]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: No entry zone
Current timestep = 2751. State = [[-0.04763369 -0.07396168  0.2370165   1.        ]]. Action = [[-0.07589769  0.04964387 -0.46971262  0.50567937]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: No entry zone
Current timestep = 2752. State = [[-0.04763369 -0.07396168  0.2370165   1.        ]]. Action = [[ 0.37143457 -0.40931904 -0.42743486  0.43920016]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: No entry zone
Current timestep = 2753. State = [[-0.04764211 -0.07389411  0.23701648  1.        ]]. Action = [[ 0.52478707 -0.27139127 -0.30534184  0.49441218]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: No entry zone
Current timestep = 2754. State = [[-0.04764211 -0.07389411  0.23701648  1.        ]]. Action = [[ 0.46335912  0.4140501  -0.47835898  0.29855013]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: No entry zone
Current timestep = 2755. State = [[-0.04385391 -0.07358136  0.23949823  1.        ]]. Action = [[ 0.30293775 -0.05726242  0.09289372  0.44356894]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 2756. State = [[-0.03906005 -0.07323933  0.24296215  1.        ]]. Action = [[-0.05680567 -0.01357657 -0.30675483  0.56688035]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: No entry zone
Current timestep = 2757. State = [[-0.03845764 -0.07321658  0.24340226  1.        ]]. Action = [[ 0.52605474 -0.22463    -0.41206396  0.40464318]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: No entry zone
Current timestep = 2758. State = [[-0.03840236 -0.07321446  0.24344754  1.        ]]. Action = [[ 0.66434836 -0.26706004 -0.36823595  0.53469646]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: No entry zone
Current timestep = 2759. State = [[-0.03218867 -0.0755556   0.24148533  1.        ]]. Action = [[ 0.59577227 -0.23139495 -0.13187909  0.49250126]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 2760. State = [[-0.0166986  -0.07769641  0.23510009  1.        ]]. Action = [[ 0.48807812 -0.12833285 -0.5407854   0.38414884]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: No entry zone
Current timestep = 2761. State = [[-0.01560966 -0.07788827  0.23544014  1.        ]]. Action = [[ 0.6617975  -0.3077016  -0.8135947   0.29210186]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: No entry zone
Current timestep = 2762. State = [[-0.01560468 -0.07803418  0.23547526  1.        ]]. Action = [[ 0.12164283 -0.29228914 -0.63947976  0.33288825]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: No entry zone
Current timestep = 2763. State = [[-0.01560468 -0.07803418  0.23547526  1.        ]]. Action = [[ 0.68322587 -0.2467761  -0.77017975  0.17017937]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: No entry zone
Current timestep = 2764. State = [[-0.25913057 -0.1452694   0.11247198  1.        ]]. Action = [[ 0.5420356  -0.6056319  -0.79601395  0.3304224 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: No entry zone
Current timestep = 2765. State = [[-0.25103444 -0.1746132   0.10548075  1.        ]]. Action = [[ 0.717783   -0.84393096  0.9393792   0.9956751 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 2766. State = [[-0.22985882 -0.19703065  0.12800871  1.        ]]. Action = [[ 0.6378379  -0.3825177   0.77715445  0.9924139 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 2767. State = [[-0.20632762 -0.21262363  0.1587571   1.        ]]. Action = [[ 0.4819311  -0.3593135   0.9411391   0.99562335]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 2768. State = [[-0.18880452 -0.21914217  0.19393496  1.        ]]. Action = [[0.22738159 0.30839896 0.88098955 0.9748614 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 2769. State = [[-0.18590412 -0.21755019  0.22770756  1.        ]]. Action = [[-0.66009337  0.19875193  0.837991    0.95728946]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 2770. State = [[-0.18803395 -0.2018612   0.2605812   1.        ]]. Action = [[0.4092524  0.7637203  0.69762003 0.94945025]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 2771. State = [[-0.18941285 -0.17628196  0.288255    1.        ]]. Action = [[-0.36507666  0.544502    0.73492575  0.95979404]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 2772. State = [[-0.18924032 -0.15219538  0.31532803  1.        ]]. Action = [[0.44352984 0.69666266 0.5657189  0.85860944]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 2773. State = [[-0.1894133  -0.12514067  0.34016123  1.        ]]. Action = [[-0.8114799  0.6954901  0.6606107  0.8241724]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 2774. State = [[-0.20713569 -0.09684935  0.3685685   1.        ]]. Action = [[-0.2214166   0.66826916  0.6212015   0.91083014]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 2775. State = [[-0.22185414 -0.07841167  0.394713    1.        ]]. Action = [[-0.626475    0.17815423  0.7704452   0.80753803]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 2776. State = [[-0.23734958 -0.07230041  0.41436112  1.        ]]. Action = [[-0.01653713  0.48485613  0.62050176  0.9271984 ]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: Workspace boundary
Current timestep = 2777. State = [[-0.23927842 -0.07110301  0.41569933  1.        ]]. Action = [[-0.37435234  0.82274973  0.8624468   0.71994495]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Current timestep = 2778. State = [[-0.23956798 -0.07126151  0.41624498  1.        ]]. Action = [[0.06713283 0.6425936  0.79479146 0.832945  ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Current timestep = 2779. State = [[-0.23937955 -0.07137805  0.416489    1.        ]]. Action = [[0.22738326 0.49143648 0.51774955 0.888767  ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 2780. State = [[-0.23933503 -0.07138565  0.4165409   1.        ]]. Action = [[0.49988258 0.36471033 0.63436246 0.9146483 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 2781. State = [[-0.23933503 -0.07138565  0.4165409   1.        ]]. Action = [[0.1715852  0.6571641  0.87847984 0.8746911 ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 2782. State = [[-0.23933503 -0.07138565  0.4165409   1.        ]]. Action = [[0.33724046 0.18080997 0.6714654  0.8379996 ]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 2783. State = [[-0.23933503 -0.07138565  0.4165409   1.        ]]. Action = [[0.09525156 0.35363865 0.802232   0.7869048 ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 2784. State = [[-0.23933503 -0.07138565  0.4165409   1.        ]]. Action = [[0.33541572 0.5578226  0.7924776  0.8088136 ]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 2785. State = [[-0.23936196 -0.07137892  0.41653985  1.        ]]. Action = [[0.14666986 0.24725163 0.8856008  0.8870888 ]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 2786. State = [[-0.23937857 -0.07143427  0.41654295  1.        ]]. Action = [[ 0.45544577 -0.13140005  0.84829617  0.78389263]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 2787. State = [[-0.23937857 -0.07143427  0.41654295  1.        ]]. Action = [[-0.18386936 -0.02432871  0.6552222   0.81752646]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 2788. State = [[-0.23937857 -0.07143427  0.41654295  1.        ]]. Action = [[0.2565261  0.04967356 0.50572324 0.80583334]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 2789. State = [[-0.23937857 -0.07143427  0.41654295  1.        ]]. Action = [[-0.23931754 -0.12440652  0.53571796  0.8554946 ]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 2790. State = [[-0.23937857 -0.07143427  0.41654295  1.        ]]. Action = [[0.062976   0.14214122 0.05802178 0.89788985]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 2791. State = [[-0.23956658 -0.07138719  0.416536    1.        ]]. Action = [[0.17611027 0.49368155 0.5484159  0.87118864]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 2792. State = [[-0.23979847 -0.07135401  0.41650385  1.        ]]. Action = [[0.5346422  0.16762638 0.4923625  0.8757045 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 2793. State = [[-0.23979847 -0.07135401  0.41650385  1.        ]]. Action = [[ 0.15895414 -0.24048889  0.6678734   0.8102021 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 2794. State = [[-0.23982528 -0.0713473   0.41650292  1.        ]]. Action = [[0.6900079  0.32013822 0.59855163 0.7399609 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 2795. State = [[-0.23967119 -0.07150497  0.41684562  1.        ]]. Action = [[ 0.6650734  -0.15279973  0.6712253   0.79080653]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 2796. State = [[-0.2396338  -0.07154987  0.41700456  1.        ]]. Action = [[0.10705006 0.41659987 0.38069236 0.9007479 ]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 2797. State = [[-0.23982032 -0.0715032   0.41699833  1.        ]]. Action = [[0.5479567  0.5468631  0.37008905 0.8533642 ]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 2798. State = [[-0.23982032 -0.0715032   0.41699833  1.        ]]. Action = [[ 0.2046169   0.7076318  -0.00237536  0.63575244]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 2799. State = [[-0.23982032 -0.0715032   0.41699833  1.        ]]. Action = [[-0.10321242  0.5608928   0.4479289   0.79800284]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 2800. State = [[-0.23982032 -0.0715032   0.41699833  1.        ]]. Action = [[0.76146865 0.4931214  0.14605749 0.8762176 ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 2801. State = [[-0.23982032 -0.0715032   0.41699833  1.        ]]. Action = [[-0.6800823   0.2927258   0.46500576  0.81018543]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 2802. State = [[-0.23982032 -0.0715032   0.41699833  1.        ]]. Action = [[-0.07220161  0.32123423  0.48596132  0.78190327]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 2803. State = [[-0.23982032 -0.0715032   0.41699833  1.        ]]. Action = [[-0.7012362   0.80925167  0.13859653  0.743989  ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 2804. State = [[-0.23982032 -0.0715032   0.41699833  1.        ]]. Action = [[0.20111418 0.45702183 0.08073497 0.7335286 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 2805. State = [[-0.23982032 -0.0715032   0.41699833  1.        ]]. Action = [[ 0.30266058 -0.02307653  0.33391452  0.7579204 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 2806. State = [[-0.23982032 -0.0715032   0.41699833  1.        ]]. Action = [[-0.13290691  0.5804391   0.59628606  0.8160684 ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 2807. State = [[-0.23982032 -0.0715032   0.41699833  1.        ]]. Action = [[0.33166313 0.47017443 0.27616072 0.6754687 ]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 2808. State = [[-0.23982032 -0.0715032   0.41699833  1.        ]]. Action = [[-0.22205597  0.46004605  0.16538763  0.6420877 ]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 2809. State = [[-0.23982032 -0.0715032   0.41699833  1.        ]]. Action = [[0.5305691  0.70065    0.30938601 0.7450627 ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 2810. State = [[-0.23982032 -0.0715032   0.41699833  1.        ]]. Action = [[ 0.7986934  -0.01542395  0.3631742   0.78096604]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 2811. State = [[-0.23982032 -0.0715032   0.41699833  1.        ]]. Action = [[0.15664577 0.39031935 0.36519647 0.6909597 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 2812. State = [[-0.24087042 -0.06702524  0.4168423   1.        ]]. Action = [[-0.02925354  0.25286937 -0.03182733  0.63769984]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 2813. State = [[-0.2421156  -0.06270761  0.41672316  1.        ]]. Action = [[ 0.10304856 -0.07328796  0.59344125  0.8294902 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Scene graph at timestep 2813 is [True, False, False, False, True, False, True, False, False, True]
State prediction error at timestep 2813 is tensor(0.0007, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 2813 of -1
Current timestep = 2814. State = [[-0.24222653 -0.06229218  0.41672623  1.        ]]. Action = [[-0.42713523  0.30204654  0.52469504  0.6833999 ]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 2815. State = [[-0.24222653 -0.06229218  0.41672623  1.        ]]. Action = [[-0.16246599  0.26214457  0.38417828  0.8194103 ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 2816. State = [[-0.24222653 -0.06229218  0.41672623  1.        ]]. Action = [[0.54254055 0.3519442  0.32119954 0.61558473]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 2817. State = [[-0.24222653 -0.06229218  0.41672623  1.        ]]. Action = [[0.22469139 0.39578605 0.30412543 0.66764426]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 2818. State = [[-0.24222653 -0.06229218  0.41672623  1.        ]]. Action = [[0.03187656 0.4877572  0.06219852 0.46450567]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 2819. State = [[-0.24222653 -0.06229218  0.41672623  1.        ]]. Action = [[-0.59164685  0.67637336  0.4819119   0.7679169 ]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 2820. State = [[-0.24222653 -0.06229218  0.41672623  1.        ]]. Action = [[-0.15960872  0.30713618  0.46620727  0.74677455]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 2821. State = [[-0.24222653 -0.06229218  0.41672623  1.        ]]. Action = [[-0.33054078  0.48019147  0.05536544  0.6952919 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 2822. State = [[-0.24222653 -0.06229218  0.41672623  1.        ]]. Action = [[ 0.34908307 -0.11160094  0.25142217  0.60593414]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 2823. State = [[-0.24222653 -0.06229218  0.41672623  1.        ]]. Action = [[0.0330441  0.02844536 0.41253448 0.7627331 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 2824. State = [[-0.24222653 -0.06229218  0.41672623  1.        ]]. Action = [[0.04143143 0.09946346 0.33535254 0.5942154 ]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 2825. State = [[-0.24222653 -0.06229218  0.41672623  1.        ]]. Action = [[-0.30736083  0.19950426  0.52504396  0.721032  ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 2826. State = [[-0.24222653 -0.06229218  0.41672623  1.        ]]. Action = [[-0.27142513  0.39199173  0.33591926  0.8106704 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 2827. State = [[-0.24222653 -0.06229218  0.41672623  1.        ]]. Action = [[ 0.12726653 -0.20789707  0.44764113  0.6555593 ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 2828. State = [[-0.24222653 -0.06229218  0.41672623  1.        ]]. Action = [[0.7604196 0.6142125 0.8657837 0.6400056]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 2829. State = [[-0.24222653 -0.06229218  0.41672623  1.        ]]. Action = [[0.52354145 0.4932227  0.49869013 0.6983533 ]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 2830. State = [[-0.24222653 -0.06229218  0.41672623  1.        ]]. Action = [[0.15623713 0.5040605  0.65259635 0.6008196 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 2831. State = [[-0.24222653 -0.06229218  0.41672623  1.        ]]. Action = [[0.32053375 0.34662175 0.4109776  0.77385426]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 2832. State = [[-0.24222653 -0.06229218  0.41672623  1.        ]]. Action = [[-0.09078747 -0.1681652   0.3513801   0.77198994]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 2833. State = [[-0.24222653 -0.06229218  0.41672623  1.        ]]. Action = [[0.5274048  0.5627873  0.7621695  0.59452844]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 2834. State = [[-0.24222653 -0.06229218  0.41672623  1.        ]]. Action = [[-0.43988574  0.56102943  0.65488064  0.7050984 ]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 2835. State = [[-0.23895548 -0.04988529  0.41450092  1.        ]]. Action = [[ 0.5768986   0.79478025 -0.34239948  0.5830622 ]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 2836. State = [[-0.23162599 -0.03570994  0.41320994  1.        ]]. Action = [[0.6490457  0.29694462 0.51629734 0.55827713]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 2837. State = [[-0.23143993 -0.03287442  0.41326138  1.        ]]. Action = [[0.25180578 0.2957468  0.42117572 0.62009144]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 2838. State = [[-0.22940539 -0.03497182  0.41423652  1.        ]]. Action = [[ 0.22877634 -0.27648723  0.01994264  0.6315565 ]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 2839. State = [[-0.22405453 -0.03720465  0.41473824  1.        ]]. Action = [[0.09170687 0.02673411 0.19660878 0.43298316]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 2840. State = [[-0.22088468 -0.03797439  0.41513726  1.        ]]. Action = [[0.43653905 0.08119142 0.60220766 0.5741265 ]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 2841. State = [[-0.22090918 -0.03809064  0.41514513  1.        ]]. Action = [[ 0.39564145 -0.07946312  0.24082828  0.63161397]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 2842. State = [[-0.220837   -0.03668978  0.4126912   1.        ]]. Action = [[-0.15914643  0.18598104 -0.37598944  0.52868223]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 2843. State = [[-0.21995209 -0.03562783  0.4064495   1.        ]]. Action = [[ 0.44904447 -0.3680551   0.09057128  0.6171087 ]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 2844. State = [[-0.22432719 -0.04207009  0.4023543   1.        ]]. Action = [[-0.4570186  -0.47760427 -0.5074771   0.61309576]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 2845. State = [[-0.22752504 -0.05042446  0.396287    1.        ]]. Action = [[ 0.40764475 -0.08107626  0.0570364   0.48236048]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 2846. State = [[-0.22156128 -0.04807313  0.3868828   1.        ]]. Action = [[ 0.37225413  0.39213395 -0.22519588  0.7454313 ]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 2847. State = [[-0.21253505 -0.04486808  0.38257453  1.        ]]. Action = [[ 0.12366784 -0.07105392  0.25230527  0.648859  ]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 2848. State = [[-0.20939243 -0.0505726   0.38675675  1.        ]]. Action = [[-0.07080185 -0.44766968  0.21510959  0.47616887]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 2849. State = [[-0.2064704 -0.0558422  0.3884979  1.       ]]. Action = [[ 0.35640395 -0.02299148 -0.12708724  0.4156642 ]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 2850. State = [[-0.20364343 -0.06232294  0.38812715  1.        ]]. Action = [[-0.3737803  -0.29193676 -0.08294582  0.44266188]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 2851. State = [[-0.20144987 -0.06040022  0.3927773   1.        ]]. Action = [[0.380898  0.576319  0.3949325 0.4570676]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 2852. State = [[-0.19983345 -0.05406671  0.3952118   1.        ]]. Action = [[-0.29433775  0.01040208 -0.23927474  0.48919237]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 2853. State = [[-0.19893177 -0.05111014  0.38853127  1.        ]]. Action = [[ 0.24416554  0.1581943  -0.39270473  0.23660064]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 2854. State = [[-0.19488363 -0.04298052  0.37376583  1.        ]]. Action = [[ 0.25988936  0.34637427 -0.4120798   0.41756475]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 2855. State = [[-0.18595071 -0.03710077  0.3624195   1.        ]]. Action = [[ 0.33759356 -0.2756927  -0.0304352   0.4458716 ]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 2856. State = [[-0.17999472 -0.03106702  0.35463774  1.        ]]. Action = [[-0.26711297  0.46456015 -0.38707942  0.48990023]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 2857. State = [[-0.17412205 -0.03051237  0.34402922  1.        ]]. Action = [[ 0.70660067 -0.31182814 -0.38719952  0.36323285]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 2858. State = [[-0.16215456 -0.03236564  0.33186907  1.        ]]. Action = [[ 0.05198944 -0.11055773  0.1057086   0.3328005 ]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 2859. State = [[-0.15646474 -0.04241085  0.32447788  1.        ]]. Action = [[ 0.47212362 -0.4692436  -0.70450383  0.39023066]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 2860. State = [[-0.1430665  -0.04910914  0.30627468  1.        ]]. Action = [[ 0.01651847  0.13478565 -0.04739738  0.28962708]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 2861. State = [[-0.13877968 -0.04445916  0.29805565  1.        ]]. Action = [[ 0.12844443  0.42541707 -0.42376912  0.36287916]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 2862. State = [[-0.12791294 -0.03977563  0.28634217  1.        ]]. Action = [[ 0.58399916 -0.06953835 -0.16138428  0.33069277]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 2863. State = [[-0.11019515 -0.03454993  0.2824276   1.        ]]. Action = [[0.32371688 0.292431   0.08297563 0.39406312]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 2864. State = [[-0.10063045 -0.03044512  0.27581444  1.        ]]. Action = [[ 0.33472252 -0.10506999 -0.5320314   0.3347454 ]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 2865. State = [[-0.08382331 -0.03002188  0.26522288  1.        ]]. Action = [[ 0.48001683 -0.13310874  0.02177894  0.32138777]]. Reward = [0.]
Curr episode timestep = 100
Above hoop
Current timestep = 2866. State = [[-0.26160786 -0.01486306  0.11307793  1.        ]]. Action = [[ 0.18540907 -0.1140849  -0.7826016   0.11537802]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: No entry zone
Above hoop
Current timestep = 2867. State = [[-0.25471127 -0.03262361  0.10772259  1.        ]]. Action = [[ 0.5689502  -0.895461    0.986856    0.99795175]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 2868. State = [[-0.23343103 -0.06194592  0.13139418  1.        ]]. Action = [[ 0.9946244  -0.8398793   0.9968308   0.98873794]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 2869. State = [[-0.19854033 -0.09347301  0.16944662  1.        ]]. Action = [[ 0.69952893 -0.75822675  0.9366267   0.99792933]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 2870. State = [[-0.17749102 -0.11262354  0.19463271  1.        ]]. Action = [[0.90274143 0.40877295 0.9530957  0.9063084 ]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: No entry zone
Current timestep = 2871. State = [[-0.16106208 -0.11971866  0.21207812  1.        ]]. Action = [[ 0.9831736 -0.3062352  0.9093127  0.9042008]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 2872. State = [[-0.12793967 -0.12868278  0.24632275  1.        ]]. Action = [[ 0.7628261  -0.03651112  0.95123994  0.9683075 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 2873. State = [[-0.09990755 -0.13291593  0.27594748  1.        ]]. Action = [[ 0.6581638  -0.20304072  0.20350337  0.65909433]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 2874. State = [[-0.08838103 -0.1455529   0.28727287  1.        ]]. Action = [[-0.26980126 -0.519917   -0.01488119  0.43290162]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 2874 is [False, True, False, True, False, False, True, False, False, True]
State prediction error at timestep 2874 is tensor(0.0004, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 2874 of -1
Current timestep = 2875. State = [[-0.08927529 -0.15417999  0.29188424  1.        ]]. Action = [[0.14217663 0.35061216 0.15448809 0.35284042]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 2876. State = [[-0.08514915 -0.14813563  0.28884834  1.        ]]. Action = [[ 0.04737413  0.20681882 -0.46185225  0.4274273 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 2877. State = [[-0.08491081 -0.14699474  0.27705535  1.        ]]. Action = [[-0.03256702 -0.25519204 -0.3035692   0.34923673]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 2878. State = [[-0.08536772 -0.14463314  0.2735328   1.        ]]. Action = [[-0.17480278  0.33510423 -0.02926528  0.41039562]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 2879. State = [[-0.08559617 -0.14250997  0.27373716  1.        ]]. Action = [[-0.26420224  0.00499201  0.25583696  0.50134444]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 2880. State = [[-0.08495671 -0.14609253  0.27362904  1.        ]]. Action = [[ 0.5010879  -0.40845042 -0.10742337  0.40204275]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 2881. State = [[-0.08539292 -0.1521023   0.27445185  1.        ]]. Action = [[-0.213418   -0.1480931   0.16357028  0.41788507]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 2882. State = [[-0.0824187  -0.15591565  0.27880183  1.        ]]. Action = [[ 0.23182714 -0.05919647  0.27725995  0.46518672]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 2883. State = [[-0.08069054 -0.15901223  0.2817839   1.        ]]. Action = [[-0.5590008   0.09452987 -0.28454214  0.45063615]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 2884. State = [[-0.08659057 -0.1604597   0.272776    1.        ]]. Action = [[-0.09830368 -0.09319782 -0.7271253   0.5376233 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 2885. State = [[-0.09342024 -0.15908599  0.26146775  1.        ]]. Action = [[-0.22697204  0.23581195 -0.03002262  0.48425388]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 2886. State = [[-0.09568001 -0.15816864  0.25992465  1.        ]]. Action = [[-0.12548614 -0.02609861  0.21742761  0.5382719 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 2887. State = [[-0.09975813 -0.15534087  0.26500112  1.        ]]. Action = [[-0.42718613  0.20679915  0.32672477  0.48144042]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 2888. State = [[-0.1110548  -0.14865057  0.27199194  1.        ]]. Action = [[-0.09286129  0.15408492  0.10476863  0.47374368]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 2889. State = [[-0.11610799 -0.14189894  0.27495915  1.        ]]. Action = [[ 0.03248715  0.19502366 -0.0009923   0.6100631 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 2890. State = [[-0.11771151 -0.14135599  0.2747538   1.        ]]. Action = [[-0.05692506 -0.31208003 -0.10800505  0.6145601 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 2891. State = [[-0.12065557 -0.14988309  0.27698186  1.        ]]. Action = [[ 0.07474709 -0.304654    0.29705858  0.67288876]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 2892. State = [[-0.12692566 -0.16403946  0.28327623  1.        ]]. Action = [[-0.5670192  -0.4065367   0.19684327  0.5446267 ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 2893. State = [[-0.14026414 -0.17022723  0.29735747  1.        ]]. Action = [[-0.49250638  0.2740147   0.53129935  0.6040437 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 2894. State = [[-0.15907879 -0.16005662  0.31070298  1.        ]]. Action = [[-0.41417396  0.43767285  0.29408443  0.7223978 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 2895. State = [[-0.17165054 -0.14252822  0.3217994   1.        ]]. Action = [[-0.07528079  0.4542954   0.20950985  0.764202  ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 2896. State = [[-0.1790116  -0.13146944  0.331707    1.        ]]. Action = [[-0.12611705  0.03584576  0.36861026  0.7426319 ]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 2897. State = [[-0.1833808  -0.12404882  0.33880758  1.        ]]. Action = [[ 0.04875231  0.25545287 -0.13102353  0.46816623]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 2898. State = [[-0.18105727 -0.11954067  0.33987695  1.        ]]. Action = [[ 0.5585611  -0.11790115  0.05529392  0.3862089 ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 2899. State = [[-0.17926691 -0.12014051  0.34127927  1.        ]]. Action = [[-0.26090908 -0.1097213  -0.1565035   0.5185013 ]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 2900. State = [[-0.18108508 -0.11797478  0.34274483  1.        ]]. Action = [[-0.37466264  0.3246379   0.23576438  0.43918014]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 2901. State = [[-0.1862356  -0.1144445   0.34549722  1.        ]]. Action = [[-0.1543122  -0.00861377  0.09435737  0.41425323]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 2902. State = [[-0.19239987 -0.11112431  0.34961092  1.        ]]. Action = [[-0.08979172  0.15975547  0.26246536  0.42033017]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 2903. State = [[-0.19327255 -0.10517114  0.3561563   1.        ]]. Action = [[0.35308504 0.1193831  0.2555492  0.3502189 ]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 2904. State = [[-0.1920872  -0.09863211  0.3578747   1.        ]]. Action = [[ 0.15419841  0.29204535 -0.26267165  0.3056903 ]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 2905. State = [[-0.18453729 -0.08809975  0.35262415  1.        ]]. Action = [[ 0.63285637  0.27813435 -0.42342627  0.3786757 ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 2906. State = [[-0.16607173 -0.08423065  0.3400536   1.        ]]. Action = [[ 0.5329926  -0.26528013 -0.40231693  0.32899046]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 2907. State = [[-0.1505089 -0.0872275  0.3217762  1.       ]]. Action = [[ 0.21530676 -0.1315406  -0.87104696  0.16266704]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 2908. State = [[-0.13502388 -0.09231638  0.2961231   1.        ]]. Action = [[ 0.6359556  -0.16942853 -0.39397722  0.28304076]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 2909. State = [[-0.11275753 -0.10085565  0.28288355  1.        ]]. Action = [[ 0.57671165 -0.3236122  -0.06381005  0.29702044]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 2910. State = [[-0.09228515 -0.10748272  0.27249798  1.        ]]. Action = [[ 0.64424455  0.0079875  -0.5202125   0.2064228 ]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 2911. State = [[-0.07057103 -0.11663114  0.2527653   1.        ]]. Action = [[ 0.5958196  -0.4881209  -0.767797    0.05924761]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 2912. State = [[-0.05081319 -0.12574942  0.2336263   1.        ]]. Action = [[ 0.6512339  -0.42886817 -0.6914955   0.11891794]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: No entry zone
Current timestep = 2913. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.61900544 -0.5269649  -0.5508151   0.1303885 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: No entry zone
Current timestep = 2914. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.4234414  -0.45695674 -0.66239595  0.22285259]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: No entry zone
Current timestep = 2915. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.3609023  -0.509909   -0.5849152   0.17766857]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: No entry zone
Current timestep = 2916. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.569628   -0.3879426  -0.6911141   0.08122277]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: No entry zone
Current timestep = 2917. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.4683838  -0.7021593  -0.8117213   0.18249607]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: No entry zone
Current timestep = 2918. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.44716406 -0.49039763 -0.8317518   0.20820725]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: No entry zone
Current timestep = 2919. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.4458233  -0.47754467 -0.4897431   0.20725024]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: No entry zone
Current timestep = 2920. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.43646383 -0.5928342  -0.792888    0.1055131 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: No entry zone
Current timestep = 2921. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.49325597 -0.76999    -0.6759268   0.10565841]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: No entry zone
Current timestep = 2922. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.44928062 -0.6004589  -0.6191161   0.15963173]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: No entry zone
Current timestep = 2923. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.3479513  -0.6201568  -0.82451886  0.17683923]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: No entry zone
Current timestep = 2924. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.4624728  -0.70257854 -0.74243563  0.1650095 ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: No entry zone
Current timestep = 2925. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.37896657 -0.46115363 -0.52987415  0.14794338]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: No entry zone
Current timestep = 2926. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.15753353 -0.57397467 -0.6709981   0.18537962]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: No entry zone
Current timestep = 2927. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.50662625 -0.61213046 -0.86319387  0.06585908]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: No entry zone
Current timestep = 2928. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.4461801  -0.6853664  -0.36616206  0.1545006 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: No entry zone
Current timestep = 2929. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.09311867 -0.29721045 -0.75368977  0.14246345]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: No entry zone
Current timestep = 2930. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.49519527 -0.5326668  -0.5571473   0.2076093 ]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: No entry zone
Current timestep = 2931. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.20607758 -0.53530866 -0.7886879   0.20236397]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: No entry zone
Current timestep = 2932. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.39566374 -0.5018756  -0.7186788   0.17278934]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: No entry zone
Current timestep = 2933. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.43687797 -0.54406357 -0.83436626  0.17978609]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: No entry zone
Current timestep = 2934. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.517686   -0.64922965 -0.61193126  0.05612421]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: No entry zone
Current timestep = 2935. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.19060862 -0.37760502 -0.68296784  0.1365143 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: No entry zone
Current timestep = 2936. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.43104017 -0.53821677 -0.7154131   0.10270011]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: No entry zone
Current timestep = 2937. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.33936596 -0.3478319  -0.8554269   0.06917083]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: No entry zone
Current timestep = 2938. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.5748136  -0.547226   -0.6963966   0.10309422]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: No entry zone
Current timestep = 2939. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.6259608  -0.32383412 -0.76541865  0.09479213]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: No entry zone
Current timestep = 2940. State = [[-0.04916888 -0.12667315  0.23249388  1.        ]]. Action = [[ 0.53443754 -0.546983   -0.86287624  0.1345228 ]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: No entry zone
Current timestep = 2941. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.7005329 -0.5662298 -0.8459472 -0.0101065]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: No entry zone
Current timestep = 2942. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.7614635  -0.63576865 -0.7801338   0.04793918]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: No entry zone
Current timestep = 2943. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.7155112  -0.41166568 -0.78332555  0.04797184]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: No entry zone
Current timestep = 2944. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.39917803 -0.56077564 -0.7411694   0.02075934]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: No entry zone
Current timestep = 2945. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.7251308  -0.54674137 -0.5960593  -0.03248876]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: No entry zone
Current timestep = 2946. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.60294044 -0.6883509  -0.7949328  -0.03349441]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: No entry zone
Current timestep = 2947. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.5455649  -0.51967657 -0.8795027   0.02689052]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: No entry zone
Current timestep = 2948. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.73272645 -0.65747744 -0.79711497  0.05900884]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: No entry zone
Current timestep = 2949. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.5126133  -0.61244375 -0.9003842  -0.00528747]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: No entry zone
Current timestep = 2950. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.5534146  -0.6407891  -0.9052057   0.01884544]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: No entry zone
Current timestep = 2951. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.63404715 -0.7296548  -0.74220264  0.08282185]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: No entry zone
Current timestep = 2952. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.38224876 -0.60224724 -0.5699785   0.0281961 ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: No entry zone
Current timestep = 2953. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.6905272  -0.6882533  -0.51471114 -0.04929233]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: No entry zone
Current timestep = 2954. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.62776923 -0.57961804 -0.62706435 -0.02514017]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: No entry zone
Current timestep = 2955. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.57435334 -0.5747374  -0.8503188  -0.00430429]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: No entry zone
Current timestep = 2956. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.43128395 -0.66249293 -0.5591212   0.08271337]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: No entry zone
Current timestep = 2957. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.38382876 -0.7187245  -0.55575246  0.04991841]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: No entry zone
Current timestep = 2958. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.7195543  -0.6647287  -0.60654545  0.06974328]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: No entry zone
Current timestep = 2959. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.5614188  -0.65052575 -0.81924534  0.01559854]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: No entry zone
Current timestep = 2960. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.56322217 -0.57600856 -0.9175803   0.01439154]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: No entry zone
Current timestep = 2961. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.50378513 -0.6493987  -0.8580604   0.07969999]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: No entry zone
Current timestep = 2962. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.69319797 -0.5248792  -0.7490464  -0.01917452]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: No entry zone
Current timestep = 2963. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.5997877  -0.6088536  -0.647588    0.03676784]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: No entry zone
Current timestep = 2964. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.62387013 -0.6827671  -0.88133657 -0.008439  ]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: No entry zone
Current timestep = 2965. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.60375476 -0.56870127 -0.7912237  -0.0312832 ]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: No entry zone
Current timestep = 2966. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.60800123 -0.6144027  -0.86847234  0.03042006]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: No entry zone
Current timestep = 2967. State = [[-0.04917913 -0.12667435  0.2324349   1.        ]]. Action = [[ 0.6211312 -0.6200115 -0.6707724  0.0316366]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: No entry zone
Current timestep = 2968. State = [[-0.2660145   0.04052226  0.11225919  1.        ]]. Action = [[ 0.6523442  -0.47904038 -0.8331714  -0.03649968]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: No entry zone
Current timestep = 2969. State = [[-0.24857776  0.04211294  0.10827432  1.        ]]. Action = [[ 0.9853909  -0.32887304  0.9926444   0.9908515 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 2970. State = [[-0.21694112  0.03932472  0.13149193  1.        ]]. Action = [[ 0.9867624  -0.02288848  0.9597359   0.9856999 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 2971. State = [[-0.17888032  0.02989318  0.16761255  1.        ]]. Action = [[ 0.9376576  -0.55162233  0.98328185  0.9774058 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 2972. State = [[-0.15369451  0.02061033  0.19244699  1.        ]]. Action = [[0.94963336 0.09053338 0.7152144  0.94787693]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: No entry zone
Current timestep = 2973. State = [[-0.14775728  0.01952298  0.19720608  1.        ]]. Action = [[ 0.90711725 -0.03472817  0.83408165  0.87634254]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 2974. State = [[-0.14695735  0.01933964  0.19803923  1.        ]]. Action = [[ 0.89177275 -0.06357253  0.60249007  0.858533  ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 2975. State = [[-0.1469655   0.01915042  0.19826883  1.        ]]. Action = [[ 0.6760218  -0.09893751  0.7826817   0.8675587 ]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 2976. State = [[-0.13382551  0.01369642  0.21197772  1.        ]]. Action = [[ 0.9227309 -0.3148905  0.9187212  0.8812063]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 2977. State = [[-0.10479776  0.00813238  0.24225633  1.        ]]. Action = [[ 0.69698536 -0.00905144  0.6854887   0.78118896]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 2978. State = [[-0.08618351  0.0075947   0.26302212  1.        ]]. Action = [[ 0.7435806  -0.36349165 -0.5693671   0.16915345]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Above hoop
Current timestep = 2979. State = [[-0.08323456  0.00702302  0.266712    1.        ]]. Action = [[ 0.74936426 -0.58959967 -0.78190553  0.0017432 ]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Above hoop
Current timestep = 2980. State = [[-0.08166004  0.00690914  0.26840943  1.        ]]. Action = [[ 0.6543791  -0.66885227 -0.79743737 -0.00935024]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: No entry zone
Above hoop
Current timestep = 2981. State = [[-0.08152152  0.00638136  0.2687145   1.        ]]. Action = [[ 0.86870277 -0.7485091  -0.7907304  -0.00303179]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: No entry zone
Above hoop
Current timestep = 2982. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.68103814 -0.617078   -0.85882837  0.02748704]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: No entry zone
Above hoop
Current timestep = 2983. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.7329824  -0.67235243 -0.89600563  0.07997179]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: No entry zone
Above hoop
Current timestep = 2984. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.7433684  -0.7109499  -0.9308524  -0.01217008]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: No entry zone
Above hoop
Current timestep = 2985. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.8299258  -0.5964207  -0.8882119   0.01238191]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: No entry zone
Above hoop
Current timestep = 2986. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.8254068  -0.69886136 -0.7901829   0.01312125]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: No entry zone
Above hoop
Current timestep = 2987. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.7450315  -0.6220087  -0.8684729   0.03083432]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: No entry zone
Above hoop
Current timestep = 2988. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.75032985 -0.6724152  -0.8902975  -0.02294934]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: No entry zone
Above hoop
Current timestep = 2989. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.7303773  -0.74159116 -0.95941544  0.00763452]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: No entry zone
Above hoop
Current timestep = 2990. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.7621392  -0.6696922  -0.9593986   0.00172377]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: No entry zone
Above hoop
Current timestep = 2991. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.82943404 -0.6506474  -0.93920636  0.04626155]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: No entry zone
Above hoop
Current timestep = 2992. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.7480663  -0.6069208  -0.9618919   0.01693165]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: No entry zone
Above hoop
Current timestep = 2993. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.6264844  -0.577085   -0.8498588  -0.00355041]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: No entry zone
Above hoop
Current timestep = 2994. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.7371311  -0.61875546 -0.9304243   0.08518589]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: No entry zone
Above hoop
Current timestep = 2995. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.7840204  -0.6988471  -0.9025316   0.00261295]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: No entry zone
Above hoop
Current timestep = 2996. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.6437013  -0.6141127  -0.94545627 -0.0134905 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: No entry zone
Above hoop
Current timestep = 2997. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.7756188  -0.6322788  -0.91671956  0.01050675]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: No entry zone
Above hoop
Current timestep = 2998. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.83547115 -0.68239766 -0.91183597  0.01289225]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: No entry zone
Above hoop
Current timestep = 2999. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.72355103 -0.70050174 -0.89877284 -0.02023894]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: No entry zone
Above hoop
Current timestep = 3000. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.7893009  -0.70109516 -0.9094465   0.01590347]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: No entry zone
Above hoop
Current timestep = 3001. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.78797805 -0.61366636 -0.90469766  0.00579917]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: No entry zone
Above hoop
Current timestep = 3002. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.655882   -0.5849644  -0.8872443  -0.00199503]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: No entry zone
Above hoop
Current timestep = 3003. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.75319695 -0.69005376 -0.88350874  0.01311696]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: No entry zone
Above hoop
Current timestep = 3004. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.7982279  -0.68813837 -0.9400994   0.01330626]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: No entry zone
Above hoop
Current timestep = 3005. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.5823612  -0.71689224 -0.8938488   0.02636123]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: No entry zone
Above hoop
Current timestep = 3006. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.77932286 -0.6473411  -0.87747556 -0.01211566]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: No entry zone
Above hoop
Current timestep = 3007. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.75969434 -0.6764139  -0.92134017  0.002689  ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: No entry zone
Above hoop
Current timestep = 3008. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.59484076 -0.70014274 -0.81823593 -0.0289315 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: No entry zone
Above hoop
Current timestep = 3009. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.6718612  -0.55226654 -0.92000276 -0.00947338]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: No entry zone
Above hoop
Current timestep = 3010. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.7601689  -0.6091922  -0.8296507   0.02676916]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: No entry zone
Above hoop
Current timestep = 3011. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.5988972  -0.65230536 -0.8954082  -0.01677251]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: No entry zone
Above hoop
Current timestep = 3012. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.8241801  -0.66333807 -0.86247927 -0.01371497]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: No entry zone
Above hoop
Current timestep = 3013. State = [[-0.08168057  0.006232    0.2687358   1.        ]]. Action = [[ 0.7279916  -0.50782454 -0.86827594  0.01246369]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: No entry zone
Above hoop
Current timestep = 3014. State = [[-0.07642926 -0.00264717  0.26154947  1.        ]]. Action = [[ 0.72001576 -0.5338409  -0.6915898   0.03858769]]. Reward = [0.]
Curr episode timestep = 45
Above hoop
Current timestep = 3015. State = [[-0.06088389 -0.01006148  0.24912992  1.        ]]. Action = [[ 0.77694464 -0.61078817 -0.8793479  -0.0075767 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: No entry zone
Above hoop
Current timestep = 3016. State = [[-0.05830568 -0.01105858  0.2474457   1.        ]]. Action = [[ 5.5653560e-01 -6.3214904e-01 -8.6118436e-01 -4.3582916e-04]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: No entry zone
Above hoop
Current timestep = 3017. State = [[-0.05829518 -0.01133223  0.24740352  1.        ]]. Action = [[ 0.82945466 -0.6684407  -0.77946687 -0.01140547]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: No entry zone
Above hoop
Current timestep = 3018. State = [[-0.05829518 -0.01133223  0.24740352  1.        ]]. Action = [[ 0.7553594  -0.7070137  -0.80843306  0.01579535]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: No entry zone
Above hoop
Current timestep = 3019. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.74030614 -0.6181207  -0.90092134 -0.03115934]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: No entry zone
Above hoop
Current timestep = 3020. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.6591836  -0.7143179  -0.841731   -0.03719544]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: No entry zone
Above hoop
Current timestep = 3021. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.7024679  -0.7189403  -0.8379946  -0.02576119]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: No entry zone
Above hoop
Current timestep = 3022. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.7460146  -0.6387145  -0.9024444  -0.04178625]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: No entry zone
Above hoop
Current timestep = 3023. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.7391763  -0.6682464  -0.8471818  -0.04204804]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: No entry zone
Above hoop
Current timestep = 3024. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.76150715 -0.6286388  -0.8341758  -0.02372319]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: No entry zone
Above hoop
Current timestep = 3025. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.7132268  -0.6513141  -0.82022077  0.0118444 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: No entry zone
Above hoop
Current timestep = 3026. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.7496822  -0.5929241  -0.8677539  -0.02278876]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: No entry zone
Above hoop
Current timestep = 3027. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.728863   -0.6533806  -0.909588    0.00443363]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: No entry zone
Above hoop
Current timestep = 3028. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.84477234 -0.65244305 -0.87588274  0.0164088 ]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: No entry zone
Above hoop
Current timestep = 3029. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.7679348  -0.6390183  -0.9178571  -0.02316123]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: No entry zone
Above hoop
Current timestep = 3030. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.7991581  -0.5772157  -0.8878572  -0.01555413]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: No entry zone
Above hoop
Current timestep = 3031. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.8412461  -0.6135296  -0.72978556 -0.02617264]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: No entry zone
Above hoop
Current timestep = 3032. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.76092803 -0.6444708  -0.7768884  -0.04484844]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: No entry zone
Above hoop
Current timestep = 3033. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.7409642  -0.6466962  -0.8631019  -0.03630525]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: No entry zone
Above hoop
Current timestep = 3034. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.81269026 -0.51110274 -0.91010666 -0.01391852]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: No entry zone
Above hoop
Current timestep = 3035. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.8233057  -0.62645483 -0.865143   -0.02433556]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: No entry zone
Above hoop
Current timestep = 3036. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.69907045 -0.70075846 -0.833459   -0.03809232]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: No entry zone
Above hoop
Current timestep = 3037. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.7481165  -0.69044304 -0.8069926  -0.023476  ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: No entry zone
Above hoop
Current timestep = 3038. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.80263174 -0.69972146 -0.8997804  -0.01142114]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: No entry zone
Above hoop
Current timestep = 3039. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.69379306 -0.6753848  -0.9518144  -0.00688863]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: No entry zone
Above hoop
Current timestep = 3040. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.8394166  -0.6746612  -0.9045238  -0.00833827]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: No entry zone
Above hoop
Current timestep = 3041. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 6.3715804e-01 -6.9501013e-01 -8.0115777e-01  6.4730644e-05]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: No entry zone
Above hoop
Current timestep = 3042. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.7006589  -0.70702904 -0.8747101  -0.00832886]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: No entry zone
Above hoop
Current timestep = 3043. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.837335   -0.69155276 -0.89939916  0.00875664]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: No entry zone
Above hoop
Current timestep = 3044. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.7920847  -0.6044254  -0.8375416  -0.00832117]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: No entry zone
Above hoop
Current timestep = 3045. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.71450734 -0.63030195 -0.81564325 -0.00181621]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: No entry zone
Above hoop
Current timestep = 3046. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.76189375 -0.54175544 -0.81744117 -0.02982998]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: No entry zone
Above hoop
Current timestep = 3047. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.73903966 -0.6201107  -0.7439767  -0.00297707]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: No entry zone
Above hoop
Current timestep = 3048. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.68401384 -0.6321715  -0.9118224  -0.01606005]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: No entry zone
Above hoop
Current timestep = 3049. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.7830279  -0.6398201  -0.9130872  -0.00310194]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: No entry zone
Above hoop
Current timestep = 3050. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.79489017 -0.6531609  -0.8358149   0.00111437]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: No entry zone
Above hoop
Current timestep = 3051. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.69558406 -0.6041349  -0.8736419   0.04054928]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: No entry zone
Above hoop
Current timestep = 3052. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.7071562  -0.63307315 -0.89444643 -0.01099789]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: No entry zone
Above hoop
Current timestep = 3053. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.67507696 -0.51564914 -0.8863152   0.02429843]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: No entry zone
Above hoop
Current timestep = 3054. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.7715056  -0.6529584  -0.881584    0.02130616]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: No entry zone
Above hoop
Current timestep = 3055. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.7302606  -0.58350956 -0.8304116   0.02543032]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: No entry zone
Above hoop
Current timestep = 3056. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.7473979  -0.54107046 -0.73203427  0.01730061]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: No entry zone
Above hoop
Current timestep = 3057. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.6924877  -0.55546504 -0.78422797  0.01590443]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: No entry zone
Above hoop
Current timestep = 3058. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 8.3405757e-01 -5.3634846e-01 -8.5032094e-01 -2.1713972e-04]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: No entry zone
Above hoop
Current timestep = 3059. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.7320132  -0.506932   -0.8194292   0.00859225]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: No entry zone
Above hoop
Current timestep = 3060. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.52140474 -0.55685496 -0.78718877 -0.02630258]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: No entry zone
Above hoop
Current timestep = 3061. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.8006984  -0.506021   -0.78344053  0.00328827]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: No entry zone
Above hoop
Current timestep = 3062. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.6400354 -0.5596544 -0.6552293 -0.0430693]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: No entry zone
Above hoop
Current timestep = 3063. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.5161294  -0.49056882 -0.90531206 -0.00404936]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: No entry zone
Above hoop
Current timestep = 3064. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.78587484 -0.6099336  -0.6944786  -0.00868732]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: No entry zone
Above hoop
Current timestep = 3065. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.7990582  -0.55192137 -0.8299522   0.03145194]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: No entry zone
Above hoop
Current timestep = 3066. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.7005273  -0.6672364  -0.7475007   0.03533161]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: No entry zone
Above hoop
Current timestep = 3067. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.6725826  -0.6105964  -0.91894126 -0.01177347]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: No entry zone
Above hoop
Current timestep = 3068. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.7404343  -0.5822231  -0.85505575  0.01033139]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: No entry zone
Above hoop
Current timestep = 3069. State = [[-0.05830393 -0.01133271  0.2473447   1.        ]]. Action = [[ 0.6437371  -0.6208672  -0.6994826   0.02970088]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: No entry zone
Above hoop
Current timestep = 3070. State = [[-0.25860903 -0.09061706  0.1192303   1.        ]]. Action = [[ 0.74077344 -0.53177464 -0.79680616  0.01136649]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: No entry zone
Above hoop
Current timestep = 3071. State = [[-0.24789654 -0.10635357  0.11283016  1.        ]]. Action = [[ 0.92693245 -0.40787232  0.9297228   0.98870516]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 3072. State = [[-0.2185748  -0.12172658  0.13655174  1.        ]]. Action = [[ 0.91671216 -0.4631976   0.9431745   0.9938896 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 3073. State = [[-0.18356869 -0.13526708  0.17284551  1.        ]]. Action = [[ 0.83925307 -0.17692018  0.9518411   0.9797629 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 3074. State = [[-0.16232759 -0.14262688  0.19630356  1.        ]]. Action = [[0.45072746 0.05915225 0.7646334  0.85715187]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: No entry zone
Current timestep = 3075. State = [[-0.15820494 -0.14409064  0.19972932  1.        ]]. Action = [[0.61090755 0.24797857 0.8294388  0.8145871 ]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 3076. State = [[-0.15009756 -0.14012487  0.21058446  1.        ]]. Action = [[0.4840287  0.34884048 0.82481813 0.90116894]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 3077. State = [[-0.13481522 -0.1365456   0.24175768  1.        ]]. Action = [[0.20308673 0.01532686 0.85600114 0.76052237]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 3078. State = [[-0.11887576 -0.1364014   0.2704955   1.        ]]. Action = [[ 0.6115904  -0.0055179   0.5416434   0.50027645]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 3079. State = [[-0.10235797 -0.13942823  0.28096396  1.        ]]. Action = [[ 0.27329254 -0.30943286 -0.59193814  0.22888315]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 3080. State = [[-0.09317691 -0.14755924  0.26957142  1.        ]]. Action = [[ 0.47545755 -0.3662299  -0.65455073  0.11258721]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 3081. State = [[-0.07594847 -0.15932     0.24849452  1.        ]]. Action = [[ 0.51401186 -0.33990777 -0.6605314   0.1233815 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 3082. State = [[-0.05788344 -0.1778136   0.22882397  1.        ]]. Action = [[ 0.21797419 -0.65459436 -0.24262881  0.10816038]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 3083. State = [[-0.05541402 -0.2039004   0.21771663  1.        ]]. Action = [[-0.3752495  -0.7148517  -0.3439237   0.01393425]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 3083 is [False, True, False, True, False, False, False, True, False, True]
State prediction error at timestep 3083 is tensor(0.0017, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3083 of -1
Current timestep = 3084. State = [[-0.06373467 -0.2390841   0.21591616  1.        ]]. Action = [[-0.62292945 -0.8655166   0.25282526  0.08446455]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 3085. State = [[-0.07989248 -0.27206963  0.23021057  1.        ]]. Action = [[-0.89815104 -0.722236    0.851354    0.25468612]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 3085 is [False, True, False, True, False, False, True, False, False, True]
State prediction error at timestep 3085 is tensor(0.0004, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3085 of -1
Current timestep = 3086. State = [[-0.10183655 -0.29519853  0.24508844  1.        ]]. Action = [[-0.93374074 -0.7726793   0.87782717  0.1499896 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 3087. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.9713566  -0.7337459   0.9354068   0.37719524]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 3088. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.96653223 -0.7190974   0.88593745  0.42235947]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 3089. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.9683213 -0.7283387  0.9704851  0.33796  ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 3090. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.95921195 -0.8821599   0.9558029   0.32081115]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 3091. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.95240456 -0.8419492   0.9412128   0.39244628]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 3092. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.94196826 -0.70487946  0.87934256  0.37404454]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 3093. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.9788119  -0.4156252   0.96578956  0.37662685]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 3094. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.7627395  -0.7947046   0.97487473  0.30610108]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 3095. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.9812304  -0.76518667  0.9624108   0.20811999]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 3096. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.91511095 -0.65112644  0.7711239   0.27082443]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 3097. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.93331546 -0.8878966   0.9723604   0.33478963]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 3098. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.95416224 -0.86251223  0.94764316  0.21369219]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 3099. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.8912249  -0.72700185  0.8861871   0.28911567]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 3100. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.975051   -0.75834775  0.8530743   0.308802  ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 3101. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.958361   -0.7668442   0.93104076  0.13758671]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 3102. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.8627226  -0.77737993  0.96620107  0.2630453 ]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 3103. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.9597325  -0.6754608   0.9562682   0.18318999]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 3104. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.9751457  -0.7816046   0.89416957  0.42613387]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 3105. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.9833969  -0.40052223  0.91647434  0.1994021 ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 3106. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.9084387  -0.77447176  0.6671586   0.2765925 ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 3107. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.9143883  -0.7835853   0.9829314   0.11656451]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 3108. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.9538112  -0.69350964  0.9442729   0.2687528 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 3109. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.98868006 -0.68468916  0.88359416  0.2340802 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 3110. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.9782862  -0.5981575   0.96025753  0.07777917]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 3111. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.9545885  -0.69800925  0.967172    0.14105225]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 3112. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.95802706 -0.79033494  0.9487003   0.19497132]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 3113. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.93667877 -0.83848214  0.6985054   0.3199612 ]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 3114. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.9388276 -0.6564907  0.9357892  0.2938472]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 3115. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.9610463  -0.71307415  0.92479134  0.12502027]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 3116. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.794471   -0.68310905  0.9815111   0.24840951]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 3117. State = [[-0.10189198 -0.29518017  0.245046    1.        ]]. Action = [[-0.96690917 -0.72429675  0.9566338   0.31282532]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 3118. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.97148967 -0.61070585  0.9389076   0.21832168]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 3119. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.98981297 -0.6355854   0.95294404  0.13351882]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 3120. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.9273522  -0.91482764  0.97050357  0.12319732]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 3121. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.94740826 -0.8160609   0.98978925  0.24059963]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 3122. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.9087461  -0.67505413  0.911201    0.243505  ]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 3123. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.9609638  -0.75115514  0.9780557   0.27126157]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 3124. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.7284179  -0.8643552   0.93418944  0.14563322]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 3125. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.94897985 -0.5088712   0.8800521   0.24949777]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 3126. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.89822185 -0.84846085  0.6417835   0.20584154]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 3127. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.88475716 -0.77316123  0.93726575  0.25371408]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 3128. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.9031285  -0.68604606  0.929919    0.02847159]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 3129. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.9452849  -0.83870494  0.83950996  0.15906322]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 3130. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.94110787 -0.77681893  0.778092    0.18851173]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 3131. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.8629612  -0.7721526   0.96066296  0.17016828]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 3132. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.95437425 -0.89650637  0.8926114   0.19001102]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 3133. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.99320537 -0.89892924  0.8783319   0.18196738]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 3134. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.9532083  -0.87842304  0.8223226   0.19490838]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 3135. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.9083394  -0.716692    0.6355176   0.14130676]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 3136. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.9568022  -0.6305192   0.88098836  0.20291483]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 3137. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.97617924 -0.91690814  0.8509288   0.21911776]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 3138. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.9392939 -0.8846404  0.8889035  0.2747363]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 3139. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.8799571  -0.51831925  0.94907486  0.11590159]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 3140. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.96721506 -0.8699201   0.992882    0.11409891]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 3141. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.89462984 -0.69679475  0.771984    0.16790748]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 3142. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.9881083  -0.7093796   0.8173673   0.25972927]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 3143. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.88804954 -0.80640763  0.633641    0.15368843]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 3144. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.9470936  -0.94295454  0.9029932   0.13169873]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 3145. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.9070614  -0.82504696  0.94008875  0.25764585]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 3146. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.8376165  -0.8326902   0.8427603   0.14533424]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 3147. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.9230683  -0.78346866  0.9291266   0.20584798]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 3148. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.9802496  -0.70064443  0.788285    0.293074  ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 3149. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.890504   -0.86288947  0.8883593   0.16899991]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 3150. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.92671067 -0.9117549   0.93195105  0.25847292]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 3151. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.9083869  -0.752243    0.9175689   0.17130542]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 3152. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.6599669  -0.8313471   0.95681536  0.26794314]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 3153. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.96951455 -0.78499687  0.7657193   0.21341598]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 3154. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.93671155 -0.6036361   0.7769089   0.12772143]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 3155. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.86838007 -0.7995137   0.881196    0.23671663]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 3156. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.96587306 -0.8828193   0.9896054   0.14877152]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 3157. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.92308676 -0.8445812   0.98824906  0.22175074]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 3158. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.775055   -0.8989436   0.9398799   0.20767486]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 3159. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.9522723  -0.6680261   0.99280953  0.25568855]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 3160. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.9554966  -0.9124472   0.93772185  0.2675997 ]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 3161. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.9299823  -0.62589705  0.97152257  0.25414062]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 3162. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.9348817 -0.7267991  0.9868779  0.3054564]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 3163. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.9728806  -0.8256439   0.8660443   0.39270794]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 3164. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.8733301  -0.8224839   0.87971425  0.20082128]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 3165. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.8987915  -0.8653411   0.90113306  0.22540486]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 3166. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.97990483 -0.29970425  0.94600236  0.21361363]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 3167. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.848825   -0.7278109   0.94230676  0.2221067 ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 3168. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.98061365 -0.7313801   0.97271097  0.24387884]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 3169. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.82671165 -0.76845694  0.97390914  0.26182282]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 3170. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.9692865  -0.8776176   0.8952942   0.22628355]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 3171. State = [[-0.10194705 -0.29516196  0.24500385  1.        ]]. Action = [[-0.98691225 -0.8988913   0.91558194  0.20122504]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 3172. State = [[-0.26924348  0.17694242  0.11363468  1.        ]]. Action = [[-0.94533783 -0.86027205  0.88699245  0.29815936]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 3173. State = [[-0.25079095  0.19392745  0.10646812  1.        ]]. Action = [[ 0.9900737  -0.26987028  0.97483706  0.9977565 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 3174. State = [[-0.2140497   0.17772591  0.13235886  1.        ]]. Action = [[ 0.99014664 -0.7348511   0.99345386  0.99346125]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 3175. State = [[-0.19175409  0.16558279  0.15711525  1.        ]]. Action = [[ 0.9941907  -0.6910858   0.99704194  0.97490716]]. Reward = [0.]
Curr episode timestep = 2
Action ignored: No entry zone
Current timestep = 3176. State = [[-0.18906716  0.16433732  0.16050093  1.        ]]. Action = [[ 0.9769492 -0.5625066  0.9480964  0.9921539]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: No entry zone
Current timestep = 3177. State = [[-0.18867303  0.16361943  0.16069277  1.        ]]. Action = [[ 0.9774833  -0.73086303  0.6346189   0.9818685 ]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 3178. State = [[-0.18839456  0.16365851  0.16090797  1.        ]]. Action = [[ 0.9458711  -0.12749058  0.9657049   0.85478115]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 3179. State = [[-0.18814637  0.16388787  0.16126217  1.        ]]. Action = [[ 0.8944175  -0.56555474  0.9136667   0.9918133 ]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 3180. State = [[-0.18811308  0.16389932  0.1613668   1.        ]]. Action = [[ 0.9932022 -0.7679781  0.9715867  0.9812207]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 3181. State = [[-0.18809347  0.16391854  0.16138215  1.        ]]. Action = [[ 0.9190861  -0.09652907  0.9050559   0.9465177 ]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 3182. State = [[-0.18805902  0.16378188  0.16139401  1.        ]]. Action = [[ 0.9983827  -0.70528173  0.96322525  0.97731304]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 3183. State = [[-0.18805902  0.16378188  0.16139401  1.        ]]. Action = [[ 0.9426886  -0.38932204  0.9822898   0.9665215 ]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 3184. State = [[-0.1880418   0.16371356  0.16139995  1.        ]]. Action = [[ 0.98768663 -0.7542038   0.97825503  0.97384834]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: No entry zone
Current timestep = 3185. State = [[-0.1880418   0.16371356  0.16139995  1.        ]]. Action = [[ 0.9645808  -0.42224908  0.97640586  0.9951147 ]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: No entry zone
Current timestep = 3186. State = [[-0.1880418   0.16371356  0.16139995  1.        ]]. Action = [[ 0.9966819  -0.7107172   0.89565945  0.9551058 ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: No entry zone
Current timestep = 3187. State = [[-0.18802473  0.16364568  0.16140586  1.        ]]. Action = [[ 0.9751799  -0.45341778  0.97247744  0.98528194]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: No entry zone
Current timestep = 3188. State = [[-0.18802473  0.16364568  0.16140586  1.        ]]. Action = [[ 0.9507823  -0.51868314  0.87244844  0.98610854]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: No entry zone
Current timestep = 3189. State = [[-0.17393829  0.163603    0.17520604  1.        ]]. Action = [[ 0.88746166 -0.00171852  0.9699764   0.9928794 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 3190. State = [[-0.15360107  0.16427773  0.19650635  1.        ]]. Action = [[ 0.9210795  -0.6606143   0.93314934  0.98721194]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: No entry zone
Current timestep = 3191. State = [[-0.13478069  0.15298294  0.21536648  1.        ]]. Action = [[ 0.9951267 -0.6742963  0.9647174  0.9790187]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 3192. State = [[-0.10299044  0.1346146   0.25035265  1.        ]]. Action = [[ 0.9169252  -0.39794195  0.8635491   0.9150057 ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 3192 is [True, False, False, False, False, True, True, False, False, True]
State prediction error at timestep 3192 is tensor(0.0007, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3192 of -1
Current timestep = 3193. State = [[-0.07514233  0.11283252  0.27529478  1.        ]]. Action = [[ 0.8139994  -0.73462397 -0.4719205   0.64129615]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 3193 is [False, True, False, False, False, True, True, False, False, True]
State prediction error at timestep 3193 is tensor(0.0024, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3193 of 1
Current timestep = 3194. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.4811219  -0.6214699  -0.85362077  0.00667787]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: No entry zone
Scene graph at timestep 3194 is [False, True, False, False, False, True, True, False, False, True]
State prediction error at timestep 3194 is tensor(0.0015, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3194 of -1
Current timestep = 3195. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.71613264 -0.7293557  -0.6662308   0.07423329]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: No entry zone
Scene graph at timestep 3195 is [False, True, False, False, False, True, True, False, False, True]
State prediction error at timestep 3195 is tensor(0.0004, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3195 of -1
Current timestep = 3196. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.7413901  -0.720251   -0.9342576   0.04793572]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: No entry zone
Scene graph at timestep 3196 is [False, True, False, False, False, True, True, False, False, True]
State prediction error at timestep 3196 is tensor(0.0015, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3196 of -1
Current timestep = 3197. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.7735505  -0.6499042  -0.9107604   0.02802193]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: No entry zone
Scene graph at timestep 3197 is [False, True, False, False, False, True, True, False, False, True]
State prediction error at timestep 3197 is tensor(0.0012, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3197 of -1
Current timestep = 3198. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.49793398 -0.6849079  -0.90077406  0.06447947]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: No entry zone
Scene graph at timestep 3198 is [False, True, False, False, False, True, True, False, False, True]
State prediction error at timestep 3198 is tensor(0.0011, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3198 of -1
Current timestep = 3199. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.7401595  -0.5410125  -0.96762514  0.06443858]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: No entry zone
Scene graph at timestep 3199 is [False, True, False, False, False, True, True, False, False, True]
State prediction error at timestep 3199 is tensor(0.0013, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3199 of -1
Current timestep = 3200. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.7545152  -0.783663   -0.84854     0.03259254]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: No entry zone
Scene graph at timestep 3200 is [False, True, False, False, False, True, True, False, False, True]
State prediction error at timestep 3200 is tensor(0.0011, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3200 of -1
Current timestep = 3201. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.6818516  -0.64099604 -0.9015845   0.04397833]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: No entry zone
Current timestep = 3202. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.75021434 -0.6753651  -0.9045139   0.01711559]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: No entry zone
Current timestep = 3203. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.55212545 -0.6607809  -0.9225951   0.02850521]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: No entry zone
Current timestep = 3204. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.73665905 -0.6682611  -0.75154155  0.03923428]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: No entry zone
Current timestep = 3205. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.6263888  -0.65368253 -0.82821876  0.07819736]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: No entry zone
Current timestep = 3206. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.57686806 -0.638898   -0.74409574  0.04925084]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: No entry zone
Current timestep = 3207. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.5823033  -0.68570644 -0.87705976  0.10421145]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: No entry zone
Current timestep = 3208. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.63596916 -0.5682818  -0.89253914  0.08780551]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: No entry zone
Current timestep = 3209. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.65160275 -0.66910595 -0.82815593  0.0158236 ]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: No entry zone
Current timestep = 3210. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 6.8701363e-01 -6.3648903e-01 -8.6315012e-01  7.2598457e-04]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: No entry zone
Current timestep = 3211. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.6881404  -0.7112165  -0.6600528   0.01759028]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: No entry zone
Current timestep = 3212. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.6376033  -0.7061368  -0.84847385  0.02458143]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: No entry zone
Current timestep = 3213. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.6138408  -0.6847595  -0.79408026  0.05150151]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: No entry zone
Current timestep = 3214. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.42355657 -0.5890848  -0.83770174 -0.01426584]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: No entry zone
Current timestep = 3215. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.68423223 -0.63999116 -0.8419915   0.03970027]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: No entry zone
Current timestep = 3216. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.62345576 -0.73887223 -0.86199284  0.02841568]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: No entry zone
Current timestep = 3217. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.6533294  -0.7404112  -0.85493493  0.01162291]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: No entry zone
Current timestep = 3218. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.5674155  -0.6786535  -0.6635988   0.01492727]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: No entry zone
Current timestep = 3219. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.6758511  -0.7014972  -0.72458047  0.06302977]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: No entry zone
Current timestep = 3220. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.51694536 -0.71738577 -0.8729762   0.04433894]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: No entry zone
Current timestep = 3221. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.62548876 -0.45830107 -0.8225835   0.00859296]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: No entry zone
Current timestep = 3222. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.7186017 -0.5738646 -0.8380661  0.0255897]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: No entry zone
Current timestep = 3223. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.6688907  -0.63905317 -0.7641169   0.0515424 ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: No entry zone
Current timestep = 3224. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.66690993 -0.72536033 -0.8296108   0.037637  ]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: No entry zone
Current timestep = 3225. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.5795543  -0.62670887 -0.8848187   0.00475192]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: No entry zone
Current timestep = 3226. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.77464986 -0.6346546  -0.8650988  -0.01392859]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: No entry zone
Current timestep = 3227. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.5536766  -0.69297814 -0.9311961  -0.00517762]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: No entry zone
Current timestep = 3228. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.70556974 -0.6460471  -0.901242   -0.04985631]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: No entry zone
Current timestep = 3229. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.6595409  -0.76523066 -0.86890817  0.03553545]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: No entry zone
Current timestep = 3230. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.6425736  -0.7589131  -0.7078267   0.01962268]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: No entry zone
Current timestep = 3231. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.7218404  -0.73054045 -0.8494717  -0.02535921]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: No entry zone
Current timestep = 3232. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.807163   -0.6776677  -0.86436445 -0.02791411]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: No entry zone
Current timestep = 3233. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.6869414  -0.6551947  -0.88771534  0.04383492]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: No entry zone
Current timestep = 3234. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.70965207 -0.65230906 -0.64173    -0.01147711]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: No entry zone
Current timestep = 3235. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.68323874 -0.6423008  -0.8438942  -0.03096467]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: No entry zone
Current timestep = 3236. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.7852974  -0.7206683  -0.9140936   0.01501989]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: No entry zone
Current timestep = 3237. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.7673509  -0.68222386 -0.8247625   0.0371002 ]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: No entry zone
Current timestep = 3238. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.830312   -0.75791466 -0.95252764  0.01982367]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: No entry zone
Current timestep = 3239. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.80114615 -0.7527828  -0.8791762   0.05426037]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: No entry zone
Current timestep = 3240. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.7559519  -0.69045615 -0.73632336  0.07556868]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: No entry zone
Current timestep = 3241. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.5172994  -0.7128152  -0.91400933  0.04796386]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: No entry zone
Current timestep = 3242. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.7753031  -0.731257   -0.81225634  0.0305233 ]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: No entry zone
Current timestep = 3243. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.7208915  -0.7061495  -0.8988931  -0.00302368]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: No entry zone
Current timestep = 3244. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.55950093 -0.72665066 -0.74617124  0.0065372 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: No entry zone
Current timestep = 3245. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.62558925 -0.6616009  -0.7777932   0.01338482]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: No entry zone
Current timestep = 3246. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.7389796  -0.7279821  -0.6705127   0.01521015]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: No entry zone
Current timestep = 3247. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.69432664 -0.65439403 -0.91530526 -0.01697916]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: No entry zone
Current timestep = 3248. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.5597669  -0.5829772  -0.7599889   0.03971267]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: No entry zone
Current timestep = 3249. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.6339463  -0.696116   -0.8282376  -0.00213653]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: No entry zone
Current timestep = 3250. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.69170547 -0.64354706 -0.8594451   0.02269971]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: No entry zone
Current timestep = 3251. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.79197514 -0.7094793  -0.84806335 -0.01642674]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: No entry zone
Current timestep = 3252. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.63127375 -0.6361231  -0.8566297  -0.01014733]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: No entry zone
Current timestep = 3253. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.7283621  -0.73772216 -0.82985383  0.02243924]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: No entry zone
Current timestep = 3254. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.8010297  -0.62077343 -0.7909103   0.01406181]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: No entry zone
Current timestep = 3255. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.6335083  -0.72237164 -0.8256382   0.01336217]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: No entry zone
Current timestep = 3256. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.78924465 -0.6042073  -0.719472   -0.00402242]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: No entry zone
Current timestep = 3257. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.58658767 -0.5344839  -0.87220347  0.03283238]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: No entry zone
Current timestep = 3258. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.7658119  -0.6387524  -0.75904024  0.06507146]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: No entry zone
Current timestep = 3259. State = [[-0.0498853   0.09696761  0.26398256  1.        ]]. Action = [[ 0.6986922  -0.7031344  -0.85187566  0.00238371]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: No entry zone
Current timestep = 3260. State = [[-0.04566726  0.08827916  0.26145908  1.        ]]. Action = [[ 0.77262473 -0.45761907 -0.5288279   0.02653217]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 3261. State = [[-0.02358689  0.07913648  0.245106    1.        ]]. Action = [[ 0.7104044  -0.6613558  -0.9140151  -0.00310373]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: No entry zone
Current timestep = 3262. State = [[-0.01756809  0.07942019  0.24280083  1.        ]]. Action = [[ 0.5310043 -0.7042573 -0.9010072 -0.027731 ]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: No entry zone
Current timestep = 3263. State = [[-0.0173119   0.07900015  0.24200904  1.        ]]. Action = [[ 0.75678587 -0.65370214 -0.93851286  0.00475633]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: No entry zone
Current timestep = 3264. State = [[-0.01738408  0.07898216  0.24148302  1.        ]]. Action = [[ 0.7285874  -0.6792911  -0.90538543 -0.02520907]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: No entry zone
Current timestep = 3265. State = [[-0.01738408  0.07898216  0.24148302  1.        ]]. Action = [[ 0.7024423  -0.8068484  -0.9301318   0.00721252]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: No entry zone
Current timestep = 3266. State = [[-0.0173931   0.07897991  0.2414175   1.        ]]. Action = [[ 0.77192914 -0.74829364 -0.90585613  0.00331736]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: No entry zone
Current timestep = 3267. State = [[-0.0173931   0.07897991  0.2414175   1.        ]]. Action = [[ 0.75160885 -0.67868024 -0.92902535 -0.0076139 ]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: No entry zone
Current timestep = 3268. State = [[-0.0173931   0.07897991  0.2414175   1.        ]]. Action = [[ 0.8178003  -0.7651755  -0.89665294  0.01687992]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: No entry zone
Current timestep = 3269. State = [[-0.0173931   0.07897991  0.2414175   1.        ]]. Action = [[ 0.6445272  -0.74159855 -0.9219239   0.0074774 ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: No entry zone
Current timestep = 3270. State = [[-0.0173931   0.07897991  0.2414175   1.        ]]. Action = [[ 0.792912   -0.6395064  -0.89345765 -0.01288557]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: No entry zone
Current timestep = 3271. State = [[-0.0173931   0.07897991  0.2414175   1.        ]]. Action = [[ 0.76738894 -0.6935223  -0.84076273  0.00938582]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: No entry zone
Current timestep = 3272. State = [[-0.0173931   0.07897991  0.2414175   1.        ]]. Action = [[ 0.6152183  -0.75870305 -0.89146674 -0.00193298]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: No entry zone
Current timestep = 3273. State = [[-0.0173931   0.07897991  0.2414175   1.        ]]. Action = [[ 0.83040524 -0.6515531  -0.79391634 -0.0095939 ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: No entry zone
Current timestep = 3274. State = [[-0.26167846 -0.17991783  0.11511622  1.        ]]. Action = [[ 0.70282924 -0.7889564  -0.85147256  0.01607752]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: No entry zone
Current timestep = 3275. State = [[-0.25352234 -0.19877341  0.10869579  1.        ]]. Action = [[0.86359143 0.17044973 0.9741179  0.9342022 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 3276. State = [[-0.22676551 -0.19066896  0.13374324  1.        ]]. Action = [[0.96005857 0.47686887 0.9809325  0.95023525]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 3277. State = [[-0.18979432 -0.17856768  0.1704205   1.        ]]. Action = [[0.95111907 0.22372866 0.9855499  0.98528147]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 3278. State = [[-0.15241489 -0.17614244  0.20576997  1.        ]]. Action = [[ 0.91853917 -0.18725455  0.693691    0.92587984]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 3279. State = [[-0.11573038 -0.16821828  0.23905483  1.        ]]. Action = [[0.74103165 0.6802181  0.9312916  0.90595245]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 3280. State = [[-0.08405677 -0.1538354   0.27552548  1.        ]]. Action = [[0.7488799 0.0673486 0.6907873 0.6933769]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 3281. State = [[-0.05886927 -0.14837784  0.30430406  1.        ]]. Action = [[0.6835754  0.12134254 0.41690624 0.39344883]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 3282. State = [[-0.03433367 -0.14867693  0.31033543  1.        ]]. Action = [[ 0.7281232  -0.2626934  -0.5159229   0.21313894]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 3283. State = [[-0.01493838 -0.1599108   0.2908102   1.        ]]. Action = [[ 0.36519265 -0.5177065  -0.8826147   0.10916603]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 3284. State = [[ 0.00504328 -0.1770928   0.26496366  1.        ]]. Action = [[ 0.737345   -0.62214065 -0.71668243  0.07343876]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 3285. State = [[ 0.03200508 -0.20058309  0.23465501  1.        ]]. Action = [[ 0.6570548  -0.69106966 -0.76362455  0.15088344]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 3286. State = [[ 0.05801567 -0.23059827  0.2065726   1.        ]]. Action = [[ 0.29758322 -0.7914126  -0.22658712  0.09226418]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 3287. State = [[ 0.06215817 -0.26377663  0.19133143  1.        ]]. Action = [[-0.70787716 -0.9494783  -0.473503    0.06541288]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 3288. State = [[ 0.05554174 -0.28535768  0.1827442   1.        ]]. Action = [[-0.9390624  -0.9877383   0.6072321   0.01717091]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Current timestep = 3289. State = [[ 0.05487405 -0.28831202  0.182296    1.        ]]. Action = [[-0.9628492  -0.97739726  0.5165746   0.0283767 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 3290. State = [[ 0.05479063 -0.28869635  0.18222569  1.        ]]. Action = [[-0.9888606  -0.9619777   0.8880782   0.02053154]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 3291. State = [[ 0.05479063 -0.28869635  0.18222569  1.        ]]. Action = [[-0.9553266  -0.981871    0.8966179   0.01073956]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 3292. State = [[ 0.05471327 -0.28888044  0.18226637  1.        ]]. Action = [[-0.987023   -0.989689    0.7878958   0.00789118]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 3293. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9773465  -0.9735765   0.89118695 -0.00423956]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 3294. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-9.875693e-01 -9.902900e-01  8.690994e-01 -4.605055e-04]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 3295. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.99047947 -0.98447573  0.9790833   0.05611444]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 3296. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.97949934 -0.9804262   0.6113777   0.06841075]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 3297. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.98115456 -0.97681695  0.83897805  0.09019125]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 3298. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.98583835 -0.983145    0.42714095  0.08378267]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 3299. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.99438405 -0.98514503  0.3531195   0.05840933]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 3300. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9793311  -0.9762882   0.82324934  0.03910232]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 3301. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.99346304 -0.9832894   0.54098797  0.07408476]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 3302. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.96209097 -0.9824913   0.6752536   0.056885  ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 3303. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.98987865 -0.96366185  0.6421226   0.07152927]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 3304. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9905007  -0.9686938   0.81923246  0.10914314]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 3305. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9931352  -0.99097025  0.9636376   0.06771922]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 3306. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.99398965 -0.94281626  0.8742106   0.11167109]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 3307. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9918646  -0.99004424  0.53669286  0.06836975]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 3308. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9899438  -0.9821624   0.95558906  0.01830912]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 3309. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.99420494 -0.98435193  0.8298087   0.06022477]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 3310. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9965079  -0.9521217   0.90058017  0.06820631]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 3311. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.995835   -0.9831243   0.9001136   0.06758821]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 3312. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.97401726 -0.9618552   0.865698    0.10926378]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 3313. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.98675543 -0.98658204  0.5549524   0.1294601 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 3314. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9949305 -0.9656338  0.8276305  0.0748148]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 3315. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.99482447 -0.9743985  -0.47352886  0.0752362 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 3316. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.99619657 -0.98909277  0.5738236   0.06601858]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 3317. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.97360176 -0.979918    0.85753596  0.06452954]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 3318. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.99895185 -0.9869955   0.8385984   0.02214181]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 3319. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.983517   -0.9790916   0.3317263   0.03725255]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 3320. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9854438  -0.97976357  0.7527771   0.08527923]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 3321. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.99129665 -0.9634717   0.94416213  0.04053032]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 3322. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.98570114 -0.9651659   0.7704611   0.08367538]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 3323. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.984349   -0.9688553   0.63456774  0.09958959]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 3324. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9872332  -0.9760262   0.7971127   0.12230015]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 3325. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9924778  -0.9645737   0.5975945   0.09151971]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 3326. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9951669  -0.9721329   0.7789532   0.11629868]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 3327. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.996593   -0.96345395  0.863837    0.11450124]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 3328. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.99733967 -0.9573644   0.02854705  0.1045047 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 3329. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9869484  -0.9545101   0.9380349   0.08047926]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 3330. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9964781  -0.9833455   0.7838422   0.12161922]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 3331. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9902121  -0.92673963  0.7178328   0.10542548]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 3332. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9825398  -0.97219634  0.4047563   0.08109009]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 3333. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9983766  -0.9551845   0.7082224   0.13745618]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 3334. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.98846114 -0.9597255   0.6873385   0.14237785]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 3335. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.99585307 -0.93574303  0.83109665  0.11039674]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 3336. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.98016006 -0.9730503   0.2740178   0.10299194]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 3337. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9967044  -0.9784168   0.9489927   0.05626643]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 3338. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9930572  -0.9680123   0.6531266   0.09515512]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 3339. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.97246814 -0.98614806  0.7951267   0.11698782]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 3340. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.89656276 -0.92719436  0.83844733  0.15379238]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 3341. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9965042  -0.93109775  0.3389429   0.1187613 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 3342. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.97664833 -0.9566203   0.9197867   0.17272592]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 3343. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.99088395 -0.9575291   0.7452923   0.2026068 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 3344. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.98683876 -0.9613764   0.8620522   0.10888219]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 3345. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.99214983 -0.9679864   0.16040754  0.15122473]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 3346. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9701583  -0.9818461   0.90709174  0.12041533]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 3347. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9909801  -0.9457877   0.73151314  0.12804747]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 3348. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9897458  -0.97014135  0.9107578   0.10873044]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 3349. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9802033  -0.97006327  0.3258587   0.10553741]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 3350. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9954969  -0.9034459   0.9064586   0.16508675]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 3351. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9844119  -0.9567151   0.6910589   0.11298513]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 3352. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9922683  -0.9644886   0.896677    0.11644459]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 3353. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9893223  -0.9621739   0.8130865   0.07020199]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 3354. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.99338067 -0.97627157  0.405537    0.18160307]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 3355. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9962365  -0.9497693   0.90377426  0.15192842]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 3356. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.98046106 -0.9685082   0.5598577   0.17126107]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 3357. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.99692714 -0.9321545   0.4331274   0.10752416]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 3358. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9838781  -0.92900914  0.39634407  0.08457279]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 3359. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.98363495 -0.86137503  0.97781515  0.14248157]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 3360. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9893692  -0.9494879   0.91611147  0.16400123]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 3361. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9995783  -0.91569847  0.28479004  0.22036386]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 3362. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.98211896 -0.94767964  0.63287663  0.11851048]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 3363. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.99481136 -0.95123464  0.82620907  0.28018534]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 3364. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.94103646 -0.9416163   0.39567828  0.14400625]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 3365. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9826264  -0.9676046   0.97937644  0.24015224]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 3366. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.99423724 -0.92770654  0.43188834  0.21573627]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 3367. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9747084  -0.9342905   0.9655223   0.16492152]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 3368. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9947435 -0.9446128  0.8795295  0.1746639]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 3369. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.96206033 -0.9172792   0.6179168   0.12399554]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 3370. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9954846  -0.94288474  0.94395256  0.14310205]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 3371. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.98642987 -0.81719023 -0.35178542  0.18528819]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 3372. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.99138826 -0.9545403   0.76502275  0.10750949]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 3373. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.99889445 -0.9554146   0.9298072   0.13867974]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 3374. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.98873353 -0.86469656  0.91901946  0.21722114]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 3375. State = [[ 0.05468741 -0.28894192  0.18227997  1.        ]]. Action = [[-0.9853299  -0.9766673   0.6854464   0.14889812]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 3376. State = [[-0.26220247 -0.15355735  0.11571945  1.        ]]. Action = [[-0.99379206 -0.97012925  0.18745697  0.17018557]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 3377. State = [[-0.25258315 -0.1753656   0.10753379  1.        ]]. Action = [[ 0.8957677  -0.30859673  0.96454597  0.9994528 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 3378. State = [[-0.22567563 -0.18315656  0.13131924  1.        ]]. Action = [[ 0.94411993 -0.08340877  0.8629029   0.94905996]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 3379. State = [[-0.18943764 -0.18867238  0.16503729  1.        ]]. Action = [[0.9868438  0.0314219  0.91724145 0.9960151 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 3380. State = [[-0.16347615 -0.19247334  0.18850102  1.        ]]. Action = [[0.60145307 0.63454676 0.9653896  0.9587462 ]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: No entry zone
Current timestep = 3381. State = [[-0.15784492 -0.19305246  0.19186899  1.        ]]. Action = [[0.9080379  0.32909465 0.33689976 0.9578726 ]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 3382. State = [[-0.15617144 -0.19265603  0.19285089  1.        ]]. Action = [[0.73163784 0.51121676 0.56498814 0.9522829 ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 3383. State = [[-0.14446874 -0.18715112  0.20651858  1.        ]]. Action = [[0.7535746  0.286062   0.95747566 0.95993614]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 3384. State = [[-0.11340714 -0.17101671  0.24095272  1.        ]]. Action = [[0.96643686 0.6358702  0.87287915 0.8469775 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 3385. State = [[-0.07987921 -0.1472842   0.2768083   1.        ]]. Action = [[0.8204131  0.67625976 0.89923346 0.8710816 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 3386. State = [[-0.05655203 -0.12153794  0.3052535   1.        ]]. Action = [[0.12475419 0.65998113 0.15145218 0.8885422 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 3387. State = [[-0.05338386 -0.09803104  0.32252938  1.        ]]. Action = [[-0.47106302  0.56548274  0.7972777   0.89837277]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 3388. State = [[-0.05579931 -0.08006194  0.3523381   1.        ]]. Action = [[0.23410535 0.20995224 0.86465335 0.7247493 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 3389. State = [[-0.04370435 -0.06495611  0.37855548  1.        ]]. Action = [[0.7771994  0.5433732  0.26590896 0.7768047 ]]. Reward = [0.]
Curr episode timestep = 12
Above hoop
Scene graph at timestep 3389 is [False, True, False, False, True, False, True, False, False, True]
State prediction error at timestep 3389 is tensor(0.0003, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3389 of 1
Current timestep = 3390. State = [[-0.02882373 -0.05266964  0.39434287  1.        ]]. Action = [[0.45332134 0.50414157 0.47251582 0.65114284]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Above hoop
Scene graph at timestep 3390 is [False, True, False, False, True, False, True, False, False, True]
State prediction error at timestep 3390 is tensor(0.0003, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3390 of -1
Current timestep = 3391. State = [[-0.02626255 -0.04995523  0.3984143   1.        ]]. Action = [[0.26222384 0.18271911 0.24899423 0.495023  ]]. Reward = [0.]
Curr episode timestep = 14
Above hoop
Current timestep = 3392. State = [[-0.02075239 -0.03999294  0.40019852  1.        ]]. Action = [[ 0.7156788   0.358418   -0.6381943   0.49636352]]. Reward = [0.]
Curr episode timestep = 15
Above hoop
Current timestep = 3393. State = [[ 1.8698983e-04 -2.8149502e-02  3.7612933e-01  1.0000000e+00]]. Action = [[-0.07763302  0.25268388 -0.46490884  0.40792632]]. Reward = [0.]
Curr episode timestep = 16
Above hoop
Current timestep = 3394. State = [[ 0.00731829 -0.02399181  0.35698035  1.        ]]. Action = [[ 0.33882463 -0.16685843 -0.7718338   0.34997606]]. Reward = [0.]
Curr episode timestep = 17
Above hoop
Current timestep = 3395. State = [[ 0.02305424 -0.02409172  0.33371356  1.        ]]. Action = [[ 0.8134084   0.02091312 -0.5313969   0.2865616 ]]. Reward = [0.]
Curr episode timestep = 18
Above hoop
Current timestep = 3396. State = [[ 0.0480345  -0.02773808  0.30725887  1.        ]]. Action = [[ 0.5453398  -0.2746935  -0.71405256  0.35033786]]. Reward = [0.]
Curr episode timestep = 19
Above hoop
Current timestep = 3397. State = [[ 0.06916732 -0.03369243  0.27583843  1.        ]]. Action = [[ 0.28620327 -0.16810185 -0.7669923   0.23209202]]. Reward = [0.]
Curr episode timestep = 20
Above hoop
Current timestep = 3398. State = [[ 0.08571674 -0.03849926  0.2569188   1.        ]]. Action = [[ 0.6694875  -0.39834124 -0.77009267  0.16760206]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 3399. State = [[ 0.08860257 -0.04026127  0.25306538  1.        ]]. Action = [[ 0.4899217  -0.47473317 -0.886642    0.22467816]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3400. State = [[ 0.08858044 -0.04032415  0.25292856  1.        ]]. Action = [[ 0.73081386 -0.47613567 -0.89900166  0.21663177]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3401. State = [[ 0.08857232 -0.0403241   0.25285602  1.        ]]. Action = [[ 0.5776882  -0.5102038  -0.8209955   0.22531629]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3402. State = [[ 0.08857232 -0.0403241   0.25285602  1.        ]]. Action = [[ 0.42381835 -0.38673973 -0.91426444  0.20300126]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3403. State = [[ 0.08857232 -0.0403241   0.25285602  1.        ]]. Action = [[ 0.5957134  -0.6786214  -0.8128251   0.19252753]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3404. State = [[ 0.08857232 -0.0403241   0.25285602  1.        ]]. Action = [[ 0.3509884  -0.44416678 -0.869684    0.16887617]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3405. State = [[ 0.08857232 -0.0403241   0.25285602  1.        ]]. Action = [[ 0.3666607  -0.5329325  -0.7014007   0.19179702]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3406. State = [[ 0.08857232 -0.0403241   0.25285602  1.        ]]. Action = [[ 0.53054476 -0.4547118  -0.87253845  0.19485354]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3407. State = [[ 0.08857232 -0.0403241   0.25285602  1.        ]]. Action = [[ 0.0170753  -0.4321772  -0.8799146   0.19617891]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: No entry zone
Current timestep = 3408. State = [[ 0.08857232 -0.0403241   0.25285602  1.        ]]. Action = [[ 0.46061325 -0.41032314 -0.83112985  0.18424392]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3409. State = [[ 0.08857232 -0.0403241   0.25285602  1.        ]]. Action = [[ 0.5488988  -0.54429036 -0.7764803   0.21883333]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3410. State = [[ 0.08857232 -0.0403241   0.25285602  1.        ]]. Action = [[ 0.5170585  -0.6464012  -0.78753895  0.18882859]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3411. State = [[ 0.08857232 -0.0403241   0.25285602  1.        ]]. Action = [[ 0.36236763 -0.5365922  -0.8553077   0.18450916]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3412. State = [[ 0.08857232 -0.0403241   0.25285602  1.        ]]. Action = [[ 0.3391472  -0.5824648  -0.83223724  0.18640137]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3413. State = [[ 0.08857232 -0.0403241   0.25285602  1.        ]]. Action = [[ 0.2696936  -0.50382817 -0.85279125  0.21013308]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3414. State = [[ 0.08857232 -0.0403241   0.25285602  1.        ]]. Action = [[ 0.5498104  -0.5350227  -0.90542644  0.24354494]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3415. State = [[ 0.08857232 -0.0403241   0.25285602  1.        ]]. Action = [[ 0.44501722 -0.6157963  -0.7438957   0.20947456]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3416. State = [[ 0.08857232 -0.0403241   0.25285602  1.        ]]. Action = [[ 0.80933535 -0.5134464  -0.7486905   0.16514838]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3417. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.5659194  -0.358593   -0.91636086  0.19757688]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3418. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.46723032 -0.61032265 -0.78209776  0.21204317]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3419. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.34110856 -0.5474337  -0.598139    0.22634399]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3420. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.7027352  -0.60211855 -0.74378383  0.23778081]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3421. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.46135116 -0.22801757 -0.7213927   0.15402675]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3422. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.48018646 -0.4861992  -0.81637305  0.21626067]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3423. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.62403786 -0.27190578 -0.8186742   0.25117397]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3424. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.7425419  -0.38268733 -0.76380867  0.21758986]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3425. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.34327078 -0.59004086 -0.77007127  0.23674667]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3426. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.02570832 -0.20632482 -0.74543756  0.19314599]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: No entry zone
Current timestep = 3427. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.38347626 -0.26817513 -0.80110115  0.22135913]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3428. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.5070945  -0.61226624 -0.78098166  0.23906898]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3429. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.24370265 -0.37636077 -0.7064766   0.19976723]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3430. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.53163695 -0.4331833  -0.8027529   0.22950733]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3431. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.37483764 -0.43562412 -0.7988163   0.22268963]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3432. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.42001903 -0.47412324 -0.82766384  0.23302221]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3433. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.6373482  -0.3665887  -0.81443894  0.19131744]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3434. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.2564671  -0.42695326 -0.6795287   0.19797838]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3435. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.44199514 -0.29307473 -0.81390715  0.19670916]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3436. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.43504453 -0.4487691  -0.7224126   0.20524538]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3437. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.38355005 -0.3869049  -0.8338121   0.2172643 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3438. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.7280085  -0.6126646  -0.8475441   0.20384395]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3439. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.5920615  -0.4838965  -0.7519138   0.21984851]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3440. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.55600595 -0.63986844 -0.7862194   0.18131828]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3441. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[-0.02387834 -0.5499951  -0.6793352   0.18843687]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: No entry zone
Current timestep = 3442. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.56919885 -0.4529891  -0.90787476  0.2258321 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3443. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.44509077 -0.45016724 -0.8708153   0.22526038]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3444. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.6503128  -0.27674    -0.684801    0.20978558]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3445. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.790629   -0.29535234 -0.59036714  0.21915615]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3446. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.2830571  -0.46987224 -0.8623213   0.22220159]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3447. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.04857194 -0.48875362 -0.78980094  0.18862748]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: No entry zone
Current timestep = 3448. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.14722395 -0.44367605 -0.70689034  0.23019505]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: No entry zone
Current timestep = 3449. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.40087628 -0.22645128 -0.878007    0.22160578]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3450. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[-0.04518855 -0.47205436 -0.7857027   0.21499908]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: No entry zone
Current timestep = 3451. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.62319386 -0.29787308 -0.5669709   0.22570121]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3452. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.67356324 -0.2909212  -0.79235613  0.19876873]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3453. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.5473331  -0.22908276 -0.76304454  0.28897262]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3454. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.34119046 -0.52192354 -0.629758    0.25621748]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3455. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.29834235 -0.73500574 -0.8786645   0.22691691]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3456. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.55348396 -0.3770535  -0.86239266  0.27625656]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3457. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.46584868 -0.56318355 -0.7099154   0.19927669]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3458. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.40616822 -0.09683436 -0.6168425   0.2169205 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3459. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.06014919 -0.5223415  -0.7556985   0.25236464]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: No entry zone
Current timestep = 3460. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.05539906 -0.13959974 -0.79168326  0.22154903]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: No entry zone
Current timestep = 3461. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.5006261  -0.42066503 -0.91424257  0.17647386]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3462. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.43146634 -0.6149327  -0.6951743   0.2276156 ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3463. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.10057783 -0.35771394 -0.8641648   0.2055465 ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: No entry zone
Current timestep = 3464. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.7603208  -0.72023666 -0.73168504  0.24127793]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3465. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.6672231  -0.24180222 -0.80896544  0.226439  ]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3466. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.08862066 -0.404566   -0.86559814  0.22859108]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: No entry zone
Current timestep = 3467. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.06294763 -0.27614808 -0.6353849   0.23291004]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: No entry zone
Current timestep = 3468. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.6163542  -0.37003958 -0.7096789   0.2544086 ]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3469. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.6329024  -0.16064024 -0.66889584  0.24737048]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3470. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.5230017  -0.09126878 -0.8256253   0.27871323]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3471. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.5023782  -0.19361728 -0.76261467  0.2566719 ]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3472. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.6404623  -0.44439256 -0.777099    0.2872926 ]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3473. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.28812551 -0.5172792  -0.6128396   0.20102715]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3474. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.35782635 -0.24143267 -0.90495855  0.25209272]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3475. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.59720707 -0.50987035 -0.5084368   0.26378238]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3476. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.16674232 -0.56370085 -0.8037679   0.25194645]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: No entry zone
Current timestep = 3477. State = [[ 0.088543   -0.04043213  0.25288287  1.        ]]. Action = [[ 0.66119456 -0.27166867 -0.7484394   0.24409151]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3478. State = [[-0.26459774 -0.06133232  0.11275017  1.        ]]. Action = [[ 0.7133219  -0.26090777 -0.7191492   0.20848131]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3479. State = [[-0.2522055  -0.07477259  0.10805761  1.        ]]. Action = [[ 0.9790838  -0.37207764  0.94882774  0.98878956]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 3480. State = [[-0.22145613 -0.08781077  0.12962487  1.        ]]. Action = [[ 0.99122214 -0.38658988  0.82692015  0.9972105 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 3481. State = [[-0.18361314 -0.09871562  0.16298085  1.        ]]. Action = [[ 0.90464354 -0.12109053  0.90359116  0.92916524]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 3482. State = [[-0.16030891 -0.10505959  0.18519318  1.        ]]. Action = [[ 0.9476212  -0.38539433  0.86365616  0.9926828 ]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: No entry zone
Current timestep = 3483. State = [[-0.15656132 -0.10583859  0.18846513  1.        ]]. Action = [[0.98591185 0.03164113 0.39179444 0.98618627]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 3484. State = [[-0.15480398 -0.10619693  0.19001596  1.        ]]. Action = [[ 0.64671993 -0.06603652  0.8838893   0.9925748 ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 3485. State = [[-0.15445562 -0.10632659  0.19030042  1.        ]]. Action = [[0.57030666 0.4917493  0.27108932 0.97901654]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 3486. State = [[-0.15389024 -0.10638065  0.19071408  1.        ]]. Action = [[0.7728548  0.14667392 0.67062855 0.96551824]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 3487. State = [[-0.15356502 -0.10655383  0.19100195  1.        ]]. Action = [[ 0.07616699 -0.10966849  0.9300288   0.97770023]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 3488. State = [[-0.15337935 -0.10655957  0.1911427   1.        ]]. Action = [[0.9694772 0.5900214 0.9168904 0.9645531]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 3489. State = [[-0.14003928 -0.10366803  0.204687    1.        ]]. Action = [[0.97986543 0.25407445 0.98474514 0.9583435 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 3490. State = [[-0.11674583 -0.09456675  0.2372275   1.        ]]. Action = [[0.08962178 0.44596303 0.7524756  0.9536865 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 3491. State = [[-0.0994983  -0.07717396  0.26619518  1.        ]]. Action = [[0.7726805 0.4969331 0.8047279 0.9510902]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 3492. State = [[-0.0714767  -0.05347483  0.29788     1.        ]]. Action = [[0.94748735 0.7703321  0.477288   0.9077909 ]]. Reward = [0.]
Curr episode timestep = 13
Above hoop
Current timestep = 3493. State = [[-0.04495157 -0.02931831  0.32686448  1.        ]]. Action = [[0.6143253  0.52365315 0.7439749  0.8188927 ]]. Reward = [0.]
Curr episode timestep = 14
Above hoop
Current timestep = 3494. State = [[-0.01946162 -0.01430542  0.347593    1.        ]]. Action = [[0.8644235  0.21814263 0.20143175 0.91559947]]. Reward = [0.]
Curr episode timestep = 15
Above hoop
Current timestep = 3495. State = [[ 0.00307834 -0.00513353  0.3631745   1.        ]]. Action = [[-0.15993142  0.16062307  0.48609233  0.6628356 ]]. Reward = [0.]
Curr episode timestep = 16
Above hoop
Current timestep = 3496. State = [[ 0.00658354 -0.00973299  0.37547016  1.        ]]. Action = [[ 0.02459705 -0.57558835  0.042189    0.5292696 ]]. Reward = [0.]
Curr episode timestep = 17
Above hoop
Current timestep = 3497. State = [[ 0.0079136  -0.01703219  0.37450388  1.        ]]. Action = [[-0.10528046 -0.10863709 -0.53981525  0.46109128]]. Reward = [0.]
Curr episode timestep = 18
Above hoop
Current timestep = 3498. State = [[ 0.01260585 -0.02525106  0.36727503  1.        ]]. Action = [[ 0.49271882 -0.29620326  0.10598683  0.2944064 ]]. Reward = [0.]
Curr episode timestep = 19
Above hoop
Current timestep = 3499. State = [[ 0.0228036  -0.03807674  0.35797566  1.        ]]. Action = [[ 0.42452168 -0.41363966 -0.42253453  0.41448712]]. Reward = [0.]
Curr episode timestep = 20
Above hoop
Current timestep = 3500. State = [[ 0.04344674 -0.0496809   0.3460447   1.        ]]. Action = [[ 0.5924101  -0.21295083 -0.04424679  0.42868614]]. Reward = [0.]
Curr episode timestep = 21
Above hoop
Current timestep = 3501. State = [[ 0.0606568  -0.05908899  0.33510974  1.        ]]. Action = [[ 0.53420687 -0.20728499 -0.60095423  0.36807108]]. Reward = [0.]
Curr episode timestep = 22
Above hoop
Current timestep = 3502. State = [[ 0.0813301  -0.06982647  0.31167755  1.        ]]. Action = [[ 0.38899803 -0.43931007 -0.5643338   0.28681636]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 3503. State = [[ 0.09810587 -0.07846552  0.2977121   1.        ]]. Action = [[ 0.6229727  -0.27221578 -0.8771106   0.25549674]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 3504. State = [[ 0.1017993  -0.08136521  0.29711872  1.        ]]. Action = [[ 0.717479   -0.44001198 -0.7729326   0.26642323]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Scene graph at timestep 3504 is [False, False, True, True, False, False, True, False, False, True]
State prediction error at timestep 3504 is tensor(4.5998e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3504 of -1
Current timestep = 3505. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.6945658  -0.6164589  -0.80814904  0.22395277]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Scene graph at timestep 3505 is [False, False, True, True, False, False, True, False, False, True]
State prediction error at timestep 3505 is tensor(5.6030e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3505 of -1
Current timestep = 3506. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.29596424 -0.31204057 -0.8824473   0.2647146 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Scene graph at timestep 3506 is [False, False, True, True, False, False, True, False, False, True]
State prediction error at timestep 3506 is tensor(5.3822e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3506 of -1
Current timestep = 3507. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.53428316 -0.45544922 -0.86904573  0.2903824 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Scene graph at timestep 3507 is [False, False, True, True, False, False, True, False, False, True]
State prediction error at timestep 3507 is tensor(8.5848e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3507 of -1
Current timestep = 3508. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.88814235 -0.3784362  -0.824937    0.22910368]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Scene graph at timestep 3508 is [False, False, True, True, False, False, True, False, False, True]
State prediction error at timestep 3508 is tensor(9.2091e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3508 of -1
Current timestep = 3509. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.43313003 -0.266258   -0.9075525   0.28530037]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Scene graph at timestep 3509 is [False, False, True, True, False, False, True, False, False, True]
State prediction error at timestep 3509 is tensor(0.0001, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3509 of -1
Current timestep = 3510. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.7831471  -0.44633877 -0.89235556  0.25785232]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Scene graph at timestep 3510 is [False, False, True, True, False, False, True, False, False, True]
State prediction error at timestep 3510 is tensor(7.0388e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3510 of -1
Current timestep = 3511. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.32863224 -0.53633666 -0.89657575  0.29829645]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Scene graph at timestep 3511 is [False, False, True, True, False, False, True, False, False, True]
State prediction error at timestep 3511 is tensor(2.8159e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3511 of -1
Current timestep = 3512. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.6111182  -0.37614512 -0.87073857  0.2661549 ]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Scene graph at timestep 3512 is [False, False, True, True, False, False, True, False, False, True]
State prediction error at timestep 3512 is tensor(4.1886e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3512 of -1
Current timestep = 3513. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.73142505 -0.5154659  -0.89282143  0.24448454]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Scene graph at timestep 3513 is [False, False, True, True, False, False, True, False, False, True]
State prediction error at timestep 3513 is tensor(2.7322e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3513 of -1
Current timestep = 3514. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.7058904  -0.50877494 -0.84664786  0.27628136]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Scene graph at timestep 3514 is [False, False, True, True, False, False, True, False, False, True]
State prediction error at timestep 3514 is tensor(2.1143e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3514 of -1
Current timestep = 3515. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.8105283  -0.34149778 -0.8308209   0.2619723 ]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Scene graph at timestep 3515 is [False, False, True, True, False, False, True, False, False, True]
State prediction error at timestep 3515 is tensor(9.8535e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3515 of -1
Current timestep = 3516. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.60487556 -0.38644207 -0.71494496  0.23600376]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Scene graph at timestep 3516 is [False, False, True, True, False, False, True, False, False, True]
State prediction error at timestep 3516 is tensor(0.0001, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3516 of -1
Current timestep = 3517. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.60236394 -0.46223342 -0.90706223  0.25937963]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Scene graph at timestep 3517 is [False, False, True, True, False, False, True, False, False, True]
State prediction error at timestep 3517 is tensor(9.3861e-06, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3517 of -1
Current timestep = 3518. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.32533097 -0.53394526 -0.8838334   0.24062681]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Scene graph at timestep 3518 is [False, False, True, True, False, False, True, False, False, True]
State prediction error at timestep 3518 is tensor(2.4083e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3518 of -1
Current timestep = 3519. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.6298753 -0.5123063 -0.8618828  0.2518735]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Scene graph at timestep 3519 is [False, False, True, True, False, False, True, False, False, True]
State prediction error at timestep 3519 is tensor(6.4118e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3519 of -1
Current timestep = 3520. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.72835636 -0.4256593  -0.84875894  0.20444703]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 3521. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.59151626 -0.66866225 -0.8919385   0.27704525]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 3522. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.69787765 -0.47435164 -0.8623019   0.2623409 ]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 3523. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.7433553  -0.496827   -0.8238884   0.24977279]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 3524. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.56417775 -0.49154735 -0.7717868   0.28657448]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 3525. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.6685562  -0.50015795 -0.8459976   0.26940203]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 3526. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.6084143  -0.40808308 -0.8373421   0.24513686]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 3527. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.57222974 -0.5226618  -0.88798726  0.22103572]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 3528. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.6791084  -0.5723205  -0.8081208   0.23422217]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 3529. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.45782185 -0.40904617 -0.88435733  0.19613862]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 3530. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.63606143 -0.61636376 -0.7562418   0.23432207]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 3531. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.59220815 -0.19489437 -0.80740803  0.20440435]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 3532. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.7644081  -0.49858165 -0.8013773   0.18575716]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 3533. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.08913171 -0.5628202  -0.8183986   0.23325157]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 3534. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.14100683 -0.5744724  -0.83168507  0.22519708]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 3535. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.7158854  -0.32573938 -0.84987134  0.2060225 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 3536. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.5927632  -0.3648845  -0.8225316   0.24910676]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 3537. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.64707446 -0.489779   -0.86083424  0.21999204]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 3538. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.6021441  -0.36583376 -0.79706484  0.23573291]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 3539. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.59928656 -0.49111712 -0.7985744   0.2197535 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 3540. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.6425209  -0.42955804 -0.8070213   0.23360121]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 3541. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.31760085 -0.53660554 -0.86562586  0.18878758]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 3542. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.51339567 -0.5944442  -0.910561    0.20398653]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 3543. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.24721277 -0.31140375 -0.7240555   0.18792057]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 3544. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.79685616 -0.5367404  -0.91608506  0.14751744]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 3545. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.670681   -0.58106595 -0.8119781   0.19844842]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 3546. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.7854998  -0.58686954 -0.90090096  0.23330092]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 3547. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.52876735 -0.42064333 -0.69811314  0.2292769 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 3548. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.68205893 -0.5050406  -0.8762262   0.2490747 ]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 3549. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.4982562  -0.4048512  -0.84956455  0.23289132]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 3550. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.06605506 -0.5757618  -0.81169116  0.25565004]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 3551. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.39532554 -0.36485684 -0.7572076   0.20105898]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 3552. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.7362354  -0.18703955 -0.8452608   0.21956158]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 3553. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.43595767 -0.54199797 -0.853874    0.24002874]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 3554. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.7276056 -0.4861529 -0.9103485  0.260916 ]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 3555. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.6426492  -0.60655457 -0.8384771   0.18917489]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 3556. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.3407166  -0.33903146 -0.81976986  0.19623911]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 3557. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.7073569  -0.41356277 -0.90956527  0.23098195]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 3558. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.5992929  -0.38217878 -0.7875952   0.1970172 ]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 3559. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.79783154 -0.2852134  -0.84499097  0.22876239]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 3560. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.7289548  -0.39603186 -0.87026536  0.21948946]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 3561. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.601367   -0.34765768 -0.7999644   0.2145617 ]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 3562. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.734043   -0.53039634 -0.82929546  0.20037079]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 3563. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.5374756  -0.48067784 -0.72603905  0.21597147]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 3564. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.6705375  -0.63983935 -0.8197359   0.2226932 ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 3565. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.7596824  -0.21638513 -0.8718951   0.21894217]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 3566. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.6405306  -0.6187404  -0.84785396  0.22424781]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 3567. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.6761391 -0.4568969 -0.8170407  0.2612288]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 3568. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.6765089  -0.43958086 -0.7335644   0.22071564]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 3569. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.6332476  -0.65733814 -0.8917033   0.21719515]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 3570. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.6718023  -0.57670605 -0.8402031   0.23470092]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 3571. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.5534947  -0.42575192 -0.8402461   0.24058795]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 3572. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.5376283  -0.46680284 -0.7891453   0.21364617]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 3573. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.58583975 -0.60223484 -0.7342892   0.24967837]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 3574. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.718619   -0.45561802 -0.69343734  0.210024  ]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 3575. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.53666425 -0.6062962  -0.81816506  0.21505153]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 3576. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.7292206  -0.46685392 -0.6670259   0.2291795 ]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 3577. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.71687007 -0.5177796  -0.81990093  0.17315733]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 3578. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.5344815  -0.2799176  -0.82087666  0.20066798]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 3579. State = [[ 0.10137051 -0.08239359  0.2972822   1.        ]]. Action = [[ 0.6796428  -0.55454415 -0.8862417   0.14776218]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 3580. State = [[-0.26942185  0.0349212   0.11412214  1.        ]]. Action = [[ 0.71231794 -0.56875986 -0.8241162   0.1655904 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 3581. State = [[-0.25624344  0.02986024  0.10952859  1.        ]]. Action = [[ 0.9661082  -0.72670436  0.98635006  0.9712548 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 3582. State = [[-0.22472851  0.01317342  0.13447778  1.        ]]. Action = [[ 0.8381536  -0.45358467  0.9747932   0.9191315 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 3583. State = [[-0.18873751 -0.00225059  0.17231826  1.        ]]. Action = [[ 0.9587984  -0.39790785  0.98864555  0.97772694]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 3584. State = [[-0.16451731 -0.01097325  0.19564688  1.        ]]. Action = [[ 0.98797905 -0.24296486  0.9361391   0.9334315 ]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: No entry zone
Current timestep = 3585. State = [[-0.14656061 -0.01448339  0.21488303  1.        ]]. Action = [[ 0.97589004 -0.09804833  0.9734485   0.986789  ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 3586. State = [[-0.11075649 -0.01641802  0.2503143   1.        ]]. Action = [[ 0.94593287 -0.03025889  0.86693823  0.9770459 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 3586 is [True, False, False, False, True, False, True, False, False, True]
State prediction error at timestep 3586 is tensor(0.0007, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3586 of 1
Current timestep = 3587. State = [[-0.07265505 -0.02297624  0.29165304  1.        ]]. Action = [[ 0.9473945  -0.35109413  0.7179532   0.89429474]]. Reward = [0.]
Curr episode timestep = 6
Above hoop
Current timestep = 3588. State = [[-0.04847841 -0.02299192  0.3196438   1.        ]]. Action = [[0.30555367 0.44317377 0.71391904 0.9144639 ]]. Reward = [0.]
Curr episode timestep = 7
Above hoop
Current timestep = 3589. State = [[-0.02538276 -0.02343627  0.34937122  1.        ]]. Action = [[ 0.9399189  -0.3498391   0.78964853  0.9214518 ]]. Reward = [0.]
Curr episode timestep = 8
Above hoop
Current timestep = 3590. State = [[ 0.00265791 -0.02503503  0.37664557  1.        ]]. Action = [[0.784225   0.03506875 0.5490178  0.70953083]]. Reward = [0.]
Curr episode timestep = 9
Above hoop
Current timestep = 3591. State = [[ 0.02714271 -0.02681748  0.3865175   1.        ]]. Action = [[ 0.66178966 -0.07424492 -0.40620434  0.5058546 ]]. Reward = [0.]
Curr episode timestep = 10
Above hoop
Current timestep = 3592. State = [[ 0.05183868 -0.03326399  0.36953992  1.        ]]. Action = [[ 0.38440752 -0.30920517 -0.5368064   0.39899588]]. Reward = [0.]
Curr episode timestep = 11
Above hoop
Current timestep = 3593. State = [[ 0.07126248 -0.04575335  0.34737277  1.        ]]. Action = [[ 0.35076165 -0.43335742 -0.6877736   0.22187161]]. Reward = [0.]
Curr episode timestep = 12
Above hoop
Current timestep = 3594. State = [[ 0.08776583 -0.05467371  0.33183354  1.        ]]. Action = [[ 0.54387116 -0.32629055 -0.8211549   0.19434261]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Current timestep = 3595. State = [[ 0.09174725 -0.05701533  0.3308152   1.        ]]. Action = [[ 0.7198167  -0.41288525 -0.76209974  0.17576516]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 3596. State = [[ 0.09188777 -0.05735846  0.33047268  1.        ]]. Action = [[ 0.48585725 -0.503868   -0.8355216   0.17428994]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 3597. State = [[ 0.0918638  -0.05753751  0.33035937  1.        ]]. Action = [[ 0.69067144 -0.51432896 -0.8928992   0.18339884]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 3598. State = [[ 0.09164417 -0.0575068   0.33027488  1.        ]]. Action = [[ 0.62466764 -0.5033433  -0.88483316  0.16508651]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 3599. State = [[ 0.09164417 -0.0575068   0.33027488  1.        ]]. Action = [[ 0.5318248  -0.557033   -0.8781933   0.20746851]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 3600. State = [[ 0.09164417 -0.0575068   0.33027488  1.        ]]. Action = [[ 0.74831724 -0.38452256 -0.95066905  0.23991275]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 3601. State = [[ 0.09156199 -0.05749529  0.33027092  1.        ]]. Action = [[ 0.59140646 -0.60189766 -0.8165604   0.2488836 ]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 3602. State = [[ 0.09156199 -0.05749529  0.33027092  1.        ]]. Action = [[ 0.45842636 -0.5839321  -0.8470594   0.21832621]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 3603. State = [[ 0.09156199 -0.05749529  0.33027092  1.        ]]. Action = [[ 0.5937078  -0.5140534  -0.82807255  0.25698388]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 3604. State = [[ 0.09156199 -0.05749529  0.33027092  1.        ]]. Action = [[ 0.5859895  -0.5767767  -0.82598305  0.19335067]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 3605. State = [[ 0.09156199 -0.05749529  0.33027092  1.        ]]. Action = [[ 0.42688382 -0.5699556  -0.6888988   0.22753084]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 3606. State = [[ 0.09156199 -0.05749529  0.33027092  1.        ]]. Action = [[ 0.80653834 -0.50223035 -0.5845745   0.2115494 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 3607. State = [[ 0.09156199 -0.05749529  0.33027092  1.        ]]. Action = [[ 0.55440474 -0.5780218  -0.69391143  0.130615  ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 3608. State = [[ 0.09156199 -0.05749529  0.33027092  1.        ]]. Action = [[ 0.7024261  -0.5002918  -0.861934    0.25710475]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 3609. State = [[ 0.09156199 -0.05749529  0.33027092  1.        ]]. Action = [[ 0.7111939  -0.53496087 -0.7373736   0.20814323]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 3610. State = [[ 0.09156199 -0.05749529  0.33027092  1.        ]]. Action = [[ 0.53145313 -0.56700474 -0.8417185   0.18666649]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 3611. State = [[ 0.09156199 -0.05749529  0.33027092  1.        ]]. Action = [[ 0.645563   -0.59799725 -0.85655457  0.2100159 ]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 3612. State = [[ 0.09156199 -0.05749529  0.33027092  1.        ]]. Action = [[ 0.3493817  -0.5059598  -0.858664    0.23650873]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 3613. State = [[ 0.09156199 -0.05749529  0.33027092  1.        ]]. Action = [[ 0.62810385 -0.6643168  -0.85433394  0.19089413]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 3614. State = [[ 0.09156199 -0.05749529  0.33027092  1.        ]]. Action = [[ 0.36397505 -0.63088226 -0.77812684  0.16702414]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 3615. State = [[ 0.09156199 -0.05749529  0.33027092  1.        ]]. Action = [[ 0.40943754 -0.6555904  -0.90562826  0.16941988]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 3616. State = [[ 0.09156199 -0.05749529  0.33027092  1.        ]]. Action = [[ 0.5602212  -0.50549287 -0.7280556   0.22318769]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 3617. State = [[ 0.09156199 -0.05749529  0.33027092  1.        ]]. Action = [[ 0.7290448  -0.57799876 -0.72689855  0.14450502]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 3618. State = [[ 0.09156199 -0.05749529  0.33027092  1.        ]]. Action = [[ 0.64753544 -0.5562463  -0.6414768   0.17817616]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 3619. State = [[ 0.09156199 -0.05749529  0.33027092  1.        ]]. Action = [[ 0.6048169  -0.6011404  -0.50524074  0.2058407 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 3620. State = [[ 0.09156199 -0.05749529  0.33027092  1.        ]]. Action = [[ 0.32829475 -0.70228213 -0.92394274  0.22915328]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 3621. State = [[ 0.09156199 -0.05749529  0.33027092  1.        ]]. Action = [[ 0.35760963 -0.7488633  -0.6215057   0.21370411]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 3622. State = [[ 0.09156199 -0.05749529  0.33027092  1.        ]]. Action = [[ 0.33894038 -0.62555563 -0.8135598   0.17895877]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 3623. State = [[ 0.09189007 -0.06623285  0.32556745  1.        ]]. Action = [[ 0.13385308 -0.62869483 -0.6571718   0.24312663]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 3624. State = [[ 0.09616148 -0.07826518  0.30816835  1.        ]]. Action = [[ 0.53399026 -0.5718228  -0.91794217  0.2263093 ]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Scene graph at timestep 3624 is [False, True, False, True, False, False, True, False, False, True]
State prediction error at timestep 3624 is tensor(0.0001, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3624 of -1
Current timestep = 3625. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.22201765 -0.64249533 -0.5725817   0.18774748]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 3626. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.24355435 -0.41797316 -0.8381826   0.18824911]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 3627. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.12383103 -0.6015968  -0.61909723  0.18383217]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 3628. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.6545104  -0.6028086  -0.8514021   0.23371077]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 3629. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.52803826 -0.47121596 -0.701229    0.21792066]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 3630. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.1640209  -0.56280273 -0.72842306  0.18084812]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 3631. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.37435067 -0.62440497 -0.880465    0.21761787]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 3632. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.6112189  -0.6136347  -0.7200505   0.21985841]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 3633. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.54214525 -0.39489675 -0.683993    0.22085047]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 3634. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.57956886 -0.62974656 -0.9119175   0.16764736]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 3635. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.79612684 -0.5566064  -0.79182625  0.18067122]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 3636. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.5670947 -0.6277196 -0.4929332  0.2524407]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 3637. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.55883837 -0.43110132 -0.6476503   0.17152941]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 3638. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.7679734  -0.47096503 -0.74487025  0.17854309]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 3639. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.33727145 -0.51815087 -0.8594932   0.20374107]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 3640. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.23445022 -0.64008296 -0.85048336  0.22810924]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 3641. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.49380422 -0.5854437  -0.87610584  0.2197361 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 3642. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.80700696 -0.574465   -0.45320594  0.18909442]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 3643. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.5136802  -0.4964803  -0.8938582   0.23920202]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 3644. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.49848855 -0.5188723  -0.39125502  0.2982025 ]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 3645. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.749863   -0.13618326 -0.83959705  0.19063187]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 3646. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.5973296  -0.3836044  -0.7558738   0.20971227]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 3647. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.40512657 -0.5626001  -0.7876611   0.28749394]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 3648. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.63355803 -0.5202622  -0.6274492   0.20893013]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 3649. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.7768376  -0.30319738 -0.70254475  0.24243784]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 3650. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.63894224 -0.2396487  -0.6790151   0.2122395 ]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 3651. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.4158628  -0.59593934 -0.71933967  0.29265893]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 3652. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.29000306 -0.7076705  -0.736637    0.33990836]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 3653. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.32274926 -0.46217108 -0.8072879   0.28912187]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 3654. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.10363603 -0.27713227 -0.72758704  0.219064  ]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 3655. State = [[ 0.09627412 -0.07961594  0.30626512  1.        ]]. Action = [[ 0.5086608  -0.50753367 -0.5398868   0.28677166]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 3656. State = [[ 0.0963326  -0.08771739  0.3010113   1.        ]]. Action = [[ 0.06209373 -0.4992041  -0.6840421   0.36214185]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 3657. State = [[ 0.1024543  -0.09768076  0.28475785  1.        ]]. Action = [[ 0.4013462  -0.27682972 -0.7384169   0.32883048]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 3658. State = [[ 0.10326062 -0.09904878  0.28257787  1.        ]]. Action = [[ 0.43495452 -0.557743   -0.5307989   0.3730905 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 3659. State = [[ 0.10325047 -0.09904828  0.28243044  1.        ]]. Action = [[ 0.5095804  -0.54609007 -0.6866498   0.37269568]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 3660. State = [[ 0.10325047 -0.09904828  0.28243044  1.        ]]. Action = [[ 0.44464946 -0.15142554 -0.68146676  0.27894711]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 3661. State = [[ 0.10325047 -0.09904828  0.28243044  1.        ]]. Action = [[ 0.38197732  0.05073798 -0.74460435  0.40007162]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 3662. State = [[ 0.10325047 -0.09904828  0.28243044  1.        ]]. Action = [[ 0.53003037 -0.3990504  -0.57429636  0.40510762]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 3663. State = [[ 0.10325047 -0.09904828  0.28243044  1.        ]]. Action = [[ 0.20184684 -0.09976041 -0.74473584  0.42024767]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 3664. State = [[ 0.10325047 -0.09904828  0.28243044  1.        ]]. Action = [[ 0.5919446  -0.24728876 -0.49221313  0.3764615 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 3665. State = [[ 0.10325047 -0.09904828  0.28243044  1.        ]]. Action = [[ 0.11986601 -0.24229103  0.01641774  0.47979605]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 3666. State = [[ 0.10324533 -0.09904803  0.28235605  1.        ]]. Action = [[ 0.3057139  -0.18953544 -0.57692343  0.430714  ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 3667. State = [[ 0.10324024 -0.09904777  0.28228232  1.        ]]. Action = [[ 0.00925505  0.09872901 -0.41952026  0.49885273]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 3668. State = [[ 0.10323513 -0.09904752  0.28220862  1.        ]]. Action = [[ 0.04205847 -0.28393447 -0.3633325   0.51798975]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 3669. State = [[ 0.10323513 -0.09904752  0.28220862  1.        ]]. Action = [[-0.00886792 -0.41292334 -0.59882295  0.5766704 ]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 3670. State = [[ 0.103197   -0.10473685  0.27625465  1.        ]]. Action = [[-0.14946634 -0.30820763 -0.64032316  0.3599993 ]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 3671. State = [[ 0.10404433 -0.11099593  0.25841638  1.        ]]. Action = [[-2.3512548e-01  1.2040138e-05 -2.4761069e-01  5.8410466e-01]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 3672. State = [[ 0.10472553 -0.11207037  0.25652426  1.        ]]. Action = [[ 0.45618892 -0.1251266  -0.5122757   0.47080064]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3673. State = [[ 0.10124312 -0.11237985  0.2510019   1.        ]]. Action = [[-0.59156716  0.12777698 -0.29724497  0.3945272 ]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 3674. State = [[ 0.09666935 -0.11421827  0.24270539  1.        ]]. Action = [[ 0.00925267 -0.18939894 -0.34357983  0.56774044]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 3675. State = [[ 0.09624493 -0.11499178  0.24275818  1.        ]]. Action = [[-0.7999322   0.12708223 -0.42472768  0.5508013 ]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: No entry zone
Current timestep = 3676. State = [[ 0.08889019 -0.11635429  0.24470256  1.        ]]. Action = [[-0.9525865   0.0021621   0.22080028  0.584386  ]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 3677. State = [[ 0.0630835  -0.10400303  0.24391477  1.        ]]. Action = [[-0.56520677  0.65074134 -0.06072223  0.4943601 ]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 3678. State = [[ 0.04846113 -0.08945679  0.24956918  1.        ]]. Action = [[0.01600659 0.04893541 0.33554792 0.78951716]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 3679. State = [[ 0.05304176 -0.084867    0.26369876  1.        ]]. Action = [[0.8555372  0.10202098 0.72644556 0.7752981 ]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 3680. State = [[ 0.05554201 -0.07217533  0.28596595  1.        ]]. Action = [[-0.11684829  0.7118056   0.79196334  0.70530725]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 3681. State = [[ 0.05723804 -0.04698321  0.30859026  1.        ]]. Action = [[0.74343085 0.4938929  0.36065042 0.8039298 ]]. Reward = [0.]
Curr episode timestep = 100
Above hoop
Current timestep = 3682. State = [[-0.26951385  0.11283332  0.11684127  1.        ]]. Action = [[0.04216087 0.12348628 0.10923529 0.7856883 ]]. Reward = [0.]
Curr episode timestep = 101
Above hoop
Current timestep = 3683. State = [[-0.24975081  0.11604526  0.11125111  1.        ]]. Action = [[ 0.99926376 -0.6711588   0.98840547  0.97589064]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 3684. State = [[-0.21842062  0.09791705  0.1358      1.        ]]. Action = [[ 0.86130357 -0.5292402   0.9808519   0.9615085 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 3685. State = [[-0.18308502  0.08133757  0.17389974  1.        ]]. Action = [[ 0.9890058  -0.38317907  0.9651643   0.98781   ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 3686. State = [[-0.15831794  0.07322989  0.19816254  1.        ]]. Action = [[ 0.74812603 -0.5669355   0.9145633   0.9618871 ]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: No entry zone
Current timestep = 3687. State = [[-0.14530376  0.06364852  0.21677308  1.        ]]. Action = [[ 0.3856008  -0.46832943  0.9867284   0.98518324]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 3688. State = [[-0.12242616  0.04825086  0.25206512  1.        ]]. Action = [[ 0.9355283  -0.43617064  0.93584454  0.88852835]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 3689. State = [[-0.09751462  0.03644142  0.2859164   1.        ]]. Action = [[ 0.46750045 -0.19718361  0.49354124  0.9591738 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 3690. State = [[-0.07813846  0.03430715  0.31479257  1.        ]]. Action = [[0.57085884 0.12684071 0.8242667  0.9911194 ]]. Reward = [0.]
Curr episode timestep = 7
Above hoop
Current timestep = 3691. State = [[-0.058584    0.03153681  0.34735906  1.        ]]. Action = [[ 0.43203688 -0.21788871  0.8162651   0.95895815]]. Reward = [0.]
Curr episode timestep = 8
Above hoop
Current timestep = 3692. State = [[-0.04401525  0.02303415  0.37449816  1.        ]]. Action = [[ 0.2807994  -0.3016324   0.3780501   0.95869315]]. Reward = [0.]
Curr episode timestep = 9
Above hoop
Current timestep = 3693. State = [[-0.03558753  0.01860501  0.38695836  1.        ]]. Action = [[ 0.62458634 -0.5253081   0.94613457  0.983474  ]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: Workspace boundary
Above hoop
Current timestep = 3694. State = [[-0.03512053  0.01672819  0.39017332  1.        ]]. Action = [[-0.15482211 -0.02845329  0.25055993  0.79513204]]. Reward = [0.]
Curr episode timestep = 11
Above hoop
Current timestep = 3695. State = [[-0.03352524  0.01551254  0.3972577   1.        ]]. Action = [[0.19883943 0.07281291 0.9245732  0.96134496]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Above hoop
Current timestep = 3696. State = [[-0.03368572  0.01437374  0.39861944  1.        ]]. Action = [[-0.07767439 -0.15462738  0.70928705  0.8454058 ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Above hoop
Current timestep = 3697. State = [[-0.03383192  0.01392755  0.39871478  1.        ]]. Action = [[0.06240654 0.07953584 0.6292845  0.9347296 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Above hoop
Current timestep = 3698. State = [[-0.03391426  0.01393793  0.39871103  1.        ]]. Action = [[ 0.5182371  -0.32593095  0.86172056  0.91215503]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Above hoop
Current timestep = 3699. State = [[-0.03391426  0.01393793  0.39871103  1.        ]]. Action = [[-0.03874528  0.57709265  0.79082024  0.9738467 ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Above hoop
Current timestep = 3700. State = [[-0.03391426  0.01393793  0.39871103  1.        ]]. Action = [[ 0.91212535 -0.14254391  0.89781356  0.9147935 ]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Above hoop
Current timestep = 3701. State = [[-0.03391426  0.01393793  0.39871103  1.        ]]. Action = [[ 0.55168307 -0.00760156  0.8320606   0.9766191 ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Above hoop
Current timestep = 3702. State = [[-0.03391426  0.01393793  0.39871103  1.        ]]. Action = [[0.46182942 0.10989535 0.70361185 0.9047644 ]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Above hoop
Current timestep = 3703. State = [[-0.03391426  0.01393793  0.39871103  1.        ]]. Action = [[0.41359794 0.0109936  0.72603035 0.99382186]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Above hoop
Current timestep = 3704. State = [[-0.03391426  0.01393793  0.39871103  1.        ]]. Action = [[ 0.43720818 -0.21948212  0.831506    0.8942766 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Above hoop
Current timestep = 3705. State = [[-0.03391426  0.01393793  0.39871103  1.        ]]. Action = [[ 0.4932933  -0.22035813  0.83168507  0.9598608 ]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Above hoop
Current timestep = 3706. State = [[-0.02941737  0.01768782  0.3952247   1.        ]]. Action = [[ 0.77720046  0.31408012 -0.25476432  0.9705701 ]]. Reward = [0.]
Curr episode timestep = 23
Above hoop
Current timestep = 3707. State = [[-0.01217203  0.02303561  0.3901387   1.        ]]. Action = [[0.60318184 0.03876889 0.7220478  0.90808547]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Above hoop
Current timestep = 3708. State = [[-0.00125038  0.02929133  0.39136654  1.        ]]. Action = [[0.86583424 0.3472302  0.23501933 0.9573368 ]]. Reward = [0.]
Curr episode timestep = 25
Above hoop
Current timestep = 3709. State = [[0.01840695 0.03840128 0.39545295 1.        ]]. Action = [[ 0.05021966 -0.10083991  0.8597226   0.9337281 ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Above hoop
Current timestep = 3710. State = [[0.02398566 0.04081012 0.39961734 1.        ]]. Action = [[-0.62986916  0.07471871  0.9157784   0.86259866]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Above hoop
Current timestep = 3711. State = [[0.02455033 0.04110086 0.39942455 1.        ]]. Action = [[-0.85546535 -0.55295974  0.623214    0.79938936]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Above hoop
Current timestep = 3712. State = [[0.02609405 0.04316031 0.3982004  1.        ]]. Action = [[ 0.06936753  0.24182105 -0.02258068  0.7124901 ]]. Reward = [0.]
Curr episode timestep = 29
Above hoop
Current timestep = 3713. State = [[0.02825384 0.04659122 0.39414936 1.        ]]. Action = [[-0.23953313  0.09797645 -0.33851534  0.84729517]]. Reward = [0.]
Curr episode timestep = 30
Above hoop
Current timestep = 3714. State = [[0.02806444 0.0480681  0.39262298 1.        ]]. Action = [[-0.49410492 -0.22929728  0.5684751   0.63134074]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Above hoop
Current timestep = 3715. State = [[0.02662337 0.04459197 0.392926   1.        ]]. Action = [[-0.6821984  -0.34784967 -0.01379138  0.6708158 ]]. Reward = [0.]
Curr episode timestep = 32
Above hoop
Current timestep = 3716. State = [[0.01797868 0.03994435 0.39894617 1.        ]]. Action = [[-0.66689116 -0.08977944  0.34787893  0.9154711 ]]. Reward = [0.]
Curr episode timestep = 33
Above hoop
Current timestep = 3717. State = [[0.00348175 0.0385472  0.40558124 1.        ]]. Action = [[-0.12945157  0.7585654   0.48960757  0.8570918 ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Above hoop
Current timestep = 3718. State = [[0.00227837 0.03888315 0.4070434  1.        ]]. Action = [[-0.5248354   0.07916427  0.88459957  0.93968153]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Above hoop
Current timestep = 3719. State = [[-0.00715463  0.04795031  0.40074733  1.        ]]. Action = [[-0.77355695  0.50356185 -0.46558523  0.9750495 ]]. Reward = [0.]
Curr episode timestep = 36
Above hoop
Current timestep = 3720. State = [[-0.0261672   0.05759946  0.3941107   1.        ]]. Action = [[-0.37149978 -0.2641213   0.6102474   0.9673444 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Above hoop
Current timestep = 3721. State = [[-0.02792392  0.05973601  0.39241183  1.        ]]. Action = [[ 0.44404566  0.1245203  -0.04580045  0.96017504]]. Reward = [0.]
Curr episode timestep = 38
Above hoop
Current timestep = 3722. State = [[-0.02680564  0.06077463  0.39286518  1.        ]]. Action = [[0.7647593  0.23065567 0.72740054 0.9908949 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Above hoop
Current timestep = 3723. State = [[-0.02669519  0.06076507  0.39286473  1.        ]]. Action = [[0.1755203  0.03398001 0.5194087  0.90013754]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Above hoop
Current timestep = 3724. State = [[-0.02439755  0.05406835  0.39389074  1.        ]]. Action = [[ 0.15428376 -0.4994024   0.09609985  0.97184086]]. Reward = [0.]
Curr episode timestep = 41
Above hoop
Current timestep = 3725. State = [[-0.0237219   0.04788524  0.39618278  1.        ]]. Action = [[0.23978376 0.0038588  0.9889822  0.82355857]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Above hoop
Current timestep = 3726. State = [[-0.02377213  0.04670735  0.3964332   1.        ]]. Action = [[0.19900656 0.25102472 0.39193678 0.9423356 ]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Above hoop
Current timestep = 3727. State = [[-0.02241065  0.04171074  0.39938274  1.        ]]. Action = [[ 0.15708673 -0.25358164  0.35564184  0.97972095]]. Reward = [0.]
Curr episode timestep = 44
Above hoop
Current timestep = 3728. State = [[-0.02152579  0.03637131  0.4044834   1.        ]]. Action = [[ 0.6302972  -0.42762548  0.97137403  0.9660425 ]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Above hoop
Current timestep = 3729. State = [[-0.0213045   0.03531191  0.40574384  1.        ]]. Action = [[0.09546196 0.10682297 0.44288576 0.9272499 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Above hoop
Current timestep = 3730. State = [[-0.0213045   0.03531191  0.40574384  1.        ]]. Action = [[0.29198873 0.29756403 0.3206997  0.945073  ]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Above hoop
Current timestep = 3731. State = [[-0.0213045   0.03531191  0.40574384  1.        ]]. Action = [[ 0.32689404 -0.154845    0.7874516   0.9854678 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Above hoop
Current timestep = 3732. State = [[-0.0213045   0.03531191  0.40574384  1.        ]]. Action = [[0.69386303 0.08716059 0.87645507 0.9070437 ]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Above hoop
Current timestep = 3733. State = [[-0.0213045   0.03531191  0.40574384  1.        ]]. Action = [[ 0.5039847  -0.32369524  0.6926255   0.92365074]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Above hoop
Current timestep = 3734. State = [[-0.0213045   0.03531191  0.40574384  1.        ]]. Action = [[ 0.23126662 -0.39489412  0.7153876   0.992429  ]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Above hoop
Current timestep = 3735. State = [[-0.0213045   0.03531191  0.40574384  1.        ]]. Action = [[-0.5657217 -0.5862135  0.753387   0.9351343]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Above hoop
Current timestep = 3736. State = [[-0.0213045   0.03531191  0.40574384  1.        ]]. Action = [[ 0.70681095 -0.18617266  0.8662983   0.93953323]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Above hoop
Current timestep = 3737. State = [[-0.0213045   0.03531191  0.40574384  1.        ]]. Action = [[0.08907902 0.4212321  0.6023332  0.95335627]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Above hoop
Current timestep = 3738. State = [[-0.02174194  0.03453232  0.40754023  1.        ]]. Action = [[-0.30277866  0.01287544  0.19400728  0.8908212 ]]. Reward = [0.]
Curr episode timestep = 55
Above hoop
Current timestep = 3739. State = [[-0.02185573  0.03400266  0.40803394  1.        ]]. Action = [[-0.15884048 -0.40018415  0.8855691   0.9658797 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Above hoop
Current timestep = 3740. State = [[-0.02195032  0.03379179  0.40824795  1.        ]]. Action = [[0.48328555 0.653188   0.82333064 0.9824796 ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Above hoop
Current timestep = 3741. State = [[-0.02314861  0.03920749  0.40893716  1.        ]]. Action = [[0.00765347 0.33897996 0.09671068 0.8315263 ]]. Reward = [0.]
Curr episode timestep = 58
Above hoop
Current timestep = 3742. State = [[-0.02570881  0.04837816  0.4092856   1.        ]]. Action = [[-0.16431296  0.24078429 -0.12659031  0.96450067]]. Reward = [0.]
Curr episode timestep = 59
Above hoop
Current timestep = 3743. State = [[-0.02716177  0.05347098  0.40934286  1.        ]]. Action = [[0.5923526  0.1484139  0.80192494 0.98733854]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Above hoop
Current timestep = 3744. State = [[-0.02564295  0.0509299   0.4077073   1.        ]]. Action = [[ 0.5948763  -0.23445678 -0.07518232  0.94612694]]. Reward = [0.]
Curr episode timestep = 61
Above hoop
Current timestep = 3745. State = [[-0.02486428  0.04858387  0.40691078  1.        ]]. Action = [[ 0.17729199 -0.05773509  0.7666862   0.9028888 ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Above hoop
Current timestep = 3746. State = [[-0.02481005  0.04847155  0.40693578  1.        ]]. Action = [[-0.03711808 -0.06566638  0.8112037   0.9529362 ]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Above hoop
Current timestep = 3747. State = [[-0.02481005  0.04847155  0.40693578  1.        ]]. Action = [[ 0.64306545 -0.26351207  0.8192978   0.97788525]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Above hoop
Current timestep = 3748. State = [[-0.02481005  0.04847155  0.40693578  1.        ]]. Action = [[0.27984357 0.48609114 0.8668227  0.9521481 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Above hoop
Current timestep = 3749. State = [[-0.02481005  0.04847155  0.40693578  1.        ]]. Action = [[0.30869722 0.29257405 0.7671106  0.9724729 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Above hoop
Current timestep = 3750. State = [[-0.02481005  0.04847155  0.40693578  1.        ]]. Action = [[0.2657721  0.30609632 0.47914743 0.9511163 ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Above hoop
Current timestep = 3751. State = [[-0.02481005  0.04847155  0.40693578  1.        ]]. Action = [[-0.15735328  0.03913808  0.8463025   0.8716519 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Above hoop
Current timestep = 3752. State = [[-0.02044711  0.04612088  0.4013213   1.        ]]. Action = [[ 0.8272364  0.0109489 -0.4779216  0.7162411]]. Reward = [0.]
Curr episode timestep = 69
Above hoop
Current timestep = 3753. State = [[-0.0011937   0.04726544  0.38734606  1.        ]]. Action = [[-0.09665024  0.20161927  0.9221406   0.8973042 ]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Above hoop
Current timestep = 3754. State = [[0.00258531 0.0408282  0.38952047 1.        ]]. Action = [[-0.26333165 -0.40823263  0.3102485   0.9671953 ]]. Reward = [0.]
Curr episode timestep = 71
Above hoop
Current timestep = 3755. State = [[0.00262912 0.03299653 0.3931912  1.        ]]. Action = [[-0.72595763  0.22626412  0.86184144  0.9275062 ]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Above hoop
Current timestep = 3756. State = [[0.00549515 0.02981611 0.39615473 1.        ]]. Action = [[ 0.42146397 -0.13464463  0.20098472  0.9321284 ]]. Reward = [0.]
Curr episode timestep = 73
Above hoop
Current timestep = 3757. State = [[0.0078084  0.03347219 0.403367   1.        ]]. Action = [[-0.23774832  0.44751883  0.33895016  0.80412054]]. Reward = [0.]
Curr episode timestep = 74
Above hoop
Current timestep = 3758. State = [[0.00973581 0.03846963 0.41020468 1.        ]]. Action = [[-0.26078618  0.42385137  0.3030553   0.754647  ]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Above hoop
Current timestep = 3759. State = [[0.00978195 0.03861899 0.41038823 1.        ]]. Action = [[-0.23199493  0.04925299  0.62001896  0.8712127 ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Above hoop
Current timestep = 3760. State = [[0.01020603 0.03660771 0.4103885  1.        ]]. Action = [[ 0.00416267 -0.259888   -0.19878668  0.9699838 ]]. Reward = [0.]
Curr episode timestep = 77
Above hoop
Current timestep = 3761. State = [[0.01041665 0.03537001 0.410391   1.        ]]. Action = [[-0.11797792  0.11853051  0.8776343   0.85627675]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Above hoop
Current timestep = 3762. State = [[0.01042436 0.03537222 0.4103238  1.        ]]. Action = [[0.28967643 0.19211638 0.5497993  0.81674254]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Above hoop
Current timestep = 3763. State = [[0.01040077 0.03503319 0.4104602  1.        ]]. Action = [[-0.67531496 -0.04384667  0.6086856   0.9059601 ]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Above hoop
Current timestep = 3764. State = [[0.01042028 0.03484911 0.41043842 1.        ]]. Action = [[-0.52428544  0.52685773  0.5534406   0.7818754 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Above hoop
Current timestep = 3765. State = [[0.01042028 0.03484911 0.41043842 1.        ]]. Action = [[-0.1482687  -0.25167334  0.5703474   0.77523446]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Above hoop
Current timestep = 3766. State = [[0.01042028 0.03484911 0.41043842 1.        ]]. Action = [[-0.3924389  -0.34022814  0.8012657   0.94855666]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Above hoop
Current timestep = 3767. State = [[0.0121295  0.03216293 0.40532973 1.        ]]. Action = [[ 0.5215547  -0.08943731 -0.25647116  0.690465  ]]. Reward = [0.]
Curr episode timestep = 84
Above hoop
Current timestep = 3768. State = [[0.01729512 0.03095026 0.3987233  1.        ]]. Action = [[-0.48534262  0.35814905  0.4514451   0.87428033]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Above hoop
Current timestep = 3769. State = [[0.01755244 0.03059358 0.39873174 1.        ]]. Action = [[-0.21920502  0.02354634  0.8670491   0.8043401 ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Above hoop
Current timestep = 3770. State = [[0.01816951 0.03917271 0.40181744 1.        ]]. Action = [[-0.07373005  0.6716535   0.17804635  0.9119165 ]]. Reward = [0.]
Curr episode timestep = 87
Above hoop
Current timestep = 3771. State = [[0.01801281 0.04651224 0.40370223 1.        ]]. Action = [[0.08182132 0.14518404 0.6473162  0.8437309 ]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Above hoop
Current timestep = 3772. State = [[0.01783113 0.04728859 0.40365657 1.        ]]. Action = [[-0.3492334   0.2475586   0.5141063   0.85921705]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Above hoop
Current timestep = 3773. State = [[0.01783113 0.04728859 0.40365657 1.        ]]. Action = [[-0.5573226   0.26337707  0.59251535  0.8468596 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Above hoop
Current timestep = 3774. State = [[0.01783113 0.04728859 0.40365657 1.        ]]. Action = [[-0.03926229  0.44873202  0.2794646   0.74774015]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Above hoop
Current timestep = 3775. State = [[0.01783381 0.04734397 0.40363392 1.        ]]. Action = [[-0.6209475   0.10107374  0.31824398  0.8255975 ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Above hoop
Current timestep = 3776. State = [[0.01783381 0.04734397 0.40363392 1.        ]]. Action = [[-0.2500831   0.24768114  0.25428545  0.7455094 ]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Above hoop
Current timestep = 3777. State = [[0.01783381 0.04734397 0.40363392 1.        ]]. Action = [[-0.41769445  0.44808483  0.7456099   0.8984028 ]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Above hoop
Current timestep = 3778. State = [[0.01783918 0.04745552 0.40358832 1.        ]]. Action = [[0.14664006 0.2384386  0.56431925 0.9132079 ]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Above hoop
Current timestep = 3779. State = [[0.01783918 0.04745552 0.40358832 1.        ]]. Action = [[0.37830758 0.2962234  0.5126345  0.8665378 ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Above hoop
Current timestep = 3780. State = [[0.01777983 0.04703191 0.4039961  1.        ]]. Action = [[-0.18483812 -0.17196822  0.14114952  0.7654457 ]]. Reward = [0.]
Curr episode timestep = 97
Above hoop
Current timestep = 3781. State = [[0.01778198 0.04664528 0.40429562 1.        ]]. Action = [[-0.00991219  0.02051175  0.58778906  0.8376517 ]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Above hoop
Current timestep = 3782. State = [[0.01777644 0.04653418 0.4043412  1.        ]]. Action = [[-0.34961355  0.3398056   0.53009987  0.8227639 ]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Above hoop
Current timestep = 3783. State = [[0.01777644 0.04653418 0.4043412  1.        ]]. Action = [[-0.34451532  0.56867266  0.502172    0.82279515]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Above hoop
Current timestep = 3784. State = [[-0.26578522  0.01381436  0.11001427  1.        ]]. Action = [[-0.24686491 -0.10239309  0.45027554  0.7601743 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Above hoop
Current timestep = 3785. State = [[-0.25390992  0.01083585  0.1046803   1.        ]]. Action = [[ 0.9326031  -0.39034212  0.9588244   0.9981396 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 3786. State = [[-0.22559893  0.00874218  0.12727386  1.        ]]. Action = [[0.88317454 0.15286565 0.9957278  0.97940314]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 3787. State = [[-0.19250529  0.00928812  0.16444446  1.        ]]. Action = [[ 0.8464122  -0.05601519  0.96478784  0.99068606]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 3788. State = [[-0.16857433  0.00949729  0.18950307  1.        ]]. Action = [[ 0.44864225 -0.22388148  0.93576944  0.9030353 ]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: No entry zone
Current timestep = 3789. State = [[-0.16289784  0.00928576  0.19338582  1.        ]]. Action = [[ 0.96694636 -0.2708435   0.9826145   0.9924165 ]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 3790. State = [[-0.16179954  0.009304    0.19415931  1.        ]]. Action = [[0.42210567 0.08926678 0.9245064  0.97501636]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 3791. State = [[-0.14996064  0.00953507  0.20710161  1.        ]]. Action = [[0.82467794 0.02725422 0.95713854 0.8833033 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 3792. State = [[-0.11803923  0.00732176  0.24107602  1.        ]]. Action = [[ 0.94217277 -0.2232086   0.85749745  0.99060583]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 3793. State = [[-0.08477892 -0.00122422  0.27920753  1.        ]]. Action = [[ 0.8025334  -0.35652018  0.94465184  0.83045506]]. Reward = [0.]
Curr episode timestep = 8
Above hoop
Current timestep = 3794. State = [[-0.05407985 -0.00685734  0.3189727   1.        ]]. Action = [[ 0.9270427  -0.02194417  0.79146075  0.9049065 ]]. Reward = [0.]
Curr episode timestep = 9
Above hoop
Current timestep = 3795. State = [[-0.02361379 -0.01096467  0.35470307  1.        ]]. Action = [[ 0.9163053 -0.1282593  0.8848846  0.9738047]]. Reward = [0.]
Curr episode timestep = 10
Above hoop
Current timestep = 3796. State = [[ 0.00793438 -0.01870091  0.39002407  1.        ]]. Action = [[ 0.69814086 -0.28683484  0.945765    0.8488865 ]]. Reward = [0.]
Curr episode timestep = 11
Above hoop
Current timestep = 3797. State = [[ 0.02742332 -0.01603356  0.41826528  1.        ]]. Action = [[-0.04180384  0.4822352   0.27821326  0.93821585]]. Reward = [0.]
Curr episode timestep = 12
Above hoop
Current timestep = 3798. State = [[ 0.03131585 -0.00124879  0.42068297  1.        ]]. Action = [[-0.17971969  0.6654854  -0.62093425  0.79024434]]. Reward = [0.]
Curr episode timestep = 13
Above hoop
Current timestep = 3799. State = [[0.0295438  0.01162255 0.41295856 1.        ]]. Action = [[ 0.17041957  0.38704884 -0.0635832   0.79693794]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Above hoop
Current timestep = 3800. State = [[0.02789773 0.02192456 0.4106477  1.        ]]. Action = [[-0.53524876  0.47387195 -0.15048063  0.8481369 ]]. Reward = [0.]
Curr episode timestep = 15
Above hoop
Current timestep = 3801. State = [[0.0236858  0.03343883 0.41085237 1.        ]]. Action = [[0.06752491 0.5121038  0.28000104 0.60854673]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Above hoop
Current timestep = 3802. State = [[0.02105034 0.0444275  0.410481   1.        ]]. Action = [[-0.03482449  0.5622573  -0.00316912  0.8466766 ]]. Reward = [0.]
Curr episode timestep = 17
Above hoop
Current timestep = 3803. State = [[0.01799951 0.05464177 0.41032356 1.        ]]. Action = [[-0.27305257  0.23751247  0.1348747   0.89789474]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Above hoop
Current timestep = 3804. State = [[0.01615925 0.06118396 0.40723974 1.        ]]. Action = [[-0.18524945  0.25314832 -0.4035673   0.7284968 ]]. Reward = [0.]
Curr episode timestep = 19
Above hoop
Current timestep = 3805. State = [[0.01555506 0.06603765 0.39809585 1.        ]]. Action = [[-0.39194274 -0.24512255  0.42536747  0.7892356 ]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Above hoop
Current timestep = 3806. State = [[0.01547462 0.06675327 0.39710504 1.        ]]. Action = [[-0.02246541  0.3581711   0.6625707   0.8173169 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Above hoop
Current timestep = 3807. State = [[0.01229975 0.07305303 0.39767405 1.        ]]. Action = [[-0.7210577   0.24019325  0.07910526  0.7197828 ]]. Reward = [0.]
Curr episode timestep = 22
Above hoop
Current timestep = 3808. State = [[0.00358488 0.08119369 0.4000424  1.        ]]. Action = [[-0.16371787  0.12594426  0.43867183  0.92749274]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Scene graph at timestep 3808 is [False, True, False, False, False, True, True, False, False, True]
State prediction error at timestep 3808 is tensor(0.0002, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3808 of -1
Current timestep = 3809. State = [[4.3902773e-04 8.2852691e-02 4.0112332e-01 1.0000000e+00]]. Action = [[0.10421789 0.3198638  0.5773611  0.7614944 ]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 3810. State = [[4.3902773e-04 8.2852691e-02 4.0112332e-01 1.0000000e+00]]. Action = [[-0.46427554  0.28278327  0.5242064   0.9129033 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 3811. State = [[-0.00299885  0.08452637  0.39924806  1.        ]]. Action = [[-0.5508436   0.01922619 -0.14054841  0.769627  ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 3812. State = [[-0.0116651   0.09025154  0.40035638  1.        ]]. Action = [[0.1585586  0.25918937 0.2902422  0.6729462 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 3813. State = [[-0.01507242  0.09356696  0.40436304  1.        ]]. Action = [[-0.23190361 -0.03046227  0.3300779   0.9384186 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 3814. State = [[-0.01524146  0.09393073  0.40451616  1.        ]]. Action = [[-0.04767096 -0.00592983  0.394673    0.87733126]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 3815. State = [[-0.01528863  0.09385265  0.4045228   1.        ]]. Action = [[-0.4953766  -0.11892354  0.62425315  0.976859  ]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 3816. State = [[-0.01528863  0.09385265  0.4045228   1.        ]]. Action = [[-0.37911165 -0.04953343  0.6285424   0.9523866 ]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 3817. State = [[-0.01528863  0.09385265  0.4045228   1.        ]]. Action = [[ 0.3687669  -0.21170795  0.47981918  0.913689  ]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 3818. State = [[-0.01528863  0.09385265  0.4045228   1.        ]]. Action = [[-0.01373625  0.0675205   0.68445563  0.94544065]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 3819. State = [[-0.01865497  0.09822614  0.40712458  1.        ]]. Action = [[-0.4015721   0.18903804  0.154881    0.95549273]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 3820. State = [[-0.02579476  0.10269734  0.41284776  1.        ]]. Action = [[0.2385993 0.5373963 0.6381748 0.8967171]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 3821. State = [[-0.02780493  0.10363695  0.41430873  1.        ]]. Action = [[-0.54611427 -0.02384287  0.81608033  0.92568994]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 3822. State = [[-0.02788952  0.10371051  0.41422236  1.        ]]. Action = [[-0.08603942  0.12805474  0.40608644  0.88186264]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 3823. State = [[-0.02788952  0.10371051  0.41422236  1.        ]]. Action = [[-0.325943    0.29372072  0.75183046  0.9735886 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 3824. State = [[-0.0279291   0.10369594  0.41423303  1.        ]]. Action = [[-0.00535011 -0.0536384   0.6059344   0.9648204 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 3825. State = [[-0.0279291   0.10369594  0.41423303  1.        ]]. Action = [[-0.23130971  0.3511343   0.21121609  0.8266909 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 3826. State = [[-0.0279372   0.10369363  0.4142984   1.        ]]. Action = [[-0.0912087   0.17012799  0.72402716  0.8599689 ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 3827. State = [[-0.0279372   0.10369363  0.4142984   1.        ]]. Action = [[0.0470922  0.05172372 0.39963186 0.8987061 ]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 3828. State = [[-0.0279372   0.10369363  0.4142984   1.        ]]. Action = [[-0.52079225 -0.27786875  0.58740115  0.95332694]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 3829. State = [[-0.0279372   0.10369363  0.4142984   1.        ]]. Action = [[ 0.10863245 -0.51990175  0.5887008   0.870353  ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 3830. State = [[-0.02796881  0.10368131  0.41424274  1.        ]]. Action = [[-0.15339029  0.28899503  0.59810233  0.8590808 ]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 3831. State = [[-0.02803207  0.10365668  0.41413146  1.        ]]. Action = [[ 0.2135024  -0.42630923  0.5509658   0.9328034 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 3832. State = [[-0.0283534   0.10214594  0.4122508   1.        ]]. Action = [[ 0.19900239 -0.1391877  -0.2612905   0.8882389 ]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 3833. State = [[-0.02888543  0.10087518  0.41038442  1.        ]]. Action = [[ 0.08467603 -0.64725685  0.82947016  0.88458395]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 3834. State = [[-0.02941236  0.09482166  0.4089741   1.        ]]. Action = [[-0.04956484 -0.30241442 -0.04188788  0.9409543 ]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 3835. State = [[-0.03122997  0.08909228  0.4068757   1.        ]]. Action = [[-0.508382   -0.14199334  0.9151201   0.9597781 ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 3836. State = [[-0.03114636  0.08822489  0.40682045  1.        ]]. Action = [[-0.28620505  0.17442131  0.25632036  0.95745695]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 3837. State = [[-0.03129486  0.09026255  0.40769985  1.        ]]. Action = [[0.0411818  0.1879003  0.17260349 0.81864953]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 3838. State = [[-0.0311619   0.09151178  0.4085434   1.        ]]. Action = [[ 0.00607133 -0.13681293  0.20573306  0.8440956 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 3839. State = [[-0.0311619   0.09151178  0.4085434   1.        ]]. Action = [[-0.18148994  0.17328286  0.35002756  0.8299515 ]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 3840. State = [[-0.0311619   0.09151178  0.4085434   1.        ]]. Action = [[ 0.00190127 -0.05750549  0.54528344  0.9628532 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 3841. State = [[-0.0311619   0.09151178  0.4085434   1.        ]]. Action = [[ 0.17114544 -0.02090466  0.7697201   0.9321902 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 3842. State = [[-0.0311619   0.09151178  0.4085434   1.        ]]. Action = [[ 0.46726942 -0.04540485  0.34874117  0.8748529 ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 3843. State = [[-0.03043484  0.0912251   0.4093583   1.        ]]. Action = [[ 0.38405418 -0.03590822  0.11102152  0.74893785]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 3844. State = [[-0.03022432  0.09110682  0.40955815  1.        ]]. Action = [[ 0.33384967 -0.01988518  0.43751764  0.9225205 ]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 3845. State = [[-0.03022432  0.09110682  0.40955815  1.        ]]. Action = [[-0.08564973 -0.35460854  0.7248728   0.9098921 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 3846. State = [[-0.03022432  0.09110682  0.40955815  1.        ]]. Action = [[ 0.5704889  -0.16539323  0.73003674  0.93311524]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 3847. State = [[-0.03022432  0.09110682  0.40955815  1.        ]]. Action = [[ 0.22027707 -0.02814531  0.8701849   0.9653312 ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 3848. State = [[-0.03022432  0.09110682  0.40955815  1.        ]]. Action = [[ 0.30058336 -0.5920988   0.35806513  0.91261256]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 3849. State = [[-0.03022432  0.09110682  0.40955815  1.        ]]. Action = [[ 0.24077857 -0.26667815  0.4516362   0.9499798 ]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 3850. State = [[-0.0298622   0.09540426  0.4107418   1.        ]]. Action = [[0.17359686 0.42300868 0.1178472  0.98236656]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 3851. State = [[-0.02989566  0.09866339  0.4100665   1.        ]]. Action = [[0.43583775 0.13557363 0.40333128 0.9701363 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 3852. State = [[-0.02977133  0.09937312  0.4097757   1.        ]]. Action = [[ 0.39102936 -0.36897665  0.5606468   0.9512124 ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 3853. State = [[-0.02926293  0.09967916  0.40983456  1.        ]]. Action = [[0.20400357 0.34529793 0.42331958 0.9496207 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 3854. State = [[-0.02855761  0.10019489  0.41008157  1.        ]]. Action = [[ 0.1064024  -0.01538134  0.85400736  0.85714865]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 3855. State = [[-0.0284552   0.10029711  0.4095476   1.        ]]. Action = [[0.0621177  0.003057   0.72827494 0.80088925]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 3856. State = [[-0.02841544  0.10031204  0.4095369   1.        ]]. Action = [[ 0.05574012 -0.14307618  0.63574064  0.8692305 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 3857. State = [[-0.02840019  0.10031641  0.40940648  1.        ]]. Action = [[0.04304326 0.19834077 0.71957016 0.8841977 ]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 3858. State = [[-0.02256003  0.09762691  0.41049644  1.        ]]. Action = [[ 0.55146265 -0.20683503  0.10046756  0.95391667]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 3859. State = [[-0.01378179  0.09782548  0.41135576  1.        ]]. Action = [[0.21475768 0.11845338 0.48024404 0.91945887]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 3860. State = [[-0.01280245  0.09781845  0.4117171   1.        ]]. Action = [[-0.12053657  0.33022177  0.1922307   0.94137335]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 3861. State = [[-0.01280314  0.09764729  0.41158178  1.        ]]. Action = [[ 0.2835039  -0.02497959  0.18767917  0.9773421 ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 3862. State = [[-0.01280314  0.09764729  0.41158178  1.        ]]. Action = [[-0.15049374  0.23334825  0.34025645  0.9451771 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 3863. State = [[-0.01274877  0.09766666  0.41143706  1.        ]]. Action = [[-0.02978176  0.45815492  0.19900632  0.880476  ]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 3864. State = [[-0.01239428  0.0975229   0.4092972   1.        ]]. Action = [[ 0.08613026  0.0013876  -0.19460106  0.8923347 ]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 3865. State = [[-0.01170113  0.09550596  0.40752983  1.        ]]. Action = [[-0.12542683 -0.15136278  0.05256665  0.90243363]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 3866. State = [[-0.01005706  0.09140555  0.40455818  1.        ]]. Action = [[ 0.04333782 -0.13818276 -0.44828618  0.9071481 ]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 3867. State = [[-0.00800333  0.08947861  0.3950607   1.        ]]. Action = [[-0.2883085   0.04994678 -0.05383217  0.89444065]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 3868. State = [[-0.01074396  0.0957491   0.39588693  1.        ]]. Action = [[-0.38150644  0.37819457  0.21998894  0.8188114 ]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 3869. State = [[-0.0139028   0.10026094  0.39734843  1.        ]]. Action = [[-0.0189414  -0.06249601 -0.10567564  0.9636854 ]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 3870. State = [[-0.01632216  0.10705101  0.39673063  1.        ]]. Action = [[ 0.11503291  0.445328   -0.02917176  0.9135995 ]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 3871. State = [[-0.0213607   0.11799229  0.39542642  1.        ]]. Action = [[-0.44680214  0.14485466 -0.28072673  0.9581671 ]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 3872. State = [[-0.02872574  0.12496927  0.38702792  1.        ]]. Action = [[-0.35157728  0.026636   -0.3292446   0.93888235]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 3873. State = [[-0.03280313  0.13014291  0.38318574  1.        ]]. Action = [[0.19230092 0.23388445 0.4360355  0.9589021 ]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 3874. State = [[-0.03114     0.12667252  0.38396803  1.        ]]. Action = [[ 0.43278146 -0.41672754 -0.1163156   0.9647981 ]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 3875. State = [[-0.02978166  0.11750367  0.38571346  1.        ]]. Action = [[-0.40691048 -0.27567798  0.03743947  0.9272969 ]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 3876. State = [[-0.03360346  0.11666961  0.39351642  1.        ]]. Action = [[-0.5885372   0.25803626  0.46043754  0.9238751 ]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 3877. State = [[-0.04427395  0.12017945  0.40286154  1.        ]]. Action = [[-0.4698019   0.52535796  0.46364152  0.9015186 ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 3878. State = [[-0.04531705  0.12082346  0.4044566   1.        ]]. Action = [[ 0.47203398 -0.16200197  0.25688136  0.8956357 ]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 3879. State = [[-0.04560667  0.12080202  0.40461224  1.        ]]. Action = [[0.10746372 0.12178409 0.87015057 0.96563554]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 3880. State = [[-0.04576068  0.12065654  0.40478668  1.        ]]. Action = [[-0.52690935 -0.3572765   0.6300708   0.96254253]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 3881. State = [[-0.04576068  0.12065654  0.40478668  1.        ]]. Action = [[ 0.12443781 -0.44164205  0.5296407   0.855958  ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 3882. State = [[-0.04575621  0.12059475  0.40480417  1.        ]]. Action = [[ 0.13259733 -0.5472906   0.80058205  0.94029725]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 3883. State = [[-0.04572952  0.12022442  0.40490913  1.        ]]. Action = [[ 0.04075563 -0.40381324  0.6669489   0.8974682 ]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 3884. State = [[-0.04586316  0.12031285  0.40514824  1.        ]]. Action = [[-0.14432335 -0.02267164  0.46366668  0.89425874]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 3885. State = [[-0.04585874  0.12025107  0.4051658   1.        ]]. Action = [[0.084409   0.6399286  0.63152623 0.91917837]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 3886. State = [[-0.26715854  0.12968543  0.11544991  1.        ]]. Action = [[ 0.13095951 -0.25924098  0.5416125   0.9487809 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 3887. State = [[-0.25036788  0.13387676  0.11047222  1.        ]]. Action = [[ 0.90502346 -0.6799657   0.9944041   0.9955965 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 3888. State = [[-0.21995091  0.11400906  0.13498433  1.        ]]. Action = [[ 0.9126308  -0.58734274  0.8860589   0.99755955]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 3889. State = [[-0.18494226  0.09294431  0.16946502  1.        ]]. Action = [[ 0.79462504 -0.596209    0.99291253  0.99466395]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 3890. State = [[-0.16404125  0.08173984  0.19404778  1.        ]]. Action = [[ 0.9469032  -0.17252219  0.47012472  0.98380995]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: No entry zone
Current timestep = 3891. State = [[-0.15993142  0.08073969  0.19822222  1.        ]]. Action = [[ 0.99337244 -0.37854588  0.90599203  0.98853564]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 3892. State = [[-0.14539711  0.07257175  0.21353298  1.        ]]. Action = [[ 0.8821318  -0.39355636  0.9413291   0.9345453 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 3893. State = [[-0.11400423  0.05799838  0.24916178  1.        ]]. Action = [[ 0.8691187  -0.4644869   0.96019316  0.97591376]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 3893 is [True, False, False, False, True, False, True, False, False, True]
State prediction error at timestep 3893 is tensor(0.0008, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3893 of 1
Current timestep = 3894. State = [[-0.08030731  0.03663704  0.29327875  1.        ]]. Action = [[ 0.93027556 -0.58021694  0.9135103   0.9238366 ]]. Reward = [0.]
Curr episode timestep = 7
Above hoop
Current timestep = 3895. State = [[-0.05032604  0.0252513   0.32983056  1.        ]]. Action = [[ 0.9278953  -0.09494454  0.89675546  0.9189837 ]]. Reward = [0.]
Curr episode timestep = 8
Above hoop
Current timestep = 3896. State = [[-0.02017681  0.02194489  0.36529636  1.        ]]. Action = [[ 0.5849037  -0.00691223  0.9124181   0.97454524]]. Reward = [0.]
Curr episode timestep = 9
Above hoop
Current timestep = 3897. State = [[0.00361356 0.03136523 0.39048153 1.        ]]. Action = [[0.71765935 0.7571769  0.30796456 0.8287842 ]]. Reward = [0.]
Curr episode timestep = 10
Above hoop
Current timestep = 3898. State = [[0.02176547 0.05258896 0.39853784 1.        ]]. Action = [[-0.3656832   0.57283926 -0.15650952  0.67332196]]. Reward = [0.]
Curr episode timestep = 11
Above hoop
Current timestep = 3899. State = [[0.01923586 0.07495663 0.39356336 1.        ]]. Action = [[-0.5454857   0.4583534  -0.51439494  0.75989175]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 3900. State = [[0.01105517 0.09834758 0.39052975 1.        ]]. Action = [[-0.3139875   0.67414033  0.11954272  0.75615954]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 3901. State = [[8.9490501e-04 1.2055962e-01 3.9095828e-01 1.0000000e+00]]. Action = [[-0.4384358   0.32552052 -0.05100846  0.7382307 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 3902. State = [[-0.00941868  0.13925758  0.39295596  1.        ]]. Action = [[-0.08271885  0.5407039   0.20660114  0.76544595]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 3903. State = [[-0.01388486  0.14884375  0.39331383  1.        ]]. Action = [[0.07963002 0.45902383 0.72922564 0.88529587]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 3904. State = [[-0.01820977  0.1565281   0.39565307  1.        ]]. Action = [[-0.32263887  0.32465887  0.2046969   0.95407903]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 3905. State = [[-0.02453277  0.16358685  0.39895052  1.        ]]. Action = [[-0.33847678  0.20398867  0.4922576   0.93536747]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 3906. State = [[-0.0264381   0.16687608  0.39698347  1.        ]]. Action = [[ 0.06057894  0.1649108  -0.33236194  0.80308807]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 3907. State = [[-0.03159313  0.17710188  0.3978142   1.        ]]. Action = [[-0.39959216  0.4507351   0.29368293  0.9295368 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 3908. State = [[-0.03770933  0.18812224  0.39995977  1.        ]]. Action = [[-0.25869358 -0.13406247  0.49118757  0.87731373]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 3909. State = [[-0.03898014  0.18382017  0.4026157   1.        ]]. Action = [[-0.33799863 -0.40552008  0.01605332  0.95840037]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 3910. State = [[-0.04735938  0.18593492  0.40978634  1.        ]]. Action = [[-0.44002128  0.3246696   0.1947949   0.9608004 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 3911. State = [[-0.05882727  0.19174993  0.4157818   1.        ]]. Action = [[-0.27304554 -0.1886279   0.14761722  0.9409574 ]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 3912. State = [[-0.06349225  0.19057831  0.41628635  1.        ]]. Action = [[-0.25786656  0.27653003  0.3539921   0.95118725]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 3913. State = [[-0.06358178  0.19065015  0.4163071   1.        ]]. Action = [[-0.25443673 -0.00936031  0.6536269   0.7055073 ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 3914. State = [[-0.06358178  0.19065015  0.4163071   1.        ]]. Action = [[-0.2791924   0.29595435  0.07118344  0.9648309 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 3915. State = [[-0.06358178  0.19065015  0.4163071   1.        ]]. Action = [[ 0.21512604 -0.14394343  0.50329864  0.90838957]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 3916. State = [[-0.06358178  0.19065015  0.4163071   1.        ]]. Action = [[-0.09023881  0.19713557  0.34141016  0.81935966]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 3917. State = [[-0.06358178  0.19065015  0.4163071   1.        ]]. Action = [[-0.40876716 -0.20243019  0.7044866   0.94264984]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 3918. State = [[-0.06358178  0.19065015  0.4163071   1.        ]]. Action = [[-0.18014824  0.18888474  0.32385528  0.90721154]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 3919. State = [[-0.06358178  0.19065015  0.4163071   1.        ]]. Action = [[0.09180999 0.21826291 0.2050016  0.95692503]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 3920. State = [[-0.06499515  0.19365302  0.41581354  1.        ]]. Action = [[ 0.12782764  0.31405902 -0.03810167  0.9348762 ]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 3921. State = [[-0.06639232  0.1964041   0.41544995  1.        ]]. Action = [[0.03167355 0.38221955 0.3343959  0.82748234]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 3922. State = [[-0.07173265  0.20676334  0.41475737  1.        ]]. Action = [[-0.4531021   0.5077243  -0.0026536   0.93368006]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 3923. State = [[-0.07965648  0.2192272   0.4153202   1.        ]]. Action = [[0.19421339 0.04410005 0.14991951 0.914621  ]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 3924. State = [[-0.08030857  0.22034079  0.41534573  1.        ]]. Action = [[-0.3022052  -0.2324655   0.50258684  0.96057034]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 3925. State = [[-0.08030857  0.22034079  0.41534573  1.        ]]. Action = [[-0.04498023  0.3381089   0.37326884  0.8831489 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 3926. State = [[-0.08034745  0.22040495  0.41534576  1.        ]]. Action = [[-0.3601699   0.49071503  0.3308077   0.93929887]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 3927. State = [[-0.0804634   0.22059622  0.41534582  1.        ]]. Action = [[ 0.03253531 -0.10274571  0.24672496  0.9309311 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 3928. State = [[-0.0804634   0.22059622  0.41534582  1.        ]]. Action = [[-0.14455062  0.583529    0.54356694  0.935076  ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 3929. State = [[-0.0804634   0.22059622  0.41534582  1.        ]]. Action = [[0.46630192 0.4625827  0.72299886 0.9810531 ]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 3930. State = [[-0.0804634   0.22059622  0.41534582  1.        ]]. Action = [[-0.16023082  0.53445196  0.53716373  0.92967534]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 3931. State = [[-0.0804634   0.22059622  0.41534582  1.        ]]. Action = [[0.24113107 0.42321098 0.06332171 0.9353857 ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 3932. State = [[-0.08448833  0.23005275  0.41296443  1.        ]]. Action = [[0.06333053 0.6852453  0.00127888 0.90504706]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 3933. State = [[-0.08869299  0.23974106  0.4123593   1.        ]]. Action = [[-0.13139772  0.12972903  0.2538178   0.9347471 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 3934. State = [[-0.08922774  0.24081738  0.41215247  1.        ]]. Action = [[-0.04638463  0.470953    0.55081844  0.9509455 ]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 3935. State = [[-0.08922774  0.24081738  0.41215247  1.        ]]. Action = [[-0.09349751  0.20672071  0.5564778   0.7243676 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 3936. State = [[-0.08922774  0.24081738  0.41215247  1.        ]]. Action = [[-0.4095255  0.0529685  0.7325562  0.9699055]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 3937. State = [[-0.09342671  0.2497625   0.40752348  1.        ]]. Action = [[-0.05633426  0.6028371  -0.28718174  0.95068765]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 3938. State = [[-0.09694353  0.25969335  0.40072703  1.        ]]. Action = [[0.16204333 0.58065724 0.37679827 0.95718837]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Scene graph at timestep 3938 is [True, False, False, False, False, True, True, False, False, True]
State prediction error at timestep 3938 is tensor(6.9175e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3938 of -1
Current timestep = 3939. State = [[-0.09729231  0.26099908  0.39953738  1.        ]]. Action = [[-0.22716081  0.27874148  0.44168115  0.9825491 ]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Scene graph at timestep 3939 is [True, False, False, False, False, True, True, False, False, True]
State prediction error at timestep 3939 is tensor(0.0001, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3939 of -1
Current timestep = 3940. State = [[-0.09729231  0.26099908  0.39953738  1.        ]]. Action = [[0.14073372 0.2358352  0.814873   0.9046409 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Scene graph at timestep 3940 is [True, False, False, False, False, True, True, False, False, True]
State prediction error at timestep 3940 is tensor(0.0002, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3940 of -1
Current timestep = 3941. State = [[-0.09729231  0.26099908  0.39953738  1.        ]]. Action = [[ 0.02858651 -0.18594104  0.79643726  0.85889006]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Scene graph at timestep 3941 is [True, False, False, False, False, True, True, False, False, True]
State prediction error at timestep 3941 is tensor(0.0001, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3941 of -1
Current timestep = 3942. State = [[-0.09729231  0.26099908  0.39953738  1.        ]]. Action = [[0.20794773 0.10165215 0.38584137 0.9244604 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Scene graph at timestep 3942 is [True, False, False, False, False, True, True, False, False, True]
State prediction error at timestep 3942 is tensor(3.8931e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3942 of -1
Current timestep = 3943. State = [[-0.10101525  0.26797426  0.3960475   1.        ]]. Action = [[-0.32763237  0.37080574 -0.3489157   0.9492924 ]]. Reward = [0.]
Curr episode timestep = 56
Scene graph at timestep 3943 is [True, False, False, False, False, True, True, False, False, True]
State prediction error at timestep 3943 is tensor(0.0002, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 3943 of -1
Current timestep = 3944. State = [[-0.10366884  0.2697685   0.39438158  1.        ]]. Action = [[-0.10921282 -0.71806955  0.52270806  0.97347784]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 3945. State = [[-0.10409837  0.2667093   0.40436208  1.        ]]. Action = [[-0.12315005  0.35249782  0.20049572  0.87402296]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 3946. State = [[-0.10577662  0.26974103  0.40783113  1.        ]]. Action = [[0.16972649 0.41084003 0.82699823 0.97367597]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 3947. State = [[-0.10587668  0.26985413  0.4079652   1.        ]]. Action = [[0.2755592  0.51690316 0.24278629 0.8868439 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 3948. State = [[-0.10587668  0.26985413  0.4079652   1.        ]]. Action = [[-0.10871476  0.03946269  0.28916872  0.9579296 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 3949. State = [[-0.10587668  0.26985413  0.4079652   1.        ]]. Action = [[-0.21237022  0.78242636 -0.07034111  0.9546441 ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 3950. State = [[-0.10587668  0.26985413  0.4079652   1.        ]]. Action = [[-0.05275929  0.37917233  0.39661837  0.9542606 ]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 3951. State = [[-0.10587668  0.26985413  0.4079652   1.        ]]. Action = [[-0.29960293 -0.11059225  0.4673381   0.9659505 ]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 3952. State = [[-0.10587668  0.26985413  0.4079652   1.        ]]. Action = [[-0.51259613  0.52782035  0.36955     0.87652135]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 3953. State = [[-0.10587668  0.26985413  0.4079652   1.        ]]. Action = [[-0.2163657   0.5432248   0.42873573  0.9376707 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 3954. State = [[-0.10736649  0.26352322  0.4026477   1.        ]]. Action = [[-0.15196544 -0.5355086  -0.65680486  0.982061  ]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 3955. State = [[-0.1108738   0.25572762  0.3950521   1.        ]]. Action = [[-0.30109644 -0.03635716 -0.22675061  0.9701648 ]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 3956. State = [[-0.1139609   0.25297546  0.38851205  1.        ]]. Action = [[ 0.31126893 -0.5079676   0.5446596   0.979362  ]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 3957. State = [[-0.11427133  0.2526823   0.38748303  1.        ]]. Action = [[ 0.23921418 -0.20985746  0.66070294  0.9350214 ]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 3958. State = [[-0.1142345  0.2528595  0.3874653  1.       ]]. Action = [[-0.38917422 -0.25612563  0.854156    0.976223  ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 3959. State = [[-0.1142609   0.25286472  0.3874896   1.        ]]. Action = [[0.20148015 0.6415715  0.92757165 0.9311204 ]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 3960. State = [[-0.11409424  0.25287032  0.38745975  1.        ]]. Action = [[0.18917775 0.76729584 0.56342554 0.9637859 ]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 3961. State = [[-0.11413411  0.25284904  0.3873692   1.        ]]. Action = [[0.02595019 0.7175268  0.89405787 0.8850852 ]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 3962. State = [[-0.11848011  0.259426    0.38768274  1.        ]]. Action = [[-0.0536539   0.47003686  0.19822884  0.98471355]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 3963. State = [[-0.12592629  0.2695922   0.39344767  1.        ]]. Action = [[-0.21322739  0.09067667  0.3687663   0.9008571 ]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 3964. State = [[-0.13089493  0.2725324   0.39953378  1.        ]]. Action = [[-0.23223221  0.49232936  0.6916206   0.94101954]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 3965. State = [[-0.1317646   0.27269965  0.40094528  1.        ]]. Action = [[-0.31493342  0.22536743  0.41420293  0.9152086 ]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 3966. State = [[-0.1317646   0.27269965  0.40094528  1.        ]]. Action = [[0.3769554  0.24575865 0.6615523  0.9891906 ]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 3967. State = [[-0.1317646   0.27269965  0.40094528  1.        ]]. Action = [[ 0.3768034  -0.20229656  0.89464784  0.693612  ]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 3968. State = [[-0.1317646   0.27269965  0.40094528  1.        ]]. Action = [[-0.25833052 -0.23016614  0.6473005   0.7576572 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 3969. State = [[-0.1317646   0.27269965  0.40094528  1.        ]]. Action = [[-0.11874694  0.71835375  0.73350537  0.9672954 ]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 3970. State = [[-0.1317646   0.27269965  0.40094528  1.        ]]. Action = [[0.18569505 0.523149   0.5876262  0.9543911 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 3971. State = [[-0.1317646   0.27269965  0.40094528  1.        ]]. Action = [[0.5111842  0.54673743 0.02963221 0.9742482 ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 3972. State = [[-0.1317646   0.27269965  0.40094528  1.        ]]. Action = [[0.06454349 0.29329038 0.46546924 0.9822861 ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 3973. State = [[-0.1317646   0.27269965  0.40094528  1.        ]]. Action = [[-0.14026207 -0.43471062  0.34158242  0.9570894 ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 3974. State = [[-0.1317646   0.27269965  0.40094528  1.        ]]. Action = [[-0.11489058  0.33082974  0.79709196  0.71969295]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 3975. State = [[-0.1317646   0.27269965  0.40094528  1.        ]]. Action = [[-0.13253117 -0.14941669  0.30357838  0.9779471 ]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 3976. State = [[-0.1317646   0.27269965  0.40094528  1.        ]]. Action = [[-0.30721492  0.30112875  0.60688686  0.9302248 ]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 3977. State = [[-0.1317646   0.27269965  0.40094528  1.        ]]. Action = [[ 0.08713782 -0.02333736  0.58816576  0.9562671 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 3978. State = [[-0.1317646   0.27269965  0.40094528  1.        ]]. Action = [[ 0.28422952 -0.47655785  0.424464    0.9579992 ]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 3979. State = [[-0.1317646   0.27269965  0.40094528  1.        ]]. Action = [[ 0.4996556  -0.22588485  0.72898245  0.99354434]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 3980. State = [[-0.1317646   0.27269965  0.40094528  1.        ]]. Action = [[ 0.3352883  -0.20199847  0.5062016   0.9190047 ]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 3981. State = [[-0.1317646   0.27269965  0.40094528  1.        ]]. Action = [[0.13552344 0.29783773 0.531337   0.93194175]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 3982. State = [[-0.13147688  0.2731819   0.4020119   1.        ]]. Action = [[0.15174842 0.09266937 0.2355566  0.9275491 ]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 3983. State = [[-0.13106027  0.27403468  0.40389287  1.        ]]. Action = [[0.516374   0.23012233 0.62735105 0.9952977 ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 3984. State = [[-0.13081022  0.27386317  0.40455085  1.        ]]. Action = [[0.12299156 0.18684435 0.71913147 0.98438203]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 3985. State = [[-0.13081022  0.27386317  0.40455085  1.        ]]. Action = [[ 0.05357111 -0.30754435  0.6496439   0.7458137 ]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 3986. State = [[-0.13081022  0.27386317  0.40455085  1.        ]]. Action = [[0.09671497 0.2739792  0.5870514  0.89579797]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 3987. State = [[-0.13081022  0.27386317  0.40455085  1.        ]]. Action = [[0.04441953 0.26081443 0.7368443  0.8490423 ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 3988. State = [[-0.2550185  -0.0083958   0.09947237  1.        ]]. Action = [[ 0.3243115   0.2264061  -0.12571073  0.9312314 ]]. Reward = [0.]
Curr episode timestep = 101
Current timestep = 3989. State = [[-0.24567403 -0.01426234  0.09310599  1.        ]]. Action = [[ 0.4673735  -0.19677532  0.8558589   0.9926989 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 3990. State = [[-0.22580905 -0.02815007  0.11443173  1.        ]]. Action = [[ 0.8380785  -0.47876793  0.9515414   0.97482336]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 3991. State = [[-0.1933315  -0.03855436  0.15004072  1.        ]]. Action = [[ 0.9765649  -0.11610919  0.98749924  0.9730556 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 3992. State = [[-0.1669405  -0.04216327  0.17458321  1.        ]]. Action = [[ 0.8749132  -0.27509344  0.91744256  0.9576491 ]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: No entry zone
Current timestep = 3993. State = [[-0.16234925 -0.0434558   0.17768195  1.        ]]. Action = [[ 0.9801067  -0.16336203  0.96267474  0.90974784]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 3994. State = [[-0.16065778 -0.04353935  0.17895408  1.        ]]. Action = [[0.9939195  0.15671206 0.862489   0.9580512 ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 3995. State = [[-0.16008043 -0.04376122  0.17938825  1.        ]]. Action = [[ 0.7603862  -0.18742788  0.9225857   0.9898641 ]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 3996. State = [[-0.16009967 -0.04442848  0.17955367  1.        ]]. Action = [[ 0.98879385 -0.3994583   0.93637097  0.9857818 ]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 3997. State = [[-0.16004136 -0.04450231  0.1795926   1.        ]]. Action = [[ 0.94102716 -0.24188817  0.73297286  0.9482689 ]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 3998. State = [[-0.16016988 -0.04462     0.17960161  1.        ]]. Action = [[0.9563091  0.23026085 0.8566972  0.9545057 ]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 3999. State = [[-0.16028927 -0.04467217  0.17960382  1.        ]]. Action = [[ 0.98089886 -0.07730204  0.96084416  0.9319824 ]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 4000. State = [[-0.16028927 -0.04467217  0.17960382  1.        ]]. Action = [[ 0.8915756 -0.4156456  0.616349   0.9826853]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: No entry zone
Current timestep = 4001. State = [[-0.16029862 -0.04473806  0.17961077  1.        ]]. Action = [[ 0.51931906 -0.5303328   0.77308655  0.9831296 ]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: No entry zone
Current timestep = 4002. State = [[-0.16038099 -0.04472777  0.17960727  1.        ]]. Action = [[0.8649833  0.14699018 0.93709135 0.9723226 ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: No entry zone
Current timestep = 4003. State = [[-0.16038099 -0.04472777  0.17960727  1.        ]]. Action = [[ 0.97005725 -0.24848121  0.8138007   0.9927782 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: No entry zone
Current timestep = 4004. State = [[-0.16039091 -0.04479765  0.17961466  1.        ]]. Action = [[0.4301058  0.22139406 0.9070598  0.9923538 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: No entry zone
Current timestep = 4005. State = [[-0.16040966 -0.0449294   0.17962861  1.        ]]. Action = [[ 0.96714914 -0.17559648  0.9359329   0.9860501 ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: No entry zone
Current timestep = 4006. State = [[-0.16040966 -0.0449294   0.17962861  1.        ]]. Action = [[ 0.8989353  -0.4394846   0.9671229   0.91981125]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: No entry zone
Current timestep = 4007. State = [[-0.16040966 -0.0449294   0.17962861  1.        ]]. Action = [[0.9607018  0.01594043 0.57762766 0.974692  ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: No entry zone
Current timestep = 4008. State = [[-0.16042836 -0.04506069  0.17964254  1.        ]]. Action = [[ 0.977479   -0.4603989   0.84613216  0.9325249 ]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: No entry zone
Current timestep = 4009. State = [[-0.16043776 -0.04512655  0.17964953  1.        ]]. Action = [[ 0.6893816  -0.26458168  0.95946527  0.93655133]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: No entry zone
Current timestep = 4010. State = [[-0.16043776 -0.04512655  0.17964953  1.        ]]. Action = [[ 0.9257597  -0.04032338  0.7776141   0.94751585]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: No entry zone
Current timestep = 4011. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.5874989  0.2862568  0.5127313  0.97674453]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: No entry zone
Current timestep = 4012. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.82905006 -0.2340616   0.77603674  0.9705851 ]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: No entry zone
Current timestep = 4013. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.98257077 -0.19966012  0.87978816  0.96871305]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: No entry zone
Current timestep = 4014. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.6953423  0.4947672  0.91287804 0.8838775 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: No entry zone
Current timestep = 4015. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.9948027  -0.34054005  0.28952622  0.924876  ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: No entry zone
Current timestep = 4016. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.97513413 0.3003403  0.91238785 0.9717753 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: No entry zone
Current timestep = 4017. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.9660826  -0.4664749   0.9507613   0.98850965]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: No entry zone
Current timestep = 4018. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.8957406  -0.41651464  0.95301104  0.9367522 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: No entry zone
Current timestep = 4019. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.9028982  -0.35575396  0.5298009   0.9063394 ]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: No entry zone
Current timestep = 4020. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.93553686 -0.5514305   0.74272966  0.93060064]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: No entry zone
Current timestep = 4021. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.8619497  -0.07403886  0.9903643   0.938823  ]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: No entry zone
Current timestep = 4022. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.8575876  0.11857319 0.9673687  0.9199717 ]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: No entry zone
Current timestep = 4023. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.66890883 -0.33509177  0.97917426  0.93399763]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: No entry zone
Current timestep = 4024. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.9425006  -0.00434196  0.8363755   0.9687152 ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: No entry zone
Current timestep = 4025. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.9788133  0.3086412  0.97064805 0.9918344 ]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: No entry zone
Current timestep = 4026. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.9654932  -0.245794    0.8451294   0.91678214]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: No entry zone
Current timestep = 4027. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.7751484  -0.107759    0.7506161   0.92339194]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: No entry zone
Current timestep = 4028. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.97287107 -0.04386932  0.954298    0.9838085 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: No entry zone
Current timestep = 4029. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.9832449  -0.02513003  0.783736    0.97733307]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: No entry zone
Current timestep = 4030. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.96480465 -0.02861232  0.77319014  0.8970256 ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: No entry zone
Current timestep = 4031. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.88891315 -0.02900147  0.68999934  0.94062924]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: No entry zone
Current timestep = 4032. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.96823204 -0.14862639  0.9493964   0.95916224]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: No entry zone
Current timestep = 4033. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.9713447  -0.0429731   0.64918375  0.8243644 ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: No entry zone
Current timestep = 4034. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.93996036 -0.28012252  0.8108213   0.97538424]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: No entry zone
Current timestep = 4035. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.9305148  -0.28665376  0.8465111   0.94658756]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: No entry zone
Current timestep = 4036. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.9939232  -0.06985611  0.74719     0.9891734 ]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: No entry zone
Current timestep = 4037. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.91483116 -0.25698125  0.8631089   0.9657626 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: No entry zone
Current timestep = 4038. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.8936975  -0.29384422  0.88162243  0.9638159 ]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: No entry zone
Current timestep = 4039. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.86161923 0.01323652 0.96243787 0.98631394]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: No entry zone
Current timestep = 4040. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.7179065  0.36604345 0.9728546  0.96911407]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: No entry zone
Current timestep = 4041. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.95407546 -0.27079844  0.96967435  0.8821739 ]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: No entry zone
Current timestep = 4042. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.95266116 0.2873348  0.96205306 0.9421073 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: No entry zone
Current timestep = 4043. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.9020997  0.21166635 0.951383   0.9793899 ]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: No entry zone
Current timestep = 4044. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.98611915 0.03580308 0.9083257  0.9716058 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: No entry zone
Current timestep = 4045. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.9613786  -0.13761973  0.8107095   0.9754362 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: No entry zone
Current timestep = 4046. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.8972721  0.44702983 0.98284173 0.9843223 ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: No entry zone
Current timestep = 4047. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.83139336 0.04389155 0.8432746  0.9441433 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: No entry zone
Current timestep = 4048. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.9657359  0.06584525 0.96295595 0.97375584]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: No entry zone
Current timestep = 4049. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.8565446  0.29889846 0.9620917  0.9558141 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: No entry zone
Current timestep = 4050. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.96427727 -0.438273    0.76019645  0.8425281 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: No entry zone
Current timestep = 4051. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.98674655 0.13592243 0.96996164 0.9805869 ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: No entry zone
Current timestep = 4052. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.93750083 0.12206125 0.9326496  0.95715797]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: No entry zone
Current timestep = 4053. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.9828969  -0.21801567  0.92228866  0.9279523 ]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: No entry zone
Current timestep = 4054. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.98467946 0.20887339 0.7444171  0.7902019 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: No entry zone
Current timestep = 4055. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.96451783 0.38884664 0.9624698  0.6699953 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: No entry zone
Current timestep = 4056. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.942219   -0.01530802  0.85621333  0.95824814]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: No entry zone
Current timestep = 4057. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.99549055 0.6479118  0.93577754 0.9120387 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: No entry zone
Current timestep = 4058. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.98112726 0.48530245 0.9051802  0.96333146]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: No entry zone
Current timestep = 4059. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.99102736 0.03889358 0.60415614 0.9292811 ]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: No entry zone
Current timestep = 4060. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.9053372  0.03881192 0.934314   0.8221841 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: No entry zone
Current timestep = 4061. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.934253   -0.4136265   0.8045056   0.91368794]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: No entry zone
Current timestep = 4062. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.93954813 -0.18058527  0.59347963  0.96095395]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: No entry zone
Current timestep = 4063. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.95611906 0.3246323  0.84518886 0.9727552 ]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: No entry zone
Current timestep = 4064. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.9722028  -0.41377336  0.84880877  0.8862473 ]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: No entry zone
Current timestep = 4065. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.8853667  0.46041083 0.90921926 0.97580194]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: No entry zone
Current timestep = 4066. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.93594    0.30184436 0.87345886 0.8272197 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: No entry zone
Current timestep = 4067. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.8991642  0.44829488 0.96525955 0.9450846 ]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: No entry zone
Current timestep = 4068. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.89251804 0.1338898  0.9901991  0.9877362 ]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: No entry zone
Current timestep = 4069. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.98443365 0.12987137 0.40426302 0.98632264]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: No entry zone
Current timestep = 4070. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.9979321  -0.19673204  0.8741994   0.987622  ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: No entry zone
Current timestep = 4071. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.95367765 -0.20685935  0.9544184   0.96610355]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: No entry zone
Current timestep = 4072. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.9939978  -0.12701595  0.931252    0.94035435]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: No entry zone
Current timestep = 4073. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.9685062  -0.44454944  0.8432038   0.9682815 ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: No entry zone
Current timestep = 4074. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.9179337 -0.1860727  0.8961818  0.9349402]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: No entry zone
Current timestep = 4075. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.9680115  0.29152727 0.7286377  0.9496083 ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: No entry zone
Current timestep = 4076. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.95506716 -0.3319745   0.8191798   0.96740127]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: No entry zone
Current timestep = 4077. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.4635291  0.22145498 0.9818075  0.9462187 ]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: No entry zone
Current timestep = 4078. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.26247334 0.66562724 0.881202   0.9285867 ]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: No entry zone
Current timestep = 4079. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.99029386 0.3825469  0.8487859  0.885998  ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: No entry zone
Current timestep = 4080. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.64228797 -0.11640775  0.93247175  0.55300283]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: No entry zone
Current timestep = 4081. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.92799747 0.2064327  0.62994695 0.8641231 ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: No entry zone
Current timestep = 4082. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.8881296  0.6426339  0.88907814 0.9527261 ]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: No entry zone
Current timestep = 4083. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.9467926  0.4523101  0.94342566 0.9207159 ]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: No entry zone
Current timestep = 4084. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.33035684 0.23819518 0.79375076 0.9141779 ]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: No entry zone
Current timestep = 4085. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[0.9652678  0.17516601 0.9170344  0.83214283]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: No entry zone
Current timestep = 4086. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.9410286  -0.2347058   0.98051345  0.91504526]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: No entry zone
Current timestep = 4087. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.74897003 -0.08344555  0.96349967  0.95099235]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: No entry zone
Current timestep = 4088. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.6869447 -0.567504   0.9519961  0.9882431]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: No entry zone
Current timestep = 4089. State = [[-0.16044717 -0.04519242  0.17965654  1.        ]]. Action = [[ 0.7121644  -0.10859305  0.8940129   0.9393306 ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: No entry zone
Current timestep = 4090. State = [[-0.2649231   0.13829392  0.12244865  1.        ]]. Action = [[0.9871918  0.45793104 0.67615104 0.9802667 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: No entry zone
Current timestep = 4091. State = [[-0.24747944  0.14206475  0.11554787  1.        ]]. Action = [[ 0.9495586  -0.85451955  0.9216962   0.98428464]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 4092. State = [[-0.2158709   0.11998323  0.139688    1.        ]]. Action = [[ 0.98004913 -0.5082849   0.9875932   0.9354124 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 4093. State = [[-0.18353504  0.10058485  0.17681643  1.        ]]. Action = [[ 0.44748688 -0.55164677  0.9878228   0.9546313 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 4094. State = [[-0.16884443  0.08930019  0.20100164  1.        ]]. Action = [[ 0.93139386 -0.2735253   0.94177926  0.9178481 ]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: No entry zone
Current timestep = 4095. State = [[-0.1515511   0.08492862  0.22079748  1.        ]]. Action = [[ 0.9066497  -0.19650859  0.9720286   0.8921335 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 4096. State = [[-0.11957315  0.07957698  0.2578495   1.        ]]. Action = [[ 0.9322989  -0.09405875  0.9341216   0.97981524]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 4097. State = [[-0.08685476  0.06672705  0.2958276   1.        ]]. Action = [[ 0.9459336 -0.6084406  0.7724972  0.9255111]]. Reward = [0.]
Curr episode timestep = 6
Above hoop
Scene graph at timestep 4097 is [False, True, False, False, True, False, True, False, False, True]
State prediction error at timestep 4097 is tensor(0.0008, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 4097 of 1
Current timestep = 4098. State = [[-0.0587658   0.0509841   0.33230445  1.        ]]. Action = [[-0.0190832  -0.1456722   0.80361784  0.862823  ]]. Reward = [0.]
Curr episode timestep = 7
Above hoop
Current timestep = 4099. State = [[-0.05042435  0.05415938  0.36043352  1.        ]]. Action = [[0.1417216  0.39330804 0.82222307 0.9054568 ]]. Reward = [0.]
Curr episode timestep = 8
Above hoop
Current timestep = 4100. State = [[-0.04432116  0.0726353   0.3849524   1.        ]]. Action = [[0.1455071 0.8500831 0.1922301 0.8962753]]. Reward = [0.]
Curr episode timestep = 9
Above hoop
Current timestep = 4101. State = [[-0.04377566  0.09442702  0.39334577  1.        ]]. Action = [[ 0.20539653  0.4316845  -0.02758121  0.55528116]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 4102. State = [[-0.04304311  0.11316804  0.39597413  1.        ]]. Action = [[-0.50711703  0.44055092  0.01676202  0.88004684]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 4103. State = [[-0.05058452  0.13117316  0.3908713   1.        ]]. Action = [[ 0.0414803   0.43966115 -0.5597603   0.6896763 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 4104. State = [[-0.05563283  0.14900766  0.37938258  1.        ]]. Action = [[-0.27597976  0.48691046 -0.13960642  0.82005763]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 4105. State = [[-0.06582792  0.17303205  0.37574592  1.        ]]. Action = [[-0.48459196  0.79813766 -0.03495616  0.7905022 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 4106. State = [[-0.0786097   0.19492036  0.3766192   1.        ]]. Action = [[-0.38027394  0.09780157  0.33101773  0.8523184 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 4107. State = [[-0.08915419  0.20789991  0.38406843  1.        ]]. Action = [[-0.28689957  0.3554895   0.3592503   0.63623476]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 4108. State = [[-0.10076458  0.2144198   0.40034583  1.        ]]. Action = [[-0.54656124 -0.15485823  0.60068893  0.86654794]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 4109. State = [[-0.11688517  0.22112562  0.41884375  1.        ]]. Action = [[-0.42852128  0.36489272 -0.03643554  0.63907194]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 4110. State = [[-0.12717395  0.23266889  0.4150978   1.        ]]. Action = [[ 0.3339975   0.4656043  -0.62608993  0.7334956 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 4111. State = [[-0.12778306  0.23725682  0.40505245  1.        ]]. Action = [[-0.72301555 -0.21610081  0.569651    0.8572688 ]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 4112. State = [[-0.12773587  0.23761046  0.40430284  1.        ]]. Action = [[ 0.18865967 -0.11549163  0.02437127  0.8868445 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 4113. State = [[-0.12702496  0.23761459  0.401674    1.        ]]. Action = [[-0.0251326   0.01904976 -0.20156771  0.8575728 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 4114. State = [[-0.12651587  0.23788907  0.39737317  1.        ]]. Action = [[-0.2859758   0.78535557  0.55977535  0.93756247]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 4115. State = [[-0.12648764  0.2354011   0.40021157  1.        ]]. Action = [[-0.5847654  -0.3445701   0.30218816  0.8925712 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 4116. State = [[-0.13393247  0.24542372  0.40371266  1.        ]]. Action = [[-0.41730058  0.7489227  -0.10140741  0.7182019 ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 4117. State = [[-0.14585245  0.25877124  0.4049396   1.        ]]. Action = [[-0.24941641  0.23288774  0.4749093   0.914201  ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 4118. State = [[-0.14708297  0.26020196  0.4049783   1.        ]]. Action = [[0.47837794 0.30521798 0.30950475 0.8760487 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 4119. State = [[-0.14721507  0.26030874  0.40501004  1.        ]]. Action = [[0.13433361 0.89933705 0.77245665 0.77388406]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 4120. State = [[-0.14721507  0.26030874  0.40501004  1.        ]]. Action = [[0.00569129 0.2855786  0.26806593 0.81216383]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 4121. State = [[-0.14725769  0.26036543  0.40501007  1.        ]]. Action = [[-0.24698967 -0.29261363  0.8678161   0.9419385 ]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 4122. State = [[-0.14725769  0.26036543  0.40501007  1.        ]]. Action = [[-0.44825274 -0.3594103   0.3728788   0.8697573 ]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 4123. State = [[-0.14725769  0.26036543  0.40501007  1.        ]]. Action = [[0.00803995 0.4500643  0.4699192  0.86999154]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 4124. State = [[-0.14725769  0.26036543  0.40501007  1.        ]]. Action = [[-0.37944043  0.01720858  0.43388367  0.7609751 ]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 4125. State = [[-0.14725769  0.26036543  0.40501007  1.        ]]. Action = [[0.26855958 0.40678906 0.5041311  0.894559  ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 4126. State = [[-0.14725769  0.26036543  0.40501007  1.        ]]. Action = [[0.4478476  0.19748569 0.42951417 0.73435795]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 4127. State = [[-0.14725769  0.26036543  0.40501007  1.        ]]. Action = [[0.36763322 0.6727927  0.6123953  0.76507854]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 4128. State = [[-0.14725769  0.26036543  0.40501007  1.        ]]. Action = [[-0.05452216 -0.04116797  0.64611316  0.88390684]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 4129. State = [[-0.14723094  0.260373    0.40501043  1.        ]]. Action = [[-0.1683293  -0.28721046  0.29786992  0.6842201 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 4130. State = [[-0.14725769  0.26036543  0.40501007  1.        ]]. Action = [[0.02667391 0.5918789  0.24284458 0.8448442 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 4131. State = [[-0.14722443  0.26044497  0.40474594  1.        ]]. Action = [[0.23997188 0.17249417 0.00649881 0.79935884]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 4132. State = [[-0.14676373  0.25918347  0.4046949   1.        ]]. Action = [[-0.06301159 -0.26951665 -0.07805669  0.9247372 ]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 4133. State = [[-0.14662059  0.2583524   0.40469655  1.        ]]. Action = [[0.05992043 0.3404491  0.3396225  0.64307797]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 4134. State = [[-0.1466378   0.25820017  0.404674    1.        ]]. Action = [[ 0.40751314 -0.786045    0.6573988   0.897707  ]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 4135. State = [[-0.14664833  0.25812903  0.40460688  1.        ]]. Action = [[0.06277895 0.80083275 0.31569755 0.45631957]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 4136. State = [[-0.14667654  0.25809258  0.40458184  1.        ]]. Action = [[0.3415085  0.00733912 0.24513996 0.8280864 ]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 4137. State = [[-0.14667654  0.25809258  0.40458184  1.        ]]. Action = [[0.49928522 0.04831064 0.78573847 0.7848542 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 4138. State = [[-0.14667511  0.2581216   0.40460655  1.        ]]. Action = [[-0.4352538   0.44426847  0.39311028  0.84568655]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 4139. State = [[-0.14667511  0.2581216   0.40460655  1.        ]]. Action = [[0.05884957 0.37175822 0.7680924  0.9084588 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 4140. State = [[-0.14667654  0.25809258  0.40458184  1.        ]]. Action = [[-0.35069674  0.608418    0.42676485  0.8153455 ]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 4141. State = [[-0.14667654  0.25809258  0.40458184  1.        ]]. Action = [[0.21642673 0.39126873 0.76056194 0.76924515]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 4142. State = [[-0.14667654  0.25809258  0.40458184  1.        ]]. Action = [[ 0.28508687 -0.24537444  0.435462    0.6442101 ]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 4143. State = [[-0.14414427  0.25268745  0.40387034  1.        ]]. Action = [[ 0.29213965 -0.34603107 -0.11039943  0.82162786]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 4144. State = [[-0.14089121  0.24691711  0.4034249   1.        ]]. Action = [[ 0.07961822 -0.6614729   0.5917902   0.8167813 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 4145. State = [[-0.14095078  0.25132084  0.39730415  1.        ]]. Action = [[ 0.06809092  0.58117306 -0.29514515  0.84214485]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 4146. State = [[-0.13584818  0.24654496  0.3924858   1.        ]]. Action = [[ 0.28108382 -0.7687261   0.32945192  0.56347346]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 4147. State = [[-0.13227627  0.23952231  0.39803666  1.        ]]. Action = [[0.03525102 0.15132356 0.00225043 0.82785606]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 4148. State = [[-0.13228749  0.23958631  0.39795506  1.        ]]. Action = [[ 0.02210724 -0.30253327  0.38764668  0.85933685]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 4149. State = [[-0.13228749  0.23958631  0.39795506  1.        ]]. Action = [[0.13723242 0.13871002 0.3518622  0.8963244 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 4150. State = [[-0.13228749  0.23958631  0.39795506  1.        ]]. Action = [[0.16938937 0.04191661 0.7845504  0.9094813 ]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 4151. State = [[-0.13227807  0.23946473  0.39801177  1.        ]]. Action = [[-0.25047606 -0.07531166 -0.09129155  0.85099554]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 4152. State = [[-0.13832936  0.25051942  0.39420116  1.        ]]. Action = [[-0.33122218  0.8108251  -0.32500917  0.78295493]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 4153. State = [[-0.14420295  0.25650027  0.392751    1.        ]]. Action = [[-0.01258099 -0.50124127  0.06374896  0.811463  ]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 4154. State = [[-0.14417139  0.25486577  0.3922777   1.        ]]. Action = [[ 0.04230046 -0.63309276  0.78973246  0.7074081 ]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 4155. State = [[-0.1441405   0.25490052  0.39230245  1.        ]]. Action = [[ 0.3116802  -0.19701272  0.7145692   0.81951284]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 4156. State = [[-0.14630447  0.2568376   0.3964198   1.        ]]. Action = [[-0.3769415   0.15443146  0.40637207  0.7020745 ]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 4157. State = [[-0.1478895   0.25866938  0.39794424  1.        ]]. Action = [[ 0.11585259 -0.27254397  0.7818699   0.7819884 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 4158. State = [[-0.14818409  0.25909552  0.39796948  1.        ]]. Action = [[-0.49563026 -0.5139669   0.7065599   0.7422415 ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 4159. State = [[-0.14818409  0.25909552  0.39796948  1.        ]]. Action = [[ 0.03051531 -0.6919945   0.85544634  0.84748685]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 4160. State = [[-0.15067214  0.2631942   0.39844587  1.        ]]. Action = [[0.12083602 0.39977574 0.16716766 0.75214005]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 4161. State = [[-0.1531032   0.26521984  0.40414128  1.        ]]. Action = [[-0.215999   -0.24361712  0.3132714   0.7940327 ]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 4162. State = [[-0.15411215  0.26440835  0.41381118  1.        ]]. Action = [[-0.51373255 -0.21641588  0.6929159   0.8043889 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 4163. State = [[-0.15350033  0.2612931   0.41543147  1.        ]]. Action = [[-0.11865896 -0.23473519  0.00669813  0.8660791 ]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 4164. State = [[-0.15353411  0.25803703  0.4169921   1.        ]]. Action = [[ 0.22567499 -0.48539692  0.4510553   0.76593876]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 4165. State = [[-0.15353252  0.2577855   0.41712853  1.        ]]. Action = [[ 0.05929279 -0.22685629  0.250831    0.7112415 ]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 4166. State = [[-0.15378912  0.25307688  0.4172967   1.        ]]. Action = [[-0.17685068 -0.38692856 -0.05916882  0.6884427 ]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 4167. State = [[-0.15769772  0.24433537  0.41525617  1.        ]]. Action = [[-0.44104987 -0.0883472   0.6453152   0.75746715]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 4168. State = [[-0.159107    0.24333967  0.41493014  1.        ]]. Action = [[ 0.03265333 -0.12808526  0.6151912   0.5400853 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 4169. State = [[-0.15934294  0.24315445  0.4156022   1.        ]]. Action = [[0.19421315 0.1575911  0.04169023 0.8546777 ]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 4170. State = [[-0.1594035   0.24310601  0.41614938  1.        ]]. Action = [[ 0.04019165 -0.38659996  0.7989261   0.7637255 ]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 4171. State = [[-0.15947893  0.24303739  0.4162249   1.        ]]. Action = [[ 0.5347761  -0.11787379  0.31745195  0.84526443]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 4172. State = [[-0.15977786  0.24275695  0.41586834  1.        ]]. Action = [[ 0.22039676 -0.39524734  0.11139286  0.65374196]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 4173. State = [[-0.1599157   0.24263044  0.41589773  1.        ]]. Action = [[-0.2524578  -0.17103142  0.838904    0.5492661 ]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 4174. State = [[-0.1599359   0.24261427  0.41607988  1.        ]]. Action = [[0.17969441 0.33225942 0.3381983  0.6491711 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 4175. State = [[-0.15997718  0.24257718  0.41614792  1.        ]]. Action = [[ 0.32231772 -0.4285584   0.18392015  0.8638599 ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 4176. State = [[-0.15997718  0.24257718  0.41614792  1.        ]]. Action = [[-0.17562413  0.4103241   0.30066025  0.69213724]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 4177. State = [[-0.16003944  0.24251929  0.41610128  1.        ]]. Action = [[0.70570314 0.5979451  0.68150425 0.68566084]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 4178. State = [[-0.1600689   0.24249144  0.41604444  1.        ]]. Action = [[ 0.3145709  -0.6778565   0.28647363  0.743726  ]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 4179. State = [[-0.16009668  0.24246518  0.41599086  1.        ]]. Action = [[0.36507976 0.22344553 0.16975355 0.8653352 ]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 4180. State = [[-0.16015208  0.24241285  0.41588408  1.        ]]. Action = [[ 0.68500376 -0.6291839   0.64333713  0.7807193 ]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 4181. State = [[-0.16015208  0.24241285  0.41588408  1.        ]]. Action = [[0.26067543 0.21197367 0.67097545 0.7489052 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 4182. State = [[-0.16015208  0.24241285  0.41588408  1.        ]]. Action = [[ 0.20369315 -0.11301768  0.65851367  0.7752615 ]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 4183. State = [[-0.16015208  0.24241285  0.41588408  1.        ]]. Action = [[ 0.4134351  -0.85268426  0.31662846  0.9195616 ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 4184. State = [[-0.16015208  0.24241285  0.41588408  1.        ]]. Action = [[-0.20434421 -0.48915434  0.7600672   0.88507366]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 4185. State = [[-0.16015208  0.24241285  0.41588408  1.        ]]. Action = [[ 0.15150392 -0.03057885  0.7583853   0.80143976]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 4186. State = [[-0.16015208  0.24241285  0.41588408  1.        ]]. Action = [[ 0.24605787 -0.52269405  0.8156252   0.7295904 ]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 4187. State = [[-0.16015208  0.24241285  0.41588408  1.        ]]. Action = [[ 0.39200664 -0.28228736  0.8483453   0.83988476]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 4188. State = [[-0.16015208  0.24241285  0.41588408  1.        ]]. Action = [[-0.26526952 -0.6444073   0.39731455  0.858814  ]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 4189. State = [[-0.16015208  0.24241285  0.41588408  1.        ]]. Action = [[0.49624538 0.48935008 0.3159529  0.8407786 ]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 4190. State = [[-0.16015208  0.24241285  0.41588408  1.        ]]. Action = [[ 0.07719028 -0.79103035  0.6188493   0.7954513 ]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 4191. State = [[-0.16015208  0.24241285  0.41588408  1.        ]]. Action = [[ 0.5823294  -0.79560715  0.58759236  0.7959981 ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 4192. State = [[-0.2536468  -0.08417989  0.09915427  1.        ]]. Action = [[ 0.32138598 -0.440997    0.628319    0.82066464]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 4193. State = [[-0.24240923 -0.095635    0.09232996  1.        ]]. Action = [[ 0.8020315  -0.20035458  0.8747709   0.9726198 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 4194. State = [[-0.21405679 -0.10220567  0.11136508  1.        ]]. Action = [[ 0.9353621  -0.06710595  0.94173586  0.96339583]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 4195. State = [[-0.19180141 -0.10550311  0.13487339  1.        ]]. Action = [[ 0.98572135 -0.45641124  0.8057103   0.9201002 ]]. Reward = [0.]
Curr episode timestep = 2
Action ignored: No entry zone
Current timestep = 4196. State = [[-0.18780245 -0.10618164  0.13830045  1.        ]]. Action = [[ 0.8644395  -0.39803833  0.83657026  0.98290884]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: No entry zone
Current timestep = 4197. State = [[-0.1866355  -0.10639211  0.13880053  1.        ]]. Action = [[ 0.88396454 -0.23899144  0.9376428   0.8491659 ]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 4198. State = [[-0.18608642 -0.10666881  0.1391291   1.        ]]. Action = [[ 0.77571356 -0.37427855  0.91436195  0.9786091 ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 4199. State = [[-0.18614495 -0.10666409  0.1391393   1.        ]]. Action = [[ 0.92691183 -0.2252754   0.95886505  0.9827887 ]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 4200. State = [[-0.18614495 -0.10666409  0.1391393   1.        ]]. Action = [[ 0.96835935 -0.51254     0.782006    0.9701779 ]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 4201. State = [[-0.18614495 -0.10666409  0.1391393   1.        ]]. Action = [[ 0.38747907 -0.10413361  0.92974687  0.8220055 ]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 4202. State = [[-0.18614495 -0.10666409  0.1391393   1.        ]]. Action = [[ 0.95066774 -0.3036797   0.9787495   0.99286413]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 4203. State = [[-0.18614495 -0.10666409  0.1391393   1.        ]]. Action = [[ 0.9685844  -0.50412846  0.69519746  0.9708619 ]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 4204. State = [[-0.18614495 -0.10666409  0.1391393   1.        ]]. Action = [[ 0.9640986  -0.6301556   0.88315403  0.82920444]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: No entry zone
Current timestep = 4205. State = [[-0.18078035 -0.10914911  0.14996076  1.        ]]. Action = [[ 0.28416955 -0.11997068  0.82375693  0.60374355]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 4206. State = [[-0.1734577  -0.11209463  0.16742599  1.        ]]. Action = [[0.6708492  0.09137976 0.9380224  0.98325586]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: No entry zone
Current timestep = 4207. State = [[-0.17273733 -0.11273216  0.16813003  1.        ]]. Action = [[ 0.98871183 -0.10265511  0.74322927  0.92508507]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: No entry zone
Current timestep = 4208. State = [[-0.17275493 -0.11279495  0.1681374   1.        ]]. Action = [[0.9334775  0.35616434 0.86755776 0.9477782 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: No entry zone
Current timestep = 4209. State = [[-0.17275493 -0.11279495  0.1681374   1.        ]]. Action = [[ 0.96439505 -0.5171611   0.7026429   0.9786215 ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: No entry zone
Current timestep = 4210. State = [[-0.17275493 -0.11279495  0.1681374   1.        ]]. Action = [[ 0.87418914 -0.413678    0.97155666  0.91030216]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: No entry zone
Current timestep = 4211. State = [[-0.17275493 -0.11279495  0.1681374   1.        ]]. Action = [[ 0.9265828  -0.26582235  0.8749006   0.95672584]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: No entry zone
Current timestep = 4212. State = [[-0.17275493 -0.11279495  0.1681374   1.        ]]. Action = [[0.9847783  0.01964724 0.5384685  0.9610479 ]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: No entry zone
Current timestep = 4213. State = [[-0.17275493 -0.11279495  0.1681374   1.        ]]. Action = [[ 0.915689   -0.24689579  0.90746343  0.988693  ]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: No entry zone
Current timestep = 4214. State = [[-0.17275493 -0.11279495  0.1681374   1.        ]]. Action = [[ 0.27588582 -0.02991658  0.9399264   0.9005728 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: No entry zone
Current timestep = 4215. State = [[-0.17275493 -0.11279495  0.1681374   1.        ]]. Action = [[0.90580225 0.06584299 0.89492285 0.8452785 ]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: No entry zone
Current timestep = 4216. State = [[-0.17275493 -0.11279495  0.1681374   1.        ]]. Action = [[ 0.8199793  -0.46707535  0.9774494   0.82593393]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: No entry zone
Current timestep = 4217. State = [[-0.17275493 -0.11279495  0.1681374   1.        ]]. Action = [[ 0.99525404 -0.11431903  0.9424573   0.9474206 ]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: No entry zone
Current timestep = 4218. State = [[-0.17275493 -0.11279495  0.1681374   1.        ]]. Action = [[ 0.980788   -0.48679137  0.8921776   0.9404974 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: No entry zone
Current timestep = 4219. State = [[-0.17094845 -0.11531378  0.1809068   1.        ]]. Action = [[-0.03667653 -0.09632361  0.9776175   0.89101934]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 4220. State = [[-0.17155968 -0.11554743  0.20359029  1.        ]]. Action = [[ 0.78551483 -0.02932054  0.8849132   0.89432883]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: No entry zone
Current timestep = 4221. State = [[-0.1634682  -0.11921998  0.22222011  1.        ]]. Action = [[ 0.43721795 -0.21116692  0.98178244  0.9827453 ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 4222. State = [[-0.1440573  -0.12515241  0.25739673  1.        ]]. Action = [[ 0.7159841  -0.01198065  0.90511835  0.8991785 ]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 4223. State = [[-0.11411075 -0.12838222  0.29577252  1.        ]]. Action = [[0.9565612  0.01073444 0.948277   0.9444852 ]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 4224. State = [[-0.08046219 -0.11933643  0.33577344  1.        ]]. Action = [[0.90753376 0.55391    0.74379957 0.56526434]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 4224 is [False, True, False, True, False, False, True, False, False, True]
State prediction error at timestep 4224 is tensor(0.0010, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 4224 of 1
Current timestep = 4225. State = [[-0.045375   -0.09989925  0.37318113  1.        ]]. Action = [[0.6792271  0.41444993 0.7669382  0.7585521 ]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 4226. State = [[-0.03401841 -0.09479395  0.39327145  1.        ]]. Action = [[0.32212532 0.80648637 0.8331487  0.6556144 ]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 4227. State = [[-0.03059708 -0.0793779   0.39810565  1.        ]]. Action = [[-0.20337933  0.90600777  0.19361722  0.8236377 ]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 4228. State = [[-0.0326196  -0.06086225  0.4004883   1.        ]]. Action = [[-0.33076656  0.83631635  0.38244045  0.80576   ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Above hoop
Current timestep = 4229. State = [[-0.03148533 -0.04604103  0.403521    1.        ]]. Action = [[0.14042938 0.7860911  0.27401137 0.800956  ]]. Reward = [0.]
Curr episode timestep = 36
Above hoop
Current timestep = 4230. State = [[-0.03054439 -0.01463068  0.41272002  1.        ]]. Action = [[-0.14500874  0.87228763  0.13499367  0.7724824 ]]. Reward = [0.]
Curr episode timestep = 37
Above hoop
Current timestep = 4231. State = [[-0.03275067  0.00456051  0.41879922  1.        ]]. Action = [[0.07068443 0.77724814 0.08804977 0.7643287 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Above hoop
Current timestep = 4232. State = [[-0.03289748  0.00702562  0.42009872  1.        ]]. Action = [[-0.12475383  0.92329717  0.04790795  0.837574  ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Above hoop
Current timestep = 4233. State = [[-0.03301037  0.00777648  0.4201459   1.        ]]. Action = [[-0.523367    0.9105334   0.08831775  0.774673  ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Above hoop
Current timestep = 4234. State = [[-0.03301037  0.00777648  0.4201459   1.        ]]. Action = [[4.1520596e-04 8.6554360e-01 2.4058235e-01 7.2926021e-01]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Above hoop
Current timestep = 4235. State = [[-0.03362197  0.02188455  0.41887107  1.        ]]. Action = [[ 0.0682689   0.8091173  -0.09094304  0.7867025 ]]. Reward = [0.]
Curr episode timestep = 42
Above hoop
Current timestep = 4236. State = [[-0.04019298  0.05034911  0.41474828  1.        ]]. Action = [[-0.54400414  0.76100993 -0.26003098  0.7432649 ]]. Reward = [0.]
Curr episode timestep = 43
Above hoop
Current timestep = 4237. State = [[-0.04654855  0.0683592   0.4116124   1.        ]]. Action = [[-0.08174342  0.74733424  0.18991709  0.676085  ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Above hoop
Current timestep = 4238. State = [[-0.04734789  0.07028388  0.4105565   1.        ]]. Action = [[-0.10540867  0.3634262   0.21047616  0.72396123]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Above hoop
Current timestep = 4239. State = [[-0.04747294  0.07073136  0.41038883  1.        ]]. Action = [[-3.4666061e-04  8.5461056e-01  3.7655497e-01  7.1889257e-01]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Above hoop
Current timestep = 4240. State = [[-0.04750499  0.0709995   0.41038403  1.        ]]. Action = [[-0.01633912  0.785537    0.3023131   0.686213  ]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Above hoop
Current timestep = 4241. State = [[-0.04888897  0.08128169  0.4044244   1.        ]]. Action = [[ 0.00150788  0.57786417 -0.34035516  0.6637484 ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 4241 is [False, True, False, False, False, True, True, False, False, True]
State prediction error at timestep 4241 is tensor(5.9074e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 4241 of -1
Current timestep = 4242. State = [[-0.05507473  0.10308178  0.39771125  1.        ]]. Action = [[-0.3573109   0.5660684   0.1441505   0.73112166]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 4243. State = [[-0.06269401  0.12581223  0.39615315  1.        ]]. Action = [[ 0.07382596  0.6253028  -0.15727437  0.82058525]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 4244. State = [[-0.07085103  0.149793    0.3923786   1.        ]]. Action = [[-0.3085885   0.74952674 -0.11231285  0.7473873 ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 4245. State = [[-0.07269061  0.16614895  0.39551112  1.        ]]. Action = [[0.40846264 0.04419601 0.3286171  0.695554  ]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 4246. State = [[-0.06305774  0.17043489  0.39999962  1.        ]]. Action = [[-0.26326883  0.6037893   0.68546724  0.58619666]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 4247. State = [[-0.06392518  0.17487495  0.4022976   1.        ]]. Action = [[-0.2195338   0.16999531  0.3103032   0.6481898 ]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 4248. State = [[-0.0705005   0.18681166  0.40796757  1.        ]]. Action = [[-0.57970387  0.30745518 -0.01106304  0.52010036]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 4249. State = [[-0.0793727   0.1952311   0.40924737  1.        ]]. Action = [[-0.32249647 -0.20279592  0.30419052  0.64045906]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 4250. State = [[-0.08449231  0.2006011   0.40960744  1.        ]]. Action = [[-0.35372317  0.19055426 -0.0279876   0.7482265 ]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 4251. State = [[-0.09539717  0.2173701   0.4098256   1.        ]]. Action = [[-0.3797995   0.69619846 -0.11758375  0.6538005 ]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 4252. State = [[-0.10597829  0.23096223  0.40997663  1.        ]]. Action = [[-0.20551044 -0.09168446  0.5730634   0.61838746]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Scene graph at timestep 4252 is [True, False, False, False, False, True, True, False, False, True]
State prediction error at timestep 4252 is tensor(0.0001, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 4252 of -1
Current timestep = 4253. State = [[-0.10803451  0.23220186  0.41005048  1.        ]]. Action = [[0.20402038 0.02345085 0.47467184 0.5682775 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 4254. State = [[-0.10803451  0.23220186  0.41005048  1.        ]]. Action = [[ 0.22374535 -0.14903867  0.62076426  0.5435846 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 4255. State = [[-0.10803451  0.23220186  0.41005048  1.        ]]. Action = [[ 0.20687592 -0.07064396  0.7263727   0.7793093 ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 4256. State = [[-0.10803451  0.23220186  0.41005048  1.        ]]. Action = [[-0.24432772 -0.7217716   0.6236912   0.6486114 ]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 4257. State = [[-0.10803451  0.23220186  0.41005048  1.        ]]. Action = [[-0.40932733 -0.22362614  0.1867348   0.60930145]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 4258. State = [[-0.10803451  0.23220186  0.41005048  1.        ]]. Action = [[-0.30091584  0.06699717  0.702132    0.5383624 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 4259. State = [[-0.10803451  0.23220186  0.41005048  1.        ]]. Action = [[-0.33049202 -0.52418065  0.46916366  0.61806035]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 4260. State = [[-0.10803451  0.23220186  0.41005048  1.        ]]. Action = [[-0.419504   -0.05705148  0.51511717  0.55189514]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 4261. State = [[-0.10803451  0.23220186  0.41005048  1.        ]]. Action = [[-0.27372986 -0.5785189   0.7597624   0.63136935]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 4262. State = [[-0.10803451  0.23220186  0.41005048  1.        ]]. Action = [[-0.34722853 -0.21205115  0.7143631   0.6224663 ]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 4263. State = [[-0.10803451  0.23220186  0.41005048  1.        ]]. Action = [[ 0.00791514 -0.440053    0.5369332   0.39108562]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 4264. State = [[-0.10803451  0.23220186  0.41005048  1.        ]]. Action = [[-0.38556355 -0.04104346  0.33086312  0.6627414 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 4265. State = [[-0.10803451  0.23220186  0.41005048  1.        ]]. Action = [[-0.561524    0.27580905  0.2673272   0.59953105]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 4266. State = [[-0.10803451  0.23220186  0.41005048  1.        ]]. Action = [[-0.50955456 -0.34253824  0.4629674   0.6241282 ]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 4267. State = [[-0.10803451  0.23220186  0.41005048  1.        ]]. Action = [[-0.4087683  -0.18210334  0.6109235   0.6278014 ]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 4268. State = [[-0.10803451  0.23220186  0.41005048  1.        ]]. Action = [[-0.2218306  -0.1174891   0.39227533  0.65604544]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 4269. State = [[-0.10803451  0.23220186  0.41005048  1.        ]]. Action = [[-0.00995165 -0.4835319   0.6323726   0.5068811 ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 4270. State = [[-0.10803451  0.23220186  0.41005048  1.        ]]. Action = [[-0.08497369 -0.42904568  0.406461    0.599972  ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 4271. State = [[-0.10803451  0.23220186  0.41005048  1.        ]]. Action = [[-0.15642631 -0.42017114  0.61182237  0.6324693 ]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 4272. State = [[-0.10803451  0.23220186  0.41005048  1.        ]]. Action = [[-0.47999     0.13436615  0.37248683  0.5965073 ]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 4273. State = [[-0.10811436  0.23232387  0.4100505   1.        ]]. Action = [[-0.40252048 -0.6037338   0.75783277  0.5611665 ]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 4274. State = [[-0.10626535  0.22488841  0.41131616  1.        ]]. Action = [[-0.09643811 -0.615206    0.07574403  0.5533358 ]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 4275. State = [[-0.10483972  0.21463822  0.41264787  1.        ]]. Action = [[0.181036   0.49862504 0.6344173  0.66327405]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 4276. State = [[-0.10434764  0.2118692   0.41333553  1.        ]]. Action = [[ 0.0386337  -0.36915857  0.17414892  0.475986  ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 4277. State = [[-0.10425083  0.21131945  0.4134938   1.        ]]. Action = [[ 0.17100108 -0.5732445   0.6167599   0.5243391 ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 4278. State = [[-0.10425083  0.21131945  0.4134938   1.        ]]. Action = [[ 0.19115973 -0.44203     0.71716785  0.6419413 ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 4279. State = [[-0.10425083  0.21131945  0.4134938   1.        ]]. Action = [[ 0.2639706  -0.28414762  0.627023    0.5891943 ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 4280. State = [[-0.1042174   0.21119025  0.41350332  1.        ]]. Action = [[-0.15606266  0.20723164  0.6222789   0.5903816 ]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 4281. State = [[-0.1042174   0.21119025  0.41350332  1.        ]]. Action = [[-0.03668535 -0.27141654  0.5954983   0.70307374]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 4282. State = [[-0.10427619  0.21124844  0.41350812  1.        ]]. Action = [[ 0.10592484 -0.00773162  0.7346723   0.62822866]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 4283. State = [[-0.10427619  0.21124844  0.41350812  1.        ]]. Action = [[ 0.06998491 -0.46561807  0.82538056  0.7176113 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 4284. State = [[-0.10427619  0.21124844  0.41350812  1.        ]]. Action = [[ 0.0642482  -0.21770865  0.5469074   0.63033795]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 4285. State = [[-0.10431378  0.21130955  0.41350815  1.        ]]. Action = [[ 0.01454067 -0.30686283  0.45833457  0.6832633 ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 4286. State = [[-0.10429706  0.21124496  0.4135129   1.        ]]. Action = [[ 0.35028672 -0.53839165  0.57263994  0.74148464]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 4287. State = [[-0.10429706  0.21124496  0.4135129   1.        ]]. Action = [[-0.5311782  -0.51371646  0.7304596   0.7083396 ]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 4288. State = [[-0.10429706  0.21124496  0.4135129   1.        ]]. Action = [[-0.35554075 -0.24219733  0.41570973  0.6918471 ]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 4289. State = [[-0.10429706  0.21124496  0.4135129   1.        ]]. Action = [[-0.15482414  0.3716389   0.18066072  0.7749326 ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 4290. State = [[-0.10429706  0.21124496  0.4135129   1.        ]]. Action = [[ 0.13031101 -0.09809577  0.41426992  0.5841739 ]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 4291. State = [[-0.10429706  0.21124496  0.4135129   1.        ]]. Action = [[-0.3383634   0.54120684  0.4684496   0.754109  ]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 4292. State = [[-0.10429706  0.21124496  0.4135129   1.        ]]. Action = [[0.05128622 0.36118317 0.44951773 0.64591026]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 4293. State = [[-0.10429706  0.21124496  0.4135129   1.        ]]. Action = [[-0.02489495  0.19950509  0.18560386  0.6300602 ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 4294. State = [[-0.26667854  0.15071304  0.10800672  1.        ]]. Action = [[-0.18946368  0.33652508  0.74495196  0.7870631 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 4295. State = [[-0.24904965  0.15522206  0.10005088  1.        ]]. Action = [[ 0.89027333 -0.8605363   0.8477142   0.77547765]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 4296. State = [[-0.21682699  0.1280024   0.12130681  1.        ]]. Action = [[ 0.9057956  -0.8312353   0.9735005   0.99497104]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 4297. State = [[-0.18229267  0.09743688  0.15887925  1.        ]]. Action = [[ 0.8828809  -0.9520846   0.94688535  0.925508  ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 4298. State = [[-0.16074003  0.07840816  0.18286665  1.        ]]. Action = [[ 0.90674996 -0.89433825  0.46059418  0.9586935 ]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: No entry zone
Current timestep = 4299. State = [[-0.156325    0.07419363  0.18657966  1.        ]]. Action = [[ 0.8111024  -0.76908326  0.8158529   0.8730252 ]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 4300. State = [[-0.15602835  0.07309064  0.18710536  1.        ]]. Action = [[ 0.99285793 -0.8716739   0.6533792   0.93968534]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 4301. State = [[-0.15571074  0.07300569  0.18732314  1.        ]]. Action = [[ 0.9663154 -0.8410044  0.9173994  0.9828247]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 4302. State = [[-0.15673758  0.06214126  0.20029238  1.        ]]. Action = [[-0.6116407 -0.7068793  0.9328146  0.9768872]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 4303. State = [[-0.15150562  0.0492589   0.23673274  1.        ]]. Action = [[0.89803386 0.04165792 0.97505987 0.94853413]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 4304. State = [[-0.12822108  0.04391123  0.27153286  1.        ]]. Action = [[ 0.9413078  -0.23717767  0.8512616   0.9841565 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 4305. State = [[-0.09855295  0.02829547  0.3106837   1.        ]]. Action = [[ 0.9945893  -0.69597095  0.967976    0.97028327]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 4306. State = [[-0.06913424  0.00251899  0.35109752  1.        ]]. Action = [[ 0.5574683  -0.703481    0.8568722   0.69554734]]. Reward = [0.]
Curr episode timestep = 11
Above hoop
Scene graph at timestep 4306 is [False, True, False, False, True, False, True, False, False, True]
State prediction error at timestep 4306 is tensor(0.0012, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 4306 of 1
Current timestep = 4307. State = [[-0.04814875 -0.00734214  0.38771158  1.        ]]. Action = [[0.18800044 0.5915251  0.6973734  0.8126112 ]]. Reward = [0.]
Curr episode timestep = 12
Above hoop
Current timestep = 4308. State = [[-0.03656706  0.01285713  0.40919453  1.        ]]. Action = [[0.35898995 0.795668   0.37845552 0.8358884 ]]. Reward = [0.]
Curr episode timestep = 13
Above hoop
Current timestep = 4309. State = [[-0.02579551  0.02769603  0.41963467  1.        ]]. Action = [[0.27125132 0.77221704 0.6470243  0.7261348 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Above hoop
Current timestep = 4310. State = [[-0.02624405  0.04057243  0.41783068  1.        ]]. Action = [[-0.27090025  0.58323765 -0.37068003  0.7957113 ]]. Reward = [0.]
Curr episode timestep = 15
Above hoop
Current timestep = 4311. State = [[-0.03228877  0.06687575  0.4105957   1.        ]]. Action = [[-0.19584674  0.92786026 -0.17021817  0.74881744]]. Reward = [0.]
Curr episode timestep = 16
Above hoop
Current timestep = 4312. State = [[-0.0420168   0.10079463  0.39946854  1.        ]]. Action = [[-0.2887659   0.80848837 -0.4906566   0.7316085 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 4313. State = [[-0.05208982  0.13340546  0.39043948  1.        ]]. Action = [[-0.21411121  0.8517122  -0.02920663  0.7003021 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 4314. State = [[-0.05950484  0.1581327   0.39162233  1.        ]]. Action = [[-0.16043937  0.32041895  0.32432854  0.6521658 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 4315. State = [[-0.06444956  0.16875337  0.39637738  1.        ]]. Action = [[-0.25249374  0.04573023  0.28986216  0.5557873 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 4316. State = [[-0.06849205  0.17246649  0.39931598  1.        ]]. Action = [[ 0.0150733  -0.4234059   0.63438165  0.68649006]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 4317. State = [[-0.0684307   0.17084835  0.4005959   1.        ]]. Action = [[-0.02843672 -0.15483701  0.08461261  0.64856815]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 4318. State = [[-0.06638529  0.17474923  0.406711    1.        ]]. Action = [[0.3436532  0.46069515 0.13363004 0.62742186]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 4319. State = [[-0.06858235  0.18812262  0.4129184   1.        ]]. Action = [[-0.25213635  0.5037857   0.14862943  0.58689034]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 4320. State = [[-0.07280988  0.19904624  0.41753536  1.        ]]. Action = [[-0.11119574  0.6795442   0.41948545  0.65175724]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 4321. State = [[-0.07281855  0.20036258  0.42007703  1.        ]]. Action = [[-0.53049564 -0.40016174  0.1437484   0.6792897 ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 4322. State = [[-0.07309921  0.20094472  0.42009678  1.        ]]. Action = [[-0.5212636   0.32624805  0.30729485  0.5698855 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 4323. State = [[-0.07308792  0.20088501  0.4201147   1.        ]]. Action = [[-0.31988806 -0.2718243   0.02384984  0.67107284]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 4324. State = [[-0.07308792  0.20088501  0.4201147   1.        ]]. Action = [[-0.44001698 -0.10683757  0.4499532   0.70962346]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 4325. State = [[-0.07308792  0.20088501  0.4201147   1.        ]]. Action = [[-0.27251446  0.08102775  0.24206877  0.5182748 ]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 4326. State = [[-0.07308792  0.20088501  0.4201147   1.        ]]. Action = [[ 0.0981586  -0.14902365  0.54376304  0.5860822 ]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 4327. State = [[-0.07308792  0.20088501  0.4201147   1.        ]]. Action = [[-0.32310462  0.14506769  0.41532087  0.49206734]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 4328. State = [[-0.07308792  0.20088501  0.4201147   1.        ]]. Action = [[0.13742149 0.06061149 0.04523921 0.5573287 ]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 4329. State = [[-0.07308792  0.20088501  0.4201147   1.        ]]. Action = [[-0.07147664  0.3674879   0.30081105  0.6226486 ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 4330. State = [[-0.07308792  0.20088501  0.4201147   1.        ]]. Action = [[-0.04413468  0.162786    0.17507172  0.56279683]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 4331. State = [[-0.07308792  0.20088501  0.4201147   1.        ]]. Action = [[-0.5034831   0.3088063   0.03888619  0.60685   ]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 4332. State = [[-0.07308792  0.20088501  0.4201147   1.        ]]. Action = [[-0.2393046   0.06869161  0.07645476  0.693071  ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 4333. State = [[-0.07308792  0.20088501  0.4201147   1.        ]]. Action = [[-0.34387898  0.2657045   0.15512252  0.6968465 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 4334. State = [[-0.07495183  0.20456988  0.41882265  1.        ]]. Action = [[-0.08460909  0.2566961  -0.12762624  0.58590174]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 4335. State = [[-0.07690655  0.20886165  0.41573447  1.        ]]. Action = [[ 0.02155793 -0.17061037  0.43024123  0.6399934 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 4336. State = [[-0.07923296  0.21433367  0.41296238  1.        ]]. Action = [[-0.11442935  0.2563789  -0.14072073  0.60248375]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 4337. State = [[-0.0816526   0.21917029  0.4111144   1.        ]]. Action = [[-4.9579144e-04  2.3386097e-01  2.8479862e-01  6.0603142e-01]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 4338. State = [[-0.08200797  0.21979979  0.4107581   1.        ]]. Action = [[-0.23467994 -0.44526017  0.26574647  0.58899784]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 4339. State = [[-0.08204643  0.21986318  0.41075814  1.        ]]. Action = [[ 0.02951169 -0.32997763  0.43805397  0.6379132 ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 4340. State = [[-0.08204643  0.21986318  0.41075814  1.        ]]. Action = [[-0.5167682  -0.20018685  0.38819718  0.53658974]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 4341. State = [[-0.08204643  0.21986318  0.41075814  1.        ]]. Action = [[-0.02039725  0.30062437  0.47253263  0.58804226]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 4342. State = [[-0.08203898  0.21986748  0.41068783  1.        ]]. Action = [[-0.42874217 -0.16474307  0.49885404  0.703719  ]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 4343. State = [[-0.08202572  0.21980828  0.41070595  1.        ]]. Action = [[-0.0169608  -0.11476654 -0.03624296  0.5822365 ]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 4344. State = [[-0.08202572  0.21980828  0.41070595  1.        ]]. Action = [[-0.09792453  0.3354274   0.76695824  0.73471594]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 4345. State = [[-0.08202572  0.21980828  0.41070595  1.        ]]. Action = [[-0.21807498 -0.05115283  0.74052393  0.75264   ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 4346. State = [[-0.08202572  0.21980828  0.41070595  1.        ]]. Action = [[-0.07617927  0.07015216  0.21097171  0.593395  ]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 4347. State = [[-0.08202572  0.21980828  0.41070595  1.        ]]. Action = [[-0.23262376  0.05699658  0.2852533   0.6338159 ]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 4348. State = [[-0.08202572  0.21980828  0.41070595  1.        ]]. Action = [[-0.03697217 -0.07832026  0.35848105  0.5310494 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 4349. State = [[-0.08201246  0.2197491   0.4107241   1.        ]]. Action = [[-0.0861606  -0.29881787  0.3683356   0.5498371 ]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 4350. State = [[-0.08201246  0.2197491   0.4107241   1.        ]]. Action = [[0.06144857 0.33675706 0.26115572 0.5348897 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 4351. State = [[-0.08047027  0.21233171  0.4128227   1.        ]]. Action = [[-0.2291038  -0.6147409  -0.07260275  0.559221  ]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 4352. State = [[-0.07901867  0.20523182  0.41496634  1.        ]]. Action = [[-0.2409569  -0.0405066   0.32000422  0.7016716 ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 4353. State = [[-0.07883806  0.20414181  0.41526556  1.        ]]. Action = [[-0.33023894  0.04368067  0.30210352  0.69556737]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 4354. State = [[-0.07877365  0.20385104  0.41529784  1.        ]]. Action = [[ 0.0881424  -0.26935357  0.03123808  0.7007179 ]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 4355. State = [[-0.07875089  0.20373285  0.41533723  1.        ]]. Action = [[-0.06984973  0.05430472  0.15988278  0.72615373]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 4356. State = [[-0.07875089  0.20373285  0.41533723  1.        ]]. Action = [[-0.20639563 -0.17002416  0.02124512  0.6245563 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 4357. State = [[-0.07875089  0.20373285  0.41533723  1.        ]]. Action = [[-0.3939219   0.35438633  0.6329489   0.58783126]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 4358. State = [[-0.07875089  0.20373285  0.41533723  1.        ]]. Action = [[-0.04218048  0.1967206   0.41289866  0.71278954]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 4359. State = [[-0.07875089  0.20373285  0.41533723  1.        ]]. Action = [[0.17000628 0.6042404  0.14077926 0.49657714]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 4360. State = [[-0.07875089  0.20373285  0.41533723  1.        ]]. Action = [[ 0.10943222 -0.0949415   0.38930237  0.69888866]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 4361. State = [[-0.07978752  0.2034948   0.41120702  1.        ]]. Action = [[-0.07072258  0.13320446 -0.31857646  0.61501026]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 4362. State = [[-0.08013779  0.20421866  0.40923068  1.        ]]. Action = [[ 0.29451203 -0.14999712  0.44223404  0.6225085 ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 4363. State = [[-0.08020459  0.20412385  0.40852916  1.        ]]. Action = [[-0.19457066 -0.02317983  0.20000076  0.5939561 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 4364. State = [[-0.08023367  0.2040909   0.40815604  1.        ]]. Action = [[-0.16520226 -0.7345905   0.3698095   0.6124829 ]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 4365. State = [[-0.08023367  0.2040909   0.40815604  1.        ]]. Action = [[-0.12578475 -0.03199714  0.5067693   0.5163796 ]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 4366. State = [[-0.08361088  0.20881158  0.4057463   1.        ]]. Action = [[-0.20327675  0.296453   -0.23730123  0.6627152 ]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 4367. State = [[-0.08609123  0.20594287  0.4011537   1.        ]]. Action = [[-0.03446817 -0.7759726   0.03764629  0.5550623 ]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 4368. State = [[-0.0877815   0.19446538  0.39886808  1.        ]]. Action = [[-0.01309651 -0.72914976  0.38864982  0.37835646]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 4369. State = [[-0.08788774  0.19364722  0.39875612  1.        ]]. Action = [[ 0.29299545 -0.4232843   0.6031139   0.68073237]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 4370. State = [[-0.08791857  0.19362079  0.39869958  1.        ]]. Action = [[ 0.24374473 -0.23975056  0.54515564  0.5038904 ]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 4371. State = [[-0.08622935  0.18675736  0.4016812   1.        ]]. Action = [[-0.03153467 -0.41300142  0.22147167  0.5662246 ]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 4372. State = [[-0.08502669  0.17921281  0.40424562  1.        ]]. Action = [[ 0.16601157 -0.01888752 -0.14360166  0.4884739 ]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 4373. State = [[-0.08493618  0.17811662  0.40367246  1.        ]]. Action = [[-0.03600544 -0.13072121  0.51166654  0.77781343]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 4374. State = [[-0.084909    0.17794043  0.40374085  1.        ]]. Action = [[-0.16731662 -0.28112316  0.45392334  0.6914413 ]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 4375. State = [[-0.08483222  0.17677519  0.4045256   1.        ]]. Action = [[-0.1565417  -0.05916959  0.16121078  0.76296926]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 4376. State = [[-0.08902122  0.18043748  0.40751794  1.        ]]. Action = [[-0.44528466  0.25819528  0.12423038  0.6378186 ]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 4377. State = [[-0.09411015  0.18400766  0.41098836  1.        ]]. Action = [[-0.02817541 -0.49886     0.60134125  0.6822072 ]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 4378. State = [[-0.09455644  0.1843842   0.41117904  1.        ]]. Action = [[-0.0604279   0.07210445  0.73557305  0.6272621 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 4379. State = [[-0.09459127  0.1844463   0.41117907  1.        ]]. Action = [[-0.14990425 -0.0908677   0.59217715  0.7214079 ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 4380. State = [[-0.09459127  0.1844463   0.41117907  1.        ]]. Action = [[ 0.13861465 -0.18803847  0.3320676   0.6271167 ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 4381. State = [[-0.09459127  0.1844463   0.41117907  1.        ]]. Action = [[ 0.3099202  -0.21677923  0.69735956  0.7201097 ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 4382. State = [[-0.09459127  0.1844463   0.41117907  1.        ]]. Action = [[ 0.26521647 -0.11250609  0.5110042   0.6052524 ]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 4383. State = [[-0.09459127  0.1844463   0.41117907  1.        ]]. Action = [[0.00085545 0.12480688 0.2849648  0.7209556 ]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 4384. State = [[-0.09606872  0.1787613   0.40888232  1.        ]]. Action = [[ 0.01013863 -0.447832   -0.16379267  0.6938236 ]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 4385. State = [[-0.10008021  0.16864406  0.40582308  1.        ]]. Action = [[-0.12574464 -0.1731875   0.30736554  0.6096058 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 4386. State = [[-0.10099407  0.16742904  0.40433484  1.        ]]. Action = [[-0.05948174 -0.54222363  0.5964551   0.7718549 ]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 4387. State = [[-0.10120273  0.16724567  0.40397492  1.        ]]. Action = [[ 0.15846491 -0.01438087  0.63087845  0.5508543 ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 4388. State = [[-0.10120048  0.16698599  0.40402347  1.        ]]. Action = [[-0.39301413 -0.6656711   0.3929882   0.73008215]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 4389. State = [[-0.1012046   0.16652438  0.4040953   1.        ]]. Action = [[ 0.45769715 -0.49844503  0.34893954  0.6850884 ]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 4390. State = [[-0.1012046   0.16652438  0.4040953   1.        ]]. Action = [[ 0.35818303 -0.38122976  0.76520896  0.57206047]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 4391. State = [[-0.09947287  0.16358945  0.40471616  1.        ]]. Action = [[ 0.24109793 -0.1922903   0.00365007  0.6394954 ]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 4392. State = [[-0.09840907  0.16084908  0.40630773  1.        ]]. Action = [[-0.15537953 -0.5025327   0.26661575  0.65764236]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 4393. State = [[-0.09831278  0.15956618  0.4068247   1.        ]]. Action = [[ 0.43351984 -0.14311463  0.3994758   0.4730904 ]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 4394. State = [[-0.09786687  0.1584824   0.40759686  1.        ]]. Action = [[-0.107476   -0.34135377  0.46630192  0.6611333 ]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 4395. State = [[-0.09370335  0.14965333  0.40781805  1.        ]]. Action = [[ 0.40389848 -0.54080856 -0.03835469  0.5813403 ]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 4396. State = [[-0.26336035  0.08173004  0.1141728   1.        ]]. Action = [[-0.26854336  0.05546737  0.33269215  0.4653473 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 4397. State = [[-0.24763954  0.07906003  0.10899939  1.        ]]. Action = [[ 0.973246   -0.7757624   0.9504652   0.98680174]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 4398. State = [[-0.21293262  0.05522522  0.13150844  1.        ]]. Action = [[ 0.99647546 -0.7997433   0.90631866  0.921854  ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 4399. State = [[-0.18122597  0.02905453  0.16611466  1.        ]]. Action = [[ 0.50496566 -0.68241054  0.85661983  0.7749907 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 4400. State = [[-0.165332    0.01336494  0.18583114  1.        ]]. Action = [[ 0.76254   -0.7213031  0.7167146  0.9696307]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: No entry zone
Current timestep = 4401. State = [[-0.16207322  0.0108592   0.18895166  1.        ]]. Action = [[ 0.5180342  -0.5405118   0.95659196  0.95514226]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 4402. State = [[-0.16136113  0.01066627  0.18956816  1.        ]]. Action = [[ 0.9625678  -0.14504051  0.97874784  0.989434  ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 4403. State = [[-0.16088206  0.01053399  0.1900003   1.        ]]. Action = [[ 0.8413327 -0.7766151  0.9307381  0.9936583]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 4404. State = [[-0.16068572  0.01048069  0.19011277  1.        ]]. Action = [[ 0.9540336  -0.6070653   0.99125504  0.87122893]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 4405. State = [[-0.16071334  0.01048341  0.19011159  1.        ]]. Action = [[ 0.98084605 -0.84527093  0.6232648   0.9358754 ]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 4406. State = [[-0.16076846  0.01048884  0.19010927  1.        ]]. Action = [[ 0.92988706 -0.5425692   0.7578149   0.9660381 ]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 4407. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.876775   -0.7358698   0.97425675  0.90970683]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 4408. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.9697192  -0.4875695   0.8571439   0.96827877]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: No entry zone
Current timestep = 4409. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.9976622  -0.09932637  0.93254614  0.9793577 ]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: No entry zone
Current timestep = 4410. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.89036155 -0.6531664   0.7745106   0.9701625 ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: No entry zone
Current timestep = 4411. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.9940933  -0.5356586   0.87670267  0.94213545]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: No entry zone
Current timestep = 4412. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.957881   -0.23669493  0.95926404  0.9138441 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: No entry zone
Current timestep = 4413. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.9180609  -0.6497211   0.48930907  0.96846294]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: No entry zone
Current timestep = 4414. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.8776382  -0.245844    0.9468553   0.88405037]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: No entry zone
Current timestep = 4415. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.98538053 -0.5904473   0.8439487   0.97659993]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: No entry zone
Current timestep = 4416. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.9461858  -0.42231202  0.7052622   0.95575345]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: No entry zone
Current timestep = 4417. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.948365   -0.49277025  0.89607215  0.8650569 ]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: No entry zone
Current timestep = 4418. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.6196072  -0.707883    0.92929304  0.9121033 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: No entry zone
Current timestep = 4419. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.9864433  -0.7025363   0.9698416   0.90996504]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: No entry zone
Current timestep = 4420. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.97106886 -0.86894464  0.9844942   0.95754457]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: No entry zone
Current timestep = 4421. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.22502434 -0.8492212   0.96266544  0.9518776 ]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: No entry zone
Current timestep = 4422. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.9804882  -0.57414937  0.9203942   0.92375946]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: No entry zone
Current timestep = 4423. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.6233237 -0.6436518  0.9118115  0.8724444]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: No entry zone
Current timestep = 4424. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.26422858 -0.8141951   0.87129617  0.8451183 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: No entry zone
Current timestep = 4425. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.86985075 -0.8393514   0.94276047  0.982882  ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: No entry zone
Current timestep = 4426. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.98154974 -0.37344503  0.24394321  0.73067045]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: No entry zone
Current timestep = 4427. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.95229816 -0.0063377   0.8881452   0.9127755 ]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: No entry zone
Current timestep = 4428. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.9791739  -0.28721142  0.98098934  0.6023892 ]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: No entry zone
Current timestep = 4429. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.98408175 -0.56024355  0.95511985  0.9256122 ]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: No entry zone
Current timestep = 4430. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.9503658  -0.26979232  0.901646    0.94980145]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: No entry zone
Current timestep = 4431. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.3175292  -0.36437267 -0.02405918  0.90306664]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: No entry zone
Current timestep = 4432. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.76296353 -0.47135246  0.9815173   0.9572444 ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: No entry zone
Current timestep = 4433. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.88686013 -0.26669842  0.61815524  0.9563167 ]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: No entry zone
Current timestep = 4434. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.9317657  -0.23974568  0.51901627  0.9525826 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: No entry zone
Current timestep = 4435. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.9521086  -0.69787353  0.93614435  0.98002946]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: No entry zone
Current timestep = 4436. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.99175143 -0.5092838   0.89926255  0.9544978 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: No entry zone
Current timestep = 4437. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[0.9044454 0.0347991 0.9275079 0.9737927]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: No entry zone
Current timestep = 4438. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.93401265 -0.5744148   0.96842384  0.944607  ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: No entry zone
Current timestep = 4439. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.46731782 -0.5702987   0.8919914   0.9534261 ]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: No entry zone
Current timestep = 4440. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.5253346  -0.64994     0.98495793  0.90978694]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: No entry zone
Current timestep = 4441. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.6755016  -0.32641798  0.9117279   0.97775936]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: No entry zone
Current timestep = 4442. State = [[-0.16079596  0.01049155  0.19010812  1.        ]]. Action = [[ 0.8993745  -0.22722465  0.87029886  0.91495943]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: No entry zone
Current timestep = 4443. State = [[-0.16204315 -0.00238961  0.2031492   1.        ]]. Action = [[-0.51752543 -0.7666627   0.8821151   0.89012265]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 4444. State = [[-0.15576477 -0.02525987  0.23962487  1.        ]]. Action = [[ 0.9626653  -0.5189592   0.98296523  0.89859223]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 4445. State = [[-0.13929802 -0.04510803  0.2759997   1.        ]]. Action = [[ 0.1862377  -0.43933594  0.9692197   0.96477556]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 4446. State = [[-0.1283121  -0.06704824  0.31489497  1.        ]]. Action = [[ 0.2102791  -0.61518556  0.94651484  0.9707508 ]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 4447. State = [[-0.1256863  -0.08387323  0.34483683  1.        ]]. Action = [[-0.32474613 -0.18194097  0.38448858  0.92243135]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 4448. State = [[-0.11608031 -0.08340845  0.3716467   1.        ]]. Action = [[0.99670005 0.3994577  0.8922248  0.7052927 ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 4449. State = [[-0.09319035 -0.06952259  0.40714586  1.        ]]. Action = [[0.83680296 0.51074314 0.7583252  0.84208846]]. Reward = [0.]
Curr episode timestep = 52
Scene graph at timestep 4449 is [False, True, False, True, False, False, True, False, False, True]
State prediction error at timestep 4449 is tensor(0.0007, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 4449 of 1
Current timestep = 4450. State = [[-0.06695228 -0.05697422  0.4342617   1.        ]]. Action = [[0.779058   0.6716418  0.81167793 0.8017199 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Above hoop
Current timestep = 4451. State = [[-0.06695228 -0.05697422  0.4342617   1.        ]]. Action = [[0.06040728 0.78974843 0.42961693 0.69864225]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Above hoop
Current timestep = 4452. State = [[-0.06695228 -0.05697422  0.4342617   1.        ]]. Action = [[-0.6336031   0.7410245   0.26067245  0.9121686 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Above hoop
Current timestep = 4453. State = [[-0.06695228 -0.05697422  0.4342617   1.        ]]. Action = [[0.31128323 0.68069696 0.33296072 0.81885886]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Above hoop
Current timestep = 4454. State = [[-0.06695228 -0.05697422  0.4342617   1.        ]]. Action = [[0.21067274 0.87032735 0.23451781 0.81743956]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Above hoop
Current timestep = 4455. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[0.21109271 0.88514185 0.01169884 0.7871231 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Above hoop
Current timestep = 4456. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[0.18099356 0.647918   0.14664078 0.73321104]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Above hoop
Current timestep = 4457. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[0.69962025 0.75393987 0.5800929  0.6963234 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Above hoop
Current timestep = 4458. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[-0.1412229   0.8908777   0.06606448  0.8322474 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Above hoop
Current timestep = 4459. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[-0.0907281   0.87670827  0.22763705  0.79240346]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Above hoop
Current timestep = 4460. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[0.11639833 0.7947345  0.16974759 0.83602905]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Above hoop
Current timestep = 4461. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[0.4579277  0.7313162  0.31403303 0.84035087]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Above hoop
Current timestep = 4462. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[0.00785351 0.7431338  0.3025571  0.6526656 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Above hoop
Current timestep = 4463. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[ 0.5177767   0.91855955 -0.09258342  0.82838714]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Above hoop
Current timestep = 4464. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[-0.00218928  0.94100356  0.05740941  0.7514062 ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Above hoop
Current timestep = 4465. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[0.50273156 0.85540056 0.32964718 0.82481456]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Above hoop
Current timestep = 4466. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[0.44248307 0.8949709  0.4979608  0.85701704]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Above hoop
Current timestep = 4467. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[ 0.27308786  0.8833097  -0.19640523  0.7991377 ]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Above hoop
Current timestep = 4468. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[0.46705246 0.8140092  0.4427129  0.8014405 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Above hoop
Current timestep = 4469. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[ 0.6363095   0.6252272  -0.03717071  0.7920735 ]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Above hoop
Current timestep = 4470. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[-0.07481289  0.9411502   0.35055184  0.8701546 ]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Above hoop
Current timestep = 4471. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[0.08721733 0.9482775  0.17807043 0.8568175 ]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Above hoop
Current timestep = 4472. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[-0.04207933  0.93741155  0.38488936  0.87759256]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Above hoop
Current timestep = 4473. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[0.07059979 0.8792596  0.26176405 0.68965244]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Above hoop
Current timestep = 4474. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[ 0.1596142   0.9015298  -0.05314237  0.82815623]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Above hoop
Current timestep = 4475. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[-0.14744532  0.8613548   0.22955513  0.7559149 ]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Above hoop
Current timestep = 4476. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[0.11525667 0.9186032  0.04278326 0.80976796]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Above hoop
Current timestep = 4477. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[0.4513812  0.8065541  0.04980516 0.83824134]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Above hoop
Current timestep = 4478. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[0.57250834 0.9497669  0.35633206 0.87768483]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Above hoop
Current timestep = 4479. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[0.10220754 0.96144736 0.4628936  0.74986553]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Above hoop
Current timestep = 4480. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[-0.09732038  0.8232932   0.17264056  0.7325132 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Above hoop
Current timestep = 4481. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[0.15499711 0.7399496  0.03982925 0.68405485]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Above hoop
Current timestep = 4482. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[-0.3648545   0.88002205 -0.1343255   0.7796997 ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Above hoop
Current timestep = 4483. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[0.5524163  0.9271947  0.40268898 0.72979724]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Above hoop
Current timestep = 4484. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[-0.14251757  0.93587804 -0.29784298  0.763687  ]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Above hoop
Current timestep = 4485. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[0.31121802 0.89804554 0.48935664 0.69944   ]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Above hoop
Current timestep = 4486. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[-0.20630515  0.7670877  -0.14143771  0.8502312 ]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Above hoop
Current timestep = 4487. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[0.09961879 0.9079293  0.26864493 0.69241476]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Above hoop
Current timestep = 4488. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[0.5519302  0.90371907 0.05799425 0.69601536]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Above hoop
Current timestep = 4489. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[0.4694736  0.8554374  0.4498539  0.81717503]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Above hoop
Current timestep = 4490. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[0.02693939 0.9186046  0.14756918 0.7302511 ]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Above hoop
Current timestep = 4491. State = [[-0.06695808 -0.05693986  0.4343677   1.        ]]. Action = [[0.03923488 0.8449044  0.31274414 0.5855615 ]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Above hoop
Current timestep = 4492. State = [[-0.06698896 -0.04228381  0.42961663  1.        ]]. Action = [[-0.07361275  0.9523599  -0.3743477   0.8803196 ]]. Reward = [0.]
Curr episode timestep = 95
Above hoop
Current timestep = 4493. State = [[-0.0674244  -0.01106911  0.41671273  1.        ]]. Action = [[ 0.19131362  0.8093841  -0.3013879   0.61088943]]. Reward = [0.]
Curr episode timestep = 96
Above hoop
Current timestep = 4494. State = [[-0.06212046  0.00659408  0.41140902  1.        ]]. Action = [[-0.64698464  0.7460587   0.15515554  0.79082155]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Above hoop
Current timestep = 4495. State = [[-0.06302416  0.02288687  0.40689275  1.        ]]. Action = [[-0.36569297  0.8026929  -0.31603187  0.5110023 ]]. Reward = [0.]
Curr episode timestep = 98
Above hoop
Current timestep = 4496. State = [[-0.070427    0.05392605  0.4001065   1.        ]]. Action = [[-0.03091764  0.83632016 -0.2054522   0.7367388 ]]. Reward = [0.]
Curr episode timestep = 99
Above hoop
Current timestep = 4497. State = [[-0.07600036  0.08227826  0.39215362  1.        ]]. Action = [[ 0.31762433  0.73126554 -0.3235162   0.6086991 ]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 4498. State = [[-0.25863796 -0.08752852  0.11362246  1.        ]]. Action = [[ 0.3291887  -0.35952902 -0.33199406  0.66841865]]. Reward = [0.]
Curr episode timestep = 101
Current timestep = 4499. State = [[-0.24896243 -0.09821136  0.10909922  1.        ]]. Action = [[ 0.7924843  -0.09071684  0.9706842   0.8173089 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 4500. State = [[-0.22910133 -0.10459136  0.13221207  1.        ]]. Action = [[ 0.48246622 -0.25537282  0.93705356  0.94276714]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 4501. State = [[-0.20176266 -0.11227108  0.15794711  1.        ]]. Action = [[ 0.9980297  -0.2251448   0.20905042  0.9577422 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 4502. State = [[-0.17938103 -0.11835573  0.16997753  1.        ]]. Action = [[ 0.9362917  -0.30278194  0.85382366  0.9658787 ]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: No entry zone
Current timestep = 4503. State = [[-0.17699862 -0.11998923  0.17177525  1.        ]]. Action = [[0.35922825 0.23830724 0.9544482  0.9807941 ]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 4504. State = [[-0.17580432 -0.12038695  0.17239761  1.        ]]. Action = [[ 0.6413536  -0.3911401   0.7807733   0.85329604]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 4505. State = [[-0.17570844 -0.12061003  0.17249551  1.        ]]. Action = [[ 0.665699   -0.07710505  0.62591076  0.9854002 ]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 4506. State = [[-0.17570844 -0.12061003  0.17249551  1.        ]]. Action = [[ 0.7720878  -0.26407182  0.96514666  0.9739671 ]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 4507. State = [[-0.1757637  -0.12065161  0.17252721  1.        ]]. Action = [[ 0.4348172  -0.49333656  0.5752497   0.7777419 ]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 4508. State = [[-0.1757637  -0.12065161  0.17252721  1.        ]]. Action = [[ 0.7756841  -0.15073645  0.86717534  0.9626062 ]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 4509. State = [[-0.1757637  -0.12065161  0.17252721  1.        ]]. Action = [[0.81619525 0.31171012 0.6411793  0.9859233 ]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 4510. State = [[-0.17586887 -0.12061702  0.17252162  1.        ]]. Action = [[0.87067175 0.17414165 0.9210211  0.9331875 ]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: No entry zone
Current timestep = 4511. State = [[-0.17594782 -0.12059104  0.1725175   1.        ]]. Action = [[ 0.9695735  -0.0825265   0.9597063   0.93121433]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: No entry zone
Current timestep = 4512. State = [[-0.17594782 -0.12059104  0.1725175   1.        ]]. Action = [[ 0.97579825 -0.09690058  0.9830538   0.89202213]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: No entry zone
Current timestep = 4513. State = [[-0.17594782 -0.12059104  0.1725175   1.        ]]. Action = [[ 0.96139264 -0.25455248  0.702191    0.9554713 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: No entry zone
Current timestep = 4514. State = [[-0.17594782 -0.12059104  0.1725175   1.        ]]. Action = [[0.8718581  0.13487315 0.87947464 0.9870417 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: No entry zone
Current timestep = 4515. State = [[-0.17594782 -0.12059104  0.1725175   1.        ]]. Action = [[ 0.9950781  -0.43202752  0.9193578   0.9857199 ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: No entry zone
Current timestep = 4516. State = [[-0.1725998  -0.12748161  0.18264306  1.        ]]. Action = [[ 0.10919976 -0.38957405  0.8144975   0.9367473 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 4517. State = [[-0.16858487 -0.13637069  0.19730373  1.        ]]. Action = [[0.94094706 0.21251369 0.98727214 0.9616327 ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: No entry zone
Current timestep = 4518. State = [[-0.16830578 -0.13704425  0.198168    1.        ]]. Action = [[ 0.3733673  -0.30790067  0.7825757   0.9577465 ]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: No entry zone
Current timestep = 4519. State = [[-0.16831237 -0.13710147  0.19820735  1.        ]]. Action = [[ 0.99755895 -0.20549744  0.7664788   0.9626901 ]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: No entry zone
Current timestep = 4520. State = [[-0.15366907 -0.14276594  0.21264984  1.        ]]. Action = [[ 0.9802165  -0.41441178  0.97252893  0.9527695 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 4521. State = [[-0.12010688 -0.1536331   0.25020993  1.        ]]. Action = [[ 0.8922832  -0.06609333  0.9745102   0.8259797 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 4522. State = [[-0.08396305 -0.16001847  0.29054356  1.        ]]. Action = [[ 0.9823153  -0.22580147  0.98486686  0.9693477 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 4523. State = [[-0.05485658 -0.16478758  0.3300781   1.        ]]. Action = [[ 0.4073112  -0.04520082  0.8180311   0.87382615]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 4524. State = [[-0.03053395 -0.15550111  0.364363    1.        ]]. Action = [[0.959095  0.7219672 0.7198944 0.7896726]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 4525. State = [[-0.00819734 -0.1309202   0.38529378  1.        ]]. Action = [[-0.02042061  0.9316094   0.04589498  0.7658646 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 4526. State = [[-0.00263442 -0.09637196  0.38537753  1.        ]]. Action = [[ 0.20616603  0.98115635 -0.29589093  0.81271625]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 4527. State = [[ 0.00668255 -0.06570108  0.38468987  1.        ]]. Action = [[0.27164412 0.51837957 0.3285036  0.77257323]]. Reward = [0.]
Curr episode timestep = 28
Above hoop
Current timestep = 4528. State = [[ 0.01376972 -0.03640176  0.39605507  1.        ]]. Action = [[-0.13934648  0.9917326   0.32202613  0.8004904 ]]. Reward = [0.]
Curr episode timestep = 29
Above hoop
Current timestep = 4529. State = [[1.2653375e-02 9.7329891e-04 4.0148920e-01 1.0000000e+00]]. Action = [[ 0.03777897  0.93687654 -0.12487507  0.7975719 ]]. Reward = [0.]
Curr episode timestep = 30
Above hoop
Current timestep = 4530. State = [[0.00947402 0.03831428 0.39901677 1.        ]]. Action = [[-0.1911549   0.9707227  -0.24811637  0.8176744 ]]. Reward = [0.]
Curr episode timestep = 31
Above hoop
Current timestep = 4531. State = [[0.00169116 0.07515164 0.38789976 1.        ]]. Action = [[-0.15562695  0.945477   -0.3425064   0.8300477 ]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 4532. State = [[-0.00303652  0.11156729  0.37559122  1.        ]]. Action = [[ 0.00240695  0.918242   -0.31513357  0.7494768 ]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 4533. State = [[-0.00269261  0.14933164  0.3643494   1.        ]]. Action = [[-0.12324244  0.9328668  -0.15505594  0.7359421 ]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 4534. State = [[-0.00850785  0.18512301  0.3521821   1.        ]]. Action = [[-0.09705794  0.8355452  -0.43564725  0.72147334]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 4535. State = [[-0.00865708  0.21082059  0.33720613  1.        ]]. Action = [[-0.06611097  0.28044057 -0.36101294  0.7070383 ]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 4536. State = [[-0.00802283  0.22490971  0.32267672  1.        ]]. Action = [[ 0.18261945  0.3821894  -0.5215459   0.516073  ]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 4537. State = [[0.00301111 0.23460564 0.31323546 1.        ]]. Action = [[ 0.27883184 -0.05619413  0.24451125  0.6905843 ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 4538. State = [[0.00698088 0.2364908  0.31268916 1.        ]]. Action = [[-0.24207765  0.02214909 -0.06809652  0.72094727]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 4539. State = [[0.0013275  0.24599065 0.30859056 1.        ]]. Action = [[-0.22904491  0.55246353 -0.32919186  0.61240673]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 4540. State = [[-0.00456101  0.259409    0.31393299  1.        ]]. Action = [[-0.1441319   0.11687088  0.7548777   0.7177069 ]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 4541. State = [[-0.00647614  0.26578572  0.32777905  1.        ]]. Action = [[-0.17278826 -0.02295905  0.18261707  0.58902454]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 4542. State = [[-0.01054147  0.27120665  0.3291014   1.        ]]. Action = [[-0.13238204  0.21733952 -0.31858075  0.7055948 ]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 4543. State = [[-0.01202324  0.26985118  0.33375767  1.        ]]. Action = [[-0.18860424 -0.37666655  0.40721333  0.51598525]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 4544. State = [[-0.01514301  0.27043003  0.3414676   1.        ]]. Action = [[0.06209207 0.31510317 0.16256464 0.513528  ]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 4545. State = [[-0.01737993  0.27021667  0.345294    1.        ]]. Action = [[-0.16069168 -0.24322712 -0.18086368  0.62778735]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 4546. State = [[-0.01732381  0.26444882  0.34609365  1.        ]]. Action = [[-0.34397185 -0.3449427   0.00977933  0.41535628]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 4547. State = [[-0.02166832  0.26272386  0.3503894   1.        ]]. Action = [[-0.21428365  0.01271856  0.0628475   0.65658   ]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 4548. State = [[-0.02997749  0.2582424   0.36101443  1.        ]]. Action = [[-0.42871392 -0.34514922  0.4340204   0.59812605]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 4549. State = [[-0.04625088  0.24443662  0.37563324  1.        ]]. Action = [[-0.3484403  -0.43285608  0.28594542  0.4558035 ]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 4550. State = [[-0.05921664  0.22636162  0.3844459   1.        ]]. Action = [[-0.00283748 -0.40715325  0.03316522  0.5611701 ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 4551. State = [[-0.06242761  0.21235628  0.3920265   1.        ]]. Action = [[-0.34292865 -0.30488288  0.31490076  0.43004847]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 4552. State = [[-0.0721135   0.19971417  0.39762524  1.        ]]. Action = [[-0.16869247 -0.3664235  -0.1461733   0.5375755 ]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 4553. State = [[-0.08148397  0.19866478  0.3959003   1.        ]]. Action = [[-0.17057323  0.37236774 -0.04548436  0.6356225 ]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 4554. State = [[-0.08594326  0.19880693  0.4017695   1.        ]]. Action = [[ 0.0027616  -0.27914798  0.28570664  0.6287005 ]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 4555. State = [[-0.08587535  0.1944888   0.40556708  1.        ]]. Action = [[-0.4299401   0.6871443   0.3326882   0.68376493]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 4556. State = [[-0.08596158  0.1942092   0.40588474  1.        ]]. Action = [[-0.21383023 -0.3098415   0.44595373  0.6492239 ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 4557. State = [[-0.0859779   0.19412439  0.40586218  1.        ]]. Action = [[-0.318071   -0.42945045  0.2520547   0.63856876]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 4558. State = [[-0.0859779   0.19412439  0.40586218  1.        ]]. Action = [[0.25709057 0.46270204 0.35560083 0.6885495 ]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 4559. State = [[-0.08597531  0.19406587  0.40595472  1.        ]]. Action = [[0.14033377 0.29793715 0.37447786 0.65997267]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 4560. State = [[-0.08597531  0.19406587  0.40595472  1.        ]]. Action = [[ 0.2717116  -0.0124464   0.22000825  0.6256745 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 4561. State = [[-0.08597531  0.19406587  0.40595472  1.        ]]. Action = [[-0.05638576 -0.1864053   0.4672469   0.77933645]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 4562. State = [[-0.08604211  0.19391982  0.40583113  1.        ]]. Action = [[ 0.3356073  -0.04594851  0.48759413  0.6698978 ]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 4563. State = [[-0.08604211  0.19391982  0.40583113  1.        ]]. Action = [[ 0.1133616  -0.22922206  0.41660583  0.58258784]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 4564. State = [[-0.0869272   0.19329007  0.4054898   1.        ]]. Action = [[-0.13988572 -0.03950047 -0.02272385  0.48862505]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 4565. State = [[-0.09074789  0.19019662  0.406374    1.        ]]. Action = [[ 0.04946375 -0.4194485   0.30466974  0.7095232 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 4566. State = [[-0.09318668  0.18845424  0.4061253   1.        ]]. Action = [[ 0.14925253 -0.21861094  0.4829266   0.5923753 ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 4567. State = [[-0.09123389  0.17782256  0.40511647  1.        ]]. Action = [[ 0.41406655 -0.6615468  -0.02001375  0.45000386]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 4568. State = [[-0.08804426  0.1643527   0.40961966  1.        ]]. Action = [[ 0.11680317 -0.17757857  0.13432872  0.45615482]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 4569. State = [[-0.08488617  0.15115112  0.41273335  1.        ]]. Action = [[ 0.2361157  -0.4344554  -0.04491633  0.6259172 ]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 4570. State = [[-0.08059198  0.14139202  0.41206077  1.        ]]. Action = [[-0.09491801 -0.001827    0.18644714  0.6219436 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 4571. State = [[-0.08148345  0.14645942  0.4082818   1.        ]]. Action = [[-0.01333082  0.57063913 -0.20735037  0.73471725]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 4572. State = [[-0.08200974  0.15090862  0.40621188  1.        ]]. Action = [[-0.23062992  0.2345047   0.7915031   0.43700767]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 4573. State = [[-0.08185633  0.15125003  0.405188    1.        ]]. Action = [[-0.23334473 -0.12076449  0.45664144  0.6880387 ]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 4574. State = [[-0.08170541  0.15130794  0.40464723  1.        ]]. Action = [[-0.23360592  0.27415514  0.78709364  0.7577684 ]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 4575. State = [[-0.08167303  0.15138674  0.40424275  1.        ]]. Action = [[ 0.23697007 -0.23638225  0.26331604  0.5312568 ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 4576. State = [[-0.08047275  0.14863385  0.40500823  1.        ]]. Action = [[ 0.01065946 -0.38265252  0.10446358  0.60343504]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 4577. State = [[-0.07930131  0.14695789  0.40673503  1.        ]]. Action = [[-0.24615222  0.00940442  0.24232948  0.60815644]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 4578. State = [[-0.07942668  0.14513755  0.40449664  1.        ]]. Action = [[ 0.04586101 -0.09371942 -0.19826883  0.607172  ]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 4579. State = [[-0.07863675  0.14301474  0.40157634  1.        ]]. Action = [[0.27777278 0.0899663  0.13138604 0.74344695]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 4580. State = [[-0.07786957  0.14277473  0.40121964  1.        ]]. Action = [[-0.37324536  0.21732676  0.4143293   0.66323864]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 4581. State = [[-0.0772206   0.14283808  0.39975202  1.        ]]. Action = [[ 0.0635134   0.03681135 -0.0899713   0.49780536]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 4582. State = [[-0.07779787  0.14641616  0.39886692  1.        ]]. Action = [[-0.23209119  0.28705144  0.2769451   0.72686994]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 4583. State = [[-0.08000655  0.15270174  0.39971545  1.        ]]. Action = [[-0.06763107  0.2646165   0.02711225  0.4435897 ]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 4584. State = [[-0.08154406  0.1568441   0.40019983  1.        ]]. Action = [[0.3647232  0.5721512  0.5210264  0.52119684]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 4585. State = [[-0.08179323  0.15729459  0.4002304   1.        ]]. Action = [[0.10621095 0.00414252 0.392812   0.48836505]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 4586. State = [[-0.08182558  0.1573586   0.4002304   1.        ]]. Action = [[-0.3326435  -0.13078159  0.5650983   0.53821063]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 4587. State = [[-0.08182558  0.1573586   0.4002304   1.        ]]. Action = [[-0.44132274 -0.46417052  0.31379342  0.5281277 ]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 4588. State = [[-0.08182558  0.1573586   0.4002304   1.        ]]. Action = [[-0.06410754  0.21019244  0.48707008  0.6434331 ]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 4589. State = [[-0.08182558  0.1573586   0.4002304   1.        ]]. Action = [[0.28689957 0.39423132 0.4559939  0.4474659 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 4590. State = [[-0.08214622  0.15553378  0.40506813  1.        ]]. Action = [[-0.39767337 -0.27509874  0.22033739  0.63647294]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 4591. State = [[-0.08287984  0.15472457  0.4117787   1.        ]]. Action = [[0.2171719  0.29586005 0.5560117  0.66625714]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 4592. State = [[-0.08295572  0.15467422  0.4124678   1.        ]]. Action = [[-0.29037905 -0.3180645   0.08679748  0.6720691 ]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 4593. State = [[-0.08296265  0.15466963  0.41253048  1.        ]]. Action = [[ 0.31359613 -0.09707576  0.4754671   0.6902492 ]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 4594. State = [[-0.08296265  0.15466963  0.41253048  1.        ]]. Action = [[-0.19103861  0.19387889  0.43796015  0.7007055 ]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 4595. State = [[-0.08296265  0.15466963  0.41253048  1.        ]]. Action = [[-0.09303331  0.57445526  0.3379104   0.6252904 ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 4596. State = [[-0.08296265  0.15466963  0.41253048  1.        ]]. Action = [[0.21651947 0.06310201 0.06361401 0.603384  ]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 4597. State = [[-0.08296265  0.15466963  0.41253048  1.        ]]. Action = [[-0.07568377  0.33950865  0.49547613  0.716431  ]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 4598. State = [[-0.08296265  0.15466963  0.41253048  1.        ]]. Action = [[0.18191314 0.3678962  0.33348203 0.57253087]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 4599. State = [[-0.08296265  0.15466963  0.41253048  1.        ]]. Action = [[ 0.42320526 -0.18337649  0.32076657  0.63615656]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 4600. State = [[-0.25932512 -0.0952783   0.09933262  1.        ]]. Action = [[-0.18055099  0.54682684  0.41262817  0.7166977 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 4601. State = [[-0.25375766 -0.10971547  0.09404162  1.        ]]. Action = [[ 0.45636606 -0.21558028  0.96200347  0.92939115]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 4602. State = [[-0.24188934 -0.11584216  0.11423633  1.        ]]. Action = [[ 0.43154025 -0.16014194  0.74375796  0.9970622 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 4603. State = [[-0.21787155 -0.12257694  0.1448466   1.        ]]. Action = [[ 0.8587655  -0.2276988   0.9569342   0.99136806]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 4604. State = [[-0.1828414  -0.12923907  0.18293849  1.        ]]. Action = [[0.9559505  0.05529141 0.9446969  0.9896419 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 4605. State = [[-0.15765011 -0.13468434  0.21866271  1.        ]]. Action = [[ 0.0369612  -0.17995816  0.98270357  0.9855249 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 4606. State = [[-0.13781388 -0.14143582  0.2571352   1.        ]]. Action = [[ 0.94616127 -0.24438179  0.7994095   0.969429  ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 4607. State = [[-0.10675032 -0.14327127  0.2933926   1.        ]]. Action = [[0.7861364 0.2657702 0.8762152 0.976717 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 4608. State = [[-0.07553106 -0.1389789   0.33282894  1.        ]]. Action = [[0.89817536 0.16246462 0.9512769  0.9571626 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 4609. State = [[-0.05845075 -0.12716989  0.37074357  1.        ]]. Action = [[-0.4561478   0.57220256  0.81407166  0.9539418 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 4610. State = [[-0.05523957 -0.10964807  0.39686632  1.        ]]. Action = [[0.15144873 0.28172565 0.4882865  0.702057  ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 4611. State = [[-0.05134463 -0.10333605  0.41100544  1.        ]]. Action = [[0.10367775 0.7787446  0.41631234 0.6234484 ]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: Workspace boundary
Current timestep = 4612. State = [[-0.04591858 -0.09094269  0.4154667   1.        ]]. Action = [[0.58389926 0.6509824  0.03490722 0.76517534]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 4613. State = [[-0.03897712 -0.07955535  0.4174665   1.        ]]. Action = [[0.4346274  0.8870902  0.03612292 0.79800296]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Current timestep = 4614. State = [[-0.03856705 -0.06179293  0.41669697  1.        ]]. Action = [[-0.21998978  0.9335171  -0.10150337  0.85850286]]. Reward = [0.]
Curr episode timestep = 13
Above hoop
Current timestep = 4615. State = [[-0.04224948 -0.02622568  0.4122074   1.        ]]. Action = [[ 0.08729422  0.96975327 -0.26580846  0.7112782 ]]. Reward = [0.]
Curr episode timestep = 14
Above hoop
Current timestep = 4616. State = [[-0.04325813  0.00840252  0.40578115  1.        ]]. Action = [[ 0.2810501   0.91457844 -0.1966641   0.6778822 ]]. Reward = [0.]
Curr episode timestep = 15
Above hoop
Current timestep = 4617. State = [[-0.03222172  0.04355536  0.39721185  1.        ]]. Action = [[ 0.2549708   0.8065903  -0.09020489  0.7246045 ]]. Reward = [0.]
Curr episode timestep = 16
Above hoop
Current timestep = 4618. State = [[-0.02924404  0.07626942  0.39219525  1.        ]]. Action = [[-0.36868763  0.8529918  -0.2121808   0.6822169 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 4619. State = [[-0.04049719  0.10862304  0.38472223  1.        ]]. Action = [[-0.20882809  0.75380313 -0.38473248  0.6850233 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 4620. State = [[-0.04266554  0.13209563  0.37570006  1.        ]]. Action = [[0.5905628  0.5102112  0.00989068 0.69136655]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 4621. State = [[-0.02783839  0.1446157   0.3656388   1.        ]]. Action = [[-0.02354997 -0.09922546 -0.37073004  0.75849247]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 4622. State = [[-0.01932816  0.14799581  0.3556555   1.        ]]. Action = [[ 0.40883076  0.19372618 -0.18324918  0.4842856 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 4623. State = [[-0.01131759  0.15618205  0.34820083  1.        ]]. Action = [[-0.1602301   0.22814405 -0.1335429   0.727278  ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 4624. State = [[-0.01347868  0.16581474  0.3456419   1.        ]]. Action = [[-0.27353853  0.15296698 -0.1652596   0.7053714 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 4625. State = [[-0.01654355  0.17158817  0.34494716  1.        ]]. Action = [[0.00974941 0.09861088 0.02525902 0.6111131 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 4626. State = [[-0.01670946  0.17258054  0.34694386  1.        ]]. Action = [[ 0.01565623 -0.06644481  0.41522074  0.6245053 ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 4627. State = [[-0.01624341  0.17122279  0.3461994   1.        ]]. Action = [[ 0.1967411  -0.05557728 -0.32752705  0.64406693]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 4628. State = [[-0.01531393  0.16877441  0.3418382   1.        ]]. Action = [[ 0.1481005  -0.11573875 -0.30206263  0.6700095 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 4629. State = [[-0.01121732  0.16913076  0.33919325  1.        ]]. Action = [[-0.03199863  0.11052549  0.4167272   0.74271894]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 4630. State = [[-0.0101942   0.17890148  0.34577656  1.        ]]. Action = [[0.14582396 0.6101426  0.12675834 0.71083236]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 4631. State = [[-0.00722133  0.1814497   0.3563705   1.        ]]. Action = [[-0.01905084 -0.5111862   0.35284984  0.54558384]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 4632. State = [[-0.00956022  0.18690456  0.36269045  1.        ]]. Action = [[-0.54785216  0.59214985 -0.12188441  0.52170277]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 4633. State = [[-0.01910348  0.20326789  0.3636377   1.        ]]. Action = [[-0.17245495  0.31178832  0.19797969  0.58111155]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 4634. State = [[-0.02279729  0.20863244  0.36465767  1.        ]]. Action = [[ 0.24990487  0.00217807 -0.03904182  0.65563583]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 4635. State = [[-0.02470522  0.21374345  0.36848733  1.        ]]. Action = [[-0.2801081   0.24412787  0.2992128   0.62774205]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 4636. State = [[-0.02597108  0.22138122  0.3789458   1.        ]]. Action = [[-0.12003118  0.05165792  0.28994298  0.59849405]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 4637. State = [[-0.02679588  0.2210068   0.39408132  1.        ]]. Action = [[-0.18329996 -0.21190941  0.4745618   0.5362897 ]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 4638. State = [[-0.02756056  0.21427274  0.40260947  1.        ]]. Action = [[ 0.03312659 -0.28117204 -0.26789957  0.6325445 ]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 4639. State = [[-0.03058274  0.21802226  0.4016067   1.        ]]. Action = [[-0.08119375  0.52627873 -0.14964616  0.53125215]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 4640. State = [[-0.0380981   0.23306106  0.39496613  1.        ]]. Action = [[-0.07067823  0.49457097 -0.36599803  0.6432762 ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 4641. State = [[-0.0465554  0.2498544  0.387885   1.       ]]. Action = [[-0.2155348   0.46228373  0.11511111  0.65535164]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 4642. State = [[-0.05484649  0.26292223  0.39027384  1.        ]]. Action = [[-0.37124288  0.04200649  0.27890778  0.6034126 ]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 4643. State = [[-0.05689895  0.26215094  0.39646986  1.        ]]. Action = [[-0.1453591  -0.4243511   0.14951265  0.64600444]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 4644. State = [[-0.05690397  0.25640425  0.40335408  1.        ]]. Action = [[ 0.23950422 -0.26454526  0.3779875   0.49938023]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 4645. State = [[-0.05778801  0.25534797  0.4050135   1.        ]]. Action = [[-0.44910204 -0.09630948  0.43667936  0.6242622 ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 4646. State = [[-0.05782871  0.2549078   0.40514994  1.        ]]. Action = [[ 0.12018371 -0.26641887  0.30625153  0.6183461 ]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 4647. State = [[-0.05792467  0.2548594   0.4052522   1.        ]]. Action = [[-0.20991176 -0.7642221   0.24659634  0.6106577 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 4648. State = [[-0.05592785  0.24986795  0.40776673  1.        ]]. Action = [[ 0.35685134 -0.2704016   0.17953765  0.5193211 ]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 4649. State = [[-0.05339209  0.24346088  0.41244513  1.        ]]. Action = [[-0.19468439 -0.3368969   0.35660207  0.66534495]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 4650. State = [[-0.0539197   0.24231789  0.41331983  1.        ]]. Action = [[-0.37661523 -0.11724758  0.02077544  0.5476303 ]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 4651. State = [[-0.05550297  0.24147841  0.41402465  1.        ]]. Action = [[-0.2575403  -0.10722005 -0.06770003  0.6167455 ]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 4652. State = [[-0.06201698  0.24111891  0.41362107  1.        ]]. Action = [[-0.13881868 -0.00717902 -0.13502163  0.61443806]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 4653. State = [[-0.06954699  0.2359307   0.41013578  1.        ]]. Action = [[-0.458223   -0.40045834 -0.24553311  0.58184576]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 4654. State = [[-0.079087    0.22882429  0.40613735  1.        ]]. Action = [[ 0.10603476 -0.06112862  0.30559325  0.54711795]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 4655. State = [[-0.08322482  0.22583887  0.40594348  1.        ]]. Action = [[0.13289154 0.05615938 0.6012356  0.6675017 ]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 4656. State = [[-0.08474481  0.22492066  0.40534192  1.        ]]. Action = [[ 0.01223326  0.02156067 -0.05149204  0.50636387]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 4657. State = [[-0.08491517  0.22506446  0.405234    1.        ]]. Action = [[-0.09210455 -0.7403839   0.26006484  0.4642179 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 4658. State = [[-0.08491517  0.22506446  0.405234    1.        ]]. Action = [[ 0.11518562 -0.47022545  0.4410889   0.45535326]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 4659. State = [[-0.08182753  0.21703678  0.4030052   1.        ]]. Action = [[ 0.43169022 -0.48781782 -0.18675202  0.5603224 ]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 4660. State = [[-0.078683    0.20311284  0.40162072  1.        ]]. Action = [[ 0.11712801 -0.34653914  0.18757546  0.5574802 ]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 4661. State = [[-0.07693448  0.19496231  0.40487555  1.        ]]. Action = [[-0.23795563 -0.12067884  0.3267877   0.59936535]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 4662. State = [[-0.07289869  0.19122507  0.40573412  1.        ]]. Action = [[ 0.6036885  -0.01877534  0.17376173  0.6857779 ]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 4663. State = [[-0.06868765  0.18775462  0.40670606  1.        ]]. Action = [[-0.02726358 -0.0965147   0.2953279   0.5908165 ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 4664. State = [[-0.06792267  0.18653461  0.4063651   1.        ]]. Action = [[-0.02724975 -0.06615907 -0.06054652  0.63129234]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 4665. State = [[-0.06673664  0.1859836   0.4010033   1.        ]]. Action = [[-0.14483869  0.08309054 -0.50895673  0.5331826 ]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 4666. State = [[-0.06379749  0.19049396  0.39269114  1.        ]]. Action = [[0.3799845  0.39495122 0.24983501 0.59651303]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 4667. State = [[-0.06386114  0.19243066  0.3923544   1.        ]]. Action = [[-0.08432943 -0.12286603  0.12621498  0.59959674]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 4668. State = [[-0.06155923  0.18776491  0.39265323  1.        ]]. Action = [[ 0.05875468 -0.36473882 -0.07867467  0.66080046]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 4669. State = [[-0.06235741  0.19031206  0.39375728  1.        ]]. Action = [[-0.13468647  0.50035477  0.14260674  0.6432462 ]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 4670. State = [[-0.06370665  0.19393691  0.39207143  1.        ]]. Action = [[-0.08573943 -0.03408408 -0.3994426   0.4469763 ]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 4671. State = [[-0.06169726  0.1913318   0.38919505  1.        ]]. Action = [[ 0.3249383  -0.24341625  0.13525403  0.59631824]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 4672. State = [[-0.0587692   0.18552566  0.39096096  1.        ]]. Action = [[ 0.01986265 -0.26610595  0.27984953  0.59419084]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 4673. State = [[-0.05617432  0.1821472   0.3973921   1.        ]]. Action = [[-0.0099088   0.045681    0.25226915  0.70222116]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 4674. State = [[-0.0559023   0.1814588   0.39850217  1.        ]]. Action = [[0.05975461 0.01263177 0.3960631  0.6089587 ]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 4675. State = [[-0.05167918  0.18476133  0.40352964  1.        ]]. Action = [[0.53664446 0.27893257 0.21113157 0.607911  ]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 4676. State = [[-0.04319258  0.19405141  0.41239524  1.        ]]. Action = [[0.23382998 0.38510013 0.22567415 0.54958606]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 4677. State = [[-0.03807747  0.20544972  0.41717488  1.        ]]. Action = [[-0.2199589   0.21529603  0.03975403  0.6507492 ]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 4678. State = [[-0.04156037  0.21700247  0.41913587  1.        ]]. Action = [[-0.1729865   0.5469105  -0.09111267  0.5938307 ]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 4679. State = [[-0.04874854  0.23548259  0.41323128  1.        ]]. Action = [[-0.13390452  0.5413933  -0.19135362  0.64765096]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 4680. State = [[-0.0501272   0.25315422  0.40572953  1.        ]]. Action = [[-0.19850707  0.25752676 -0.21171659  0.6886356 ]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 4681. State = [[-0.05237291  0.25926545  0.40349814  1.        ]]. Action = [[-0.10903424 -0.12330884 -0.08900368  0.47851086]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 4682. State = [[-0.05225609  0.25955924  0.40002748  1.        ]]. Action = [[ 0.06488919 -0.04851478 -0.34545636  0.58363366]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 4683. State = [[-0.05171561  0.25899437  0.3936885   1.        ]]. Action = [[-0.37248743 -0.13701063  0.06153178  0.6625546 ]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 4684. State = [[-0.05390156  0.25391227  0.39683473  1.        ]]. Action = [[-0.45237243 -0.42211962  0.11475337  0.48250365]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 4685. State = [[-0.06060565  0.24924512  0.39967042  1.        ]]. Action = [[-0.06473839 -0.3455398   0.5901382   0.44552612]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 4686. State = [[-0.06713607  0.24576944  0.40089536  1.        ]]. Action = [[-0.45997858 -0.20867908  0.02075458  0.52305627]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 4687. State = [[-0.07504262  0.23607688  0.40138617  1.        ]]. Action = [[ 0.01065886 -0.34320253 -0.01504248  0.44057798]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 4688. State = [[-0.07695534  0.22882022  0.40151587  1.        ]]. Action = [[ 0.04704297 -0.3086667   0.5105765   0.5946038 ]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 4689. State = [[-0.07709657  0.22667244  0.40291157  1.        ]]. Action = [[ 0.2806642  -0.6503526   0.7186028   0.44763196]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 4690. State = [[-0.07648009  0.21931547  0.3985915   1.        ]]. Action = [[ 0.32689965 -0.53523165 -0.46398246  0.5698712 ]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 4691. State = [[-0.07820506  0.2076365   0.3907978   1.        ]]. Action = [[-0.18347734 -0.0662325   0.26252794  0.50524545]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 4692. State = [[-0.07755268  0.20363396  0.39528838  1.        ]]. Action = [[ 0.5603492  -0.39440405  0.638018    0.57348466]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 4693. State = [[-0.07751398  0.20347513  0.39543143  1.        ]]. Action = [[-0.18383676 -0.31311387  0.7011411   0.5589495 ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 4694. State = [[-0.07402682  0.19603004  0.39872557  1.        ]]. Action = [[ 0.43065286 -0.44556546  0.19021928  0.7037828 ]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 4695. State = [[-0.07288043  0.18594351  0.4077937   1.        ]]. Action = [[-0.39081502 -0.10397243  0.32739615  0.61916673]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 4696. State = [[-0.07392454  0.18158264  0.4147703   1.        ]]. Action = [[ 0.43393803 -0.08354485  0.6655024   0.47375178]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 4697. State = [[-0.07331628  0.17424776  0.41618493  1.        ]]. Action = [[ 0.21560013 -0.4287396  -0.02452588  0.6793214 ]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 4698. State = [[-0.07445659  0.1668889   0.4159874   1.        ]]. Action = [[0.0585295  0.59493613 0.00437987 0.55584   ]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 4699. State = [[-0.07491327  0.16354826  0.4163576   1.        ]]. Action = [[-0.30278343  0.0887531   0.38682032  0.6772728 ]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 4700. State = [[-0.07269636  0.16039306  0.4154765   1.        ]]. Action = [[ 0.5030298  -0.06721073 -0.05165631  0.61092865]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 4701. State = [[-0.07145253  0.15801238  0.41493925  1.        ]]. Action = [[-0.5435096   0.43109548  0.18701458  0.7211988 ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 4702. State = [[-0.2646026  -0.02426664  0.10677525  1.        ]]. Action = [[-0.06571454 -0.05993408 -0.12151772  0.61845136]]. Reward = [0.]
Curr episode timestep = 101
Current timestep = 4703. State = [[-0.26666054 -0.02622781  0.09196858  1.        ]]. Action = [[-0.7076374  -0.19981885  0.9649346   0.9874015 ]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Current timestep = 4704. State = [[-0.2664189  -0.02628289  0.09199994  1.        ]]. Action = [[-0.57363784 -0.38171673  0.838639    0.95407367]]. Reward = [0.]
Curr episode timestep = 1
Action ignored: Workspace boundary
Current timestep = 4705. State = [[-0.25300345 -0.03232988  0.10007828  1.        ]]. Action = [[ 0.9337634 -0.2631092  0.9630506  0.9611137]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 4706. State = [[-0.22574633 -0.04709919  0.12441992  1.        ]]. Action = [[ 0.73658895 -0.3939625   0.9603429   0.93144107]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 4707. State = [[-0.19861563 -0.05905976  0.1603866   1.        ]]. Action = [[ 0.53893924 -0.19753754  0.984663    0.97870946]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 4708. State = [[-0.18323953 -0.06415483  0.1861387   1.        ]]. Action = [[ 0.9658462  -0.46845496  0.9861777   0.85448265]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 4709. State = [[-0.17879243 -0.06612944  0.18968925  1.        ]]. Action = [[ 0.9769008  -0.71987325  0.9391166   0.98092794]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 4710. State = [[-0.17902261 -0.06675785  0.1897495   1.        ]]. Action = [[ 0.6597973  -0.22996694  0.9720181   0.83930147]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 4711. State = [[-0.17917101 -0.06679569  0.18975115  1.        ]]. Action = [[ 0.9461528  -0.08820784  0.8826921   0.9280257 ]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 4712. State = [[-0.17937258 -0.06675605  0.1897867   1.        ]]. Action = [[ 0.9818227 -0.5339358  0.9746014  0.9330714]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 4713. State = [[-0.17863408 -0.06680711  0.19017124  1.        ]]. Action = [[ 0.88521135 -0.1713947   0.9560777   0.96017647]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 4714. State = [[-0.17723978 -0.07734136  0.20254986  1.        ]]. Action = [[-0.00464171 -0.6380849   0.95281863  0.8922591 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 4715. State = [[-0.16350201 -0.0950834   0.2385384   1.        ]]. Action = [[ 0.99666023 -0.4108473   0.9543301   0.96701276]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 4716. State = [[-0.13641691 -0.11008435  0.27699968  1.        ]]. Action = [[ 0.3253548  -0.19153708  0.9535074   0.98588693]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 4717. State = [[-0.1115652  -0.11396752  0.31531382  1.        ]]. Action = [[0.8680917  0.1008817  0.869396   0.90579164]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 4718. State = [[-0.08717227 -0.11862056  0.3534183   1.        ]]. Action = [[ 0.45398486 -0.36787432  0.93671346  0.86215794]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 4719. State = [[-0.06443037 -0.12390454  0.38646036  1.        ]]. Action = [[ 0.95126843 -0.02750105  0.45791626  0.8584609 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 4720. State = [[-0.04319001 -0.12493657  0.4019127   1.        ]]. Action = [[-0.35525697  0.69674826  0.72298217  0.7839749 ]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 4721. State = [[-0.03935425 -0.12518322  0.40464732  1.        ]]. Action = [[-0.04368562  0.931545    0.45203936  0.6417556 ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 4722. State = [[-0.03767403 -0.1132474   0.40537697  1.        ]]. Action = [[0.00355184 0.8929992  0.00186217 0.8398981 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 4723. State = [[-0.03682047 -0.10033662  0.4068167   1.        ]]. Action = [[0.3328557  0.9340699  0.5318222  0.81502664]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 4724. State = [[-0.03533751 -0.08428735  0.40554652  1.        ]]. Action = [[ 0.11080527  0.8600348  -0.04811978  0.8097153 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 4725. State = [[-0.03196653 -0.05225316  0.4032247   1.        ]]. Action = [[ 0.20589554  0.9325366  -0.00952512  0.8253728 ]]. Reward = [0.]
Curr episode timestep = 22
Above hoop
Current timestep = 4726. State = [[-0.02522431 -0.01584887  0.40791097  1.        ]]. Action = [[0.19528902 0.89186335 0.21786463 0.724877  ]]. Reward = [0.]
Curr episode timestep = 23
Above hoop
Current timestep = 4727. State = [[-0.01900844  0.00351901  0.4109858   1.        ]]. Action = [[-0.55996305  0.9049399   0.20904624  0.80155325]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Above hoop
Current timestep = 4728. State = [[-0.01748459  0.0219497   0.40871522  1.        ]]. Action = [[-0.02978677  0.9400549  -0.3808745   0.81263304]]. Reward = [0.]
Curr episode timestep = 25
Above hoop
Current timestep = 4729. State = [[-0.02204649  0.05440541  0.39996952  1.        ]]. Action = [[ 0.14263773  0.83288145 -0.18317258  0.8170552 ]]. Reward = [0.]
Curr episode timestep = 26
Above hoop
Current timestep = 4730. State = [[-0.01263485  0.08817969  0.39437494  1.        ]]. Action = [[0.31470168 0.8864161  0.10842597 0.7361603 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 4731. State = [[-0.00999109  0.12300147  0.39458668  1.        ]]. Action = [[-0.4685688   0.8534243  -0.03672636  0.67635775]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 4732. State = [[-0.02018183  0.15295708  0.39216876  1.        ]]. Action = [[ 0.2839787   0.7157327  -0.15856248  0.63932025]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 4733. State = [[-0.01355194  0.17751278  0.38444564  1.        ]]. Action = [[-0.08403373  0.41974723 -0.1343723   0.64274716]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 4734. State = [[-0.00856029  0.19140738  0.3812987   1.        ]]. Action = [[ 0.15279078  0.13393831 -0.04700023  0.6472759 ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 4735. State = [[-0.0061137   0.20086734  0.3761532   1.        ]]. Action = [[ 0.03810906  0.34092557 -0.31769323  0.5884317 ]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 4736. State = [[-0.0066615   0.2115568   0.36335364  1.        ]]. Action = [[-0.23288786  0.14654756 -0.2659375   0.58131003]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 4737. State = [[-0.0073272   0.21317522  0.35594395  1.        ]]. Action = [[ 0.32923114 -0.1784848  -0.3473543   0.5217464 ]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 4738. State = [[7.9060509e-04 2.1703441e-01 3.4690830e-01 1.0000000e+00]]. Action = [[0.08054507 0.2710905  0.05241942 0.5543797 ]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 4739. State = [[0.00819536 0.21635285 0.343373   1.        ]]. Action = [[ 0.45179558 -0.23635459 -0.1079942   0.5454054 ]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 4740. State = [[0.0192347  0.21111122 0.33636114 1.        ]]. Action = [[ 0.023947  -0.2874328 -0.2212491  0.5281205]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 4741. State = [[0.02315227 0.20677453 0.33322147 1.        ]]. Action = [[ 0.04881418 -0.00737172 -0.04186767  0.5591612 ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 4742. State = [[0.0273397  0.20457886 0.33120483 1.        ]]. Action = [[ 0.43134177 -0.0552299   0.05122161  0.64487946]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 4743. State = [[0.03646015 0.20404024 0.32698712 1.        ]]. Action = [[-0.12620687  0.07711339 -0.21941495  0.5495136 ]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 4744. State = [[0.03637217 0.20958453 0.32241538 1.        ]]. Action = [[-0.283103    0.27499986 -0.20805943  0.6453421 ]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 4745. State = [[0.03225105 0.21777302 0.31620845 1.        ]]. Action = [[ 0.06934631  0.30453908 -0.22391552  0.554795  ]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 4746. State = [[0.03364865 0.21572429 0.311052   1.        ]]. Action = [[ 0.0727725 -0.5517904  0.1433487  0.530627 ]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 4747. State = [[0.03807137 0.20224245 0.3151104  1.        ]]. Action = [[-0.01982242 -0.4680581   0.14296651  0.6178149 ]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 4748. State = [[0.04286984 0.18898334 0.32474864 1.        ]]. Action = [[ 0.07048953 -0.3097697   0.36874986  0.5903995 ]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 4749. State = [[0.04567099 0.1792999  0.33220038 1.        ]]. Action = [[-0.09318656 -0.14054847 -0.15839589  0.54895043]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 4750. State = [[0.04269061 0.18008056 0.32787213 1.        ]]. Action = [[-0.36619043  0.14120936 -0.39970875  0.5156609 ]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 4751. State = [[0.03878232 0.18700872 0.3259815  1.        ]]. Action = [[-0.20717525  0.26682878  0.072438    0.6248821 ]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 4752. State = [[0.03252412 0.1988976  0.3269056  1.        ]]. Action = [[-0.36237645  0.24858999  0.17623949  0.49021482]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 4753. State = [[0.02657635 0.19707303 0.3341066  1.        ]]. Action = [[-0.33499795 -0.4836676   0.22627175  0.45750916]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 4754. State = [[0.01859699 0.18454735 0.34345484 1.        ]]. Action = [[-0.02776361 -0.3106345   0.35784924  0.53377616]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 4755. State = [[0.01617476 0.17549895 0.35105166 1.        ]]. Action = [[ 0.23052597 -0.06348777 -0.06273866  0.52225065]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 4756. State = [[0.01715418 0.16704904 0.35417488 1.        ]]. Action = [[ 0.05987871 -0.3786713   0.21613836  0.46102846]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 4757. State = [[0.01522982 0.16792046 0.36060026 1.        ]]. Action = [[-0.08445686  0.52759457  0.26586795  0.64205   ]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 4758. State = [[0.01070481 0.17685245 0.3645674  1.        ]]. Action = [[-0.24801731  0.10260975 -0.18658423  0.6007377 ]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 4759. State = [[0.00687329 0.18390489 0.36404648 1.        ]]. Action = [[0.08642268 0.24812591 0.12719667 0.60304976]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 4760. State = [[0.00568835 0.18594684 0.3638782  1.        ]]. Action = [[-0.07903135 -0.18966544 -0.11595142  0.48060882]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 4761. State = [[0.00107712 0.18633799 0.35806248 1.        ]]. Action = [[-0.26253772  0.11537397 -0.36393273  0.62662125]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 4762. State = [[-0.00200335  0.18703406  0.35474625  1.        ]]. Action = [[ 0.08464432 -0.10440379  0.07634974  0.61528516]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 4763. State = [[-6.9405755e-04  1.8114118e-01  3.5486209e-01  1.0000000e+00]]. Action = [[ 1.5807211e-01 -3.4510887e-01  2.3412704e-04  5.7229900e-01]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 4764. State = [[6.6001643e-04 1.7527506e-01 3.6211643e-01 1.0000000e+00]]. Action = [[0.21680498 0.15712357 0.64299023 0.5249021 ]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 4765. State = [[-0.00188506  0.18005846  0.37602863  1.        ]]. Action = [[-0.39122045  0.35491264  0.45941746  0.6322229 ]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 4766. State = [[-0.00822369  0.18781227  0.38777357  1.        ]]. Action = [[0.08380473 0.07790625 0.08304489 0.51397586]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 4767. State = [[-0.01055687  0.19624238  0.39461407  1.        ]]. Action = [[0.03849006 0.44992352 0.3821714  0.43770218]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 4768. State = [[-0.01685765  0.21403512  0.40269995  1.        ]]. Action = [[-0.05837095  0.6992518   0.0925343   0.6089809 ]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 4769. State = [[-0.02248211  0.22968903  0.40018523  1.        ]]. Action = [[ 0.07907319  0.26951456 -0.6519402   0.69955945]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 4770. State = [[-0.02133277  0.24033275  0.38517004  1.        ]]. Action = [[ 0.07768476  0.2635616  -0.22457421  0.56507957]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 4771. State = [[-0.01828346  0.24714756  0.37866277  1.        ]]. Action = [[ 0.17437983 -0.07395905 -0.02865541  0.60702276]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 4772. State = [[-0.01490425  0.24246684  0.3752871   1.        ]]. Action = [[ 0.22173464 -0.33974797 -0.09833133  0.5436075 ]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 4773. State = [[-0.00880761  0.22988829  0.3773011   1.        ]]. Action = [[-0.02314532 -0.55419886  0.31511307  0.5756246 ]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 4774. State = [[-0.00432542  0.2199253   0.3788259   1.        ]]. Action = [[-0.00577945 -0.15581882 -0.42220175  0.50127625]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 4775. State = [[-0.0024377   0.21246672  0.3761924   1.        ]]. Action = [[-0.16830629 -0.3229493  -0.08816504  0.64430773]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 4776. State = [[-0.00513404  0.21461141  0.37484017  1.        ]]. Action = [[-0.20690095  0.48927283  0.10602701  0.51237094]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 4777. State = [[-0.00922258  0.22230402  0.3749157   1.        ]]. Action = [[-0.17480123  0.23886251 -0.00820005  0.63523316]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 4778. State = [[-0.0116851   0.22613946  0.37985367  1.        ]]. Action = [[-0.08291167 -0.03303409  0.44957948  0.54284704]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 4779. State = [[-0.01204831  0.2273184   0.37882245  1.        ]]. Action = [[ 0.3051374   0.05016124 -0.32656634  0.5685719 ]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 4780. State = [[-0.01168863  0.2268857   0.37875268  1.        ]]. Action = [[-0.13134295 -0.1821835   0.08845699  0.49245787]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 4781. State = [[-0.01187445  0.22771002  0.37616628  1.        ]]. Action = [[-0.00730932  0.23751318 -0.37282407  0.49532986]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 4782. State = [[-0.0138867   0.23147447  0.38058093  1.        ]]. Action = [[-0.3331765   0.09750235  0.73605204  0.5725095 ]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 4783. State = [[-0.01752616  0.23584022  0.38965616  1.        ]]. Action = [[0.05255437 0.0746994  0.6965941  0.59641886]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 4784. State = [[-0.01764288  0.23680425  0.3873833   1.        ]]. Action = [[ 0.38942552  0.04970348 -0.18724358  0.55505633]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 4785. State = [[-0.01710498  0.2330606   0.3923765   1.        ]]. Action = [[-0.21400917 -0.32323897  0.46220386  0.59161806]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 4786. State = [[-0.01846138  0.2250472   0.39783117  1.        ]]. Action = [[-0.49219573 -0.30284762 -0.21424425  0.5228102 ]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 4787. State = [[-0.02324137  0.21960203  0.39790383  1.        ]]. Action = [[-0.5864138  -0.10208243  0.54580283  0.59241307]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 4788. State = [[-0.02362999  0.21694791  0.39911306  1.        ]]. Action = [[ 0.23287416 -0.04633772  0.19759393  0.48688054]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 4789. State = [[-0.02424001  0.21386352  0.40115142  1.        ]]. Action = [[-0.30200958 -0.05887544 -0.09819424  0.54775095]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 4790. State = [[-0.03037589  0.21643122  0.40324247  1.        ]]. Action = [[-0.48520464  0.04682612  0.05801189  0.5747589 ]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 4791. State = [[-0.04450089  0.2161477   0.4048368   1.        ]]. Action = [[-0.31017697 -0.08399808  0.29684758  0.6796789 ]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 4792. State = [[-0.04689921  0.21173039  0.4056022   1.        ]]. Action = [[-0.01236147 -0.36675203 -0.06340891  0.47188914]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 4793. State = [[-0.05080537  0.20001103  0.4047666   1.        ]]. Action = [[-0.3004012  -0.26271963 -0.09448445  0.6609236 ]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 4794. State = [[-0.05522507  0.18543564  0.40512344  1.        ]]. Action = [[ 0.16744399 -0.46918535  0.09444427  0.70060086]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 4795. State = [[-0.05753754  0.17397876  0.4065754   1.        ]]. Action = [[ 0.40397418 -0.3213123   0.7662364   0.51853514]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 4796. State = [[-0.0587169   0.17130888  0.4044117   1.        ]]. Action = [[ 0.17869401 -0.29208803  0.632761    0.68735003]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 4797. State = [[-0.05878089  0.17117849  0.4042873   1.        ]]. Action = [[ 0.47122312 -0.17358029  0.39629364  0.537922  ]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 4798. State = [[-0.05878089  0.17117849  0.4042873   1.        ]]. Action = [[ 0.4197185  -0.10962433  0.5401195   0.5557376 ]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 4799. State = [[-0.05878089  0.17117849  0.4042873   1.        ]]. Action = [[ 0.41980636 -0.01244295  0.42623913  0.7088332 ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 4800. State = [[-0.05878089  0.17117849  0.4042873   1.        ]]. Action = [[ 0.43319964 -0.51683444  0.2435093   0.61550176]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 4801. State = [[-0.05499253  0.16501786  0.40558973  1.        ]]. Action = [[ 0.40639234 -0.35153794  0.04802155  0.5473435 ]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 4802. State = [[-0.04672026  0.15058911  0.40949574  1.        ]]. Action = [[ 0.54176664 -0.49362588  0.17308247  0.50310516]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 4803. State = [[-0.03867367  0.13294873  0.41097662  1.        ]]. Action = [[-0.01167428 -0.270684    0.04877555  0.63770664]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 4804. State = [[-0.26213142  0.05816178  0.09667218  1.        ]]. Action = [[0.20093656 0.3581016  0.16981483 0.6942651 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 4805. State = [[-0.25537136  0.06075901  0.09120156  1.        ]]. Action = [[ 0.40480983 -0.2356255   0.9408586   0.9211116 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 4806. State = [[-0.23247126  0.04530879  0.11210594  1.        ]]. Action = [[ 0.9944613  -0.88001335  0.94235516  0.9824836 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 4807. State = [[-0.20397526  0.01762336  0.14695843  1.        ]]. Action = [[ 0.40021896 -0.7850889   0.8315606   0.9094598 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 4808. State = [[-0.18129392 -0.00668503  0.18055975  1.        ]]. Action = [[ 0.66280234 -0.5531572   0.9435799   0.9231384 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 4809. State = [[-0.16314696 -0.02054252  0.20384602  1.        ]]. Action = [[ 0.4664129  -0.37803566  0.9138994   0.96629715]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 4810. State = [[-0.14674637 -0.03046996  0.22066452  1.        ]]. Action = [[ 0.97876143 -0.5159859   0.9233084   0.9720608 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 4811. State = [[-0.11651037 -0.04898834  0.25722322  1.        ]]. Action = [[ 0.7470701  -0.5143877   0.85675573  0.9163914 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 4811 is [True, False, False, False, True, False, True, False, False, True]
State prediction error at timestep 4811 is tensor(0.0006, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 4811 of 1
Current timestep = 4812. State = [[-0.08973536 -0.07480107  0.30016205  1.        ]]. Action = [[ 0.22063076 -0.7652938   0.7965114   0.951002  ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 4812 is [False, True, False, True, False, False, True, False, False, True]
State prediction error at timestep 4812 is tensor(0.0007, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 4812 of -1
Current timestep = 4813. State = [[-0.07426478 -0.10105443  0.33278653  1.        ]]. Action = [[ 0.7637893  -0.50293046  0.78838444  0.9145119 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 4814. State = [[-0.05693048 -0.11042714  0.36090338  1.        ]]. Action = [[ 0.05434883 -0.03985     0.84382856  0.7939172 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 4815. State = [[-0.04144496 -0.1075195   0.3886809   1.        ]]. Action = [[0.79711175 0.48886824 0.4934361  0.84273934]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 4816. State = [[-0.01724329 -0.08791532  0.40839863  1.        ]]. Action = [[0.69798887 0.8171072  0.33112025 0.7021642 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 4817. State = [[ 0.00519047 -0.05773373  0.41798088  1.        ]]. Action = [[ 0.35977626  0.95225644 -0.00521296  0.796409  ]]. Reward = [0.]
Curr episode timestep = 12
Above hoop
Current timestep = 4818. State = [[ 0.01275532 -0.02235317  0.41962904  1.        ]]. Action = [[-0.3314618   0.9255061  -0.20661259  0.78656614]]. Reward = [0.]
Curr episode timestep = 13
Above hoop
Current timestep = 4819. State = [[0.00687294 0.01355046 0.41545078 1.        ]]. Action = [[-0.08621645  0.83079374 -0.13638818  0.83811164]]. Reward = [0.]
Curr episode timestep = 14
Above hoop
Current timestep = 4820. State = [[0.0018464  0.04678795 0.40662384 1.        ]]. Action = [[ 0.30378795  0.8641918  -0.50539047  0.76654315]]. Reward = [0.]
Curr episode timestep = 15
Above hoop
Current timestep = 4821. State = [[0.01041743 0.08073728 0.38534224 1.        ]]. Action = [[-0.18154699  0.9066402  -0.43334162  0.7239437 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 4822. State = [[0.0114639  0.11586314 0.3729047  1.        ]]. Action = [[-0.06661445  0.7239468  -0.12995923  0.628963  ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 4823. State = [[0.01236773 0.13991559 0.3739812  1.        ]]. Action = [[0.21475983 0.3976667  0.35070658 0.54228616]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 4824. State = [[0.01306614 0.14974916 0.37781346 1.        ]]. Action = [[-0.40380532 -0.02286243 -0.09997874  0.47931027]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 4825. State = [[0.00727891 0.16497639 0.37417218 1.        ]]. Action = [[-0.20325059  0.76550627 -0.23651612  0.75508785]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 4826. State = [[-0.00360036  0.18686855  0.37149876  1.        ]]. Action = [[-0.17758423  0.35155058  0.08959424  0.59279346]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 4827. State = [[-0.0073083   0.19466546  0.3699718   1.        ]]. Action = [[ 0.18254292  0.0445236  -0.09168297  0.55369854]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 4828. State = [[-0.00656344  0.19144008  0.3697295   1.        ]]. Action = [[-0.13585675 -0.40286255  0.04155278  0.54260266]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 4829. State = [[-0.00440204  0.18061031  0.37576148  1.        ]]. Action = [[-0.16606557 -0.4751644   0.35885072  0.47951114]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 4830. State = [[-0.00597017  0.1737771   0.38727894  1.        ]]. Action = [[-0.16028786  0.1840756   0.4674914   0.42446947]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 4831. State = [[-0.00934976  0.17233288  0.39709184  1.        ]]. Action = [[ 0.07019699 -0.12197047  0.06419945  0.2958219 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 4832. State = [[-0.01084095  0.16996169  0.3992917   1.        ]]. Action = [[-9.8089635e-02  4.0149689e-04  4.9569845e-02  4.9066186e-01]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 4833. State = [[-0.01007548  0.16837022  0.39911672  1.        ]]. Action = [[ 0.41363263 -0.1097067  -0.14501423  0.5449438 ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 4834. State = [[-0.0079816   0.16613892  0.3943256   1.        ]]. Action = [[ 0.2790048  -0.02984607 -0.22639424  0.6201613 ]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 4835. State = [[-0.0052317   0.1630712   0.39302284  1.        ]]. Action = [[-0.16582632 -0.18220782  0.08545375  0.46512341]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 4836. State = [[-0.00677327  0.1678913   0.38952732  1.        ]]. Action = [[ 0.07128203  0.6652045  -0.3983581   0.57110035]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 4837. State = [[-0.00128008  0.17695753  0.38059306  1.        ]]. Action = [[ 0.04712975 -0.06814384 -0.06441623  0.6499646 ]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 4838. State = [[-0.00465409  0.18517205  0.3783285   1.        ]]. Action = [[-0.41876185  0.44919705 -0.20920765  0.6515722 ]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 4839. State = [[-0.00981459  0.18940826  0.3748629   1.        ]]. Action = [[-0.38067305 -0.44589388 -0.27652872  0.41631055]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 4840. State = [[-0.01212641  0.18139833  0.37091815  1.        ]]. Action = [[-0.16912973 -0.4072963  -0.09413886  0.59822273]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 4841. State = [[-0.01323416  0.17054783  0.37421095  1.        ]]. Action = [[ 0.05677319 -0.12624103  0.4923458   0.55263376]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 4842. State = [[-0.01291889  0.17011195  0.37806448  1.        ]]. Action = [[0.29224825 0.3232864  0.02699316 0.6877217 ]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 4843. State = [[-0.01120559  0.17082328  0.38342342  1.        ]]. Action = [[ 0.16962063 -0.11803102  0.38572717  0.552032  ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 4844. State = [[-0.00817124  0.17189597  0.39276353  1.        ]]. Action = [[0.123734   0.17347646 0.43806696 0.7530569 ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 4845. State = [[-0.00865644  0.17711936  0.3999785   1.        ]]. Action = [[-0.2835623   0.14619923 -0.01175272  0.56035423]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 4846. State = [[-0.01173246  0.18046921  0.40382412  1.        ]]. Action = [[0.26302528 0.25104094 0.4096464  0.63149667]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 4847. State = [[-0.01150017  0.18211655  0.40373155  1.        ]]. Action = [[0.32118928 0.16854465 0.01669717 0.5659692 ]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 4848. State = [[-0.01063085  0.18400525  0.40651903  1.        ]]. Action = [[0.0722717  0.0751524  0.22269034 0.64038134]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 4849. State = [[-0.00915499  0.18741201  0.41245165  1.        ]]. Action = [[-0.3731271   0.6576898   0.28508914  0.5466044 ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 4850. State = [[-0.00937169  0.18791823  0.41316864  1.        ]]. Action = [[-0.4092301  -0.17081308  0.24518824  0.6658224 ]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 4851. State = [[-0.00911559  0.18795769  0.41103473  1.        ]]. Action = [[ 0.02918494 -0.03853106 -0.22086352  0.48703444]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 4852. State = [[-0.00534824  0.18417965  0.40434247  1.        ]]. Action = [[ 0.3096925  -0.2532475  -0.16949952  0.6746218 ]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 4853. State = [[-0.00217996  0.18242449  0.39660013  1.        ]]. Action = [[ 0.2705207   0.20020485 -0.4651866   0.5288528 ]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 4854. State = [[0.00373528 0.18683988 0.37403157 1.        ]]. Action = [[-0.06787872  0.00332367 -0.5971413   0.56604826]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 4855. State = [[0.00914414 0.18662214 0.3624875  1.        ]]. Action = [[-0.12882853 -0.23393041 -0.17072546  0.5624137 ]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 4856. State = [[0.0106874 0.1842904 0.3551937 1.       ]]. Action = [[-0.08875096 -0.01824021 -0.3130114   0.49646425]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 4857. State = [[0.01394361 0.17503622 0.35757583 1.        ]]. Action = [[-0.01784605 -0.49344033  0.59028506  0.50417566]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 4858. State = [[0.01924596 0.15947518 0.37248686 1.        ]]. Action = [[ 0.07261634 -0.4212466   0.35825956  0.5618465 ]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 4859. State = [[0.01752778 0.14558142 0.37368196 1.        ]]. Action = [[-0.40412605 -0.35388088 -0.5260331   0.53596425]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 4860. State = [[0.00829616 0.1453895  0.36320966 1.        ]]. Action = [[-0.4854167   0.38345146 -0.32361186  0.44736362]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 4861. State = [[-0.00144031  0.15390669  0.35791424  1.        ]]. Action = [[-0.15705013  0.2442522   0.19389093  0.42993438]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 4862. State = [[-0.00520074  0.1569731   0.3629065   1.        ]]. Action = [[ 0.26070595 -0.08119595  0.22095883  0.49172962]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 4863. State = [[-0.00567839  0.15474609  0.36397702  1.        ]]. Action = [[-0.20684326 -0.03127182 -0.17391884  0.46448207]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 4864. State = [[-0.00602962  0.15527986  0.36426866  1.        ]]. Action = [[0.18524158 0.14115882 0.15650833 0.543694  ]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 4865. State = [[-0.00614608  0.15564227  0.3641526   1.        ]]. Action = [[-0.07232434 -0.13869113 -0.19681847  0.6750877 ]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 4866. State = [[-0.0040058   0.1512136   0.36950502  1.        ]]. Action = [[ 0.28632784 -0.24063247  0.5463295   0.66259027]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 4867. State = [[-0.00342553  0.14903839  0.37649024  1.        ]]. Action = [[-0.03565133  0.24544668 -0.00792605  0.5964372 ]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 4868. State = [[-0.00559889  0.15275028  0.3805244   1.        ]]. Action = [[-0.31114864  0.10832155  0.3090409   0.5751703 ]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 4869. State = [[-0.00962378  0.15793654  0.39444473  1.        ]]. Action = [[0.00585175 0.12875521 0.5560914  0.64586353]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 4870. State = [[-0.01140526  0.15931357  0.40449134  1.        ]]. Action = [[0.11731219 0.2839967  0.51080537 0.5478376 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 4871. State = [[-0.01495711  0.16535327  0.40658066  1.        ]]. Action = [[-0.29459703  0.22039282  0.03758299  0.52749276]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 4872. State = [[-0.01983965  0.17014174  0.41042283  1.        ]]. Action = [[-0.02841133  0.2999575   0.36806548  0.59101427]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 4873. State = [[-0.02191821  0.1732099   0.41167712  1.        ]]. Action = [[-0.05425107  0.17520332  0.05503058  0.65836203]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 4874. State = [[-0.02194314  0.17777237  0.41173822  1.        ]]. Action = [[0.6091498  0.16739559 0.07338333 0.69786024]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 4875. State = [[-0.02071734  0.18075329  0.41161725  1.        ]]. Action = [[ 0.03722131  0.10083342 -0.09470838  0.51995707]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 4876. State = [[-0.02060263  0.18090527  0.41095698  1.        ]]. Action = [[-0.03333473  0.16993272  0.5990169   0.63432837]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 4877. State = [[-0.02041537  0.18790318  0.40714762  1.        ]]. Action = [[ 0.15921903  0.525095   -0.2975818   0.5095272 ]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 4878. State = [[-0.01350638  0.19305266  0.3974748   1.        ]]. Action = [[ 0.2022785  -0.39007866 -0.16014999  0.70942616]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 4879. State = [[-0.01141172  0.1937791   0.39657375  1.        ]]. Action = [[0.06173182 0.24547565 0.21210587 0.5964923 ]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 4880. State = [[-0.00848904  0.20196326  0.39766902  1.        ]]. Action = [[ 0.12787032  0.36962724 -0.10062468  0.56289744]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 4881. State = [[-0.00330236  0.20867196  0.39210466  1.        ]]. Action = [[ 0.11967313 -0.13745844 -0.05644304  0.49952543]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 4882. State = [[7.8475155e-04 2.0248753e-01 3.8945773e-01 1.0000000e+00]]. Action = [[ 0.3808775  -0.24583656 -0.51681626  0.5604427 ]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 4883. State = [[0.0105571  0.196593   0.37742656 1.        ]]. Action = [[-0.05971491 -0.15359735  0.20223594  0.5619892 ]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 4884. State = [[0.01306656 0.19102372 0.37641975 1.        ]]. Action = [[-0.10656947 -0.28860974 -0.19297141  0.40969384]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 4885. State = [[0.0164091  0.18426369 0.37219685 1.        ]]. Action = [[ 0.1432358  -0.14734346 -0.21845603  0.5798814 ]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 4886. State = [[0.02063766 0.17597382 0.3691804  1.        ]]. Action = [[ 0.2628392  -0.15082628  0.16069806  0.5752989 ]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 4887. State = [[0.02588605 0.1740806  0.36960277 1.        ]]. Action = [[0.39459085 0.18253875 0.01997054 0.5750154 ]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 4888. State = [[0.0377648  0.1674283  0.36499727 1.        ]]. Action = [[ 0.1351707  -0.48861206 -0.25458157  0.44283628]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 4889. State = [[0.04647605 0.15507895 0.36243284 1.        ]]. Action = [[ 0.04896748 -0.2876141  -0.00272518  0.50264466]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 4890. State = [[0.04820942 0.15164556 0.35396525 1.        ]]. Action = [[-0.31132817  0.1781702  -0.6044387   0.5507518 ]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 4891. State = [[0.04806426 0.15269578 0.3444902  1.        ]]. Action = [[-0.02905869  0.0201968  -0.15118635  0.5750488 ]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 4892. State = [[0.04755549 0.15418714 0.3385742  1.        ]]. Action = [[-0.13522422  0.04473197 -0.20112872  0.43592918]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 4893. State = [[0.04975516 0.150953   0.33143926 1.        ]]. Action = [[ 0.47373295 -0.24119079 -0.3844579   0.60250163]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 4894. State = [[0.05103866 0.15539262 0.32053858 1.        ]]. Action = [[-0.4880668   0.30554748  0.31423855  0.5669646 ]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 4895. State = [[0.04846269 0.1553671  0.31788343 1.        ]]. Action = [[-0.43319273 -0.29683924 -0.44536948  0.74182177]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 4896. State = [[0.04246207 0.14386342 0.32012796 1.        ]]. Action = [[-0.46835017 -0.5101725   0.44099748  0.5220418 ]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 4897. State = [[0.02757304 0.1247538  0.32477644 1.        ]]. Action = [[-0.21363676 -0.55525947 -0.07115245  0.6402838 ]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 4898. State = [[0.01734471 0.10342515 0.3279227  1.        ]]. Action = [[-0.31998718 -0.52744645  0.16857076  0.4269123 ]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 4899. State = [[0.00790222 0.09043767 0.33535698 1.        ]]. Action = [[-0.09574318  0.00598443  0.24887466  0.47151256]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 4900. State = [[-0.00267569  0.0932683   0.353838    1.        ]]. Action = [[-0.48764336  0.24464345  0.7481253   0.26129496]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 4901. State = [[-0.02341281  0.09901896  0.36530566  1.        ]]. Action = [[-0.29194218  0.09075809 -0.02727479  0.44958472]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 4902. State = [[-0.03105509  0.09873571  0.37108183  1.        ]]. Action = [[ 0.11880672 -0.0761615   0.19852567  0.55494034]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 4903. State = [[-0.03706691  0.08569147  0.38749772  1.        ]]. Action = [[-0.3999045  -0.67558694  0.8258188   0.45637774]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 4904. State = [[-0.0461012   0.06966686  0.4058878   1.        ]]. Action = [[ 0.13567162 -0.21850872  0.11565626  0.41455483]]. Reward = [0.]
Curr episode timestep = 99
Above hoop
Current timestep = 4905. State = [[-0.05308108  0.06645951  0.41309065  1.        ]]. Action = [[-0.46173286  0.17024422  0.16995072  0.5811782 ]]. Reward = [0.]
Curr episode timestep = 100
Above hoop
Current timestep = 4906. State = [[-0.26451683  0.10258742  0.09146804  1.        ]]. Action = [[-0.3568021   0.36815226  0.51156735  0.6293423 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Above hoop
Current timestep = 4907. State = [[-0.2621603   0.11393294  0.07814062  1.        ]]. Action = [[-0.27777576 -0.89637035  0.9679675   0.8788421 ]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Current timestep = 4908. State = [[-0.24768667  0.10187633  0.08603099  1.        ]]. Action = [[ 0.8952627  -0.83213127  0.96481335  0.86254716]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 4909. State = [[-0.21667399  0.08187385  0.10989881  1.        ]]. Action = [[ 0.92651343 -0.45440125  0.98510194  0.88925576]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 4910. State = [[-0.18078484  0.06139582  0.14762832  1.        ]]. Action = [[ 0.90989614 -0.6537399   0.9313202   0.9512079 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 4911. State = [[-0.1636125   0.03871119  0.18372221  1.        ]]. Action = [[-0.81969583 -0.6140605   0.9613055   0.934278  ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 4912. State = [[-0.16665842  0.02587187  0.20873487  1.        ]]. Action = [[ 0.9717299  -0.17060661  0.947696    0.917192  ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 4913. State = [[-0.16547695  0.02296137  0.22458582  1.        ]]. Action = [[ 0.24925804 -0.01670897  0.93893087  0.91764545]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 4914. State = [[-0.16732267  0.02248594  0.25280938  1.        ]]. Action = [[-0.08169496  0.09564567  0.53184044  0.85526204]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 4915. State = [[-0.15790541  0.01668283  0.27948797  1.        ]]. Action = [[ 0.9387665  -0.47189164  0.9534576   0.89236844]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 4916. State = [[-1.3301146e-01  6.2634886e-06  3.2005614e-01  1.0000000e+00]]. Action = [[ 0.40708065 -0.5357613   0.953841    0.87471867]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 4917. State = [[-0.11066517 -0.01430135  0.36042202  1.        ]]. Action = [[ 0.92287385 -0.22298539  0.93986964  0.46640563]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 4918. State = [[-0.08211952 -0.02311812  0.3999484   1.        ]]. Action = [[ 0.9349903  -0.18398869  0.96205723  0.8202268 ]]. Reward = [0.]
Curr episode timestep = 11
Above hoop
Current timestep = 4919. State = [[-0.05923058 -0.02612467  0.4243705   1.        ]]. Action = [[0.533448   0.41092324 0.43158257 0.8092859 ]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Above hoop
Current timestep = 4920. State = [[-0.05286764 -0.02641823  0.4286745   1.        ]]. Action = [[0.1339376  0.8522942  0.04583418 0.69145167]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Above hoop
Current timestep = 4921. State = [[-0.0529087  -0.02667474  0.42873248  1.        ]]. Action = [[0.56267166 0.75888777 0.32629704 0.6655805 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Above hoop
Current timestep = 4922. State = [[-0.05293963 -0.02686742  0.4287761   1.        ]]. Action = [[0.39653814 0.6751994  0.23172092 0.63529074]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Above hoop
Current timestep = 4923. State = [[-0.05296674 -0.02686154  0.4287746   1.        ]]. Action = [[-0.16088408  0.824757    0.39197516  0.6384648 ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Above hoop
Current timestep = 4924. State = [[-0.05296674 -0.02686154  0.4287746   1.        ]]. Action = [[0.09555686 0.8652959  0.0232029  0.7641889 ]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Above hoop
Current timestep = 4925. State = [[-0.05296674 -0.02686154  0.4287746   1.        ]]. Action = [[-0.67803967  0.7007272  -0.11144733  0.74507904]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Above hoop
Current timestep = 4926. State = [[-0.05296674 -0.02686154  0.4287746   1.        ]]. Action = [[0.46599305 0.77823925 0.35983706 0.6637541 ]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Above hoop
Current timestep = 4927. State = [[-0.05296674 -0.02686154  0.4287746   1.        ]]. Action = [[0.25366116 0.72911835 0.2931049  0.7261276 ]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Above hoop
Current timestep = 4928. State = [[-0.05296674 -0.02686154  0.4287746   1.        ]]. Action = [[0.08178627 0.9248526  0.03226411 0.7803235 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Above hoop
Current timestep = 4929. State = [[-0.05296674 -0.02686154  0.4287746   1.        ]]. Action = [[0.6817385  0.8883754  0.10336494 0.7057841 ]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Above hoop
Current timestep = 4930. State = [[-0.05448607 -0.0185078   0.42710105  1.        ]]. Action = [[-0.34707236  0.6298351  -0.352606    0.7050966 ]]. Reward = [0.]
Curr episode timestep = 23
Above hoop
Current timestep = 4931. State = [[-0.05600442 -0.01096065  0.42623606  1.        ]]. Action = [[ 0.10022306  0.9417596  -0.03433108  0.695832  ]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Above hoop
Current timestep = 4932. State = [[-0.05618648 -0.00987106  0.4260487   1.        ]]. Action = [[0.38795996 0.79633284 0.40213263 0.7796426 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Above hoop
Current timestep = 4933. State = [[-0.05618454 -0.00967581  0.4260199   1.        ]]. Action = [[ 0.27355218  0.81843114 -0.1375786   0.7856034 ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Above hoop
Current timestep = 4934. State = [[-0.05618454 -0.00967581  0.4260199   1.        ]]. Action = [[-0.07270026  0.7247071  -0.12703466  0.7623482 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Above hoop
Current timestep = 4935. State = [[-0.054674    0.0041606   0.42086905  1.        ]]. Action = [[ 0.86394274  0.8874879  -0.29259098  0.6672976 ]]. Reward = [0.]
Curr episode timestep = 28
Above hoop
Current timestep = 4936. State = [[-0.03036381  0.03208999  0.40648398  1.        ]]. Action = [[ 0.3716272   0.64204025 -0.10257798  0.6873205 ]]. Reward = [0.]
Curr episode timestep = 29
Above hoop
Current timestep = 4937. State = [[-0.0206966   0.06148464  0.40650758  1.        ]]. Action = [[-0.1951459  0.9292722  0.1433661  0.6973536]]. Reward = [0.]
Curr episode timestep = 30
Above hoop
Current timestep = 4938. State = [[-0.02733316  0.09291995  0.40909857  1.        ]]. Action = [[-0.2529968   0.70752954  0.03944016  0.7181566 ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 4939. State = [[-0.03377772  0.10941982  0.40921995  1.        ]]. Action = [[-0.3648113  -0.05921906  0.2567253   0.72005343]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 4940. State = [[-0.03449249  0.11126583  0.40920687  1.        ]]. Action = [[-0.32375145  0.35216963  0.43681216  0.6102667 ]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 4941. State = [[-0.03459382  0.11156549  0.40923363  1.        ]]. Action = [[-0.27378303 -0.23358428  0.3033594   0.60580325]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 4942. State = [[-0.03462948  0.11160775  0.4092069   1.        ]]. Action = [[0.03256798 0.24219275 0.30227697 0.65446067]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 4943. State = [[-0.03462948  0.11160775  0.4092069   1.        ]]. Action = [[0.20847034 0.5681362  0.35667944 0.6289232 ]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 4944. State = [[-0.03462948  0.11160775  0.4092069   1.        ]]. Action = [[0.06186247 0.06846666 0.3617568  0.6109954 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 4945. State = [[-0.03462948  0.11160775  0.4092069   1.        ]]. Action = [[-0.17903751  0.07124066  0.37352645  0.63993824]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 4946. State = [[-0.03462948  0.11160775  0.4092069   1.        ]]. Action = [[-0.08594471 -0.33253694  0.14509952  0.5347054 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 4947. State = [[-0.03462948  0.11160775  0.4092069   1.        ]]. Action = [[-0.27087545 -0.08050758  0.26419294  0.6599245 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 4948. State = [[-0.03457162  0.11158422  0.40885517  1.        ]]. Action = [[ 0.06657004 -0.049474   -0.09313995  0.64233136]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 4949. State = [[-0.03641966  0.11687786  0.4069314   1.        ]]. Action = [[-0.22402209  0.31164384 -0.17491704  0.59972167]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 4950. State = [[-0.03802511  0.12150625  0.4049269   1.        ]]. Action = [[ 0.16420603 -0.08026242  0.49179018  0.57583   ]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 4951. State = [[-0.03803054  0.12200923  0.40365002  1.        ]]. Action = [[ 0.36706364 -0.07308102  0.5560553   0.49512935]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 4952. State = [[-0.03819408  0.1194692   0.40392444  1.        ]]. Action = [[-0.40631527 -0.260633    0.10844266  0.6878016 ]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 4953. State = [[-0.03770549  0.11017962  0.4068943   1.        ]]. Action = [[ 0.20124173 -0.48443162  0.1562612   0.24506402]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 4954. State = [[-0.03747946  0.10206903  0.4094135   1.        ]]. Action = [[-0.6247367  -0.23136318  0.37041545  0.40624547]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 4955. State = [[-0.03745445  0.10093115  0.4096905   1.        ]]. Action = [[-0.176839   -0.15555215  0.26238537  0.6004473 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 4956. State = [[-0.03390706  0.10337222  0.40730855  1.        ]]. Action = [[ 0.61834836  0.26597488 -0.09992087  0.6064967 ]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 4957. State = [[-0.02988546  0.10791417  0.40628323  1.        ]]. Action = [[-0.40119016  0.10773098 -0.2512169   0.49958014]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 4958. State = [[-0.02989341  0.10809657  0.40545976  1.        ]]. Action = [[ 0.20149684 -0.21244562  0.14611197  0.5414171 ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 4959. State = [[-0.02968198  0.1076638   0.40465194  1.        ]]. Action = [[-0.05344385  0.09981465 -0.14881986  0.63513994]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 4960. State = [[-0.02950384  0.10778799  0.40292555  1.        ]]. Action = [[ 0.45494413 -0.3172599   0.52937627  0.5273988 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 4961. State = [[-0.02657438  0.10699362  0.4034103   1.        ]]. Action = [[ 0.60900164 -0.05215752  0.2376566   0.34567547]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 4962. State = [[-0.02054423  0.11088449  0.4034226   1.        ]]. Action = [[-0.34200907  0.23862553 -0.12236333  0.50886965]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 4963. State = [[-0.02035698  0.11205687  0.3961969   1.        ]]. Action = [[-0.05328798 -0.14987206 -0.5743843   0.49632478]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 4964. State = [[-0.01956335  0.11213001  0.38840085  1.        ]]. Action = [[ 0.5844972  -0.0184955   0.5747464   0.59994054]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 4965. State = [[-0.01946552  0.11216274  0.38719648  1.        ]]. Action = [[ 0.2578237  -0.2522716   0.67796075  0.4982965 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 4966. State = [[-0.01509803  0.10884874  0.3886566   1.        ]]. Action = [[ 0.60877144 -0.15254748  0.2991389   0.7135012 ]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 4967. State = [[-0.00817341  0.10429571  0.38918573  1.        ]]. Action = [[-0.25287354 -0.1800853  -0.2519821   0.5608785 ]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 4968. State = [[-0.01036762  0.10830941  0.38854516  1.        ]]. Action = [[-0.15231621  0.51854575  0.106704    0.5581815 ]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 4969. State = [[-0.01096487  0.11094739  0.386662    1.        ]]. Action = [[ 0.3390584  -0.20355934 -0.16610259  0.38550234]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 4970. State = [[-0.00769726  0.11048411  0.38014027  1.        ]]. Action = [[ 0.00574803 -0.3064468   0.79883707  0.5694754 ]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 4971. State = [[-0.00638245  0.10778636  0.38076815  1.        ]]. Action = [[ 0.14249825 -0.15032887  0.12528157  0.5191072 ]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 4972. State = [[5.9987983e-04 1.0236415e-01 3.9117971e-01 1.0000000e+00]]. Action = [[ 0.2986225  -0.1968019   0.56958795  0.56429076]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 4973. State = [[0.00454198 0.1012549  0.40009457 1.        ]]. Action = [[-0.22455728  0.20744443 -0.26639628  0.56209934]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 4974. State = [[0.00250603 0.11018671 0.3964803  1.        ]]. Action = [[-0.0648706   0.47966826 -0.38264     0.41368985]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 4975. State = [[0.00388191 0.12205157 0.37822315 1.        ]]. Action = [[ 0.38216972  0.351233   -0.48384386  0.5655378 ]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 4976. State = [[0.01643834 0.13070148 0.36063838 1.        ]]. Action = [[-0.10619307 -0.0895375  -0.29069674  0.48192692]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 4977. State = [[0.02109277 0.13219993 0.35878065 1.        ]]. Action = [[ 0.43644595 -0.00225043  0.31630373  0.5731697 ]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 4978. State = [[0.02742758 0.12929639 0.3567197  1.        ]]. Action = [[-0.11286151 -0.30704904 -0.38770282  0.46123004]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 4979. State = [[0.03388893 0.11601506 0.34858277 1.        ]]. Action = [[ 0.5311887  -0.53964627 -0.04364139  0.56445086]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 4980. State = [[0.04608586 0.09936904 0.3409054  1.        ]]. Action = [[ 0.1487689  -0.37418807 -0.39360964  0.5603843 ]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 4981. State = [[0.05268952 0.09104042 0.32605287 1.        ]]. Action = [[ 0.05693257 -0.00821948 -0.58537835  0.5850787 ]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 4982. State = [[0.05489948 0.09282131 0.31431356 1.        ]]. Action = [[0.03275073 0.29620957 0.14987195 0.5673559 ]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 4983. State = [[0.06040805 0.09379145 0.31093955 1.        ]]. Action = [[ 0.15405226 -0.1949057  -0.18590808  0.5875838 ]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 4984. State = [[0.06179627 0.0904007  0.30996647 1.        ]]. Action = [[-0.11030203 -0.1616695   0.1014607   0.6217234 ]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 4985. State = [[0.06150642 0.09277725 0.30670837 1.        ]]. Action = [[ 0.28589916  0.4887457  -0.37837958  0.5755793 ]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 4986. State = [[0.06936182 0.10030963 0.28899974 1.        ]]. Action = [[ 0.12746406 -0.03025723 -0.49162441  0.53496766]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 4987. State = [[0.07772996 0.09822845 0.26941597 1.        ]]. Action = [[ 0.24950588 -0.27689826 -0.4789484   0.5449214 ]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 4988. State = [[0.08513616 0.09720553 0.26123896 1.        ]]. Action = [[0.01065397 0.17033982 0.13276911 0.6298821 ]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 4989. State = [[0.08525649 0.097357   0.25414503 1.        ]]. Action = [[-0.1858291  -0.10319579 -0.4565125   0.5920303 ]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 4990. State = [[0.08546411 0.09713197 0.24618487 1.        ]]. Action = [[ 0.14945138  0.09536588 -0.29806435  0.50418544]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 4991. State = [[0.08666447 0.09698693 0.23559798 1.        ]]. Action = [[ 0.5373719   0.08014119 -0.12868947  0.65293765]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 4992. State = [[0.08664265 0.09696402 0.23498467 1.        ]]. Action = [[-0.24162507 -0.33615172 -0.13842392  0.5556586 ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: No entry zone
Current timestep = 4993. State = [[0.08664265 0.09696402 0.23498467 1.        ]]. Action = [[ 0.3431623  -0.184354    0.0864687   0.40958202]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 4994. State = [[0.08664265 0.09696402 0.23498467 1.        ]]. Action = [[-0.25600207 -0.471515    0.02529323  0.3560233 ]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: No entry zone
Current timestep = 4995. State = [[0.08667605 0.09900078 0.23602925 1.        ]]. Action = [[-0.24489743  0.07719088  0.23183787  0.6213896 ]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 4996. State = [[0.08767545 0.1002584  0.23781525 1.        ]]. Action = [[ 0.11182749  0.1030196  -0.4371938   0.4467734 ]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: No entry zone
Current timestep = 4997. State = [[0.08816964 0.10093926 0.23871425 1.        ]]. Action = [[ 0.24756801 -0.66310745  0.514843    0.41536713]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 4998. State = [[0.09128459 0.09474375 0.24573268 1.        ]]. Action = [[ 0.03642249 -0.41687995  0.46770918  0.5578141 ]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 4999. State = [[0.09521004 0.08861691 0.2602962  1.        ]]. Action = [[0.07752597 0.08403909 0.42792773 0.55841756]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 5000. State = [[0.09377312 0.09398513 0.2744393  1.        ]]. Action = [[-0.22064924  0.34864223  0.35278296  0.61967707]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 5001. State = [[0.09119572 0.0989634  0.28483832 1.        ]]. Action = [[-0.07832259 -0.14281452 -0.02390015  0.66174924]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 5002. State = [[0.08985759 0.10216091 0.2866321  1.        ]]. Action = [[-0.02961802  0.24722874 -0.14223427  0.6221039 ]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 5003. State = [[0.08565475 0.11394367 0.2903848  1.        ]]. Action = [[-0.12516558  0.46134496  0.44959402  0.66487396]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 5004. State = [[0.08123536 0.12262344 0.29467714 1.        ]]. Action = [[-0.25597703 -0.10122496 -0.24873275  0.6306002 ]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 5005. State = [[0.08050354 0.1216294  0.2921597  1.        ]]. Action = [[ 0.26240683 -0.13864142 -0.17472899  0.5716008 ]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 5006. State = [[0.082427   0.11703165 0.28981742 1.        ]]. Action = [[ 0.33260167 -0.19216079  0.0086453   0.5994421 ]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 5007. State = [[0.08107259 0.1213734  0.29109114 1.        ]]. Action = [[-0.5999435   0.48762846  0.2317704   0.6563177 ]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 5008. State = [[-0.26115647 -0.11219719  0.10304934  1.        ]]. Action = [[ 0.32822752  0.33328688 -0.3471378   0.584846  ]]. Reward = [0.]
Curr episode timestep = 101
Current timestep = 5009. State = [[-0.25070688 -0.12972553  0.09594891  1.        ]]. Action = [[ 0.9673202  -0.37880933  0.815017    0.9708233 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 5010. State = [[-0.23772363 -0.14537445  0.11325193  1.        ]]. Action = [[-0.4037106  -0.42178535  0.91446996  0.9222679 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 5011. State = [[-0.22608258 -0.15914509  0.14798912  1.        ]]. Action = [[ 0.9466344  -0.23681408  0.9560245   0.9856576 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 5012. State = [[-0.19585368 -0.1662755   0.18448505  1.        ]]. Action = [[ 0.92054796 -0.01026636  0.780426    0.956262  ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 5013. State = [[-0.17306349 -0.17026106  0.20442873  1.        ]]. Action = [[ 0.819396   -0.12341678  0.9780657   0.9697578 ]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 5014. State = [[-0.15502462 -0.17806898  0.22098923  1.        ]]. Action = [[ 0.9482887  -0.53522944  0.94969344  0.95249116]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 5015. State = [[-0.1248712  -0.19677581  0.25760758  1.        ]]. Action = [[ 0.6367042  -0.49430346  0.8938856   0.974722  ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 5016. State = [[-0.10333038 -0.20632732  0.29526064  1.        ]]. Action = [[0.28522086 0.18784142 0.8976681  0.99249506]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 5017. State = [[-0.07856627 -0.20687693  0.33181593  1.        ]]. Action = [[0.94528484 0.00927508 0.9772626  0.9402689 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 5018. State = [[-0.05153963 -0.20465979  0.3716304   1.        ]]. Action = [[0.8892021  0.09664237 0.85152006 0.6458465 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 5019. State = [[-0.02934261 -0.19399177  0.40435383  1.        ]]. Action = [[-0.14187396  0.73058915  0.60739875  0.7270787 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 5020. State = [[-0.02498853 -0.17883258  0.4203212   1.        ]]. Action = [[-0.07004476  0.96474147  0.20260394  0.8645568 ]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: Workspace boundary
Current timestep = 5021. State = [[-0.02393031 -0.17721428  0.4231056   1.        ]]. Action = [[ 0.5058632   0.9152913  -0.05237114  0.82105994]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Current timestep = 5022. State = [[-0.02355226 -0.17682035  0.42633754  1.        ]]. Action = [[-0.23554748  0.8617072   0.02645266  0.84041166]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Current timestep = 5023. State = [[-0.02364851 -0.17657016  0.42633268  1.        ]]. Action = [[0.12420619 0.83626246 0.0126946  0.82623506]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 5024. State = [[-0.02355867 -0.17655884  0.4264712   1.        ]]. Action = [[0.5941489  0.9660797  0.02825773 0.86341953]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 5025. State = [[-0.02357669 -0.17657919  0.42644444  1.        ]]. Action = [[-0.2882136   0.88238895  0.32182026  0.84727645]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 5026. State = [[-0.0232674 -0.1630118  0.4229689  1.       ]]. Action = [[-0.2912954   0.9449192  -0.38384092  0.76149464]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 5027. State = [[-0.02560383 -0.14346057  0.421367    1.        ]]. Action = [[ 0.27863765  0.84020054 -0.06504488  0.7512183 ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 5028. State = [[-0.02237073 -0.1252619   0.4115958   1.        ]]. Action = [[ 0.59379876  0.94721806 -0.5215336   0.7282729 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 5029. State = [[-0.01715308 -0.09137405  0.39871973  1.        ]]. Action = [[-0.13765758  0.91288614 -0.06124884  0.7134483 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 5030. State = [[-0.0199406  -0.06050914  0.3963733   1.        ]]. Action = [[-0.07070172  0.521961   -0.1306085   0.7225013 ]]. Reward = [0.]
Curr episode timestep = 21
Above hoop
Current timestep = 5031. State = [[-0.02154802 -0.03673815  0.38746306  1.        ]]. Action = [[-0.2649132  0.6392126 -0.5057996  0.6563333]]. Reward = [0.]
Curr episode timestep = 22
Above hoop
Current timestep = 5032. State = [[-0.02207396 -0.02458538  0.3814004   1.        ]]. Action = [[-0.09555775 -0.17224348  0.14459133  0.6655071 ]]. Reward = [0.]
Curr episode timestep = 23
Above hoop
Current timestep = 5033. State = [[-0.01903415 -0.02464645  0.3863911   1.        ]]. Action = [[ 0.51205015 -0.01251072  0.56949735  0.59690833]]. Reward = [0.]
Curr episode timestep = 24
Above hoop
Current timestep = 5034. State = [[-0.01394169 -0.02365145  0.3944403   1.        ]]. Action = [[0.03097355 0.08546507 0.23380196 0.5694319 ]]. Reward = [0.]
Curr episode timestep = 25
Above hoop
Current timestep = 5035. State = [[-0.01552412 -0.01306121  0.39540917  1.        ]]. Action = [[-0.42057145  0.58874273 -0.2369076   0.4862758 ]]. Reward = [0.]
Curr episode timestep = 26
Above hoop
Current timestep = 5036. State = [[-0.02015175  0.00667164  0.3918502   1.        ]]. Action = [[ 0.11987531  0.43138087 -0.33210158  0.6073431 ]]. Reward = [0.]
Curr episode timestep = 27
Above hoop
Current timestep = 5037. State = [[-0.02150829  0.00958615  0.38872635  1.        ]]. Action = [[-0.07059926 -0.4373374  -0.13179475  0.47962677]]. Reward = [0.]
Curr episode timestep = 28
Above hoop
Current timestep = 5038. State = [[-2.0531503e-02  5.0243998e-05  3.7929562e-01  1.0000000e+00]]. Action = [[ 0.27800655 -0.29978573 -0.33579814  0.55106616]]. Reward = [0.]
Curr episode timestep = 29
Above hoop
Current timestep = 5039. State = [[-0.01342421 -0.00990449  0.3729781   1.        ]]. Action = [[ 0.5438024  -0.2724529   0.24456382  0.527781  ]]. Reward = [0.]
Curr episode timestep = 30
Above hoop
Current timestep = 5040. State = [[-0.00359113 -0.01912167  0.37739193  1.        ]]. Action = [[ 0.13029921 -0.22176683  0.17346835  0.696116  ]]. Reward = [0.]
Curr episode timestep = 31
Above hoop
Current timestep = 5041. State = [[ 0.00120526 -0.02204664  0.37678957  1.        ]]. Action = [[ 0.69348955  0.14933097 -0.5443265   0.49920988]]. Reward = [0.]
Curr episode timestep = 32
Above hoop
Current timestep = 5042. State = [[ 0.02402853 -0.02031846  0.35973847  1.        ]]. Action = [[ 0.29417992 -0.03898633 -0.06898957  0.502566  ]]. Reward = [0.]
Curr episode timestep = 33
Above hoop
Current timestep = 5043. State = [[ 0.03777677 -0.01996106  0.35076123  1.        ]]. Action = [[-0.38397753  0.16846764 -0.24431384  0.51587963]]. Reward = [0.]
Curr episode timestep = 34
Above hoop
Current timestep = 5044. State = [[ 0.03632716 -0.01196751  0.3497498   1.        ]]. Action = [[-0.11145604  0.43137848 -0.07885075  0.6028764 ]]. Reward = [0.]
Curr episode timestep = 35
Above hoop
Current timestep = 5045. State = [[ 0.0356669  -0.0050018   0.34922272  1.        ]]. Action = [[ 0.31671524 -0.01141447  0.07310379  0.4869039 ]]. Reward = [0.]
Curr episode timestep = 36
Above hoop
Current timestep = 5046. State = [[ 0.03792813 -0.00424975  0.35264525  1.        ]]. Action = [[-0.13989627 -0.00318879  0.4448632   0.47635365]]. Reward = [0.]
Curr episode timestep = 37
Above hoop
Current timestep = 5047. State = [[ 0.03861846 -0.00390818  0.35401392  1.        ]]. Action = [[ 0.16085231  0.03954184 -0.01796699  0.53845465]]. Reward = [0.]
Curr episode timestep = 38
Above hoop
Current timestep = 5048. State = [[ 0.04074949 -0.00102091  0.35788882  1.        ]]. Action = [[0.15577972 0.15852904 0.16383386 0.6115546 ]]. Reward = [0.]
Curr episode timestep = 39
Above hoop
Current timestep = 5049. State = [[0.04275572 0.00312905 0.36233768 1.        ]]. Action = [[-0.05230165  0.11784542 -0.29110897  0.60957265]]. Reward = [0.]
Curr episode timestep = 40
Above hoop
Current timestep = 5050. State = [[0.0419572 0.0088993 0.355623  1.       ]]. Action = [[-0.12895739  0.16032743 -0.2288478   0.47946024]]. Reward = [0.]
Curr episode timestep = 41
Above hoop
Current timestep = 5051. State = [[0.04341776 0.01159551 0.35870346 1.        ]]. Action = [[ 0.00463724 -0.08480346  0.68260825  0.40099394]]. Reward = [0.]
Curr episode timestep = 42
Above hoop
Current timestep = 5052. State = [[0.04895907 0.00149961 0.3686891  1.        ]]. Action = [[ 0.48514152 -0.70969754  0.02956593  0.5371517 ]]. Reward = [0.]
Curr episode timestep = 43
Above hoop
Current timestep = 5053. State = [[ 0.05332836 -0.00137664  0.37849972  1.        ]]. Action = [[0.23645973 0.48816228 0.42273235 0.5407264 ]]. Reward = [0.]
Curr episode timestep = 44
Above hoop
Current timestep = 5054. State = [[0.06346256 0.00607224 0.38696253 1.        ]]. Action = [[0.27633607 0.1897862  0.01719022 0.61898375]]. Reward = [0.]
Curr episode timestep = 45
Above hoop
Current timestep = 5055. State = [[0.07205527 0.01127644 0.39334524 1.        ]]. Action = [[-0.24168336  0.00729525  0.18233347  0.582731  ]]. Reward = [0.]
Curr episode timestep = 46
Above hoop
Current timestep = 5056. State = [[0.07167276 0.01179659 0.39340097 1.        ]]. Action = [[ 0.11292088 -0.07124388 -0.25506067  0.55427814]]. Reward = [0.]
Curr episode timestep = 47
Above hoop
Current timestep = 5057. State = [[0.07308651 0.00983999 0.38189855 1.        ]]. Action = [[ 0.20030856 -0.1440543  -0.5273791   0.61625624]]. Reward = [0.]
Curr episode timestep = 48
Above hoop
Current timestep = 5058. State = [[0.08237536 0.01140402 0.3748622  1.        ]]. Action = [[0.28439844 0.18991971 0.28496218 0.46837497]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 5059. State = [[0.09079938 0.01506801 0.37488565 1.        ]]. Action = [[ 0.06274295  0.06945384 -0.16064191  0.43537557]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 5060. State = [[0.09255509 0.01591565 0.37182578 1.        ]]. Action = [[ 0.50088906  0.15154123 -0.06179303  0.57309055]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 5061. State = [[0.09088322 0.02351557 0.3713679  1.        ]]. Action = [[-0.20489562  0.45172834 -0.015692    0.45856142]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 5062. State = [[0.08829039 0.03768427 0.36667424 1.        ]]. Action = [[ 0.11945975  0.5109755  -0.30463076  0.47738433]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 5063. State = [[0.09221239 0.04838972 0.3602306  1.        ]]. Action = [[ 0.31250715 -0.14112008  0.39578128  0.37898552]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 5064. State = [[0.09304031 0.0496623  0.360501   1.        ]]. Action = [[ 0.24507189 -0.5834687   0.18563437  0.42544913]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 5065. State = [[0.09376936 0.04451587 0.3608947  1.        ]]. Action = [[-0.07529998 -0.44875395 -0.08748734  0.38958788]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 5066. State = [[0.09391943 0.04134328 0.3614593  1.        ]]. Action = [[ 0.21521926 -0.18913841 -0.46126944  0.40847635]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 5067. State = [[0.09393319 0.04090013 0.36155558 1.        ]]. Action = [[ 0.3024416  -0.45595646  0.1711564   0.4157201 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 5068. State = [[0.09377058 0.0376746  0.36235297 1.        ]]. Action = [[-0.37448096 -0.1315993  -0.11528206  0.47094274]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 5069. State = [[0.09355413 0.03499164 0.36290517 1.        ]]. Action = [[ 0.608799   -0.27413225 -0.00513554  0.39941752]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 5070. State = [[0.09344386 0.03466979 0.3628383  1.        ]]. Action = [[ 0.5174236  -0.43247318 -0.16986579  0.4280734 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 5071. State = [[0.0915828  0.0284658  0.35619968 1.        ]]. Action = [[-0.03909689 -0.39860964 -0.45959544  0.37947536]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 5072. State = [[0.08964627 0.02421054 0.35021782 1.        ]]. Action = [[ 0.6020005  -0.5021787   0.12237775  0.41640127]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 5073. State = [[0.08798233 0.01345625 0.34680942 1.        ]]. Action = [[-0.15177125 -0.52406967 -0.12163359  0.38129604]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 5074. State = [[ 0.08779377 -0.00415242  0.34418193  1.        ]]. Action = [[ 0.00378847 -0.5461712  -0.23623163  0.34413004]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 5075. State = [[ 0.08770582 -0.01613628  0.33764184  1.        ]]. Action = [[ 0.7067952  -0.46814787 -0.24530411  0.3409307 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 5076. State = [[ 0.08707509 -0.01821249  0.3358678   1.        ]]. Action = [[ 0.31647158  0.26835656 -0.35233486  0.401608  ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 5077. State = [[ 0.0870159  -0.01826742  0.33579838  1.        ]]. Action = [[ 0.3481264  -0.02491093  0.26125228  0.3681581 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 5078. State = [[ 0.08723304 -0.01840761  0.3357619   1.        ]]. Action = [[ 0.58251786 -0.25602126 -0.11850059  0.39523208]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 5079. State = [[ 0.08832965 -0.0250855   0.33123484  1.        ]]. Action = [[ 0.2340436  -0.33918673 -0.34135652  0.42674708]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 5080. State = [[ 0.09206755 -0.03146747  0.32331404  1.        ]]. Action = [[ 0.39174318 -0.6170071  -0.28284025  0.3039925 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 5081. State = [[ 0.09248473 -0.03272478  0.32237405  1.        ]]. Action = [[ 0.48254073 -0.52069193  0.12482333  0.31734443]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 5082. State = [[ 0.09261141 -0.0328005   0.32216918  1.        ]]. Action = [[ 0.69284165 -0.3539796  -0.02473319  0.43900597]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 5083. State = [[ 0.09260936 -0.03280071  0.32202083  1.        ]]. Action = [[ 0.8071749  -0.4472612  -0.41754925  0.41815507]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 5084. State = [[ 0.09260936 -0.03280071  0.32202083  1.        ]]. Action = [[ 0.62727904 -0.36849236  0.08660233  0.26955175]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 5085. State = [[ 0.0926585  -0.03269354  0.3220459   1.        ]]. Action = [[ 0.6054075  -0.38702118  0.3772571   0.35482287]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 5086. State = [[ 0.09286889 -0.03217624  0.32204038  1.        ]]. Action = [[ 0.6191499  -0.5970391   0.24712384  0.37776387]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 5087. State = [[ 0.09238932 -0.04376843  0.32530516  1.        ]]. Action = [[-0.1984129  -0.63561946  0.20185137  0.32701695]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 5088. State = [[ 0.0904016  -0.05471867  0.32808587  1.        ]]. Action = [[ 0.7223381  -0.67614746  0.2782482   0.4241209 ]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 5089. State = [[ 0.08949099 -0.05857808  0.3287975   1.        ]]. Action = [[ 0.7531946  -0.66796803  0.16103339  0.3287922 ]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 5090. State = [[ 0.08929286 -0.05951596  0.3289754   1.        ]]. Action = [[ 0.60167384 -0.7591235   0.0631026   0.28683293]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 5091. State = [[ 0.08931419 -0.05972175  0.32897246  1.        ]]. Action = [[ 0.7231066  -0.5659112   0.27472794  0.33950198]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 5092. State = [[ 0.08928055 -0.05973752  0.32891965  1.        ]]. Action = [[ 0.49102283 -0.73436826  0.08822286  0.24889827]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 5093. State = [[ 0.0892733  -0.05978954  0.32893974  1.        ]]. Action = [[ 0.8019316 -0.7505735  0.1550622  0.2913103]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 5094. State = [[ 0.0892733  -0.05978954  0.32893974  1.        ]]. Action = [[ 0.6159612  -0.7140656  -0.4450959   0.26084876]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 5095. State = [[ 0.0892733  -0.05978954  0.32893974  1.        ]]. Action = [[ 0.6074805  -0.85917884  0.72713387  0.19892812]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 5096. State = [[ 0.0892733  -0.05978954  0.32893974  1.        ]]. Action = [[ 0.68502903 -0.81152976  0.79805756  0.17122447]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 5097. State = [[ 0.0892733  -0.05978954  0.32893974  1.        ]]. Action = [[ 0.6963725  -0.67019385  0.47649157  0.20131564]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 5098. State = [[ 0.0892733  -0.05978954  0.32893974  1.        ]]. Action = [[ 0.7368542  -0.79818916  0.20269084  0.07902539]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 5099. State = [[ 0.0892733  -0.05978954  0.32893974  1.        ]]. Action = [[ 0.70113075 -0.8861374   0.75458527  0.15959454]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 5100. State = [[ 0.0892733  -0.05978954  0.32893974  1.        ]]. Action = [[ 0.248842   -0.8685014   0.6573335   0.20694971]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 5101. State = [[ 0.08935253 -0.05980813  0.32893968  1.        ]]. Action = [[ 0.8684678  -0.9722106  -0.26367736  0.19945312]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 5102. State = [[ 0.08836152 -0.07348916  0.3331376   1.        ]]. Action = [[-0.12563473 -0.85502356  0.28060532  0.20223069]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 5103. State = [[ 0.08842801 -0.08846053  0.33985132  1.        ]]. Action = [[ 0.53777933 -0.68548787  0.6490693   0.26079738]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 5104. State = [[ 0.08774267 -0.09135584  0.34024522  1.        ]]. Action = [[ 0.9360962  -0.8869399  -0.00945973  0.27275574]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 5105. State = [[ 0.08775576 -0.09151745  0.34024525  1.        ]]. Action = [[ 0.81276464 -0.7528479   0.49960613  0.27267766]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 5106. State = [[ 0.08772198 -0.09153465  0.3401932   1.        ]]. Action = [[ 0.32355785 -0.78552085  0.4936347   0.22761548]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 5107. State = [[ 0.08772198 -0.09153465  0.3401932   1.        ]]. Action = [[ 0.875576   -0.75227726  0.0348767   0.18821931]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 5108. State = [[ 0.08772198 -0.09153465  0.3401932   1.        ]]. Action = [[ 0.5775415  -0.7109041  -0.11651498  0.34787846]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 5109. State = [[ 0.08772198 -0.09153465  0.3401932   1.        ]]. Action = [[ 0.657691   -0.63149613  0.3500768   0.23454249]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 5110. State = [[-0.25881252 -0.09113353  0.11137178  1.        ]]. Action = [[ 0.70057356 -0.5051105  -0.17667186  0.21260023]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 5111. State = [[-0.2581987  -0.10454948  0.10322136  1.        ]]. Action = [[-0.14833862 -0.2030161   0.93280435  0.95715797]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 5112. State = [[-0.25217527 -0.11797736  0.11836136  1.        ]]. Action = [[ 0.5764775  -0.5308555   0.36884224  0.97248673]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 5113. State = [[-0.23856547 -0.13704038  0.13884123  1.        ]]. Action = [[ 0.63796306 -0.6367541   0.7684002   0.93288803]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 5114. State = [[-0.22676373 -0.15979049  0.16940269  1.        ]]. Action = [[-0.28768897 -0.4364314   0.8780067   0.9238663 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 5115. State = [[-0.22214767 -0.17703426  0.20666192  1.        ]]. Action = [[ 0.34132242 -0.3217063   0.9802216   0.9291221 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 5116. State = [[-0.20739071 -0.18379147  0.24160726  1.        ]]. Action = [[0.6442785  0.11707091 0.8256109  0.93469095]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 5117. State = [[-0.17846371 -0.19122149  0.2772018   1.        ]]. Action = [[ 0.9046967  -0.4103043   0.9857131   0.98248005]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 5118. State = [[-0.14895003 -0.20090385  0.31856403  1.        ]]. Action = [[ 0.46605122 -0.16308218  0.958537    0.89992094]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 5119. State = [[-0.12334407 -0.20723891  0.35705256  1.        ]]. Action = [[0.89670587 0.02452147 0.8609867  0.5047586 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 5120. State = [[-0.09747665 -0.20589171  0.39519468  1.        ]]. Action = [[0.648391   0.14568365 0.7441473  0.80624866]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 5121. State = [[-0.08002101 -0.2042866   0.4159926   1.        ]]. Action = [[0.98578    0.20366895 0.8792865  0.5474777 ]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: Workspace boundary
Current timestep = 5122. State = [[-0.07821917 -0.20350067  0.4201342   1.        ]]. Action = [[0.89212894 0.02098966 0.8092216  0.5537487 ]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: Workspace boundary
Current timestep = 5123. State = [[-0.07810532 -0.20325719  0.4200948   1.        ]]. Action = [[0.5126207  0.04808617 0.7160468  0.4158708 ]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Current timestep = 5124. State = [[-0.07802116 -0.20307696  0.4200657   1.        ]]. Action = [[ 0.8826107  -0.05041039  0.8954619   0.5488181 ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Current timestep = 5125. State = [[-0.07802116 -0.20307696  0.4200657   1.        ]]. Action = [[ 0.9057238  -0.23866242  0.8669784   0.35882556]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 5126. State = [[-0.07793726 -0.2028971   0.4200367   1.        ]]. Action = [[ 0.8893306  -0.25422215  0.88542247  0.4909135 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 5127. State = [[-0.07785323 -0.2027168   0.42000768  1.        ]]. Action = [[ 0.81731606 -0.01635814  0.7628608   0.41945887]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 5128. State = [[-0.07785323 -0.2027168   0.42000768  1.        ]]. Action = [[ 0.8844011  -0.09753132  0.97944105  0.61255324]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 5129. State = [[-0.07785323 -0.2027168   0.42000768  1.        ]]. Action = [[ 0.9118055  -0.43789423  0.91819656  0.4424138 ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 5130. State = [[-0.07785323 -0.2027168   0.42000768  1.        ]]. Action = [[ 0.75887465 -0.5899896   0.94098186  0.60681486]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 5131. State = [[-0.07785323 -0.2027168   0.42000768  1.        ]]. Action = [[ 0.8548353  -0.23933744  0.957278    0.35844827]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 5132. State = [[-0.07785323 -0.2027168   0.42000768  1.        ]]. Action = [[ 0.88569796 -0.5247019   0.93822837  0.5511253 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 5133. State = [[-0.07785323 -0.2027168   0.42000768  1.        ]]. Action = [[ 0.837924  -0.4357065  0.817415   0.271101 ]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 5134. State = [[-0.07785323 -0.2027168   0.42000768  1.        ]]. Action = [[ 0.89099646 -0.57944596  0.8723984   0.51146424]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 5135. State = [[-0.07785323 -0.2027168   0.42000768  1.        ]]. Action = [[ 0.98603034 -0.07033968  0.9815093   0.44412565]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 5136. State = [[-0.07785323 -0.2027168   0.42000768  1.        ]]. Action = [[ 0.9741914  -0.3232097   0.8567655   0.53249717]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 5137. State = [[-0.07785323 -0.2027168   0.42000768  1.        ]]. Action = [[ 0.90032315 -0.31957185  0.7550504   0.4886341 ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 5138. State = [[-0.07785323 -0.2027168   0.42000768  1.        ]]. Action = [[ 0.8628149  -0.06742764  0.9534198   0.46352744]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 5139. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.87929916 -0.07988423  0.84259224  0.38032973]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 5140. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.95170426 -0.13379937  0.9296938   0.56913507]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 5141. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.9380467  -0.46870816  0.7291261   0.48675275]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 5142. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.9672494  -0.35314894  0.9443581   0.41865134]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 5143. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.659986   -0.37854838  0.75780153  0.34345853]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 5144. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.20619583 -0.25732613  0.96788347  0.21806097]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 5145. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.96791244 -0.21443522  0.7474134   0.3943249 ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 5146. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.9124098  -0.65980333  0.8093972   0.47370708]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 5147. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.91141415 -0.45686424  0.857337    0.5333059 ]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 5148. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[0.96195054 0.03214896 0.8056276  0.61585057]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 5149. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.4265622  -0.32200068  0.87722516  0.39228344]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 5150. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.91997457 -0.23375142  0.9487667   0.48869526]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 5151. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.9051404  -0.21957791  0.9414898   0.5119084 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 5152. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.9366336  -0.54449385  0.9326556   0.41085494]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 5153. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.79185057 -0.18790221  0.96240497  0.32570422]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 5154. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.949914   -0.45221364  0.8989011   0.31697452]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 5155. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.94862866 -0.20291603  0.8903718   0.533129  ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 5156. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.8360591  -0.4263608   0.84948397  0.51779294]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 5157. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[0.65343285 0.04101706 0.9287834  0.440768  ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 5158. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.9816375  -0.28114575  0.9596567   0.5112194 ]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 5159. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.97233343 -0.24380839  0.9322901   0.39123988]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 5160. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.99374115 -0.75550824  0.83548856  0.44140363]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 5161. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.98063636 -0.4953506   0.94659686  0.61396945]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 5162. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.9514556  -0.37490177  0.9856882   0.6127529 ]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 5163. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.7089932  -0.6216115   0.6251552   0.55383635]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 5164. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.89360344 -0.6061701   0.8771744   0.39424753]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 5165. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.8743508  -0.48248422  0.39580595  0.4351127 ]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 5166. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.9189379  -0.5756901   0.81689143  0.5645354 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 5167. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.93801796 -0.2708943   0.8047559   0.39430618]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 5168. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.9106269 -0.4775036  0.9827647  0.560231 ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 5169. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.92779016 -0.45133668  0.75028586  0.5317261 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 5170. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.9579624  -0.42446876  0.83955     0.63627934]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 5171. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.95073843 -0.38297987  0.92444944  0.44946718]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 5172. State = [[-0.07782524 -0.20265669  0.419998    1.        ]]. Action = [[ 0.95566237 -0.5954988   0.70159006  0.51446295]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 5173. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.958827   -0.43368232  0.8238349   0.60997033]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 5174. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.8991051 -0.6789106  0.9440627  0.5404806]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 5175. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.92313266 -0.37084854  0.96401596  0.3994875 ]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 5176. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[0.9295069  0.10239971 0.8609271  0.48911   ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 5177. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.8805125  -0.36686522  0.930629    0.450979  ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 5178. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.8748412  -0.39063632  0.93831515  0.4478866 ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 5179. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.96288514 -0.43174362  0.85250056  0.3891145 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 5180. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.86393404 -0.38736486  0.7895336   0.61049724]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 5181. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.9321269  -0.27829015  0.80828524  0.26695275]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 5182. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.67068744 -0.76300925  0.9888849   0.5603733 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 5183. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.92711663 -0.5823595   0.66772366  0.5740304 ]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 5184. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.93240917 -0.60464984  0.80955744  0.59773767]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 5185. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.8376713 -0.2802493  0.7997513  0.4680245]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 5186. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.9832109  -0.5344958   0.87196183  0.439731  ]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 5187. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.7473768  -0.24719435  0.927943    0.49604058]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 5188. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.86392164 -0.6327248   0.5695412   0.493016  ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 5189. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.94711864 -0.16041303  0.91345894  0.26622248]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 5190. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.9724071  -0.49111557  0.66660357  0.49722743]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 5191. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.8771765  -0.16832113  0.93924797  0.50115013]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 5192. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.89421344 -0.31998718  0.71132946  0.57379484]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 5193. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.93161726 -0.2729131   0.5398513   0.41786563]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 5194. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.97600675 -0.46854794  0.9681779   0.34148622]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 5195. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.9641433  -0.44484663  0.9284266   0.37903118]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 5196. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.92723966 -0.6434236   0.85158825  0.4093423 ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 5197. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.9553107  -0.16006547  0.87629414  0.6065397 ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 5198. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.7999878  -0.40542197  0.8865075   0.51660395]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 5199. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.9469553  -0.42649543  0.96281123  0.5923846 ]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 5200. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.9691391  -0.34302217  0.768677    0.57309175]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 5201. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.91263485 -0.4405439   0.8547082   0.547529  ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 5202. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.90350175 -0.5469702   0.786121    0.6469252 ]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 5203. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.8135544  -0.03606939  0.8843353   0.488353  ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 5204. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.9155408  -0.06562382  0.9884747   0.26677322]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 5205. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.98517156 -0.5015183   0.79774916  0.49500895]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 5206. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.9743824  -0.29495287  0.77682185  0.63995934]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 5207. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.90692854 -0.57159156  0.86444795  0.48017192]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 5208. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.9117187 -0.2886659  0.9771867  0.6335566]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 5209. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.90043736 -0.29389238  0.9037409   0.46688962]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 5210. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.93711734 -0.6435424   0.90199506  0.4806944 ]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 5211. State = [[-0.07784991 -0.20264427  0.41999662  1.        ]]. Action = [[ 0.85788035 -0.5608518   0.80321836  0.5615821 ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 5212. State = [[-0.26531947  0.15826541  0.11022619  1.        ]]. Action = [[ 0.9085376  -0.4693166   0.9844403   0.47964287]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 5213. State = [[-0.247766    0.16511193  0.10352006  1.        ]]. Action = [[ 0.85502946 -0.7086541   0.9297223   0.90373373]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 5214. State = [[-0.23096061  0.15377651  0.11330889  1.        ]]. Action = [[-0.8377428  -0.65715384  0.9673674   0.8826829 ]]. Reward = [0.]
Curr episode timestep = 1
Action ignored: Workspace boundary
Current timestep = 5215. State = [[-0.21533225  0.13846768  0.12741043  1.        ]]. Action = [[ 0.7876607  -0.81725526  0.8787396   0.9487487 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 5216. State = [[-0.18883832  0.11520389  0.16129507  1.        ]]. Action = [[ 0.6445329  -0.61973506  0.9955027   0.7989061 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 5217. State = [[-0.17286575  0.10245747  0.18579042  1.        ]]. Action = [[ 0.95515895 -0.5626127   0.67535853  0.79008806]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 5218. State = [[-0.16986336  0.10145281  0.18848568  1.        ]]. Action = [[ 0.981997   -0.95740914  0.8236302   0.90694535]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 5219. State = [[-0.16888477  0.10107064  0.18943375  1.        ]]. Action = [[ 0.24168396 -0.48110557  0.914443    0.90293   ]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 5220. State = [[-0.16887276  0.10079964  0.18952817  1.        ]]. Action = [[ 0.88639903 -0.52768177  0.9266529   0.8925345 ]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 5221. State = [[-0.16884518  0.10059415  0.18955655  1.        ]]. Action = [[ 0.8126068  -0.79333806  0.80682623  0.65195036]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 5222. State = [[-0.16884518  0.10059415  0.18955655  1.        ]]. Action = [[ 0.32068634 -0.54579914  0.8913032   0.90285873]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 5223. State = [[-0.16884518  0.10059415  0.18955655  1.        ]]. Action = [[ 0.53548837 -0.8545593   0.9466109   0.8581443 ]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 5224. State = [[-0.1668385   0.0895293   0.20299095  1.        ]]. Action = [[-0.15331382 -0.6448219   0.9546982   0.4519701 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 5225. State = [[-0.158642    0.06840371  0.23815568  1.        ]]. Action = [[ 0.62372637 -0.5771913   0.9365361   0.92093813]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 5226. State = [[-0.13933854  0.04465365  0.27641648  1.        ]]. Action = [[ 0.5919168 -0.6450705  0.976792   0.6276487]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 5227. State = [[-0.11509068  0.0148842   0.31790543  1.        ]]. Action = [[ 0.77887845 -0.87964106  0.96706045  0.72808313]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 5228. State = [[-0.09941907 -0.01505723  0.35833952  1.        ]]. Action = [[ 0.00909293 -0.7158302   0.98338175  0.4466362 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 5229. State = [[-0.0892049  -0.04160957  0.3970388   1.        ]]. Action = [[ 0.48260188 -0.5973107   0.95122564  0.28150332]]. Reward = [0.]
Curr episode timestep = 16
Above hoop
Current timestep = 5230. State = [[-0.08194235 -0.05378146  0.4237192   1.        ]]. Action = [[ 0.9888207  -0.50503945  0.6405275   0.32880664]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Above hoop
Current timestep = 5231. State = [[-0.08073286 -0.05608292  0.4282882   1.        ]]. Action = [[ 0.9891021  -0.66142875  0.60538507  0.60433745]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Above hoop
Current timestep = 5232. State = [[-0.08086582 -0.05641767  0.42831224  1.        ]]. Action = [[ 0.97763896 -0.5700858   0.89139366  0.45886374]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Above hoop
Current timestep = 5233. State = [[-0.08086582 -0.05641767  0.42831224  1.        ]]. Action = [[ 0.98158646 -0.702329    0.91602635  0.31552315]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Above hoop
Current timestep = 5234. State = [[-0.08086582 -0.05641767  0.42831224  1.        ]]. Action = [[ 0.78896224 -0.7554925   0.87231207  0.44575393]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Above hoop
Current timestep = 5235. State = [[-0.08083021 -0.05640557  0.4285434   1.        ]]. Action = [[ 0.88528407 -0.83053327  0.93510544  0.31179547]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Above hoop
Current timestep = 5236. State = [[-0.08083021 -0.05640557  0.4285434   1.        ]]. Action = [[ 0.97426915 -0.44906807  0.8657874   0.49868762]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Above hoop
Current timestep = 5237. State = [[-0.08093376 -0.05636645  0.4285371   1.        ]]. Action = [[ 0.9507166  -0.5646072   0.8812989   0.38333583]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Above hoop
Current timestep = 5238. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.98894596 -0.59313637  0.891377    0.3177086 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Above hoop
Current timestep = 5239. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.98885655 -0.47936445  0.8452475   0.42900836]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Above hoop
Current timestep = 5240. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.9637104  -0.78759915  0.6767374   0.5226753 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Above hoop
Current timestep = 5241. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.989089   -0.4753902   0.89760983  0.3265493 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Above hoop
Current timestep = 5242. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.94375634 -0.6140223   0.94466853  0.3454528 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Above hoop
Current timestep = 5243. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.9883975  -0.5963854   0.78425455  0.41652894]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Above hoop
Current timestep = 5244. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.9875752  -0.7937492   0.89993525  0.37993288]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Above hoop
Current timestep = 5245. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.8287232  -0.6300686   0.96360636  0.49883652]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Above hoop
Current timestep = 5246. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.93016195 -0.6058317   0.9577539   0.432508  ]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Above hoop
Current timestep = 5247. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.8140652  -0.6286481   0.96006846  0.23268235]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Above hoop
Current timestep = 5248. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.99651146 -0.6817679   0.61038995  0.2270596 ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Above hoop
Current timestep = 5249. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.4955517  -0.6335011   0.83057404  0.45135498]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Above hoop
Current timestep = 5250. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.94964075 -0.24933839  0.9814724   0.41222477]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Above hoop
Current timestep = 5251. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.9678471  -0.6142738  -0.02583742  0.4144187 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Above hoop
Current timestep = 5252. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.66188025 -0.4229058   0.9318733   0.5829625 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Above hoop
Current timestep = 5253. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.8618113  -0.4624974   0.95095086  0.4389882 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Above hoop
Current timestep = 5254. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.91783667 -0.783827    0.784418    0.35381484]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Above hoop
Current timestep = 5255. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.78724885 -0.7860803   0.62307835  0.03385293]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Above hoop
Current timestep = 5256. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.995342   -0.50125265  0.9215245   0.24072707]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Above hoop
Current timestep = 5257. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.4439485  -0.9250096   0.7556226   0.31637955]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Above hoop
Current timestep = 5258. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.9800823  -0.77239597  0.87306976  0.44983697]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Above hoop
Current timestep = 5259. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.96386456 -0.7823172   0.924916    0.08304799]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Above hoop
Current timestep = 5260. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.70625234 -0.8247406   0.9639809   0.23487973]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Above hoop
Current timestep = 5261. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.9486455  -0.7950125   0.7606118   0.39358044]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Above hoop
Current timestep = 5262. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.98346424 -0.861242    0.67011046  0.32533693]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Above hoop
Current timestep = 5263. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.9615369  -0.7725067   0.93105006  0.15513754]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Above hoop
Current timestep = 5264. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.9860811  -0.6363421   0.8936838   0.46809196]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Above hoop
Current timestep = 5265. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.9678786  -0.853184    0.98703074  0.47662628]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Above hoop
Current timestep = 5266. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.9413104  -0.3417827   0.5369904   0.27540135]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Above hoop
Current timestep = 5267. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.7366272  -0.7725502   0.7396096   0.33000827]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Above hoop
Current timestep = 5268. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.9052994  -0.55722225  0.9782176   0.28853762]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Above hoop
Current timestep = 5269. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.95788455 -0.6803058   0.95040464  0.3604982 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Above hoop
Current timestep = 5270. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.9161501  -0.43667245  0.926244    0.40393853]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Above hoop
Current timestep = 5271. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.8506603 -0.5547777  0.8757634  0.4076221]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Above hoop
Current timestep = 5272. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.95755124 -0.5810614   0.81057703  0.4700601 ]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Above hoop
Current timestep = 5273. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.9695054  -0.62630016  0.8445802   0.58483815]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Above hoop
Current timestep = 5274. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.9568651 -0.629398   0.9530088  0.5067687]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Above hoop
Current timestep = 5275. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.947649   -0.4662181   0.806607    0.41618276]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Above hoop
Current timestep = 5276. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.8084136  -0.48323083  0.92108154  0.43873966]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Above hoop
Current timestep = 5277. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.8326721  -0.7252774   0.9800594   0.38708067]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Above hoop
Current timestep = 5278. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.9715556 -0.7248166  0.922171   0.5200908]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Above hoop
Current timestep = 5279. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.83636117 -0.6651412   0.82930386  0.4083799 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Above hoop
Current timestep = 5280. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.88997066 -0.560957    0.7924528   0.52874327]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Above hoop
Current timestep = 5281. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.96454155 -0.7274124   0.7492466   0.3523028 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Above hoop
Current timestep = 5282. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.990139   -0.501215    0.980492    0.57138145]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Above hoop
Current timestep = 5283. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.60464644 -0.5390889   0.91302943  0.06671011]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Above hoop
Current timestep = 5284. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.9719385 -0.7677857  0.6741413  0.3748356]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Above hoop
Current timestep = 5285. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.91841865 -0.7176933   0.97311115  0.2488854 ]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Above hoop
Current timestep = 5286. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.62314093 -0.816096    0.9409778   0.5288538 ]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Above hoop
Current timestep = 5287. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.9935919  -0.72339094  0.7450733   0.3373183 ]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Above hoop
Current timestep = 5288. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.84659743 -0.57210207  0.29104066  0.54032516]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Above hoop
Current timestep = 5289. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.96044505 -0.7876645   0.64756584  0.40746427]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Above hoop
Current timestep = 5290. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.9648466 -0.7178697  0.855489   0.5613649]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Above hoop
Current timestep = 5291. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.78941464 -0.65831447  0.89559007  0.4077351 ]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Above hoop
Current timestep = 5292. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.874591   -0.82497126  0.9115257   0.5606593 ]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Above hoop
Current timestep = 5293. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.92681384 -0.5775134   0.94584656  0.33054018]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Above hoop
Current timestep = 5294. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.9780698  -0.6720841   0.9909643   0.29732704]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Above hoop
Current timestep = 5295. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.9385122  -0.49987763  0.89137125  0.40429962]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Above hoop
Current timestep = 5296. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.92140853 -0.6723266   0.8886006   0.33685184]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Above hoop
Current timestep = 5297. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.79609084 -0.86285126  0.69626427  0.25615442]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Above hoop
Current timestep = 5298. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.8956789  -0.3442337   0.7523172   0.24761987]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Above hoop
Current timestep = 5299. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.8797835  -0.42978394  0.9199152   0.48300004]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Above hoop
Current timestep = 5300. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.8357613  -0.567098    0.47429204  0.42178714]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Above hoop
Current timestep = 5301. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.9544883  -0.71948963  0.44493556  0.459486  ]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Above hoop
Current timestep = 5302. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.95976007 -0.51649857  0.8795047   0.42515945]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Above hoop
Current timestep = 5303. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.9917197  -0.6792386   0.86773515  0.5374428 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Above hoop
Current timestep = 5304. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.8933344  -0.54384166  0.87222016  0.47519398]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Above hoop
Current timestep = 5305. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.33476257 -0.7097583   0.84147453  0.4008844 ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Above hoop
Current timestep = 5306. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.72672296 -0.44529665 -0.07811666  0.37007666]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Above hoop
Current timestep = 5307. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.92062974 -0.1793049   0.7989552   0.47869706]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Above hoop
Current timestep = 5308. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.8183032  -0.4017464   0.81983876  0.445485  ]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Above hoop
Current timestep = 5309. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.9670254  -0.47535902  0.91602576  0.6147207 ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Above hoop
Current timestep = 5310. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.75175476 -0.7055035   0.9759971   0.39258623]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Above hoop
Current timestep = 5311. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.98341465 -0.8068581   0.60923505  0.40858412]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Above hoop
Current timestep = 5312. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.9159174  -0.7608099   0.8124186   0.42654908]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Above hoop
Current timestep = 5313. State = [[-0.08114085 -0.05628821  0.42852482  1.        ]]. Action = [[ 0.97142005 -0.7167684   0.8787725   0.37981224]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Above hoop
Current timestep = 5314. State = [[-0.25765985 -0.05864503  0.11192001  1.        ]]. Action = [[ 0.79927635 -0.6611613   0.9514737   0.3017466 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Above hoop
Current timestep = 5315. State = [[-0.2549417  -0.07672326  0.10531824  1.        ]]. Action = [[ 0.16410863 -0.7391494   0.9012543   0.8696139 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 5316. State = [[-0.2514838  -0.09960824  0.12483323  1.        ]]. Action = [[-0.12868202 -0.4321645   0.9617703   0.98927784]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 5317. State = [[-0.2523817  -0.11924963  0.16046266  1.        ]]. Action = [[-0.14459634 -0.43453407  0.9558934   0.9972186 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 5318. State = [[-0.25456774 -0.13000748  0.18702571  1.        ]]. Action = [[-0.6691088  -0.6004737   0.9810722   0.98792064]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: Workspace boundary
Current timestep = 5319. State = [[-0.25178653 -0.1352038   0.20101768  1.        ]]. Action = [[ 0.161793   -0.19430411  0.91830194  0.9926566 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 5320. State = [[-0.24899082 -0.14392409  0.23381212  1.        ]]. Action = [[ 0.15896237 -0.30164057  0.7663009   0.9972384 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 5321. State = [[-0.23918736 -0.14974622  0.25748166  1.        ]]. Action = [[0.51659167 0.15368974 0.20480227 0.973542  ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 5322. State = [[-0.2239478  -0.15490079  0.27849045  1.        ]]. Action = [[ 0.24929786 -0.36447585  0.9849496   0.90155196]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 5323. State = [[-0.21109158 -0.16120875  0.31450284  1.        ]]. Action = [[0.16542292 0.04815626 0.93944633 0.9872978 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 5324. State = [[-0.19888443 -0.15719268  0.3526863   1.        ]]. Action = [[0.42084312 0.27920985 0.9421735  0.94312453]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 5325. State = [[-0.18582045 -0.14687394  0.3914025   1.        ]]. Action = [[0.07768917 0.39829397 0.97660017 0.91532683]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 5326. State = [[-0.18093503 -0.13884972  0.4183939   1.        ]]. Action = [[0.5318061  0.3807404  0.91390586 0.7286732 ]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: Workspace boundary
Current timestep = 5327. State = [[-0.18014936 -0.13783026  0.42223948  1.        ]]. Action = [[0.9379804  0.18184805 0.8571626  0.65295553]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Current timestep = 5328. State = [[-0.17851825 -0.13784616  0.42541215  1.        ]]. Action = [[ 0.91395783 -0.05854744  0.8800396   0.8100207 ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Current timestep = 5329. State = [[-0.17871356 -0.13787183  0.4255112   1.        ]]. Action = [[0.8333342  0.37938762 0.84892154 0.799526  ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 5330. State = [[-0.17869274 -0.13785431  0.42553657  1.        ]]. Action = [[ 0.9470445 -0.3802334  0.8809843  0.8003404]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 5331. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.81279397 0.14260232 0.85987306 0.8079288 ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 5332. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[ 0.8316977  -0.34992194  0.94959617  0.78796625]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 5333. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[ 0.8340614  -0.37122416  0.87644434  0.75000143]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 5334. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[ 0.8714812  -0.13577133  0.9778545   0.84355974]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 5335. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[ 0.88636494 -0.02210754  0.96588135  0.7996087 ]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 5336. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[ 0.78968775 -0.04030514  0.98592067  0.83802795]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 5337. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.76811945 0.03173184 0.87372994 0.73714054]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 5338. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.88075614 0.04767978 0.91151536 0.77605915]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 5339. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.7743013 0.1347444 0.9805485 0.7325816]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 5340. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[ 0.62445164 -0.00312364  0.95987177  0.7514434 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 5341. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[ 0.7942301  -0.04917401  0.8607664   0.870734  ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 5342. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.25888193 0.17407978 0.95665526 0.6489899 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 5343. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[ 0.7767595  -0.22651505  0.9391401   0.8688592 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 5344. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.31045318 0.0441519  0.9103184  0.7687851 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 5345. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.88246727 0.02082276 0.994285   0.75015366]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 5346. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[ 0.5655687  -0.3156436   0.74024343  0.87851954]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 5347. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.9587722  0.44544125 0.89642215 0.7398114 ]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 5348. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.9714308  0.13444018 0.9708266  0.72297275]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 5349. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[ 0.97575235 -0.06014943  0.9200604   0.5802711 ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 5350. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.96832216 0.0213387  0.8995098  0.8657427 ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 5351. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[ 0.73391557 -0.31804073  0.9748907   0.804533  ]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 5352. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.6815102  0.13118649 0.92552876 0.72530365]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 5353. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.74771047 0.04887402 0.9637356  0.7985976 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 5354. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[ 0.9336817  -0.22405678  0.95999193  0.79756474]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 5355. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.67068505 0.03177059 0.9355316  0.80949664]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 5356. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.7952182  0.07088733 0.911307   0.81964874]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 5357. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.66120553 0.21377194 0.6699717  0.66053617]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 5358. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.9386263 0.4242735 0.9287437 0.8422959]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 5359. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.8168211  0.5577564  0.5670638  0.78348684]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 5360. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.93174934 0.08447611 0.976784   0.81090355]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 5361. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.6911578  0.00260592 0.8581035  0.7746533 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 5362. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.51886666 0.11593676 0.8941721  0.71625113]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 5363. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.8409867  0.17264128 0.9456558  0.72411966]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 5364. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.8211241  0.01223934 0.58782244 0.8570566 ]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 5365. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.7629702  0.14624524 0.8674396  0.8998239 ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 5366. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[ 0.2074666  -0.03069687  0.8451688   0.8477825 ]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 5367. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.83433616 0.29158425 0.9670994  0.7268981 ]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 5368. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[-0.01371855  0.10263968  0.9675348   0.7927369 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 5369. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.23786867 0.2436192  0.88059247 0.7081921 ]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 5370. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[ 0.94415605 -0.07888997  0.9204953   0.6571356 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 5371. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.6783165  0.31526697 0.95673764 0.8268292 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 5372. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.6497917  0.13166893 0.9022932  0.9146185 ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 5373. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[ 0.90689325 -0.18582112  0.9177654   0.6145408 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 5374. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.9705081  0.05393136 0.5374296  0.74587905]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 5375. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.78517437 0.32969344 0.8814895  0.8878081 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 5376. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.6881914  0.55833673 0.9914398  0.80240965]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 5377. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[ 0.8721378  -0.15565693  0.8254279   0.6642051 ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 5378. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.571548   0.49848247 0.69770014 0.7287257 ]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 5379. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.7860811  0.10525572 0.9160855  0.8618109 ]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 5380. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.63362503 0.4102366  0.94896626 0.9168427 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 5381. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.53972423 0.3797555  0.8707557  0.79956913]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 5382. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.8381405  0.06712723 0.9484787  0.8453655 ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 5383. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.7108114  0.1667223  0.93848693 0.92994237]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 5384. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.9424515  0.1097976  0.74721086 0.7728077 ]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 5385. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.9697602  0.24299967 0.5484208  0.7367605 ]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 5386. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.7649461  0.28045404 0.9617958  0.8383868 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 5387. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.7343905  0.31712902 0.61960495 0.513816  ]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 5388. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[-0.01597887  0.22507131  0.8659501   0.8978975 ]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 5389. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.59459615 0.01045561 0.8283719  0.9281404 ]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 5390. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[ 0.9467516  -0.10213888  0.9849355   0.96733403]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 5391. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.726614  0.1455605 0.9170916 0.6351867]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 5392. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[ 0.9339769  -0.01499426  0.8093746   0.9200237 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 5393. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[ 0.80804944 -0.04054564  0.95583403  0.7324822 ]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 5394. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.91916525 0.10939705 0.6317916  0.91492057]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 5395. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[ 0.23950028 -0.19381827  0.9337915   0.663532  ]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 5396. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.911934   0.30793536 0.9623072  0.9545928 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 5397. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.9515784  0.14928782 0.97691727 0.9410424 ]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 5398. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[ 0.05596721 -0.09969091  0.8108301   0.853819  ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 5399. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.7960701  0.2870233  0.888031   0.81562054]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 5400. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.30486882 0.2858938  0.5332732  0.95403457]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 5401. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.09632063 0.36517382 0.88167095 0.9561758 ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 5402. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.9229077  0.27713037 0.98122406 0.8551848 ]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 5403. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.94583774 0.36660194 0.7072873  0.7939925 ]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 5404. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.79852486 0.17054689 0.9723232  0.7557858 ]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 5405. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[ 0.6080191  -0.40320402  0.5198016   0.8901677 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 5406. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.9122493  0.35730457 0.88547516 0.6991496 ]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 5407. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.5448241  0.01705182 0.94151294 0.94247234]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 5408. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.36116207 0.3195846  0.70050836 0.8854222 ]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 5409. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.93010783 0.5689361  0.9505892  0.75664496]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 5410. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.69492435 0.04576528 0.9150884  0.8416579 ]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 5411. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.8494165  0.2770896  0.94351053 0.80328345]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 5412. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.85390997 0.24174571 0.9290712  0.94281673]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 5413. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[ 0.83101666 -0.00245214  0.7871671   0.9369428 ]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 5414. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.5149982  0.18082654 0.9534917  0.90681636]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 5415. State = [[-0.17871828 -0.13784346  0.4255355   1.        ]]. Action = [[0.3052516  0.2771567  0.60997033 0.9378581 ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 5416. State = [[-0.26228184  0.07427087  0.11008409  1.        ]]. Action = [[0.4400041 0.220469  0.8381617 0.8582636]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 5417. State = [[-0.26277068  0.08244143  0.09674811  1.        ]]. Action = [[-0.4218446  -0.85973704  0.9866668   0.9991038 ]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Current timestep = 5418. State = [[-0.262821    0.08288477  0.09673325  1.        ]]. Action = [[-0.3098334  -0.76773745  0.87125015  0.9926537 ]]. Reward = [0.]
Curr episode timestep = 1
Action ignored: Workspace boundary
Current timestep = 5419. State = [[-0.26271605  0.08328924  0.09675099  1.        ]]. Action = [[-0.66504014 -0.50015557  0.3776132   0.9778578 ]]. Reward = [0.]
Curr episode timestep = 2
Action ignored: Workspace boundary
Current timestep = 5420. State = [[-0.26274508  0.08354241  0.0967428   1.        ]]. Action = [[-0.7485888 -0.7684252  0.7826793  0.983166 ]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: Workspace boundary
Current timestep = 5421. State = [[-0.2627747   0.08379986  0.09673458  1.        ]]. Action = [[-0.26714444 -0.7941799   0.79768074  0.991776  ]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: Workspace boundary
Current timestep = 5422. State = [[-0.26279706  0.08399348  0.09672846  1.        ]]. Action = [[-0.6678672  -0.60966367  0.9439467   0.9925169 ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: Workspace boundary
Current timestep = 5423. State = [[-0.26279706  0.08399348  0.09672846  1.        ]]. Action = [[-0.21543801 -0.82754356  0.79082894  0.97421074]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: Workspace boundary
Current timestep = 5424. State = [[-0.2628044   0.08405688  0.09672647  1.        ]]. Action = [[-0.40728164 -0.72282255  0.824831    0.98351526]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: Workspace boundary
Current timestep = 5425. State = [[-0.25478312  0.07687093  0.10433671  1.        ]]. Action = [[ 0.417387   -0.5450417   0.9703201   0.99238753]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 5426. State = [[-0.24743098  0.06829378  0.11503781  1.        ]]. Action = [[-0.35999912 -0.6114788   0.9225428   0.99260163]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: Workspace boundary
Current timestep = 5427. State = [[-0.24367     0.05443983  0.11961814  1.        ]]. Action = [[-0.05909038 -0.78410465  0.32595217  0.9917375 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 5428. State = [[-0.2418411   0.04113693  0.12745823  1.        ]]. Action = [[-0.5243316 -0.7774285  0.8471185  0.9798546]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: Workspace boundary
Current timestep = 5429. State = [[-0.24109976  0.02842087  0.14004846  1.        ]]. Action = [[-0.24082816 -0.6193183   0.9368954   0.9976692 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 5430. State = [[-0.2420288   0.00763589  0.17431448  1.        ]]. Action = [[ 0.11233854 -0.55170393  0.9020138   0.8946327 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 5431. State = [[-0.24212784 -0.00214843  0.20196235  1.        ]]. Action = [[0.13801837 0.12295282 0.5172572  0.991354  ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 5432. State = [[-0.23386587 -0.00971865  0.22581212  1.        ]]. Action = [[ 0.5154984  -0.5292064   0.6297338   0.98570836]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 5433. State = [[-0.21260871 -0.03073526  0.25182673  1.        ]]. Action = [[ 0.63349795 -0.69280255  0.52449787  0.9490353 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 5434. State = [[-0.19954742 -0.04996391  0.27621794  1.        ]]. Action = [[-0.151923   -0.23018909  0.6906159   0.9770522 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 5435. State = [[-0.18836217 -0.05532276  0.30557802  1.        ]]. Action = [[0.6297035  0.15814161 0.9547503  0.98573554]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 5436. State = [[-0.1773379  -0.04953718  0.3417961   1.        ]]. Action = [[-0.34105825  0.29208434  0.7873837   0.8855932 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 5437. State = [[-0.16926788 -0.04491461  0.3738575   1.        ]]. Action = [[ 0.9550282  -0.04754221  0.7590437   0.8875383 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 5438. State = [[-0.15440375 -0.04336333  0.398219    1.        ]]. Action = [[ 0.6086657  -0.28767723  0.9134283   0.8779013 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 5439. State = [[-0.15114865 -0.04302056  0.4037794   1.        ]]. Action = [[ 0.6251123  -0.06554788  0.633278    0.85415053]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 5440. State = [[-0.1511939  -0.04303413  0.40375337  1.        ]]. Action = [[ 0.8555157  -0.07709038  0.9482335   0.77065825]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 5441. State = [[-0.1511939  -0.04303413  0.40375337  1.        ]]. Action = [[0.6684519  0.08851075 0.93901575 0.78383636]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 5442. State = [[-0.1511939  -0.04303413  0.40375337  1.        ]]. Action = [[0.02579176 0.17601478 0.9287895  0.50867736]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 5443. State = [[-0.1511939  -0.04303413  0.40375337  1.        ]]. Action = [[ 0.827641   -0.45575964  0.77579796  0.6159594 ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 5444. State = [[-0.1511939  -0.04303413  0.40375337  1.        ]]. Action = [[ 0.974998   -0.3192768   0.24708998  0.5442835 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 5445. State = [[-0.1511939  -0.04303413  0.40375337  1.        ]]. Action = [[ 0.882179   -0.14310807  0.985186    0.66713214]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 5446. State = [[-0.1511939  -0.04303413  0.40375337  1.        ]]. Action = [[ 0.7768779  -0.5188767   0.42859077  0.7960352 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 5447. State = [[-0.14149489 -0.04828074  0.40561855  1.        ]]. Action = [[ 0.83535564 -0.3280036   0.10271478  0.82713675]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 5448. State = [[-0.12476733 -0.05228887  0.4084831   1.        ]]. Action = [[0.85181093 0.07034373 0.5999675  0.79895294]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 5449. State = [[-0.12119873 -0.05488875  0.4083696   1.        ]]. Action = [[ 0.8051331  -0.28882015  0.8808248   0.5647712 ]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 5450. State = [[-0.12133047 -0.05552768  0.40842846  1.        ]]. Action = [[ 0.9794183  -0.37797725  0.807536    0.37640512]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 5451. State = [[-0.12133047 -0.05552768  0.40842846  1.        ]]. Action = [[ 0.95104325 -0.25710583  0.5536498   0.59999895]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 5452. State = [[-0.12137254 -0.0557199   0.40846187  1.        ]]. Action = [[ 0.65504014 -0.44284832  0.7755585   0.5566015 ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 5453. State = [[-0.12138648 -0.05578353  0.40847293  1.        ]]. Action = [[ 0.9724231  -0.222148    0.32627916  0.43662393]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 5454. State = [[-0.12138648 -0.05578353  0.40847293  1.        ]]. Action = [[-0.29108423 -0.518206    0.83322287  0.7059469 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 5455. State = [[-0.12138648 -0.05578353  0.40847293  1.        ]]. Action = [[ 0.9120934  -0.42863864  0.59195364  0.44072223]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 5456. State = [[-0.12142865 -0.05597571  0.40850633  1.        ]]. Action = [[0.9418678  0.19097924 0.76900125 0.34089112]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 5457. State = [[-0.12144271 -0.05603977  0.40851748  1.        ]]. Action = [[ 0.90104675 -0.62339664  0.54335546  0.59268546]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 5458. State = [[-0.12144271 -0.05603977  0.40851748  1.        ]]. Action = [[ 0.9350579  -0.6068914   0.38287997  0.59892917]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 5459. State = [[-0.12144271 -0.05603977  0.40851748  1.        ]]. Action = [[ 0.7460234  -0.6598998   0.80628157  0.45498085]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 5460. State = [[-0.12144271 -0.05603977  0.40851748  1.        ]]. Action = [[ 0.97265625 -0.62387925  0.32480907  0.56447506]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 5461. State = [[-0.12144271 -0.05603977  0.40851748  1.        ]]. Action = [[ 0.9622035  -0.4890436   0.86868596  0.38307798]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 5462. State = [[-0.11255264 -0.06451115  0.4056881   1.        ]]. Action = [[ 0.97440743 -0.59262353 -0.26568145  0.54698765]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 5463. State = [[-0.08862726 -0.07391576  0.3996853   1.        ]]. Action = [[ 0.88410425 -0.7581682   0.8697851   0.4544593 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 5464. State = [[-0.0849956  -0.07509921  0.3991755   1.        ]]. Action = [[ 0.96937084 -0.69576234  0.89675903  0.19283688]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 5465. State = [[-0.07539969 -0.08439293  0.40242994  1.        ]]. Action = [[ 0.72957397 -0.5052516   0.2103939   0.38351429]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 5466. State = [[-0.05369557 -0.108248    0.39893916  1.        ]]. Action = [[ 0.95055175 -0.8803436  -0.6272566   0.32455146]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 5467. State = [[-0.01753019 -0.13928504  0.38026088  1.        ]]. Action = [[ 0.955421   -0.6437636  -0.3618015   0.16864705]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 5468. State = [[ 0.0214156  -0.16195051  0.37726977  1.        ]]. Action = [[ 0.9559257  -0.48660314  0.48326182  0.15360463]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 5469. State = [[ 0.04666501 -0.18139687  0.37529528  1.        ]]. Action = [[ 0.49184465 -0.51314855 -0.8332965   0.19083226]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 5470. State = [[ 0.06904383 -0.19378318  0.35654774  1.        ]]. Action = [[ 0.7214545  -0.6038247   0.81818056  0.17928898]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 5471. State = [[ 0.07564142 -0.19524425  0.35599732  1.        ]]. Action = [[ 0.7907417  -0.7284247  -0.9927016   0.17313325]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 5472. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.9023404  -0.732031   -0.6757636   0.14461946]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 5473. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.8495759  -0.74846226 -0.866906    0.10283947]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 5474. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.90047693 -0.7128048  -0.54557216  0.08305621]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 5475. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.47561717 -0.57233495  0.22303128  0.10273981]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 5476. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.94236636 -0.56377447 -0.6989969   0.08141184]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 5477. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.7134943  -0.6536829  -0.9232259   0.13837183]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 5478. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.95280826 -0.47138286 -0.80012125  0.07674456]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 5479. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.88265204 -0.5670032  -0.35425723  0.02940965]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 5480. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.75908697 -0.5080931  -0.88172907  0.07956779]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 5481. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.8138039  -0.6511728  -0.75972503  0.05248213]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 5482. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.7711332  -0.44145548 -0.50012845  0.09505785]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 5483. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.8115816  -0.35132134 -0.79867303  0.03349924]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 5484. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.71325433 -0.49035692 -0.87900794  0.08499479]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 5485. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.85957074 -0.5901932  -0.83720905  0.08374858]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 5486. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.84846675 -0.7359535  -0.96773183  0.06971896]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 5487. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.95532274 -0.65331215 -0.914835    0.05822515]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 5488. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.75082135 -0.6711667  -0.96020895  0.09124637]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 5489. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.8625741  -0.71603084 -0.95833284  0.08676136]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 5490. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.89344907 -0.71021134 -0.70587033  0.03044868]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 5491. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.88993335 -0.59972304 -0.77709657  0.01958847]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 5492. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.8438947  -0.67935467 -0.833236    0.05216622]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 5493. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.9227829 -0.6918997 -0.970524   0.0477612]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 5494. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.95621085 -0.52408516 -0.97394437  0.06784439]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 5495. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.89663196 -0.53537446 -0.932821    0.05448496]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 5496. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.9537251  -0.73457164 -0.9461843   0.03201032]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 5497. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.97947574 -0.5759369  -0.97551316  0.03252697]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 5498. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.6684153  -0.70870817 -0.95160043  0.03108752]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 5499. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.8624599  -0.65069187 -0.824634    0.0070883 ]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 5500. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.9506383  -0.534049   -0.88443136  0.03358829]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 5501. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.92048466 -0.5907263  -0.98401326  0.03991711]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 5502. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.93840694 -0.7664752  -0.92817104  0.04710722]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 5503. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.9166348 -0.734689  -0.8744174  0.0122937]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 5504. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.7657678  -0.6470349  -0.940708    0.01906574]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 5505. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.95724845 -0.7214426  -0.9783938   0.05106771]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 5506. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.9445087  -0.66627556 -0.73017186  0.09363317]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 5507. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.9619924  -0.58673275 -0.94465137  0.07299805]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 5508. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.9227557  -0.6173688  -0.84508437  0.04648066]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 5509. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.9358276  -0.42955315 -0.9483555   0.03239536]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 5510. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.9485506  -0.6445229  -0.8717838   0.08185363]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 5511. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.8324194  -0.61066633 -0.9450019   0.05640447]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 5512. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.95184207 -0.6535359  -0.85945195  0.06371772]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 5513. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.9314848  -0.6995235  -0.9012914   0.08692038]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 5514. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.96525645 -0.7046879  -0.90588087  0.02316368]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 5515. State = [[ 0.07562734 -0.1955635   0.35592607  1.        ]]. Action = [[ 0.7802632  -0.49843    -0.7253066   0.04604673]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 5516. State = [[ 0.07532883 -0.20335768  0.35108712  1.        ]]. Action = [[ 0.44395518 -0.5491679  -0.82457995  0.04399657]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 5517. State = [[ 0.0895065  -0.21561995  0.32819915  1.        ]]. Action = [[ 0.839682   -0.4450338  -0.93376905  0.01100755]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 5518. State = [[-0.2607385  -0.1272864   0.11238051  1.        ]]. Action = [[ 0.8992975  -0.60995466 -0.86892486  0.08517909]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 5519. State = [[-0.26143706 -0.15235463  0.10192148  1.        ]]. Action = [[ 0.05969262 -0.7053163   0.70584226  0.9698825 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 5520. State = [[-0.25997764 -0.17911465  0.11398558  1.        ]]. Action = [[ 0.01599681 -0.73935694  0.46940935  0.9988148 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 5521. State = [[-0.2563221  -0.20516208  0.12292726  1.        ]]. Action = [[ 0.33674634 -0.6761946  -0.38148487  0.99045205]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 5522. State = [[-0.25071332 -0.23299351  0.13181046  1.        ]]. Action = [[ 0.21795893 -0.6678742   0.97389853  0.99807954]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 5523. State = [[-0.24458733 -0.25484714  0.14600535  1.        ]]. Action = [[-0.0622564  -0.41486585 -0.22803783  0.99709415]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 5524. State = [[-0.24110182 -0.2724971   0.15178156  1.        ]]. Action = [[ 0.19187927 -0.47857368  0.52399063  0.9963776 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 5525. State = [[-0.23186372 -0.2908885   0.17229311  1.        ]]. Action = [[ 0.2049253  -0.3962338   0.9997572   0.99740577]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 5526. State = [[-0.22099656 -0.30780908  0.21137089  1.        ]]. Action = [[ 0.35102677 -0.33411407  0.99691796  0.99735284]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 5527. State = [[-0.21191478 -0.31752118  0.23657832  1.        ]]. Action = [[ 0.5065048  -0.32167363  0.8571589   0.9886975 ]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: Workspace boundary
Current timestep = 5528. State = [[-0.20892747 -0.31953627  0.24108721  1.        ]]. Action = [[ 0.765537  -0.2491504  0.7364135  0.9312768]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: Workspace boundary
Current timestep = 5529. State = [[-0.20878316 -0.3198668   0.24164401  1.        ]]. Action = [[ 0.7901372  -0.12732714  0.605006    0.96303403]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: Workspace boundary
Current timestep = 5530. State = [[-0.20842278 -0.32017612  0.242326    1.        ]]. Action = [[ 0.6083214  -0.01211596  0.07276297  0.98831224]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: Workspace boundary
Current timestep = 5531. State = [[-0.20867443 -0.32029766  0.24239776  1.        ]]. Action = [[ 0.6222067  -0.19696689  0.9819814   0.91592026]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Current timestep = 5532. State = [[-0.20830859 -0.3205983   0.24268512  1.        ]]. Action = [[ 0.39546847 -0.22819388  0.9489337   0.9910207 ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Current timestep = 5533. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.6566372 -0.2886269  0.6261313  0.9762192]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 5534. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.6816373  -0.1486392   0.96117234  0.99854136]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 5535. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.5321816  -0.28483975  0.4181249   0.9885235 ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 5536. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.643904   -0.07982528  0.56102896  0.9944024 ]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 5537. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[0.29524696 0.03458655 0.7448695  0.9930196 ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 5538. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.7109276   0.17068207 -0.65324706  0.98884296]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 5539. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.51708484 -0.12125164  0.4730898   0.96766114]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 5540. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.6106925  -0.07641417  0.9019846   0.9902034 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 5541. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[0.26222444 0.03964674 0.95673406 0.9895382 ]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 5542. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.5408926  -0.12860757  0.8407488   0.98863304]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 5543. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[0.29619074 0.03678405 0.86079204 0.98497295]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 5544. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.5373895  -0.34129846  0.8987005   0.99322224]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 5545. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.3622712  -0.25118446  0.9372685   0.9690435 ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 5546. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.59506345 -0.4147638   0.95581114  0.99880934]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 5547. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.5954149  -0.03869617  0.4434451   0.985291  ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 5548. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.70473576 -0.4870606   0.9087248   0.97707677]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 5549. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.56217694 -0.16323996  0.7894908   0.97022796]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 5550. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.372504   -0.10538554  0.9210539   0.9800327 ]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 5551. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.547341   -0.19869828  0.85981417  0.99794674]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 5552. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.2554189  -0.23070908  0.9306047   0.97544897]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 5553. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.44498253 -0.2558657   0.9653375   0.97763824]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 5554. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.58392286 -0.07417393  0.808627    0.9908149 ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 5555. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.48589206 -0.320611    0.14813077  0.97988987]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 5556. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.39119565 -0.09576303  0.851478    0.95479774]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 5557. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.6090294  -0.34224343  0.9211178   0.98759055]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 5558. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.57899773 -0.10856169  0.5768622   0.94568074]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 5559. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.20830369 -0.33155644  0.40968752  0.9972464 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 5560. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.690887   -0.07444245  0.00781572  0.99029696]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 5561. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.5444081  -0.21085894  0.99038553  0.97377634]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 5562. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[0.50959945 0.13959455 0.45265925 0.9746461 ]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 5563. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.59324527 -0.07085073  0.8967179   0.9905882 ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 5564. State = [[-0.20845161 -0.32072362  0.24271321  1.        ]]. Action = [[ 0.74618316 -0.01309872  0.9664948   0.9745581 ]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 5565. State = [[-0.2002684  -0.31792796  0.25233477  1.        ]]. Action = [[0.6308167  0.21650743 0.75186574 0.98996603]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 5566. State = [[-0.18785155 -0.31859094  0.26904854  1.        ]]. Action = [[ 0.74997854 -0.2999521   0.47800517  0.99411595]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 5567. State = [[-0.18616629 -0.31853375  0.27047238  1.        ]]. Action = [[ 0.7244438  -0.06556302  0.9779879   0.9977559 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 5568. State = [[-0.18604669 -0.31836444  0.27038088  1.        ]]. Action = [[ 0.6916834  -0.09552181  0.6236117   0.98736525]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 5569. State = [[-0.18593656 -0.31806168  0.27026296  1.        ]]. Action = [[ 0.17228961 -0.13245487  0.71798444  0.96604586]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 5570. State = [[-0.18596414 -0.3180615   0.27024478  1.        ]]. Action = [[0.35677314 0.08560717 0.7881237  0.965832  ]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 5571. State = [[-0.1860472  -0.31806102  0.27019006  1.        ]]. Action = [[ 0.75926423 -0.03840446  0.54726887  0.90962386]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 5572. State = [[-0.17593643 -0.31309873  0.28299704  1.        ]]. Action = [[0.660305   0.28964925 0.89274824 0.9548216 ]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 5573. State = [[-0.14974414 -0.30501366  0.31739214  1.        ]]. Action = [[0.83013964 0.1140269  0.881526   0.9818661 ]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 5574. State = [[-0.13082552 -0.30282915  0.34259754  1.        ]]. Action = [[ 0.658067   -0.12137634  0.73308825  0.89383364]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 5575. State = [[-0.11875662 -0.29927686  0.3443438   1.        ]]. Action = [[ 0.76376987  0.11005366 -0.21269917  0.8915558 ]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 5576. State = [[-0.09498797 -0.29550737  0.34356138  1.        ]]. Action = [[ 7.9731119e-01 -4.9043298e-02  2.6702881e-05  9.4246411e-01]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 5577. State = [[-0.06640078 -0.2932708   0.3570555   1.        ]]. Action = [[0.76100826 0.17086053 0.8142011  0.81395316]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 5578. State = [[-0.03830464 -0.29248708  0.38342333  1.        ]]. Action = [[ 0.74448895 -0.12671185  0.667222    0.69040096]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 5579. State = [[-0.00836783 -0.29136023  0.4011125   1.        ]]. Action = [[0.92103624 0.11318302 0.12325239 0.5135679 ]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 5580. State = [[ 0.0217915  -0.29101035  0.40096313  1.        ]]. Action = [[ 0.9345945  -0.24876899 -0.5367544   0.35659158]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 5581. State = [[ 0.05050579 -0.29679808  0.3866346   1.        ]]. Action = [[ 0.9254103  -0.6931071  -0.73598075  0.34153605]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 5582. State = [[ 0.0627208 -0.2999218  0.3871317  1.       ]]. Action = [[ 0.9727535  -0.44731104 -0.6643338   0.1797291 ]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 5583. State = [[ 0.06413441 -0.3002064   0.3885442   1.        ]]. Action = [[ 0.93931544 -0.62404954 -0.85120386  0.16140294]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 5584. State = [[ 0.06404239 -0.3001595   0.3884681   1.        ]]. Action = [[ 0.9424318  -0.4570191  -0.826045    0.07386029]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 5585. State = [[ 0.06401542 -0.30021402  0.3884768   1.        ]]. Action = [[ 0.94693696 -0.7514748  -0.42194676  0.14260077]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 5586. State = [[ 0.06384211 -0.30012718  0.38846737  1.        ]]. Action = [[ 0.86882186 -0.44129717 -0.71072114  0.125669  ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 5587. State = [[ 0.06381497 -0.300182    0.38847616  1.        ]]. Action = [[ 0.90622604 -0.6994889  -0.6547879   0.08360994]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 5588. State = [[ 0.06381497 -0.300182    0.38847616  1.        ]]. Action = [[ 0.9062891  -0.6114346  -0.77677685  0.12408936]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 5589. State = [[ 0.06381497 -0.300182    0.38847616  1.        ]]. Action = [[ 0.9243126  -0.3164549  -0.514375    0.11947799]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 5590. State = [[ 0.06381497 -0.300182    0.38847616  1.        ]]. Action = [[ 0.9007561  -0.6166227  -0.8784248   0.14759016]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 5591. State = [[ 0.06381497 -0.300182    0.38847616  1.        ]]. Action = [[ 0.84036016 -0.45169866 -0.9515      0.13577557]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 5592. State = [[ 0.06381497 -0.300182    0.38847616  1.        ]]. Action = [[ 0.94529366 -0.56981486 -0.7528012   0.08131349]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 5593. State = [[ 0.06381497 -0.300182    0.38847616  1.        ]]. Action = [[ 0.89779997 -0.7061735  -0.7492623   0.14307618]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 5594. State = [[ 0.06379028 -0.30016965  0.38847482  1.        ]]. Action = [[ 0.87429476 -0.7643826  -0.8251085   0.12543094]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 5595. State = [[ 0.06379028 -0.30016965  0.38847482  1.        ]]. Action = [[ 0.93500996 -0.4575041  -0.68623793  0.16312659]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 5596. State = [[ 0.06379028 -0.30016965  0.38847482  1.        ]]. Action = [[ 0.9339262  -0.6143871  -0.31349635  0.08447766]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 5597. State = [[ 0.06379028 -0.30016965  0.38847482  1.        ]]. Action = [[ 0.9662962  -0.6801923  -0.5217525   0.13070798]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 5598. State = [[ 0.06379028 -0.30016965  0.38847482  1.        ]]. Action = [[ 0.9422884  -0.5559026  -0.83438873  0.0902133 ]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 5599. State = [[ 0.06371596 -0.3001324   0.3884709   1.        ]]. Action = [[ 0.9479079  -0.5641224  -0.86457044  0.14508688]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 5600. State = [[ 0.06371596 -0.3001324   0.3884709   1.        ]]. Action = [[ 0.91024864 -0.52421576 -0.59850127  0.09692252]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 5601. State = [[ 0.06371596 -0.3001324   0.3884709   1.        ]]. Action = [[ 0.932914   -0.66724694 -0.5133565   0.12045658]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 5602. State = [[ 0.06371596 -0.3001324   0.3884709   1.        ]]. Action = [[ 0.1491996  -0.6355179  -0.47502393  0.11421418]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 5603. State = [[ 0.06371596 -0.3001324   0.3884709   1.        ]]. Action = [[ 0.9442159  -0.6091504  -0.73873645  0.12389529]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 5604. State = [[ 0.06371596 -0.3001324   0.3884709   1.        ]]. Action = [[ 0.924634   -0.5350138  -0.7612556   0.04955375]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 5605. State = [[ 0.06371596 -0.3001324   0.3884709   1.        ]]. Action = [[ 0.55075955 -0.4393323  -0.9023473   0.13474083]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 5606. State = [[ 0.06371596 -0.3001324   0.3884709   1.        ]]. Action = [[ 0.91283906 -0.64305687 -0.2678945   0.14976263]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 5607. State = [[ 0.06371596 -0.3001324   0.3884709   1.        ]]. Action = [[ 0.9479754  -0.7075576  -0.6963006   0.17779446]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 5608. State = [[ 0.06371596 -0.3001324   0.3884709   1.        ]]. Action = [[ 0.9430189  -0.7684447  -0.78043115  0.15879095]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 5609. State = [[ 0.06371596 -0.3001324   0.3884709   1.        ]]. Action = [[ 0.97081137 -0.42091525 -0.9085424   0.17129421]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 5610. State = [[ 0.06371596 -0.3001324   0.3884709   1.        ]]. Action = [[ 0.9370873  -0.6167491  -0.90968573  0.10072529]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 5611. State = [[ 0.06371596 -0.3001324   0.3884709   1.        ]]. Action = [[ 0.62495327 -0.41884637 -0.41860908  0.11802459]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 5612. State = [[ 0.06371596 -0.3001324   0.3884709   1.        ]]. Action = [[ 0.91344833 -0.6666047  -0.80999494  0.19993663]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 5613. State = [[ 0.06371596 -0.3001324   0.3884709   1.        ]]. Action = [[ 0.7118257  -0.5510073  -0.5835475   0.13339198]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 5614. State = [[ 0.06371596 -0.3001324   0.3884709   1.        ]]. Action = [[ 0.9165323  -0.6732451   0.06569242  0.06265795]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 5615. State = [[ 0.06371596 -0.3001324   0.3884709   1.        ]]. Action = [[ 0.7835758  -0.63434833 -0.83444804  0.2089026 ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 5616. State = [[ 0.06371596 -0.3001324   0.3884709   1.        ]]. Action = [[ 0.64991844 -0.4786502  -0.04396254  0.1386627 ]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 5617. State = [[ 0.06371596 -0.3001324   0.3884709   1.        ]]. Action = [[ 0.98822427 -0.5696041  -0.2900712   0.15011442]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 5618. State = [[ 0.06371596 -0.3001324   0.3884709   1.        ]]. Action = [[ 0.9194139  -0.56653833 -0.08182347  0.1684326 ]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 5619. State = [[ 0.06371596 -0.3001324   0.3884709   1.        ]]. Action = [[ 0.7654669  -0.6240088  -0.89423865  0.1519711 ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 5620. State = [[-0.26307842  0.0215032   0.1139567   1.        ]]. Action = [[ 0.6224189  -0.5659935  -0.04897982  0.22354722]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 5621. State = [[-0.26137552  0.0137484   0.1066538   1.        ]]. Action = [[-0.03947836 -0.84347713  0.8795967   0.97245383]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 5622. State = [[-0.258272    0.00194364  0.11553107  1.        ]]. Action = [[-0.63376045 -0.84485173  0.5856216   0.9843483 ]]. Reward = [0.]
Curr episode timestep = 1
Action ignored: Workspace boundary
Current timestep = 5623. State = [[-0.2564501  -0.01049775  0.12669109  1.        ]]. Action = [[ 0.08815861 -0.58690697  0.87785316  0.99790025]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 5624. State = [[-0.2516674  -0.03438604  0.15666442  1.        ]]. Action = [[ 0.28983903 -0.83984876  0.7763181   0.98220754]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 5625. State = [[-0.24695013 -0.05884782  0.18800694  1.        ]]. Action = [[ 0.15100074 -0.5386438   0.8682928   0.9908433 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 5626. State = [[-0.24243309 -0.08138666  0.22170036  1.        ]]. Action = [[-0.04975611 -0.577599    0.8576057   0.9939877 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 5627. State = [[-0.23725723 -0.10574949  0.25851235  1.        ]]. Action = [[ 0.19487178 -0.58259857  0.9528811   0.9745976 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 5628. State = [[-0.22676282 -0.12168125  0.29343385  1.        ]]. Action = [[ 0.3813604  -0.09596139  0.6988702   0.9923419 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 5629. State = [[-0.2114917  -0.12456872  0.32031256  1.        ]]. Action = [[0.29255676 0.16562223 0.56005085 0.99501264]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 5630. State = [[-0.19148424 -0.12920412  0.3487391   1.        ]]. Action = [[ 0.7777406 -0.3815363  0.9580195  0.9763938]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 5631. State = [[-0.16795726 -0.13678558  0.38256252  1.        ]]. Action = [[ 0.64538527 -0.19688404  0.3314947   0.98562336]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 5632. State = [[-0.15013704 -0.14320669  0.40264934  1.        ]]. Action = [[ 0.41031826 -0.23540324  0.36380732  0.93425286]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 5633. State = [[-0.13882089 -0.14762281  0.41312063  1.        ]]. Action = [[ 0.7803441  -0.15908879  0.6623182   0.7238244 ]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Current timestep = 5634. State = [[-0.13809566 -0.14926828  0.41285658  1.        ]]. Action = [[ 0.5845088  -0.19648504  0.7181537   0.8461019 ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Current timestep = 5635. State = [[-0.13839248 -0.14994691  0.41294757  1.        ]]. Action = [[0.49961782 0.11298227 0.40838218 0.8837576 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 5636. State = [[-0.12782013 -0.15014184  0.4131565   1.        ]]. Action = [[ 0.85947466 -0.01418692 -0.02670741  0.65490913]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 5637. State = [[-0.10642621 -0.15121198  0.41361892  1.        ]]. Action = [[0.9130583  0.19872427 0.3382218  0.68912196]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 5638. State = [[-0.09780581 -0.15123336  0.4067031   1.        ]]. Action = [[ 0.70605373 -0.05401486 -0.5700917   0.66388595]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 5639. State = [[-0.07364964 -0.1548872   0.38745692  1.        ]]. Action = [[ 0.83244526 -0.20460081 -0.6625278   0.5899329 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 5640. State = [[-0.03804372 -0.1619879   0.37859195  1.        ]]. Action = [[ 0.79926753 -0.20673406  0.4820336   0.666147  ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 5641. State = [[-0.01272765 -0.17165354  0.37659714  1.        ]]. Action = [[ 0.901129   -0.34565657 -0.6389367   0.33689368]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 5642. State = [[ 0.01938619 -0.18760289  0.35722134  1.        ]]. Action = [[ 0.9758947  -0.5121923  -0.5034773   0.11621213]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 5643. State = [[ 0.05745686 -0.208974    0.33611453  1.        ]]. Action = [[ 0.95101357 -0.6302736  -0.35337174  0.15873384]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 5644. State = [[ 0.08888841 -0.2235937   0.32391125  1.        ]]. Action = [[ 0.95022273 -0.70600575 -0.6972863   0.07530558]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 5645. State = [[ 0.09881064 -0.22553279  0.325349    1.        ]]. Action = [[ 0.96338284 -0.7818524  -0.6522688   0.08311605]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 5646. State = [[ 0.10039213 -0.2258464   0.32506305  1.        ]]. Action = [[ 0.89906645 -0.73060375 -0.8640083   0.00483036]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Scene graph at timestep 5646 is [False, False, True, True, False, False, True, False, False, True]
State prediction error at timestep 5646 is tensor(0.0005, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 5646 of -1
Current timestep = 5647. State = [[ 0.10042614 -0.22583912  0.3246752   1.        ]]. Action = [[ 0.93241787 -0.83080006 -0.80977875  0.00684452]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Scene graph at timestep 5647 is [False, False, True, True, False, False, True, False, False, True]
State prediction error at timestep 5647 is tensor(0.0005, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 5647 of -1
Current timestep = 5648. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.8449092  -0.77462786 -0.832723    0.05304003]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Scene graph at timestep 5648 is [False, False, True, True, False, False, True, False, False, True]
State prediction error at timestep 5648 is tensor(0.0002, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 5648 of -1
Current timestep = 5649. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.9574039  -0.8368673  -0.6709908   0.02872288]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 5650. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.82631934 -0.80107445 -0.7971886   0.05229294]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 5651. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.8392582  -0.8930737  -0.860596    0.01389599]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 5652. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.8713951  -0.86756563 -0.72312236 -0.00442535]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 5653. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.7919078  -0.8390108  -0.43322313  0.03534496]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 5654. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.9678968  -0.8608469  -0.89128     0.01031268]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 5655. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.977211   -0.8592517  -0.91480535  0.03974664]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 5656. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.9125812  -0.80227786 -0.5721035   0.04494834]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 5657. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.869635   -0.7333985  -0.06415665  0.06107438]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 5658. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.9695456  -0.70336235 -0.7472763   0.0824343 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 5659. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.961045   -0.7442649  -0.80740035  0.00387394]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 5660. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.89766765 -0.79710513 -0.7699595   0.03809226]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 5661. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 9.4761896e-01 -7.3597783e-01 -8.7204468e-01 -7.1668625e-04]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 5662. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.97776246 -0.7920672  -0.73636156 -0.03660983]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 5663. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.8376001  -0.85432816 -0.43706286  0.05119014]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 5664. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 8.9038312e-01 -7.2218817e-01 -9.4900823e-01  7.0631504e-04]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 5665. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.5524719  -0.7845734  -0.8627473   0.02834439]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 5666. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.9250095  -0.8454665  -0.950511    0.00119269]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 5667. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.8387705  -0.8622359  -0.9066688   0.02660525]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 5668. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.8920753  -0.8547095  -0.8138393   0.02708101]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 5669. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.8903775  -0.85162437 -0.77960235  0.01885033]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 5670. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.95136786 -0.91239935 -0.9633262   0.00301445]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 5671. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.7840183  -0.85906774 -0.91775197 -0.01741731]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 5672. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.09497523 -0.8990848  -0.70667934  0.00725806]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 5673. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.97044396 -0.88578796 -0.9019591  -0.0032534 ]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 5674. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.6806458  -0.72960097 -0.96059173  0.01519871]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 5675. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.86198115 -0.8744317  -0.627367    0.02519536]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 5676. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.9221393  -0.84573066 -0.77332675 -0.02724355]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 5677. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.8582301  -0.7995566  -0.822098   -0.01271397]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 5678. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.91481173 -0.68958575 -0.8501394  -0.0331251 ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 5679. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.8488815  -0.82638127 -0.9043173   0.00604475]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 5680. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.7705147  -0.8133669  -0.8127003  -0.02809429]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 5681. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.9571376  -0.8551667  -0.7796802  -0.01146382]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 5682. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.7516792  -0.718105   -0.67915416 -0.03095472]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 5683. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.9742868  -0.81868166 -0.6733451  -0.05132073]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 5684. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.9289024  -0.77296823 -0.92090124  0.00874782]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 5685. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.94463205 -0.7372061  -0.9053643  -0.00102681]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 5686. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.9619051  -0.83720714 -0.834534   -0.0460484 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 5687. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.9437151  -0.8549334  -0.84134    -0.00117576]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 5688. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.9646566  -0.70619756 -0.5492004  -0.01768267]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 5689. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.80806947 -0.8702086  -0.8361648  -0.02304113]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 5690. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.95838034 -0.8342761  -0.83842325  0.01865041]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 5691. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.75501955 -0.77164125 -0.4544053  -0.04049641]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 5692. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.95208406 -0.8752416  -0.7521283  -0.01158875]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 5693. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.85169816 -0.80266297 -0.5252869   0.00889659]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 5694. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.91203964 -0.73597366 -0.8658802  -0.01478672]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 5695. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.8758347  -0.8322326  -0.9277679   0.03040862]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 5696. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 8.0132341e-01 -7.1864790e-01 -8.0552244e-01 -8.6486340e-05]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 5697. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.9097302  -0.91245115 -0.46531737 -0.01534814]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 5698. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.97762    -0.7538893  -0.7660688  -0.05183184]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 5699. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.96883535 -0.8319548  -0.75340265 -0.02422589]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 5700. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.9658191  -0.848927   -0.8878751  -0.00660437]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 5701. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.7741895  -0.8580605  -0.87463576 -0.02947468]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 5702. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.63442445 -0.84377694 -0.6603207  -0.0140602 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 5703. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.9730277  -0.8821515  -0.9250506  -0.00286269]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 5704. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.9358113  -0.84717244 -0.8810491  -0.00794625]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 5705. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.8309233  -0.7695201  -0.89127976 -0.06329811]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 5706. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.7788563  -0.7387943  -0.7782192  -0.00627667]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 5707. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 9.8266912e-01 -8.3001232e-01 -9.5710766e-01 -2.0736456e-04]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 5708. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.9265177  -0.85893756 -0.88877827  0.00341535]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 5709. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.85830474 -0.75183773 -0.678632   -0.02426195]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 5710. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.864455   -0.8295434  -0.6897801  -0.03312159]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 5711. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.91468954 -0.87868464 -0.9694786  -0.01964903]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 5712. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.87641585 -0.80117893 -0.5743057   0.01131153]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 5713. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.95838475 -0.84031963 -0.92977417 -0.00341928]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 5714. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.94455695 -0.81572926 -0.8257641   0.02098536]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 5715. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.9684     -0.87087524 -0.6763764  -0.02120078]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 5716. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.9868486  -0.84709436 -0.87534547 -0.01960266]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 5717. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.9639666  -0.9048618  -0.7452475   0.01358938]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 5718. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.96308076 -0.8439213  -0.91828007  0.01427531]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 5719. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.91236806 -0.82062465 -0.7898675  -0.00304615]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 5720. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 9.0815544e-01 -8.7633330e-01 -7.6313621e-01  3.4105778e-04]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 5721. State = [[ 0.10042538 -0.22583905  0.32460117  1.        ]]. Action = [[ 0.98216116 -0.87954617 -0.8976935  -0.02889305]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 5722. State = [[-0.26049063 -0.10115582  0.11118458  1.        ]]. Action = [[ 0.89170694 -0.8778286  -0.8265407  -0.0421074 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 5723. State = [[-0.26006433 -0.12406723  0.10254483  1.        ]]. Action = [[ 0.07515788 -0.68718344  0.82776     0.9777608 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 5724. State = [[-0.2598922  -0.14630505  0.10982144  1.        ]]. Action = [[-0.08770335 -0.6190357  -0.2201494   0.9732251 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 5725. State = [[-0.26095095 -0.17640151  0.11835926  1.        ]]. Action = [[-0.12215102 -0.7947664   0.78125143  0.9574586 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 5726. State = [[-0.26110554 -0.19930899  0.13247675  1.        ]]. Action = [[ 0.22889602 -0.37395507  0.06141591  0.97279716]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 5727. State = [[-0.2605423  -0.208261    0.13410495  1.        ]]. Action = [[-0.18031096 -0.4222772   0.8727937   0.9699516 ]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: Workspace boundary
Current timestep = 5728. State = [[-0.2577688  -0.22068204  0.14567722  1.        ]]. Action = [[ 0.16925597 -0.66429716  0.8047073   0.9810815 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 5729. State = [[-0.24982919 -0.24302197  0.17690508  1.        ]]. Action = [[ 0.2995448  -0.56397706  0.91470647  0.99185324]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 5730. State = [[-0.23842958 -0.2657911   0.20056787  1.        ]]. Action = [[ 0.36043823 -0.65432984 -0.2582175   0.98446894]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 5731. State = [[-0.22634853 -0.29191887  0.21004388  1.        ]]. Action = [[ 0.39062536 -0.65659475  0.45321834  0.99645805]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 5732. State = [[-0.20791616 -0.3095511   0.22772597  1.        ]]. Action = [[ 0.5041754 -0.151555   0.7654562  0.9980016]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 5733. State = [[-0.19356039 -0.3178378   0.24265349  1.        ]]. Action = [[ 0.6128222  -0.36702967  0.76625955  0.96252894]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: Workspace boundary
Current timestep = 5734. State = [[-0.19153516 -0.31952825  0.24487676  1.        ]]. Action = [[ 0.2974851  -0.4719113   0.99542713  0.9874755 ]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: Workspace boundary
Current timestep = 5735. State = [[-0.19103128 -0.3202612   0.24596329  1.        ]]. Action = [[ 0.5989747  -0.20363128  0.6769599   0.9869572 ]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Current timestep = 5736. State = [[-0.19091134 -0.3205487   0.246168    1.        ]]. Action = [[0.79859304 0.09205878 0.23326528 0.9798937 ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Current timestep = 5737. State = [[-0.19119659 -0.3209008   0.24624695  1.        ]]. Action = [[ 0.41873896 -0.39651817  0.6252191   0.98967123]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 5738. State = [[-0.19131905 -0.32105175  0.24628088  1.        ]]. Action = [[ 0.61876607  0.00630081 -0.08277601  0.97880507]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 5739. State = [[-0.19135988 -0.32110205  0.2462922   1.        ]]. Action = [[ 0.5586935  -0.33363986 -0.45990074  0.9884925 ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 5740. State = [[-0.19135988 -0.32110205  0.2462922   1.        ]]. Action = [[ 0.75148344 -0.05222487  0.98618674  0.9197154 ]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 5741. State = [[-0.19135988 -0.32110205  0.2462922   1.        ]]. Action = [[ 0.41989422 -0.10015625  0.73519206  0.9848088 ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 5742. State = [[-0.19135988 -0.32110205  0.2462922   1.        ]]. Action = [[ 0.7238301  -0.19301122  0.9349687   0.93336797]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 5743. State = [[-0.19135988 -0.32110205  0.2462922   1.        ]]. Action = [[ 0.59300566 -0.26182973  0.7854254   0.97791004]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 5744. State = [[-0.19135988 -0.32110205  0.2462922   1.        ]]. Action = [[ 0.38150072 -0.4791993   0.76588726  0.9909769 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 5745. State = [[-0.19135988 -0.32110205  0.2462922   1.        ]]. Action = [[ 0.6781231  -0.50965697 -0.6721606   0.8411238 ]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 5746. State = [[-0.19135988 -0.32110205  0.2462922   1.        ]]. Action = [[ 0.63575387 -0.31450605  0.6253077   0.99397445]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 5747. State = [[-0.19135988 -0.32110205  0.2462922   1.        ]]. Action = [[ 0.20649981 -0.38487196  0.6289706   0.9855943 ]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 5748. State = [[-0.18319102 -0.31730032  0.24827494  1.        ]]. Action = [[ 6.8377614e-01  2.3311186e-01 -2.8920174e-04  9.8904204e-01]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 5749. State = [[-0.172811   -0.31631598  0.25144997  1.        ]]. Action = [[ 0.31311107 -0.38028288  0.92133725  0.9240228 ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 5750. State = [[-0.17171754 -0.31482032  0.2511607   1.        ]]. Action = [[ 0.7056718  -0.11339355  0.90759706  0.91198397]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 5751. State = [[-0.17128944 -0.31474134  0.25128624  1.        ]]. Action = [[ 0.48787248 -0.23152322  0.797549    0.94647264]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 5752. State = [[-0.17117023 -0.3145844   0.25125363  1.        ]]. Action = [[ 0.41886485 -0.32431924  0.88080215  0.8585104 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 5753. State = [[-0.16240355 -0.31276497  0.2615587   1.        ]]. Action = [[0.46359968 0.10604763 0.9036524  0.6883142 ]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 5754. State = [[-0.14763106 -0.31417263  0.27918693  1.        ]]. Action = [[-0.23965257 -0.25981104  0.11251223  0.970163  ]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 5755. State = [[-0.14559542 -0.3146229   0.2814322   1.        ]]. Action = [[ 0.7700181  -0.22955364  0.3898003   0.9423325 ]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 5756. State = [[-0.14548936 -0.3143642   0.28145602  1.        ]]. Action = [[ 0.5793836  -0.2582147   0.24603629  0.9127978 ]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 5757. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.2265724  -0.38420993  0.948869    0.9418268 ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 5758. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.90762925 -0.27100122  0.82377267  0.93964636]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 5759. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.65072465 -0.39168572  0.95908856  0.99061847]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 5760. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.6920788  -0.28346777  0.49365473  0.9317908 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 5761. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.64831793 -0.29701793  0.8896351   0.9577873 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 5762. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.7536119  -0.52445245  0.98327494  0.9775517 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 5763. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.49625587 -0.16032714  0.70123196  0.9442873 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 5764. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.33307266 -0.21015209  0.61269724  0.89799476]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 5765. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.7697718  -0.3458177   0.89612746  0.8144865 ]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 5766. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.8111863 -0.3419801  0.4267354  0.9861829]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 5767. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.8183135  -0.24930573  0.77560985  0.96071696]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 5768. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.5694059  -0.14235902  0.8395884   0.96526456]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 5769. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.8098092  -0.02151006  0.67946815  0.83819175]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 5770. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.74448323 -0.5564767   0.2674557   0.9684806 ]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 5771. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.77022934 -0.18929374 -0.8718795   0.382473  ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 5772. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.5456369  -0.29056954  0.45467722  0.95342016]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 5773. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.20266712 -0.3737529   0.67366195  0.8982146 ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 5774. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.41977382 -0.12033474  0.3709644   0.97423935]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 5775. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.7520176 -0.3572818  0.407789   0.9948696]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 5776. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.33406472 -0.14800751  0.8539901   0.9099537 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 5777. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.5122895  -0.16020161  0.32705235  0.90083396]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 5778. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.60119617 -0.04410952  0.5412326   0.96224046]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 5779. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.6652634  -0.00167435  0.8386545   0.92169225]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 5780. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.699265   -0.1494919   0.9138137   0.99201035]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 5781. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.7258663  -0.24687612  0.7118175   0.75764394]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 5782. State = [[-0.14553334 -0.31425005  0.28145218  1.        ]]. Action = [[ 0.5978055  -0.6125986   0.863564    0.94461346]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 5783. State = [[-0.13703685 -0.31145284  0.28700832  1.        ]]. Action = [[0.6449187  0.10750806 0.19669485 0.9594414 ]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 5784. State = [[-0.12743591 -0.3100706   0.29525265  1.        ]]. Action = [[ 0.61740756 -0.116485    0.4487052   0.98055327]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 5785. State = [[-0.12554577 -0.3099521   0.2963387   1.        ]]. Action = [[ 0.7073995  -0.3327484   0.62509036  0.8998623 ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 5786. State = [[-0.11351897 -0.30722472  0.308169    1.        ]]. Action = [[0.7228358  0.08506095 0.8548207  0.969367  ]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 5787. State = [[-0.09859812 -0.3062429   0.3270077   1.        ]]. Action = [[ 0.6566365  -0.13090777  0.01905477  0.9757855 ]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 5788. State = [[-0.09573325 -0.30624503  0.33066532  1.        ]]. Action = [[ 0.07175446 -0.11286587  0.6912277   0.91311765]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 5789. State = [[-0.08519482 -0.30504408  0.34290385  1.        ]]. Action = [[0.736228   0.00878918 0.8903899  0.9162209 ]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 5790. State = [[-0.07064051 -0.305333    0.36415637  1.        ]]. Action = [[ 0.8305532  -0.23484719  0.6259701   0.80172205]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 5791. State = [[-0.06775239 -0.3059725   0.36866006  1.        ]]. Action = [[ 0.80169606 -0.316756    0.447371    0.42350447]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 5792. State = [[-0.05624356 -0.302174    0.37840915  1.        ]]. Action = [[0.921139   0.10370481 0.6132406  0.7370126 ]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 5793. State = [[-0.02820026 -0.2946774   0.38453737  1.        ]]. Action = [[ 0.89482224  0.25222194 -0.3902024   0.6728358 ]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 5794. State = [[-0.00376166 -0.29214525  0.3777577   1.        ]]. Action = [[ 0.90173626 -0.36967587  0.13924003  0.4155854 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 5795. State = [[ 0.00969305 -0.29282779  0.38379472  1.        ]]. Action = [[ 0.8452469  -0.21272004  0.39583993  0.46028185]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 5796. State = [[ 0.03372715 -0.29565576  0.38453636  1.        ]]. Action = [[ 0.98085475 -0.3175665  -0.6308303   0.38141847]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 5797. State = [[ 0.07033761 -0.3032698   0.37164325  1.        ]]. Action = [[ 0.9809551  -0.20480424  0.45143533  0.37027144]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 5798. State = [[ 0.10177194 -0.3106008   0.37769467  1.        ]]. Action = [[ 0.75507736 -0.5515502   0.3995695   0.21671724]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 5799. State = [[ 0.113481   -0.31514996  0.38236848  1.        ]]. Action = [[ 0.9220338  -0.69662774 -0.84190947  0.12909567]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 5800. State = [[ 0.11695434 -0.3149896   0.38524565  1.        ]]. Action = [[ 0.982429   -0.8555387  -0.6968918   0.17190254]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 5801. State = [[ 0.11729845 -0.31466085  0.38672858  1.        ]]. Action = [[ 0.8902128  -0.8725396  -0.7295166   0.19113064]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 5802. State = [[ 0.11729845 -0.31466085  0.38672858  1.        ]]. Action = [[ 0.91470575 -0.7736153  -0.8092107   0.20336235]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 5803. State = [[ 0.11729845 -0.31466085  0.38672858  1.        ]]. Action = [[ 0.83619285 -0.79112375 -0.32650077  0.21202755]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 5804. State = [[ 0.11729845 -0.31466085  0.38672858  1.        ]]. Action = [[ 0.90920115 -0.62677526 -0.7977437   0.16404986]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 5805. State = [[ 0.11719949 -0.31461114  0.38672364  1.        ]]. Action = [[ 0.9747968  -0.5032796  -0.74718463  0.18736553]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 5806. State = [[ 0.11713056 -0.31457564  0.38664275  1.        ]]. Action = [[ 0.9311515  -0.7099523  -0.72669303  0.17046213]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 5807. State = [[ 0.11713585 -0.31457743  0.38656625  1.        ]]. Action = [[ 0.93641496 -0.7616826  -0.58250755  0.1870979 ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 5808. State = [[ 0.11713585 -0.31457743  0.38656625  1.        ]]. Action = [[ 0.90169096 -0.6138506  -0.20317513  0.19533741]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 5809. State = [[ 0.11713585 -0.31457743  0.38656625  1.        ]]. Action = [[ 0.6361737  -0.5005338  -0.7747809   0.18206024]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 5810. State = [[ 0.11713585 -0.31457743  0.38656625  1.        ]]. Action = [[ 0.958354   -0.73194546 -0.78209203  0.16267323]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 5811. State = [[ 0.11713585 -0.31457743  0.38656625  1.        ]]. Action = [[ 0.912796   -0.47590095 -0.5105028   0.20118117]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 5812. State = [[ 0.11713585 -0.31457743  0.38656625  1.        ]]. Action = [[ 0.82115626 -0.36141717 -0.8340806   0.23769164]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 5813. State = [[ 0.11713585 -0.31457743  0.38656625  1.        ]]. Action = [[ 0.91204274 -0.4092238  -0.60345167  0.21477664]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 5814. State = [[ 0.11713585 -0.31457743  0.38656625  1.        ]]. Action = [[ 0.8633373  -0.65065473 -0.8229424   0.2749195 ]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 5815. State = [[ 0.11713585 -0.31457743  0.38656625  1.        ]]. Action = [[ 0.9619384  -0.8013954  -0.88477063  0.26966906]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 5816. State = [[ 0.11713585 -0.31457743  0.38656625  1.        ]]. Action = [[ 0.8857515  -0.76894516 -0.5905841   0.22993517]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 5817. State = [[ 0.11713585 -0.31457743  0.38656625  1.        ]]. Action = [[ 0.8745649  -0.62430495 -0.8698741   0.25675   ]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 5818. State = [[ 0.11713585 -0.31457743  0.38656625  1.        ]]. Action = [[ 0.9295006  -0.70248944 -0.95989776  0.21997666]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 5819. State = [[ 0.11713585 -0.31457743  0.38656625  1.        ]]. Action = [[ 0.9571805  -0.54420865 -0.6811467   0.24067366]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 5820. State = [[ 0.11713585 -0.31457743  0.38656625  1.        ]]. Action = [[ 0.92813754 -0.6772688  -0.7899241   0.25451684]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 5821. State = [[ 0.11713585 -0.31457743  0.38656625  1.        ]]. Action = [[ 0.82222104 -0.67440873 -0.66748476  0.16706884]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 5822. State = [[ 0.11714114 -0.31457925  0.38648978  1.        ]]. Action = [[ 0.8597553  -0.4678772  -0.78854334  0.26709592]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 5823. State = [[ 0.11714114 -0.31457925  0.38648978  1.        ]]. Action = [[ 0.87354064 -0.44925666 -0.6415826   0.22352707]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 5824. State = [[-0.26127425 -0.03344418  0.10950929  1.        ]]. Action = [[ 0.9043143  -0.78512365 -0.8746307   0.25977206]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 5825. State = [[-0.26251402 -0.03775821  0.09460417  1.        ]]. Action = [[-0.44222796 -0.49238837  0.82805324  0.96720004]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Current timestep = 5826. State = [[-0.26072454 -0.04992498  0.09804764  1.        ]]. Action = [[ 0.08381414 -0.66376185  0.5698626   0.99795425]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 5827. State = [[-0.26019272 -0.0626037   0.10239836  1.        ]]. Action = [[-0.30280292 -0.707256    0.94002664  0.9917853 ]]. Reward = [0.]
Curr episode timestep = 2
Action ignored: Workspace boundary
Current timestep = 5828. State = [[-0.25686082 -0.07364008  0.11013798  1.        ]]. Action = [[ 0.10017836 -0.5411339   0.6275346   0.9889823 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 5829. State = [[-0.25021955 -0.09605671  0.13366902  1.        ]]. Action = [[ 0.35012293 -0.6758513   0.77168536  0.97810245]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 5830. State = [[-0.24422893 -0.12018137  0.14790888  1.        ]]. Action = [[-0.02348405 -0.5699143  -0.5524395   0.9809729 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 5831. State = [[-0.2427302  -0.14409728  0.15374051  1.        ]]. Action = [[-0.1385153  -0.49777263  0.83382916  0.99434805]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 5832. State = [[-0.23906146 -0.16274565  0.1755395   1.        ]]. Action = [[ 0.35660505 -0.56471974  0.8455577   0.8934753 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 5833. State = [[-0.230252   -0.18207207  0.20850535  1.        ]]. Action = [[ 0.16445887 -0.3485018   0.81747496  0.9578848 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 5834. State = [[-0.22553146 -0.20150484  0.23558114  1.        ]]. Action = [[-0.01812923 -0.57126427  0.41347277  0.9950447 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 5835. State = [[-0.21799749 -0.22468248  0.259849    1.        ]]. Action = [[ 0.3692348 -0.5943773  0.8854158  0.9842608]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 5836. State = [[-0.20660275 -0.24432021  0.28738597  1.        ]]. Action = [[ 0.22920048 -0.314723    0.3733878   0.98624706]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 5837. State = [[-0.1971347 -0.2592444  0.3132367  1.       ]]. Action = [[ 0.18265426 -0.33486116  0.9483911   0.9263723 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 5838. State = [[-0.18511662 -0.26988652  0.33125705  1.        ]]. Action = [[ 0.61060834 -0.15343893 -0.51174796  0.9764855 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 5839. State = [[-0.1661792  -0.27082273  0.33725473  1.        ]]. Action = [[0.5783738  0.21901035 0.5854747  0.98312783]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 5840. State = [[-0.1463871  -0.27251545  0.35906258  1.        ]]. Action = [[ 0.4857334  -0.30709696  0.5852643   0.92809343]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 5841. State = [[-0.12523511 -0.27386478  0.38388056  1.        ]]. Action = [[0.82330346 0.08768821 0.668875   0.91262627]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 5842. State = [[-0.09903955 -0.27158797  0.38721314  1.        ]]. Action = [[ 0.5492581   0.13463974 -0.7951218   0.88736737]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 5843. State = [[-0.08096902 -0.27286446  0.37500292  1.        ]]. Action = [[0.8833798  0.06601202 0.6183096  0.67999697]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 5844. State = [[-0.07977282 -0.27275455  0.37373707  1.        ]]. Action = [[0.73075604 0.4541353  0.9156542  0.74599814]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 5845. State = [[-0.07264553 -0.27283752  0.38371792  1.        ]]. Action = [[ 0.33148766 -0.02322888  0.75493646  0.7814462 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 5846. State = [[-0.05539346 -0.2741138   0.40329745  1.        ]]. Action = [[ 0.8122066  -0.24702787  0.37091756  0.59410167]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 5847. State = [[-0.03306293 -0.2766463   0.40551418  1.        ]]. Action = [[ 0.66632533 -0.05756831 -0.56563085  0.62710047]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 5848. State = [[-0.00895507 -0.28333718  0.38858524  1.        ]]. Action = [[ 0.7215235  -0.38423717 -0.5929984   0.64301336]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 5849. State = [[ 0.01541086 -0.2919259   0.37269354  1.        ]]. Action = [[ 0.9355576  -0.21984017  0.6629206   0.38142085]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 5850. State = [[ 0.0195898  -0.29226983  0.371179    1.        ]]. Action = [[ 0.97551036 -0.41923797  0.23991418  0.42764843]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 5851. State = [[ 0.01962105 -0.2922764   0.37064186  1.        ]]. Action = [[ 0.84850323 -0.5460642  -0.09091747  0.53280437]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 5852. State = [[ 0.02718676 -0.29531798  0.37147024  1.        ]]. Action = [[ 0.8821094  -0.29274702 -0.01657563  0.4849398 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 5853. State = [[ 0.04982787 -0.30281925  0.36703113  1.        ]]. Action = [[ 0.8458154  -0.5416131   0.7988281   0.41038954]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 5854. State = [[ 0.05592324 -0.3042218   0.36862132  1.        ]]. Action = [[ 0.5440248  -0.42675936  0.3975811   0.34619784]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 5855. State = [[ 0.05602299 -0.30422145  0.36812103  1.        ]]. Action = [[ 0.88910294 -0.32456124 -0.28582072  0.3130679 ]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 5856. State = [[ 0.05602658 -0.30422232  0.36805025  1.        ]]. Action = [[ 0.74050796 -0.3352388   0.516593    0.44968665]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 5857. State = [[ 0.0560302  -0.30422318  0.36797878  1.        ]]. Action = [[ 0.89228797 -0.42312217  0.18897498  0.42679477]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 5858. State = [[ 0.0560302  -0.30422318  0.36797878  1.        ]]. Action = [[ 0.8797333  -0.474064   -0.50871307  0.44482446]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 5859. State = [[ 0.0560665  -0.30422008  0.36803272  1.        ]]. Action = [[ 0.89397466 -0.00545293  0.29055405  0.3358637 ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 5860. State = [[ 0.0560665  -0.30422008  0.36803272  1.        ]]. Action = [[ 0.89710045 -0.54426235  0.44123793  0.337551  ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 5861. State = [[ 0.0560665  -0.30422008  0.36803272  1.        ]]. Action = [[ 0.9251926  -0.2599398   0.26818538  0.47277117]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 5862. State = [[ 0.0560665  -0.30422008  0.36803272  1.        ]]. Action = [[ 0.9716754 -0.3127774 -0.3098842  0.4651822]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 5863. State = [[ 0.0560665  -0.30422008  0.36803272  1.        ]]. Action = [[ 0.9161265  -0.60760516 -0.26083052  0.31512153]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 5864. State = [[ 0.0560665  -0.30422008  0.36803272  1.        ]]. Action = [[ 0.67697453 -0.5969116  -0.51490504  0.2598014 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 5865. State = [[ 0.0560665  -0.30422008  0.36803272  1.        ]]. Action = [[ 0.95026076 -0.37878668 -0.53310496  0.35637462]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 5866. State = [[ 0.0560665  -0.30422008  0.36803272  1.        ]]. Action = [[ 0.9758241  -0.3395403  -0.35577536  0.26671994]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 5867. State = [[ 0.0560665  -0.30422008  0.36803272  1.        ]]. Action = [[ 0.30232203 -0.18415922  0.7903366   0.3308288 ]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 5868. State = [[ 0.0560665  -0.30422008  0.36803272  1.        ]]. Action = [[ 0.66835546 -0.42018938 -0.277484    0.39659095]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 5869. State = [[ 0.0560665  -0.30422008  0.36803272  1.        ]]. Action = [[ 0.9607333  -0.7192921  -0.5549812   0.33514667]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 5870. State = [[ 0.0560665  -0.30422008  0.36803272  1.        ]]. Action = [[ 0.9358649  -0.29394573 -0.4669407   0.32757115]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 5871. State = [[ 0.0560665  -0.30422008  0.36803272  1.        ]]. Action = [[ 0.71048105 -0.63843507  0.59283495  0.36179054]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 5872. State = [[ 0.0560665  -0.30422008  0.36803272  1.        ]]. Action = [[ 0.948189   -0.4462154  -0.66786504  0.362437  ]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 5873. State = [[ 0.0560665  -0.30422008  0.36803272  1.        ]]. Action = [[ 0.84592724 -0.313241    0.06492293  0.36939514]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 5874. State = [[ 0.0560665  -0.30422008  0.36803272  1.        ]]. Action = [[ 0.8406081  -0.44466972 -0.39859545  0.38921452]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 5875. State = [[ 0.0560665  -0.30422008  0.36803272  1.        ]]. Action = [[ 0.98270273 -0.0637784  -0.2938434   0.42970288]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 5876. State = [[ 0.0560665  -0.30422008  0.36803272  1.        ]]. Action = [[ 0.87735    -0.33021927  0.6370127   0.37665117]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 5877. State = [[ 0.0560665  -0.30422008  0.36803272  1.        ]]. Action = [[ 0.9681599  -0.30695188  0.51899743  0.26801527]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 5878. State = [[ 0.0560665  -0.30422008  0.36803272  1.        ]]. Action = [[0.91803145 0.05075908 0.20980978 0.47903883]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 5879. State = [[ 0.0560665  -0.30422008  0.36803272  1.        ]]. Action = [[ 0.79633963 -0.29948294 -0.0826813   0.4011463 ]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 5880. State = [[ 0.06124943 -0.304251    0.3673868   1.        ]]. Action = [[ 0.7522924  -0.12024063 -0.06615013  0.42517674]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 5881. State = [[ 0.08019715 -0.3071925   0.363497    1.        ]]. Action = [[ 0.8205962  -0.28545493 -0.11646557  0.32000196]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 5882. State = [[ 0.08680428 -0.30957618  0.3650146   1.        ]]. Action = [[ 0.9104811  -0.64716333  0.3808763   0.21912014]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 5883. State = [[ 0.0866173  -0.30953822  0.36483204  1.        ]]. Action = [[ 0.76770306 -0.54621506  0.67654276  0.1776135 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 5884. State = [[ 0.08652525 -0.30953738  0.364848    1.        ]]. Action = [[ 0.8810067  -0.6635724   0.27429175  0.1544503 ]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 5885. State = [[ 0.08652525 -0.30953738  0.364848    1.        ]]. Action = [[ 0.88011026 -0.7681322  -0.8384197   0.16058445]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 5886. State = [[ 0.08652525 -0.30953738  0.364848    1.        ]]. Action = [[ 0.90875006 -0.615883   -0.16827816  0.18215394]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 5887. State = [[ 0.08652525 -0.30953738  0.364848    1.        ]]. Action = [[ 0.68008184 -0.4917969   0.04195344  0.21556044]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 5888. State = [[ 0.08652853 -0.30953822  0.36477336  1.        ]]. Action = [[ 0.8932258  -0.61013865  0.04252684  0.26883626]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 5889. State = [[ 0.08652853 -0.30953822  0.36477336  1.        ]]. Action = [[ 0.85623085 -0.48681545 -0.08635563  0.18099499]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 5890. State = [[ 0.08652853 -0.30953822  0.36477336  1.        ]]. Action = [[ 0.7460716  -0.6388835   0.0391171   0.21775794]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 5891. State = [[ 0.08652853 -0.30953822  0.36477336  1.        ]]. Action = [[ 0.96681213 -0.5863981  -0.810541    0.30070448]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 5892. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.9601306  -0.6165867  -0.13408077  0.15745664]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 5893. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.94061255 -0.5540416  -0.22281885  0.2331965 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 5894. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.9259696  -0.5190199  -0.41312277  0.18903422]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 5895. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.97433686 -0.74390674 -0.25651085  0.17084694]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 5896. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.945104   -0.5240846   0.6183101   0.26714694]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 5897. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.98320246 -0.36981583 -0.04337996  0.25763297]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 5898. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.90251255 -0.5282241  -0.26161027  0.27669287]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 5899. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.6574311  -0.63340825 -0.58177644  0.31118524]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 5900. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.8550441  -0.5304873  -0.26859474  0.35952377]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 5901. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.95067084 -0.46785796 -0.41360652  0.24050975]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 5902. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.92097306 -0.5946961   0.465639    0.24795163]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 5903. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.7574142  -0.37718344 -0.31940848  0.42716217]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 5904. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.75228643 -0.5359545   0.05220592  0.23879862]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 5905. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.87640774 -0.48108113  0.8109442   0.37539434]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 5906. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.9423673  -0.5746674   0.077829    0.27197766]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 5907. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.93617857 -0.5739674   0.31206906  0.3978691 ]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 5908. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.8756877  -0.48501492 -0.448959    0.3130877 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 5909. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.9247596 -0.5383354  0.6282276  0.2827406]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 5910. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.2841946  -0.53583497  0.12097645  0.25177383]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 5911. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.33223593 -0.74737316 -0.17097884  0.19589198]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 5912. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.73395586 -0.66673315 -0.48339015  0.270728  ]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 5913. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.9499328  -0.64210576  0.07559943  0.2087102 ]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 5914. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.83446527 -0.60410744 -0.5924798   0.18495357]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 5915. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.9846301  -0.60515463  0.1839801   0.19878829]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 5916. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.93066514 -0.14732063  0.7256398   0.24764371]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 5917. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.8929293  -0.731813    0.29809308  0.25446403]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 5918. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.9636252  -0.599089   -0.31287318  0.26034653]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 5919. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.9245949  -0.53401166  0.3221724   0.28638327]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 5920. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.98934793 -0.6330815   0.4278834   0.22129571]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 5921. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.81261754 -0.30758548 -0.18332356  0.31474638]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 5922. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.96772766 -0.57082117  0.12527275  0.33979785]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 5923. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.97065425 -0.5467757  -0.09372044  0.26528525]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 5924. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.78220797 -0.5051328  -0.46066773  0.3132763 ]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 5925. State = [[ 0.08653178 -0.30953902  0.36469945  1.        ]]. Action = [[ 0.8005159  -0.58202374  0.30493414  0.2652892 ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 5926. State = [[-0.26029164 -0.16752619  0.11052024  1.        ]]. Action = [[ 0.7224088  -0.63584846 -0.49023652  0.30368567]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 5927. State = [[-0.25996318 -0.1938496   0.10311545  1.        ]]. Action = [[ 0.11004901 -0.5104911   0.84391785  0.99424684]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 5928. State = [[-0.2557241  -0.2137494   0.11876984  1.        ]]. Action = [[ 0.1131562  -0.66457653  0.6134684   0.9821453 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 5929. State = [[-0.25070667 -0.23986161  0.1440089   1.        ]]. Action = [[ 0.24202013 -0.70197695  0.8505436   0.9938073 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 5930. State = [[-0.24295697 -0.26517037  0.17460097  1.        ]]. Action = [[ 0.14454186 -0.5591226   0.67012525  0.98005164]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 5931. State = [[-0.23164223 -0.28650704  0.199724    1.        ]]. Action = [[ 0.4045987  -0.48842758  0.43548048  0.9777286 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 5932. State = [[-0.21435846 -0.30478925  0.22458763  1.        ]]. Action = [[ 0.51540816 -0.27333236  0.9570805   0.93006575]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 5933. State = [[-0.20026577 -0.31400952  0.2464699   1.        ]]. Action = [[ 0.62398744 -0.45291257  0.78491044  0.97575665]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: Workspace boundary
Current timestep = 5934. State = [[-0.198499   -0.3148995   0.24955842  1.        ]]. Action = [[ 0.4313761  -0.15113366  0.99262166  0.9984616 ]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: Workspace boundary
Current timestep = 5935. State = [[-0.1983646  -0.31478012  0.2511147   1.        ]]. Action = [[0.60564387 0.06235969 0.05822515 0.9305129 ]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: Workspace boundary
Current timestep = 5936. State = [[-0.1984309  -0.3146638   0.25165293  1.        ]]. Action = [[0.04914665 0.00382495 0.94886065 0.9902929 ]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: Workspace boundary
Current timestep = 5937. State = [[-0.1984309  -0.3146638   0.25165293  1.        ]]. Action = [[ 0.62940824 -0.2792819   0.96118855  0.9333482 ]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: Workspace boundary
Current timestep = 5938. State = [[-0.1984309  -0.3146638   0.25165293  1.        ]]. Action = [[ 0.81415987 -0.05019736 -0.426139    0.9956987 ]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: Workspace boundary
Current timestep = 5939. State = [[-0.1984445  -0.31462494  0.25192308  1.        ]]. Action = [[ 0.23636317 -0.23938775  0.785661    0.98345065]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Current timestep = 5940. State = [[-0.1984445  -0.31462494  0.25192308  1.        ]]. Action = [[ 0.5849922  -0.2612257   0.36124325  0.9608829 ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Current timestep = 5941. State = [[-0.1984445  -0.31462494  0.25192308  1.        ]]. Action = [[ 0.80853224 -0.16036493 -0.14737034  0.98375773]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 5942. State = [[-0.1984445  -0.31462494  0.25192308  1.        ]]. Action = [[ 0.65150917 -0.28072643  0.88849294  0.966851  ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 5943. State = [[-0.1984445  -0.31462494  0.25192308  1.        ]]. Action = [[ 0.6250168  -0.52554584  0.6877332   0.9878025 ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 5944. State = [[-0.1984445  -0.31462494  0.25192308  1.        ]]. Action = [[ 0.75741696 -0.25834286  0.5408189   0.9661753 ]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 5945. State = [[-0.1984445  -0.31462494  0.25192308  1.        ]]. Action = [[0.49883962 0.05454648 0.87694156 0.9897704 ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 5946. State = [[-0.1984445  -0.31462494  0.25192308  1.        ]]. Action = [[ 0.3127625  -0.24206567  0.8981228   0.8433932 ]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 5947. State = [[-0.19184506 -0.31318036  0.26573154  1.        ]]. Action = [[0.3712052  0.17052424 0.9259672  0.9955411 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 5948. State = [[-0.183504   -0.31475535  0.283702    1.        ]]. Action = [[ 0.6141739  -0.24576342  0.9995936   0.9966681 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 5949. State = [[-0.18160802 -0.3156597   0.28600082  1.        ]]. Action = [[ 0.8415179  -0.01210624  0.7958379   0.9813864 ]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 5950. State = [[-0.1811569  -0.31579667  0.2865965   1.        ]]. Action = [[0.3279674  0.02278447 0.9458897  0.99207616]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 5951. State = [[-0.1811569  -0.31579667  0.2865965   1.        ]]. Action = [[ 0.6221788  -0.39733112  0.87977934  0.96132827]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 5952. State = [[-0.1811569  -0.31579667  0.2865965   1.        ]]. Action = [[ 0.5568807  -0.10402489  0.91545534  0.9188497 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 5953. State = [[-0.18100528 -0.31588727  0.2867251   1.        ]]. Action = [[ 0.3292246  -0.03810805  0.8321605   0.9661242 ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 5954. State = [[-0.17130667 -0.31070852  0.29561773  1.        ]]. Action = [[0.6639652  0.25729644 0.53561854 0.96726835]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 5955. State = [[-0.14892586 -0.30389017  0.31756997  1.        ]]. Action = [[0.85853875 0.03565085 0.3513105  0.96071386]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 5956. State = [[-0.1227615  -0.2992728   0.33350813  1.        ]]. Action = [[0.7925291  0.09209752 0.19305193 0.8199134 ]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 5957. State = [[-0.09638225 -0.29578888  0.33943105  1.        ]]. Action = [[ 0.4349662   0.14979112 -0.01724964  0.9715636 ]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 5958. State = [[-0.08830479 -0.29557973  0.34152803  1.        ]]. Action = [[-0.478271   -0.1568116   0.03990698  0.9615028 ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 5959. State = [[-0.08182311 -0.29366526  0.34776956  1.        ]]. Action = [[0.8959013  0.18214989 0.40327454 0.87706757]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 5960. State = [[-0.05828069 -0.28996482  0.368795    1.        ]]. Action = [[0.7842734  0.02938724 0.6962528  0.8948281 ]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 5961. State = [[-0.03382688 -0.29177624  0.38777056  1.        ]]. Action = [[ 0.50310874 -0.18551815  0.22984791  0.6600368 ]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 5962. State = [[-0.01003295 -0.2893274   0.39146483  1.        ]]. Action = [[ 0.79196334  0.2781136  -0.3063035   0.5563173 ]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 5963. State = [[ 0.00836224 -0.28666687  0.3744511   1.        ]]. Action = [[ 0.09313834 -0.01807564 -0.90127665  0.30030584]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 5964. State = [[ 0.02534867 -0.28710228  0.352013    1.        ]]. Action = [[ 0.81508887 -0.16196138 -0.340625    0.43930137]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 5965. State = [[ 0.05754532 -0.2909061   0.34131154  1.        ]]. Action = [[ 0.83591497 -0.05975443  0.25108325  0.4812981 ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 5966. State = [[ 0.08120285 -0.292888    0.3430471   1.        ]]. Action = [[ 0.8366811  -0.31102622  0.46726322  0.40514207]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 5967. State = [[ 0.08688226 -0.29319006  0.34509134  1.        ]]. Action = [[ 0.900928   -0.45839792  0.35055494  0.33903968]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 5968. State = [[ 0.08675989 -0.2931284   0.34501117  1.        ]]. Action = [[ 0.97905385 -0.00989783 -0.0155465   0.39162564]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 5969. State = [[ 0.08675989 -0.2931284   0.34501117  1.        ]]. Action = [[ 0.2533548  -0.09169614 -0.23270333  0.60412073]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 5970. State = [[ 0.08675989 -0.2931284   0.34501117  1.        ]]. Action = [[ 0.9265059  -0.0296154  -0.43600804  0.38513136]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 5971. State = [[ 0.08675989 -0.2931284   0.34501117  1.        ]]. Action = [[0.7016771  0.09026957 0.13255358 0.49128747]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 5972. State = [[ 0.08675989 -0.2931284   0.34501117  1.        ]]. Action = [[ 0.33476186 -0.03961933  0.4916371   0.37292957]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 5973. State = [[ 0.08675989 -0.2931284   0.34501117  1.        ]]. Action = [[ 0.7986833   0.13452673 -0.6802194   0.41580892]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 5974. State = [[ 0.08668561 -0.2930911   0.34500745  1.        ]]. Action = [[ 0.58574533 -0.2876289  -0.13214374  0.37752533]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 5975. State = [[ 0.08668561 -0.2930911   0.34500745  1.        ]]. Action = [[0.959496   0.2251985  0.3522898  0.56606007]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 5976. State = [[ 0.08146937 -0.29996648  0.35444844  1.        ]]. Action = [[-0.72149855 -0.18164611  0.6176202   0.47168994]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 5977. State = [[ 0.07612823 -0.30649576  0.365927    1.        ]]. Action = [[ 0.9839659   0.17069316 -0.6514205   0.5251112 ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 5978. State = [[ 0.07383216 -0.30794907  0.36859074  1.        ]]. Action = [[ 0.738698    0.01279557 -0.79911673  0.46962714]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 5979. State = [[ 0.07327627 -0.30767655  0.36883995  1.        ]]. Action = [[0.88321376 0.04874671 0.38127732 0.4765954 ]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 5980. State = [[ 0.0732505  -0.30772737  0.36885506  1.        ]]. Action = [[0.81220317 0.23020339 0.6535728  0.65660775]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 5981. State = [[ 0.07315397 -0.30767307  0.36885023  1.        ]]. Action = [[0.9700564  0.17959106 0.30391932 0.39217806]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 5982. State = [[ 0.07296079 -0.30756438  0.36884087  1.        ]]. Action = [[0.84506416 0.25536728 0.02281451 0.6802449 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 5983. State = [[ 0.07296079 -0.30756438  0.36884087  1.        ]]. Action = [[ 0.7837744   0.43990695 -0.62382525  0.61859107]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 5984. State = [[ 0.07296079 -0.30756438  0.36884087  1.        ]]. Action = [[0.7031617 0.3730508 0.8689201 0.65713  ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 5985. State = [[ 0.07296079 -0.30756438  0.36884087  1.        ]]. Action = [[0.9895084  0.23077536 0.6409271  0.65874267]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 5986. State = [[ 0.07296079 -0.30756438  0.36884087  1.        ]]. Action = [[0.81179416 0.24348712 0.7191148  0.46860886]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 5987. State = [[ 0.07314268 -0.29677746  0.37659085  1.        ]]. Action = [[-0.2139206  0.7497084  0.4055593  0.6437969]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 5988. State = [[ 0.07199239 -0.2815747   0.3859773   1.        ]]. Action = [[0.6941407  0.39012063 0.1393516  0.74032116]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 5989. State = [[ 0.07119631 -0.27910826  0.39132336  1.        ]]. Action = [[0.9552103  0.36995006 0.38816345 0.71778107]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 5990. State = [[ 0.0730261  -0.26873985  0.39117354  1.        ]]. Action = [[0.23722959 0.54250693 0.0523566  0.6730702 ]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 5991. State = [[ 0.07623213 -0.24822925  0.39229515  1.        ]]. Action = [[0.22289741 0.51542926 0.14124334 0.71886384]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 5992. State = [[ 0.0781986  -0.23644452  0.3935029   1.        ]]. Action = [[ 0.79878235  0.20369136 -0.70482826  0.6084378 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 5993. State = [[ 0.07773252 -0.22735071  0.38777995  1.        ]]. Action = [[-0.5072841   0.46508002 -0.7115356   0.5678096 ]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 5994. State = [[ 0.07518317 -0.21920642  0.38199258  1.        ]]. Action = [[0.86371803 0.2285577  0.09498656 0.55177426]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 5995. State = [[ 0.07576819 -0.21159399  0.37386554  1.        ]]. Action = [[ 0.36382866  0.29496694 -0.4907654   0.49001634]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 5996. State = [[ 0.07691195 -0.20630272  0.36225635  1.        ]]. Action = [[ 0.5090914   0.01717627 -0.43251193  0.48917007]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 5997. State = [[ 0.07707708 -0.20536593  0.3611877   1.        ]]. Action = [[ 0.8663869   0.17267573 -0.71655107  0.40636182]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 5998. State = [[ 0.07712013 -0.20529145  0.36025548  1.        ]]. Action = [[ 0.9085368  -0.55205655 -0.73149526  0.37457204]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 5999. State = [[ 0.0771242  -0.20534702  0.35969833  1.        ]]. Action = [[ 0.88945556 -0.3878622  -0.10764843  0.33173442]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 6000. State = [[ 0.077127   -0.2053474   0.35962683  1.        ]]. Action = [[ 0.47617126 -0.6704422  -0.8719441   0.31219685]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 6001. State = [[ 0.077127   -0.2053474   0.35962683  1.        ]]. Action = [[ 0.5629883   0.07984817 -0.59594744  0.28777015]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 6002. State = [[ 0.07715962 -0.2052969   0.35925037  1.        ]]. Action = [[ 0.82612896 -0.47737008 -0.67469484  0.37238503]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 6003. State = [[ 0.07716237 -0.20529729  0.35917887  1.        ]]. Action = [[ 0.6979921  -0.28005672 -0.9501605   0.4207921 ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 6004. State = [[ 0.07892884 -0.20778093  0.35255665  1.        ]]. Action = [[ 0.36003244 -0.3067441  -0.6936779   0.444054  ]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 6005. State = [[ 0.08491676 -0.20968595  0.33144337  1.        ]]. Action = [[ 0.83349276 -0.01092005 -0.745129    0.38817346]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 6006. State = [[ 0.08583959 -0.21001135  0.32738575  1.        ]]. Action = [[ 0.835832   -0.17947423 -0.21581566  0.38767874]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 6007. State = [[ 0.08612545 -0.21014822  0.32549956  1.        ]]. Action = [[ 0.77844656 -0.23644805 -0.2100063   0.3138255 ]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 6008. State = [[ 0.08622276 -0.21019411  0.32513568  1.        ]]. Action = [[ 0.92808986 -0.21396387 -0.47133887  0.38346553]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 6009. State = [[ 0.08622276 -0.21019411  0.32513568  1.        ]]. Action = [[ 0.95391715 -0.32057524 -0.7862762   0.37877905]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 6010. State = [[ 0.08622276 -0.21019411  0.32513568  1.        ]]. Action = [[ 0.571643   -0.47322983 -0.40662187  0.4202609 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 6011. State = [[ 0.08622276 -0.21019411  0.32513568  1.        ]]. Action = [[ 0.49462366  0.09029245 -0.66186804  0.36746335]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 6012. State = [[ 0.08622276 -0.21019411  0.32513568  1.        ]]. Action = [[ 0.57510376 -0.3435849  -0.5800597   0.35371113]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 6013. State = [[ 0.08622276 -0.21019411  0.32513568  1.        ]]. Action = [[ 0.7906349  -0.11912954 -0.51016927  0.45673442]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 6014. State = [[ 0.08622276 -0.21019411  0.32513568  1.        ]]. Action = [[ 0.9658797   0.19372213 -0.20821851  0.3794955 ]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 6015. State = [[ 0.08622276 -0.21019411  0.32513568  1.        ]]. Action = [[ 0.9094651  -0.18660277  0.34060764  0.41939902]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 6016. State = [[ 0.08708619 -0.21209566  0.31933302  1.        ]]. Action = [[ 0.04225349 -0.12916899 -0.4520899   0.5183362 ]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 6017. State = [[ 0.08802429 -0.21325731  0.31197426  1.        ]]. Action = [[ 0.7495862  -0.09336942 -0.3812579   0.48063302]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 6018. State = [[ 0.08824925 -0.21335085  0.3107143   1.        ]]. Action = [[ 0.2567222  -0.29665804 -0.81155014  0.45351517]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 6019. State = [[ 0.08827557 -0.21339004  0.31029633  1.        ]]. Action = [[0.4021901  0.24100661 0.16033006 0.4486556 ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 6020. State = [[ 0.08866008 -0.21873842  0.30534565  1.        ]]. Action = [[ 0.16672444 -0.30480266 -0.47123957  0.4564426 ]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 6021. State = [[ 0.09164582 -0.22371466  0.28998786  1.        ]]. Action = [[ 0.9605434  -0.1738931   0.3730681   0.49480677]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 6022. State = [[ 0.09186481 -0.2246576   0.28906205  1.        ]]. Action = [[0.91964936 0.05312002 0.4931538  0.49187696]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 6023. State = [[ 0.09186481 -0.2246576   0.28906205  1.        ]]. Action = [[ 0.34992182  0.21074355 -0.10137933  0.49230897]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 6024. State = [[ 0.09186044 -0.224657    0.2889889   1.        ]]. Action = [[ 0.95104146 -0.28200608 -0.29672784  0.4194442 ]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 6025. State = [[ 0.08998246 -0.23018165  0.29289746  1.        ]]. Action = [[-0.6012094  -0.11655688  0.2801479   0.47593307]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 6026. State = [[ 0.08840416 -0.23747262  0.30008864  1.        ]]. Action = [[ 0.78909874  0.52202463 -0.29309225  0.3815483 ]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 6027. State = [[ 0.08810633 -0.2387643   0.3019319   1.        ]]. Action = [[ 0.8176863   0.4371673  -0.52469796  0.58630466]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 6028. State = [[-0.25931326 -0.08083776  0.10938936  1.        ]]. Action = [[0.7826965  0.25297308 0.18902397 0.51176786]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 6029. State = [[-0.25857538 -0.10027131  0.1020748   1.        ]]. Action = [[-0.03036076 -0.6646527   0.9641026   0.9387307 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 6030. State = [[-0.2572781  -0.1229804   0.12484641  1.        ]]. Action = [[-0.14667821 -0.4874754   0.9401344   0.9150131 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 6031. State = [[-0.2600352  -0.14566061  0.15719543  1.        ]]. Action = [[-0.17826962 -0.6175025   0.65837526  0.99279404]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 6032. State = [[-0.2651581  -0.16982186  0.18805476  1.        ]]. Action = [[-0.02837503 -0.6515272   0.9759054   0.98551357]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 6033. State = [[-0.2670092  -0.18532899  0.21466945  1.        ]]. Action = [[-0.2224248  -0.55568075  0.73463345  0.99681306]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: Workspace boundary
Current timestep = 6034. State = [[-0.2645132  -0.19556336  0.22372328  1.        ]]. Action = [[ 0.19727266 -0.43247193  0.42223752  0.9850619 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 6035. State = [[-0.26411718 -0.20476119  0.23385751  1.        ]]. Action = [[-0.381935   -0.5043723   0.71118367  0.9861835 ]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: Workspace boundary
Current timestep = 6036. State = [[-0.25864354 -0.21539234  0.24501632  1.        ]]. Action = [[ 0.39196157 -0.721407    0.864447    0.9542663 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 6037. State = [[-0.2509112  -0.24113686  0.27878717  1.        ]]. Action = [[ 0.02946901 -0.58577114  0.948606    0.9982289 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 6038. State = [[-0.23877242 -0.2660106   0.31625026  1.        ]]. Action = [[ 0.69262624 -0.7141432   0.9771998   0.9858732 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 6039. State = [[-0.21682507 -0.28875577  0.34141028  1.        ]]. Action = [[ 0.7736852  -0.48235488 -0.4266373   0.9606769 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 6040. State = [[-0.1889525  -0.30203986  0.35291934  1.        ]]. Action = [[ 0.6318345  -0.26059926  0.9685919   0.8032181 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 6041. State = [[-0.17241062 -0.31062344  0.38009232  1.        ]]. Action = [[ 0.07271743 -0.07701308  0.46310842  0.91698766]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 6042. State = [[-0.1674155  -0.31470242  0.39531037  1.        ]]. Action = [[ 0.7637963  -0.15187359  0.6456387   0.96794987]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Current timestep = 6043. State = [[-0.1662237  -0.31529215  0.3972138   1.        ]]. Action = [[ 0.6273401  -0.18216306  0.7087443   0.8369403 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 6044. State = [[-0.16614106 -0.31532562  0.39734358  1.        ]]. Action = [[0.19078434 0.21068895 0.72800064 0.90485835]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 6045. State = [[-0.16614106 -0.31532562  0.39734358  1.        ]]. Action = [[ 0.6078819  -0.21075714  0.61355853  0.9488392 ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 6046. State = [[-0.16614106 -0.31532562  0.39734358  1.        ]]. Action = [[ 0.8162968  -0.05391753 -0.24581349  0.9368032 ]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 6047. State = [[-0.16614106 -0.31532562  0.39734358  1.        ]]. Action = [[0.9355445  0.32197404 0.9317889  0.86825085]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 6048. State = [[-0.16037989 -0.3100791   0.38931724  1.        ]]. Action = [[ 0.62028027  0.31047833 -0.66803694  0.9142499 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 6049. State = [[-0.13972527 -0.30638775  0.37201065  1.        ]]. Action = [[ 0.44760573  0.20953178 -0.25440514  0.9339138 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 6050. State = [[-0.12797812 -0.30512515  0.36617005  1.        ]]. Action = [[ 0.09416556 -0.38403976  0.55700386  0.9781301 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 6051. State = [[-0.12731078 -0.3041651   0.36600992  1.        ]]. Action = [[ 0.513106   -0.13026625 -0.65474856  0.9762006 ]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 6052. State = [[-0.11693905 -0.29760262  0.371229    1.        ]]. Action = [[0.7140386  0.3498435  0.41909146 0.9872886 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 6053. State = [[-0.10169354 -0.2912765   0.37796155  1.        ]]. Action = [[0.60739255 0.38809323 0.9615414  0.9914863 ]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 6054. State = [[-0.09545798 -0.28308642  0.36928308  1.        ]]. Action = [[ 0.48994327  0.2780347  -0.7274595   0.90558076]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 6055. State = [[-0.06910037 -0.2689756   0.35560027  1.        ]]. Action = [[0.7974167  0.6095238  0.06417549 0.8102884 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 6056. State = [[-0.05740144 -0.25146344  0.36326855  1.        ]]. Action = [[-0.7191145   0.46934557  0.62933016  0.73667455]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 6057. State = [[-0.05444122 -0.23637037  0.37366205  1.        ]]. Action = [[0.8492694  0.18154716 0.05494964 0.85752964]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 6058. State = [[-0.04576767 -0.23129302  0.3784922   1.        ]]. Action = [[0.62030065 0.15248084 0.9493109  0.6865791 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 6059. State = [[-0.03510166 -0.22390032  0.38109165  1.        ]]. Action = [[0.63323426 0.3257568  0.06578815 0.27800715]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 6060. State = [[-0.02161996 -0.21904644  0.38296992  1.        ]]. Action = [[0.7847345  0.22430432 0.9006815  0.5622525 ]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 6061. State = [[-0.01403058 -0.21629898  0.39076117  1.        ]]. Action = [[0.55863523 0.02319229 0.4871112  0.6682551 ]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 6062. State = [[-6.5579626e-04 -2.1488783e-01  3.9354140e-01  1.0000000e+00]]. Action = [[ 0.10578418 -0.16816032 -0.3963784   0.58367074]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 6063. State = [[ 0.00484794 -0.2158742   0.38792065  1.        ]]. Action = [[-0.08396602 -0.0683378   0.6645963   0.52370477]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 6064. State = [[ 0.00809984 -0.21791576  0.38325042  1.        ]]. Action = [[ 0.9158108  -0.26759958 -0.59044623  0.48027444]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 6065. State = [[ 0.03930207 -0.22629395  0.36223543  1.        ]]. Action = [[ 0.8707737  -0.16813266 -0.28293395  0.61477375]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 6066. State = [[ 0.07144848 -0.22972026  0.33912656  1.        ]]. Action = [[ 0.43270087  0.0198046  -0.6870314   0.59303   ]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 6067. State = [[ 0.09326285 -0.22087559  0.31269383  1.        ]]. Action = [[ 0.49369848  0.61582065 -0.8134488   0.67494094]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 6068. State = [[ 0.11385784 -0.2129029   0.2924507   1.        ]]. Action = [[ 0.6922507  -0.01922691 -0.8963694   0.59178567]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 6069. State = [[ 0.11577816 -0.20981374  0.27881232  1.        ]]. Action = [[-0.28000748  0.18167591 -0.81030744  0.5503503 ]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 6070. State = [[ 0.11496708 -0.20886166  0.26615882  1.        ]]. Action = [[ 0.38507736 -0.12863493 -0.5898969   0.4193592 ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 6071. State = [[ 0.11490595 -0.20885614  0.26547718  1.        ]]. Action = [[ 0.81459475 -0.03348976 -0.91108674  0.47787464]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 6072. State = [[ 0.11489908 -0.20885551  0.26540095  1.        ]]. Action = [[ 0.87899566 -0.22396421 -0.84906065  0.26270032]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 6073. State = [[ 0.11489908 -0.20885551  0.26540095  1.        ]]. Action = [[ 0.85493207 -0.32416773 -0.0653705   0.39509106]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 6074. State = [[ 0.11489908 -0.20885551  0.26540095  1.        ]]. Action = [[ 0.38075888 -0.24977994 -0.3560391   0.36438656]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 6075. State = [[ 0.11489908 -0.20885551  0.26540095  1.        ]]. Action = [[ 0.37575948 -0.5110424  -0.7272026   0.35221684]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 6076. State = [[ 0.11489908 -0.20885551  0.26540095  1.        ]]. Action = [[ 0.7120397   0.09984028 -0.81044847  0.30960393]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 6077. State = [[ 0.11489908 -0.20885551  0.26540095  1.        ]]. Action = [[ 0.8037381   0.06254554 -0.9287746   0.39050865]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 6078. State = [[ 0.11489908 -0.20885551  0.26540095  1.        ]]. Action = [[-0.22025031 -0.11722112 -0.4872539   0.4007386 ]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 6079. State = [[ 0.11489908 -0.20885551  0.26540095  1.        ]]. Action = [[ 0.80809    -0.6279477  -0.86904997  0.46069503]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 6080. State = [[ 0.11489908 -0.20885551  0.26540095  1.        ]]. Action = [[ 0.5564654   0.30156446 -0.91113067  0.40413547]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 6081. State = [[ 0.11489908 -0.20885551  0.26540095  1.        ]]. Action = [[ 0.60983837 -0.10158509 -0.73770845  0.36560583]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 6082. State = [[ 0.11489908 -0.20885551  0.26540095  1.        ]]. Action = [[ 0.89467883 -0.5196628  -0.60525715  0.3865447 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 6083. State = [[ 0.11489908 -0.20885551  0.26540095  1.        ]]. Action = [[-0.02263457 -0.35720545 -0.75977534  0.3982042 ]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 6084. State = [[ 0.11489908 -0.20885551  0.26540095  1.        ]]. Action = [[ 0.5709301  -0.60194933 -0.87613076  0.40342999]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 6085. State = [[ 0.11489908 -0.20885551  0.26540095  1.        ]]. Action = [[ 0.76880336 -0.10128212 -0.73740196  0.3327495 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 6086. State = [[ 0.11489908 -0.20885551  0.26540095  1.        ]]. Action = [[ 0.7568991   0.03503942 -0.6661639   0.3505683 ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 6087. State = [[ 0.11489908 -0.20885551  0.26540095  1.        ]]. Action = [[ 0.9488871  -0.33729923 -0.22998273  0.37083304]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 6088. State = [[ 0.11489908 -0.20885551  0.26540095  1.        ]]. Action = [[ 0.21001184 -0.08612156 -0.6221772   0.32736576]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 6089. State = [[ 0.11489908 -0.20885551  0.26540095  1.        ]]. Action = [[ 0.29815376 -0.46969128 -0.62118137  0.31189823]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 6090. State = [[ 0.11489908 -0.20885551  0.26540095  1.        ]]. Action = [[ 0.00189412 -0.42891324 -0.9712976   0.39246178]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 6091. State = [[ 0.11489908 -0.20885551  0.26540095  1.        ]]. Action = [[ 0.06635118 -0.31029642 -0.7509342   0.348207  ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 6092. State = [[ 0.11489908 -0.20885551  0.26540095  1.        ]]. Action = [[ 0.4729743  -0.41560674 -0.9223636   0.3842702 ]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 6093. State = [[ 0.11489908 -0.20885551  0.26540095  1.        ]]. Action = [[ 0.9647659  -0.5238855  -0.8316963   0.39647555]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 6094. State = [[ 0.11489908 -0.20885551  0.26540095  1.        ]]. Action = [[-0.18804133 -0.19431603 -0.49517357  0.4337039 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 6095. State = [[ 0.11045482 -0.21505825  0.25747     1.        ]]. Action = [[-0.5440852  -0.4265027  -0.67726105  0.4156809 ]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 6096. State = [[ 0.10832912 -0.22043705  0.244724    1.        ]]. Action = [[ 0.39640856 -0.05807632 -0.8516418   0.5       ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 6097. State = [[ 0.10815274 -0.22102429  0.24355845  1.        ]]. Action = [[ 0.26018715  0.4206667  -0.86019653  0.51752067]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 6098. State = [[ 0.10815274 -0.22102429  0.24355845  1.        ]]. Action = [[ 0.9175029 -0.4476663  0.1773225  0.5445703]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 6099. State = [[ 0.10815274 -0.22102429  0.24355845  1.        ]]. Action = [[ 0.68803644  0.2707517  -0.75089943  0.501457  ]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 6100. State = [[ 0.10815274 -0.22102429  0.24355845  1.        ]]. Action = [[ 0.24046302 -0.1155504  -0.17873907  0.36979795]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 6101. State = [[ 0.10815274 -0.22102429  0.24355845  1.        ]]. Action = [[ 0.49662733 -0.14109147  0.1697309   0.4167267 ]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 6102. State = [[ 0.10815274 -0.22102429  0.24355845  1.        ]]. Action = [[ 0.6553688  -0.16998905 -0.24084508  0.35612202]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 6103. State = [[ 0.10294378 -0.22871852  0.2423473   1.        ]]. Action = [[-0.5130389  -0.31729323 -0.00356036  0.34383595]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 6104. State = [[ 0.09323284 -0.24140196  0.23842004  1.        ]]. Action = [[-0.17035782 -0.249372   -0.16399741  0.52042484]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 6105. State = [[ 0.08565799 -0.2405111   0.2262404   1.        ]]. Action = [[-0.09831339  0.38071346 -0.66843015  0.37459862]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 6106. State = [[ 0.07278103 -0.2428624   0.2037556   1.        ]]. Action = [[-0.39274508 -0.3646487  -0.74510413  0.4492674 ]]. Reward = [0.]
Curr episode timestep = 77
Scene graph at timestep 6106 is [False, True, False, True, False, False, False, True, False, True]
State prediction error at timestep 6106 is tensor(9.4272e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 6106 of -1
Current timestep = 6107. State = [[ 0.06549282 -0.24759719  0.18475826  1.        ]]. Action = [[ 0.9642165  -0.6245787  -0.01140642  0.41306722]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Scene graph at timestep 6107 is [False, True, False, True, False, False, False, True, False, True]
State prediction error at timestep 6107 is tensor(0.0003, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 6107 of -1
Current timestep = 6108. State = [[ 0.06549282 -0.24759719  0.18475826  1.        ]]. Action = [[ 0.8098248  -0.52654165  0.55314755  0.42287755]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Scene graph at timestep 6108 is [False, True, False, True, False, False, False, True, False, True]
State prediction error at timestep 6108 is tensor(5.3157e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 6108 of -1
Current timestep = 6109. State = [[ 0.0652873  -0.25491935  0.18861344  1.        ]]. Action = [[-0.25985438 -0.39493978  0.43901896  0.3078891 ]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 6110. State = [[ 0.05870955 -0.2679982   0.18345761  1.        ]]. Action = [[ 0.05490959 -0.43290865 -0.82910484  0.49961472]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 6111. State = [[ 0.05929296 -0.28361344  0.17789124  1.        ]]. Action = [[ 0.35424638 -0.5298121   0.82429624  0.39359152]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 6112. State = [[ 0.06136242 -0.292834    0.18739906  1.        ]]. Action = [[ 0.5494255  -0.79672354  0.9456725   0.1651268 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 6113. State = [[ 0.06115428 -0.29398903  0.18766014  1.        ]]. Action = [[ 0.40876818 -0.70258516 -0.6511634   0.37290168]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 6114. State = [[ 0.06022842 -0.30045882  0.19059163  1.        ]]. Action = [[-0.16529298 -0.24516445  0.17405677  0.484998  ]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 6115. State = [[ 0.05269032 -0.30879804  0.1965561   1.        ]]. Action = [[-0.70476234  0.04664791  0.20512187  0.475497  ]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 6116. State = [[ 0.04572403 -0.3135205   0.20230061  1.        ]]. Action = [[ 0.6333525  -0.4045601   0.06157207  0.35188293]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 6117. State = [[ 0.04401508 -0.31428555  0.20188749  1.        ]]. Action = [[ 0.69662094 -0.20435154  0.82602763  0.54365826]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 6118. State = [[ 0.0424443  -0.31455564  0.20103355  1.        ]]. Action = [[ 0.4508016  -0.73919    -0.48635387  0.57444024]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 6119. State = [[ 0.04167966 -0.31450847  0.20053093  1.        ]]. Action = [[-0.19315773 -0.5725911   0.51826274  0.50624275]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 6120. State = [[ 0.04163935 -0.3145214   0.20055924  1.        ]]. Action = [[-0.03786933 -0.41373932  0.21630025  0.5932386 ]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 6121. State = [[ 0.04163935 -0.3145214   0.20055924  1.        ]]. Action = [[ 0.66765404 -0.34322637  0.40468323  0.26826286]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 6122. State = [[ 0.04163935 -0.3145214   0.20055924  1.        ]]. Action = [[-9.3519688e-05 -7.3070937e-01  2.5590420e-01  2.2537053e-01]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 6123. State = [[ 0.04163935 -0.3145214   0.20055924  1.        ]]. Action = [[ 0.03595972 -0.08372837  0.55982184  0.18656433]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 6124. State = [[ 0.04163935 -0.3145214   0.20055924  1.        ]]. Action = [[ 0.01268506 -0.5093977   0.87870455  0.46173048]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 6125. State = [[ 0.04163935 -0.3145214   0.20055924  1.        ]]. Action = [[ 0.12334645 -0.59530014  0.9621844   0.4470383 ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 6126. State = [[ 0.04163935 -0.3145214   0.20055924  1.        ]]. Action = [[ 0.5986569  -0.03023201  0.17668188  0.4645667 ]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 6127. State = [[ 0.04163935 -0.3145214   0.20055924  1.        ]]. Action = [[ 0.9058585  -0.7343072   0.6662966   0.57503057]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 6128. State = [[ 0.04163935 -0.3145214   0.20055924  1.        ]]. Action = [[ 0.3764143  -0.44189328 -0.5992756   0.46313214]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 6129. State = [[ 0.04158528 -0.3145329   0.20051806  1.        ]]. Action = [[ 0.09543991 -0.15026802 -0.9624347   0.533792  ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 6130. State = [[-0.25970674 -0.18591624  0.106428    1.        ]]. Action = [[ 0.47278714 -0.70453644 -0.19133925  0.62001395]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 6131. State = [[-0.25884867 -0.21499135  0.1010993   1.        ]]. Action = [[ 0.12203515 -0.57822317  0.92341304  0.9864123 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 6132. State = [[-0.2556388  -0.23517841  0.12051746  1.        ]]. Action = [[ 0.00162792 -0.5226506   0.78417134  0.9810667 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 6133. State = [[-0.2477456  -0.2543859   0.14917265  1.        ]]. Action = [[ 0.4468596  -0.50043625  0.7775328   0.9566413 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 6134. State = [[-0.24227428 -0.2748359   0.17999582  1.        ]]. Action = [[-0.2269975  -0.5247695   0.94444585  0.99509966]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 6135. State = [[-0.2403719  -0.29414275  0.21431372  1.        ]]. Action = [[ 0.23130822 -0.37394947  0.6591537   0.9844315 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 6136. State = [[-0.23552205 -0.30485678  0.23293349  1.        ]]. Action = [[ 0.4461534  -0.39976466  0.73931956  0.99723494]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: Workspace boundary
Current timestep = 6137. State = [[-0.23403712 -0.30710337  0.2359267   1.        ]]. Action = [[ 0.3134086  -0.23626888  0.35505092  0.9912329 ]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: Workspace boundary
Current timestep = 6138. State = [[-0.23382631 -0.3079846   0.23659104  1.        ]]. Action = [[ 0.4888463  -0.57550454  0.9542184   0.9907253 ]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: Workspace boundary
Current timestep = 6139. State = [[-0.22772923 -0.30680382  0.24534588  1.        ]]. Action = [[0.3865745  0.15093827 0.64981174 0.9556484 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 6140. State = [[-0.22156951 -0.30736738  0.25927222  1.        ]]. Action = [[ 0.5665064  -0.5365174  -0.9187786   0.99343693]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: Workspace boundary
Current timestep = 6141. State = [[-0.21946812 -0.30807722  0.26128623  1.        ]]. Action = [[ 0.47518706 -0.35758197  0.23142183  0.9983175 ]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: Workspace boundary
Current timestep = 6142. State = [[-0.21916534 -0.308193    0.26147628  1.        ]]. Action = [[ 0.3825798  -0.2362141   0.924551    0.99677205]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: Workspace boundary
Current timestep = 6143. State = [[-0.21918504 -0.30817345  0.26147512  1.        ]]. Action = [[ 0.6021762  -0.2968669   0.65955853  0.96239054]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Current timestep = 6144. State = [[-0.20830996 -0.30637977  0.26253524  1.        ]]. Action = [[ 0.85944366 -0.00529557 -0.18044889  0.9961636 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 6145. State = [[-0.19593173 -0.30602866  0.26247856  1.        ]]. Action = [[ 0.1920402  -0.25032127  0.02911007  0.9725838 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 6146. State = [[-0.1948916  -0.30488223  0.26229742  1.        ]]. Action = [[ 0.7065135  -0.13969123  0.9915981   0.99713254]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 6147. State = [[-0.19395636 -0.30395803  0.26223028  1.        ]]. Action = [[ 0.5667558 -0.6143617  0.8037722  0.9866173]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 6148. State = [[-0.19321588 -0.30328044  0.26224616  1.        ]]. Action = [[ 0.8211074  -0.3056494   0.17717826  0.9671452 ]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 6149. State = [[-0.19282363 -0.3027798   0.2621543   1.        ]]. Action = [[ 0.45483577 -0.47611862  0.30555892  0.9941349 ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 6150. State = [[-0.19264826 -0.30251083  0.26210713  1.        ]]. Action = [[ 0.88011825 -0.4543574   0.5413395   0.98556817]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 6151. State = [[-0.19249183 -0.3023105   0.26207063  1.        ]]. Action = [[ 0.63692546 -0.46242857  0.5522101   0.9442885 ]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 6152. State = [[-0.19249183 -0.3023105   0.26207063  1.        ]]. Action = [[ 0.3624668  -0.2218166  -0.06076455  0.9719467 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 6153. State = [[-0.19255325 -0.30225453  0.26206627  1.        ]]. Action = [[ 0.63932383 -0.39541233  0.9793441   0.89776456]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 6154. State = [[-0.19251409 -0.30220437  0.26205716  1.        ]]. Action = [[-0.19057977 -0.31445903  0.97869265  0.9979472 ]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 6155. State = [[-0.18254404 -0.30301374  0.25839162  1.        ]]. Action = [[ 0.8338866 -0.1575185 -0.4777078  0.995358 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 6156. State = [[-0.16423324 -0.3100109   0.24779442  1.        ]]. Action = [[ 0.7871535  -0.63525605 -0.41747808  0.98470974]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 6157. State = [[-0.16226828 -0.31047124  0.24718298  1.        ]]. Action = [[ 0.81138587 -0.41529548  0.10775423  0.9880316 ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 6158. State = [[-0.15593666 -0.3042274   0.25529733  1.        ]]. Action = [[0.27391374 0.45497227 0.83493674 0.9686022 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 6159. State = [[-0.14457898 -0.29788202  0.2688775   1.        ]]. Action = [[ 0.95016754 -0.7060224   0.93332434  0.89061   ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 6160. State = [[-0.14253418 -0.29775244  0.27121183  1.        ]]. Action = [[ 0.8298633  -0.24667722  0.9970639   0.9279326 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 6161. State = [[-0.14252156 -0.2975185   0.27123153  1.        ]]. Action = [[ 0.68029666 -0.2542172  -0.28415507  0.89928913]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 6162. State = [[-0.1306675  -0.30034387  0.2860884   1.        ]]. Action = [[ 0.866817   -0.23498023  0.9643519   0.9773605 ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 6163. State = [[-0.11312691 -0.3054327   0.31051084  1.        ]]. Action = [[ 0.88288546 -0.34051234 -0.36789167  0.9934404 ]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 6164. State = [[-0.09827722 -0.30054045  0.32804194  1.        ]]. Action = [[0.9023869  0.28977215 0.9786049  0.9656248 ]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 6165. State = [[-0.0751156  -0.28723073  0.36390448  1.        ]]. Action = [[0.2589897  0.48048675 0.90876985 0.9705739 ]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 6166. State = [[-0.06328365 -0.2732424   0.37443605  1.        ]]. Action = [[ 0.4384427   0.14174163 -0.9931638   0.86493886]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 6167. State = [[-0.0458608  -0.2700414   0.35376477  1.        ]]. Action = [[ 0.6582849  -0.05775779 -0.4881853   0.87642837]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 6168. State = [[-0.01799375 -0.27451834  0.35430434  1.        ]]. Action = [[ 0.75491667 -0.2276206   0.88205993  0.49537516]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 6169. State = [[ 0.00570553 -0.27534297  0.37097624  1.        ]]. Action = [[0.5709795  0.0990361  0.19403565 0.6462624 ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 6170. State = [[ 0.02350589 -0.26654276  0.36785752  1.        ]]. Action = [[ 0.48107433  0.35783112 -0.9074245   0.6776166 ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 6171. State = [[ 0.03591716 -0.26636744  0.3381466   1.        ]]. Action = [[-0.53436345 -0.22829711 -0.9813935   0.6712712 ]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 6172. State = [[ 0.03689691 -0.26285863  0.31345627  1.        ]]. Action = [[ 0.30169296  0.4655261  -0.05833328  0.6968005 ]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 6173. State = [[ 0.03784701 -0.2555734   0.30352953  1.        ]]. Action = [[-0.34754997  0.06287169 -0.67042357  0.59079695]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 6174. State = [[ 0.03400118 -0.25616667  0.27971128  1.        ]]. Action = [[-0.6589624  -0.04085827 -0.80008024  0.51222444]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 6175. State = [[ 0.02591804 -0.25503048  0.25284687  1.        ]]. Action = [[ 0.6195929  -0.01340389 -0.67338943  0.5833814 ]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 6176. State = [[ 0.03978506 -0.26099366  0.2351602   1.        ]]. Action = [[ 0.8880905  -0.5659726   0.487468    0.54234517]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 6177. State = [[ 0.0573541  -0.27561986  0.24897704  1.        ]]. Action = [[ 0.05413568 -0.3380242   0.869347    0.5698315 ]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 6178. State = [[ 0.06281902 -0.27970743  0.25837     1.        ]]. Action = [[ 0.6003072  -0.02721721 -0.8274142   0.71800685]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 6179. State = [[ 0.08161905 -0.2750703   0.23244943  1.        ]]. Action = [[ 0.4264295   0.4387884  -0.49962342  0.7534001 ]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 6180. State = [[ 0.09622456 -0.27018625  0.22370291  1.        ]]. Action = [[-0.48359823  0.2440846   0.37787247  0.7185104 ]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 6181. State = [[ 0.09585331 -0.26640657  0.22771889  1.        ]]. Action = [[ 0.42789853  0.17514348 -0.93372756  0.5746455 ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 6182. State = [[ 0.09561674 -0.26542836  0.22884168  1.        ]]. Action = [[ 0.75698924 -0.11493653  0.16641939  0.6392573 ]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 6183. State = [[ 0.09549695 -0.26543486  0.22885247  1.        ]]. Action = [[ 0.6015661   0.21090126 -0.22748297  0.651736  ]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 6184. State = [[ 0.0942948  -0.26481527  0.22903755  1.        ]]. Action = [[-0.6646388   0.19980764 -0.12751889  0.519428  ]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 6185. State = [[ 0.0832493  -0.2503359   0.22001322  1.        ]]. Action = [[-0.66453683  0.73560286 -0.71946496  0.5739535 ]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 6186. State = [[ 0.06778992 -0.24001138  0.20565201  1.        ]]. Action = [[ 0.07714391 -0.28858    -0.18387413  0.45659435]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 6187. State = [[ 0.06582499 -0.24143156  0.2021138   1.        ]]. Action = [[ 0.7256911  -0.12440145 -0.87723714  0.3854239 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 6188. State = [[ 0.0640138  -0.2514608   0.19866616  1.        ]]. Action = [[ 0.16726458 -0.7116347  -0.17340362  0.41205132]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 6189. State = [[ 0.06189308 -0.25611973  0.1879317   1.        ]]. Action = [[ 0.2589271   0.2973863  -0.7722433   0.37296605]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 6190. State = [[ 0.06284028 -0.2542416   0.1646771   1.        ]]. Action = [[ 0.7560811 -0.3636316  0.6881869  0.5468998]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 6191. State = [[ 0.06329495 -0.26322863  0.16272995  1.        ]]. Action = [[ 0.01476002 -0.6340558  -0.03472924  0.40828073]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 6192. State = [[ 0.06538031 -0.27834955  0.17229283  1.        ]]. Action = [[ 0.1369152  -0.2883346   0.9123993   0.15065193]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 6193. State = [[ 0.06682593 -0.28793442  0.18246256  1.        ]]. Action = [[ 0.7065582  -0.621232    0.7693441   0.47828484]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 6194. State = [[ 0.07070255 -0.29296926  0.18781833  1.        ]]. Action = [[ 0.41693938 -0.38433778  0.18400955  0.36058712]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 6195. State = [[ 0.07018502 -0.30429828  0.20335697  1.        ]]. Action = [[-0.8226405  -0.13542181  0.60596704  0.53905344]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 6196. State = [[ 0.06364875 -0.3131862   0.21363424  1.        ]]. Action = [[ 0.8587136  -0.16769892  0.83545506  0.62728786]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 6197. State = [[ 0.0554724  -0.31574675  0.21194868  1.        ]]. Action = [[-0.88839453  0.12928736 -0.35653073  0.6131592 ]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 6198. State = [[ 0.04171759 -0.31421655  0.20931889  1.        ]]. Action = [[ 0.47228396 -0.41402566 -0.8205494   0.5045502 ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 6199. State = [[ 0.04161305 -0.31399313  0.20918158  1.        ]]. Action = [[ 0.78568494 -0.57300204  0.6113707   0.6131127 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 6200. State = [[ 0.04159021 -0.31404638  0.209209    1.        ]]. Action = [[ 0.98875237 -0.45673496 -0.49351883  0.65645754]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 6201. State = [[ 0.04159021 -0.31404638  0.209209    1.        ]]. Action = [[-0.76363266 -0.22352391 -0.2774099   0.6004324 ]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 6202. State = [[ 0.04905347 -0.30738667  0.22134271  1.        ]]. Action = [[0.8198744  0.26972413 0.94992757 0.7351861 ]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 6203. State = [[ 0.05508431 -0.2941174   0.24187207  1.        ]]. Action = [[-0.00356728  0.30155194  0.4091227   0.5947678 ]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 6204. State = [[ 0.0532533  -0.2890695   0.24584393  1.        ]]. Action = [[ 0.30767715 -0.3044368  -0.8172946   0.72542524]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 6205. State = [[ 0.06154169 -0.28744477  0.23543066  1.        ]]. Action = [[0.6560106  0.01822495 0.102718   0.69315994]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 6206. State = [[ 0.07901949 -0.2801219   0.24134082  1.        ]]. Action = [[0.2102871  0.47061205 0.65764356 0.4915228 ]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 6207. State = [[ 0.08726507 -0.26458254  0.24656788  1.        ]]. Action = [[-0.19059652  0.6815798  -0.60376537  0.5861342 ]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 6208. State = [[ 0.08820327 -0.2524187   0.2423495   1.        ]]. Action = [[ 0.6983235   0.1550647  -0.99684566  0.4931004 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 6209. State = [[ 0.0883266  -0.25085318  0.24151582  1.        ]]. Action = [[ 0.80134094  0.58273876 -0.88141686  0.64450645]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 6210. State = [[ 0.08820954 -0.24738027  0.23760094  1.        ]]. Action = [[-0.02745253  0.19562948 -0.26440644  0.73115206]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 6211. State = [[ 0.08552834 -0.24526326  0.23090269  1.        ]]. Action = [[-0.5520805  -0.02094543 -0.20019609  0.5262021 ]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 6212. State = [[ 0.07969049 -0.24691264  0.21927309  1.        ]]. Action = [[ 0.271564   -0.11128271 -0.68284374  0.73744845]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 6213. State = [[ 0.07924577 -0.24357033  0.18968517  1.        ]]. Action = [[ 0.26115978  0.1885432  -0.8180543   0.62659025]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 6214. State = [[ 0.08177051 -0.24545716  0.16902646  1.        ]]. Action = [[-0.01832879 -0.3884619   0.14770687  0.3956157 ]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 6215. State = [[ 0.08143333 -0.26081732  0.1749286   1.        ]]. Action = [[-0.15130526 -0.75543505  0.37373066  0.38317335]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 6216. State = [[ 0.08001003 -0.274885    0.17857102  1.        ]]. Action = [[ 0.5579195  -0.669817    0.72782207  0.48104882]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 6217. State = [[ 0.07825565 -0.28464168  0.19158779  1.        ]]. Action = [[-0.56071246 -0.17436987  0.80482507  0.58090854]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 6218. State = [[ 0.06975932 -0.2990614   0.19397853  1.        ]]. Action = [[-0.11147213 -0.46680033 -0.85405636  0.5143434 ]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 6219. State = [[ 0.06301199 -0.30427763  0.18559936  1.        ]]. Action = [[ 0.0375334  -0.4870664   0.21571445  0.7174473 ]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 6220. State = [[ 0.06219216 -0.3049698   0.1848981   1.        ]]. Action = [[ 0.29464006 -0.1848988   0.33029294  0.38815403]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 6221. State = [[ 0.06221996 -0.304961    0.1849196   1.        ]]. Action = [[-0.5381566  -0.44140685  0.43166423  0.4234419 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 6222. State = [[ 0.06221996 -0.304961    0.1849196   1.        ]]. Action = [[-0.7788959  -0.6776465   0.37793887  0.5518043 ]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 6223. State = [[ 0.06221996 -0.304961    0.1849196   1.        ]]. Action = [[-0.05773866 -0.43462622  0.4318788   0.5560775 ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 6224. State = [[ 0.06221996 -0.304961    0.1849196   1.        ]]. Action = [[-0.00789607 -0.62465936  0.9753529   0.54074836]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 6225. State = [[ 0.06221996 -0.304961    0.1849196   1.        ]]. Action = [[-0.9315776  -0.6721423  -0.32342875  0.48453963]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 6226. State = [[ 0.06221996 -0.304961    0.1849196   1.        ]]. Action = [[-0.01512265 -0.6355816   0.42264223  0.56129944]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 6227. State = [[ 0.06221996 -0.304961    0.1849196   1.        ]]. Action = [[ 0.50234437 -0.4578802  -0.7568751   0.5015869 ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 6228. State = [[ 0.06221996 -0.304961    0.1849196   1.        ]]. Action = [[-0.28327525 -0.799144   -0.75662947  0.70156574]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 6229. State = [[ 0.06221996 -0.304961    0.1849196   1.        ]]. Action = [[ 0.7545388  -0.00222737  0.5302321   0.5229697 ]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 6230. State = [[ 0.06221996 -0.304961    0.1849196   1.        ]]. Action = [[-0.3884511  -0.36632717 -0.2863891   0.6050252 ]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 6231. State = [[ 0.06221996 -0.304961    0.1849196   1.        ]]. Action = [[ 0.9592756  -0.7786547   0.8899195   0.42790198]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 6232. State = [[-0.26729885  0.10380758  0.104759    1.        ]]. Action = [[ 0.65370154 -0.30905908  0.98403     0.4539852 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 6233. State = [[-0.25985554  0.11230206  0.09731525  1.        ]]. Action = [[ 0.18109441 -0.27480024  0.84375334  0.93967295]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 6234. State = [[-0.2514706   0.09689644  0.11617636  1.        ]]. Action = [[-0.12603158 -0.81298757  0.9335749   0.9372673 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 6235. State = [[-0.25112444  0.07260422  0.14360179  1.        ]]. Action = [[-0.24874204 -0.65185803  0.40426254  0.81424916]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 6236. State = [[-0.25998014  0.04910856  0.15757345  1.        ]]. Action = [[-0.1283428  -0.61626464  0.18131292  0.77711177]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 6237. State = [[-0.25860724  0.02685256  0.17062062  1.        ]]. Action = [[ 0.35215497 -0.5923247   0.6976774   0.9616884 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 6238. State = [[-0.25356135  0.00333467  0.20209353  1.        ]]. Action = [[ 0.09335947 -0.589617    0.98259914  0.9250542 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 6239. State = [[-0.252338   -0.01753531  0.23824756  1.        ]]. Action = [[-0.04164505 -0.47983462  0.920501    0.9965391 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 6239 is [True, False, False, False, True, False, True, False, False, True]
State prediction error at timestep 6239 is tensor(0.0040, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 6239 of 1
Current timestep = 6240. State = [[-0.25565916 -0.03391118  0.2641817   1.        ]]. Action = [[-0.7468528 -0.7007619  0.9006562  0.9950528]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: Workspace boundary
Current timestep = 6241. State = [[-0.25243238 -0.04107428  0.27602306  1.        ]]. Action = [[ 0.08955193 -0.5239419   0.8854699   0.99870443]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 6242. State = [[-0.24618688 -0.05752506  0.31011653  1.        ]]. Action = [[ 0.16461778 -0.3409741   0.85635877  0.98937714]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 6243. State = [[-0.2298872  -0.074682    0.34635067  1.        ]]. Action = [[ 0.76387596 -0.49946964  0.86527276  0.98749745]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 6244. State = [[-0.21421303 -0.084615    0.3726025   1.        ]]. Action = [[ 0.29264593 -0.05119264 -0.02717501  0.9431498 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 6245. State = [[-0.20174229 -0.08937366  0.38805863  1.        ]]. Action = [[ 0.43688786 -0.15580821  0.6029488   0.9377384 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 6246. State = [[-0.19181997 -0.09583097  0.3920672   1.        ]]. Action = [[ 0.3484707  -0.15052956 -0.93836355  0.92119527]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 6247. State = [[-0.17750718 -0.09951127  0.37619084  1.        ]]. Action = [[ 0.8017678 -0.5082125  0.8075552  0.9262843]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 6248. State = [[-0.16825625 -0.10834417  0.3674636   1.        ]]. Action = [[ 0.77781796 -0.45944202 -0.57173777  0.8271439 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 6249. State = [[-0.14042538 -0.12332752  0.3465408   1.        ]]. Action = [[ 0.81949127 -0.34375435 -0.55198026  0.96275496]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 6250. State = [[-0.10452521 -0.13202219  0.33643672  1.        ]]. Action = [[ 0.8790593  -0.10493129  0.2674384   0.8275044 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 6251. State = [[-0.07390859 -0.14022109  0.34459212  1.        ]]. Action = [[ 0.884917   -0.35907853  0.5520874   0.8455491 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 6252. State = [[-0.04663358 -0.15257959  0.34823868  1.        ]]. Action = [[ 0.75067854 -0.2737559  -0.5640714   0.68902636]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 6253. State = [[-0.01738271 -0.15565458  0.3286364   1.        ]]. Action = [[ 0.9058039   0.10527802 -0.76250166  0.5062258 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 6254. State = [[ 0.00809618 -0.15809815  0.29979464  1.        ]]. Action = [[ 0.0821104  -0.10947967 -0.6962995   0.4999826 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 6255. State = [[ 0.02422936 -0.16442677  0.27959368  1.        ]]. Action = [[ 0.3265028  -0.25448406 -0.21561778  0.33732617]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 6256. State = [[ 0.03229157 -0.17680113  0.26673585  1.        ]]. Action = [[-0.20721614 -0.39501864 -0.4018153   0.37386274]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 6257. State = [[ 0.04028805 -0.18609889  0.27258426  1.        ]]. Action = [[ 0.6033318  -0.11554325  0.90483403  0.33518147]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 6258. State = [[ 0.04744753 -0.18965812  0.2781957   1.        ]]. Action = [[-0.32117772  0.00822103 -0.793819    0.40956545]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 6259. State = [[ 0.04709075 -0.19275057  0.25886238  1.        ]]. Action = [[ 0.39037585 -0.15446836 -0.47552478  0.39868188]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 6260. State = [[ 0.06413084 -0.19437863  0.24035206  1.        ]]. Action = [[ 0.8408971  -0.03890365 -0.23016298  0.59449935]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 6261. State = [[ 0.08051947 -0.19538632  0.22012202  1.        ]]. Action = [[-0.03877407  0.08310926 -0.8587952   0.4293263 ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 6262. State = [[ 0.08924409 -0.19380943  0.20011266  1.        ]]. Action = [[ 0.45755482 -0.37320012 -0.35003722  0.36675048]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 6263. State = [[ 0.08876613 -0.19623722  0.19504383  1.        ]]. Action = [[-0.3189125  -0.09249711 -0.38494444  0.42093718]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 6264. State = [[ 0.08608413 -0.20160334  0.18396391  1.        ]]. Action = [[-0.18576849 -0.15058857 -0.28859228  0.26879   ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 6265. State = [[ 0.08083218 -0.20791313  0.1704261   1.        ]]. Action = [[-0.07995892 -0.11249036 -0.7978262   0.4331193 ]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 6266. State = [[ 0.07651834 -0.21644369  0.13664171  1.        ]]. Action = [[ 0.06417918 -0.33371818 -0.9085446   0.27714193]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 6267. State = [[ 0.07870717 -0.23220173  0.12297276  1.        ]]. Action = [[ 0.09974337 -0.55412865  0.9514022   0.27432418]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 6268. State = [[ 0.07686146 -0.25449383  0.13040783  1.        ]]. Action = [[-0.29986554 -0.69679785 -0.41910636  0.17829478]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 6269. State = [[ 0.06760793 -0.28935555  0.14000243  1.        ]]. Action = [[-0.7296099 -0.9057458  0.8515415  0.1741811]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 6270. State = [[ 0.05770876 -0.31193218  0.1514236   1.        ]]. Action = [[-0.79597986 -0.9222189   0.8609054   0.28824282]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 6271. State = [[ 0.04790376 -0.31607836  0.16458905  1.        ]]. Action = [[-0.8055584   0.32474864  0.73362577  0.51333785]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 6272. State = [[ 0.02967858 -0.31072423  0.17979917  1.        ]]. Action = [[-0.91101056 -0.8075784  -0.05295324  0.5600394 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 6273. State = [[ 0.02900787 -0.31098345  0.18149573  1.        ]]. Action = [[-0.01598316 -0.8262308   0.6921332   0.50252473]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 6274. State = [[ 0.0284642  -0.31098607  0.18184403  1.        ]]. Action = [[-0.7388868  -0.15307552  0.842402    0.37666297]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 6275. State = [[ 0.0294286  -0.29894963  0.17421117  1.        ]]. Action = [[ 0.38992906  0.67215586 -0.7183864   0.51685786]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 6276. State = [[ 0.03702977 -0.28069782  0.16468883  1.        ]]. Action = [[ 0.8055899   0.02564657 -0.17358482  0.31494975]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 6277. State = [[ 0.04881307 -0.2813234   0.14851277  1.        ]]. Action = [[ 0.37247086 -0.5329186  -0.5802437   0.55641246]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 6278. State = [[ 0.06106901 -0.28802335  0.13279256  1.        ]]. Action = [[-0.6231461  -0.7917292  -0.33778965  0.37209463]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 6279. State = [[ 0.06140606 -0.2884123   0.1317492   1.        ]]. Action = [[ 0.5605755  -0.9297822   0.9768827   0.39642775]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 6280. State = [[ 0.0613649  -0.28840882  0.13160703  1.        ]]. Action = [[-0.82866365 -0.95730555  0.96524835  0.4163878 ]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 6281. State = [[ 0.0613649  -0.28840882  0.13160703  1.        ]]. Action = [[-0.75330204 -0.7949295   0.8738197   0.23229492]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 6282. State = [[ 0.06142148 -0.28840238  0.13164936  1.        ]]. Action = [[ 0.27515554 -0.8821636   0.94779515  0.23953927]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 6283. State = [[ 0.06142148 -0.28840238  0.13164936  1.        ]]. Action = [[-0.9819051 -0.9679443 -0.9878709  0.468498 ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 6284. State = [[ 0.06142148 -0.28840238  0.13164936  1.        ]]. Action = [[-0.9042585  -0.94403076  0.13859296  0.33037448]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 6285. State = [[ 0.06142148 -0.28840238  0.13164936  1.        ]]. Action = [[-0.926238   -0.76334965  0.6309186   0.3785702 ]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 6286. State = [[ 0.06142148 -0.28840238  0.13164936  1.        ]]. Action = [[-0.99848086 -0.7257654   0.98289967  0.39460886]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 6287. State = [[ 0.06142148 -0.28840238  0.13164936  1.        ]]. Action = [[-0.96376014 -0.78706235  0.3988061   0.53506815]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 6288. State = [[ 0.06142148 -0.28840238  0.13164936  1.        ]]. Action = [[-0.9628448  -0.85008985  0.9780159   0.49736655]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 6289. State = [[ 0.05539246 -0.29819822  0.13587613  1.        ]]. Action = [[-0.8828728  -0.32521904  0.39327693  0.41622996]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 6290. State = [[ 0.05103532 -0.3074107   0.14070746  1.        ]]. Action = [[-0.9430618  -0.83174634  0.7444446   0.23262382]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 6291. State = [[ 0.04886485 -0.30979344  0.1409699   1.        ]]. Action = [[-0.97368664 -0.95896375 -0.01010305  0.42630565]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 6292. State = [[ 0.04773409 -0.31033644  0.14051728  1.        ]]. Action = [[-0.89154834 -0.93576795  0.9171653   0.41712213]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 6293. State = [[ 0.04775924 -0.31040505  0.14062756  1.        ]]. Action = [[-0.90427303 -0.66303486  0.9483142   0.4844098 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 6294. State = [[ 0.04775924 -0.31040505  0.14062756  1.        ]]. Action = [[-0.9890249  -0.9510472   0.82487226  0.52958345]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 6295. State = [[ 0.04775924 -0.31040505  0.14062756  1.        ]]. Action = [[ 0.16353524 -0.7050159   0.90172935  0.5537338 ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 6296. State = [[ 0.04775924 -0.31040505  0.14062756  1.        ]]. Action = [[-0.69789255 -0.5935381   0.97467124  0.3172791 ]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 6297. State = [[ 0.04770178 -0.3104219   0.1405915   1.        ]]. Action = [[-0.9817015  -0.66069037  0.00840306  0.24718237]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 6298. State = [[ 0.04770178 -0.3104219   0.1405915   1.        ]]. Action = [[-0.98870456 -0.7321539   0.18135536  0.59815884]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 6299. State = [[ 0.04770178 -0.3104219   0.1405915   1.        ]]. Action = [[-0.9977731  -0.76915085  0.82077885  0.32794857]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 6300. State = [[ 0.04770178 -0.3104219   0.1405915   1.        ]]. Action = [[-0.9418927 -0.8630805  0.9732375  0.4276601]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 6301. State = [[ 0.04770178 -0.3104219   0.1405915   1.        ]]. Action = [[-0.9149061  -0.6465671   0.22957206  0.34900284]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 6302. State = [[ 0.04770178 -0.3104219   0.1405915   1.        ]]. Action = [[-0.9897004  -0.648399   -0.07589376  0.35222626]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 6303. State = [[ 0.04770178 -0.3104219   0.1405915   1.        ]]. Action = [[-0.95325005 -0.7371259   0.04172063  0.41442847]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 6304. State = [[ 0.04770178 -0.3104219   0.1405915   1.        ]]. Action = [[-0.99168813 -0.7995394   0.72858655  0.601773  ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 6305. State = [[ 0.04014007 -0.31625214  0.15545431  1.        ]]. Action = [[-0.9480979   0.03843129  0.9914086   0.03878689]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 6306. State = [[ 0.01987412 -0.3147667   0.17654733  1.        ]]. Action = [[-0.40059924 -0.47900558  0.55175436  0.37121236]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 6307. State = [[ 0.01992927 -0.31515563  0.17926557  1.        ]]. Action = [[-0.69757545 -0.07803261  0.9649575   0.5234146 ]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 6308. State = [[ 0.01923681 -0.31537628  0.17997262  1.        ]]. Action = [[-0.8141549  -0.5999246  -0.7805585   0.79832256]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 6309. State = [[ 0.01824302 -0.3156322   0.1809496   1.        ]]. Action = [[ 0.4021461 -0.6796948  0.3792516  0.6478118]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 6310. State = [[ 0.01631511 -0.31613967  0.1815838   1.        ]]. Action = [[-0.8962068   0.02577293 -0.9575381   0.25687766]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 6311. State = [[ 0.01470509 -0.31626996  0.18196195  1.        ]]. Action = [[ 0.5807543  -0.51395035  0.79045725  0.55669475]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 6312. State = [[ 0.01426536 -0.31589824  0.18192264  1.        ]]. Action = [[-0.21225125 -0.18887281  0.4310975   0.43222666]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 6313. State = [[ 0.01420683 -0.31591278  0.18188742  1.        ]]. Action = [[ 0.49737835 -0.09124923  0.74980116  0.8735044 ]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 6314. State = [[ 0.01420683 -0.31591278  0.18188742  1.        ]]. Action = [[ 0.18205476 -0.52174675  0.58268595  0.67146015]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 6315. State = [[ 0.01711862 -0.30453447  0.18581744  1.        ]]. Action = [[0.06580746 0.73123634 0.32082772 0.46911263]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 6316. State = [[ 0.01735576 -0.28873074  0.1906606   1.        ]]. Action = [[-0.84782666 -0.798438   -0.70907927  0.5499449 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 6317. State = [[ 0.00797114 -0.2812279   0.19802122  1.        ]]. Action = [[-0.87555075  0.43786514  0.3094313   0.47034883]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 6318. State = [[-0.00326736 -0.26309448  0.2207624   1.        ]]. Action = [[0.7267301  0.24469292 0.9299866  0.7199477 ]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 6319. State = [[-0.0032025  -0.2584106   0.24254851  1.        ]]. Action = [[-0.22216582 -0.11110181  0.2781229   0.44600797]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 6320. State = [[-0.0083128  -0.26046553  0.24250989  1.        ]]. Action = [[-0.19884431 -0.098207   -0.936957    0.62102795]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 6321. State = [[-0.0086984  -0.25796005  0.22422941  1.        ]]. Action = [[ 0.6149931   0.03651142 -0.83598244  0.4549229 ]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 6322. State = [[-1.5121000e-04 -2.5168371e-01  2.0061284e-01  1.0000000e+00]]. Action = [[0.18572843 0.30222678 0.0259316  0.7141292 ]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 6323. State = [[ 0.01225231 -0.24781741  0.19837955  1.        ]]. Action = [[ 0.94495964 -0.22190237 -0.19146132  0.3383255 ]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 6324. State = [[ 0.04003461 -0.24099582  0.18138908  1.        ]]. Action = [[ 0.4764583   0.45382726 -0.3195908   0.6363151 ]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 6325. State = [[ 0.05101734 -0.24240358  0.16306968  1.        ]]. Action = [[ 0.16620314 -0.6374506  -0.72128296  0.55299735]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 6326. State = [[ 0.06458577 -0.253011    0.15533282  1.        ]]. Action = [[0.09699023 0.07979751 0.8092737  0.44918394]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 6327. State = [[ 0.06526368 -0.26441625  0.17695536  1.        ]]. Action = [[-0.54062694 -0.4689747   0.89006877  0.5416291 ]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 6328. State = [[ 0.06092313 -0.27535957  0.20930934  1.        ]]. Action = [[-0.1825298   0.01410651  0.69941473  0.60108936]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 6329. State = [[ 0.05643367 -0.27097085  0.21917604  1.        ]]. Action = [[-0.26390845  0.5467458  -0.62276727  0.82441306]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 6330. State = [[ 0.04255395 -0.25113362  0.20300198  1.        ]]. Action = [[-0.5133352   0.6204629  -0.95396924  0.74445283]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 6331. State = [[ 0.03486785 -0.22830985  0.18421897  1.        ]]. Action = [[ 0.522184    0.37726998 -0.17915368  0.64987135]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 6332. State = [[ 0.04314067 -0.21631856  0.17473418  1.        ]]. Action = [[0.45630658 0.07648182 0.01682615 0.4673841 ]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 6333. State = [[ 0.06039286 -0.20961373  0.16888104  1.        ]]. Action = [[ 0.9369918  -0.09245938 -0.26878315  0.48153687]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 6334. State = [[-0.25142154 -0.10973221  0.08724088  1.        ]]. Action = [[ 0.51632357 -0.14834583 -0.2604816   0.2150501 ]]. Reward = [0.]
Curr episode timestep = 101
Current timestep = 6335. State = [[-0.24863458 -0.13180585  0.08087068  1.        ]]. Action = [[ 0.01949608 -0.7093959   0.88693345  0.9115536 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 6336. State = [[-0.24442425 -0.15778907  0.09745491  1.        ]]. Action = [[ 0.27248454 -0.74160826  0.61126804  0.96519077]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 6337. State = [[-0.23383628 -0.18711087  0.11891451  1.        ]]. Action = [[ 0.45525098 -0.7380891   0.47981     0.9945998 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 6338. State = [[-0.21296725 -0.21209782  0.14331068  1.        ]]. Action = [[ 0.68810964 -0.52678007  0.88165057  0.9718641 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 6339. State = [[-0.18843201 -0.23181431  0.17744543  1.        ]]. Action = [[ 0.4341296  -0.37599236  0.92032886  0.9883666 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 6340. State = [[-0.16460873 -0.24867414  0.21188888  1.        ]]. Action = [[ 0.789853   -0.3872763   0.8281138   0.99829197]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 6341. State = [[-0.14148398 -0.26810554  0.24561039  1.        ]]. Action = [[ 0.2971698  -0.5049091   0.77749467  0.84296274]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 6342. State = [[-0.12196355 -0.2864114   0.28189585  1.        ]]. Action = [[ 0.53191555 -0.31052768  0.9955306   0.966491  ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 6343. State = [[-0.09848579 -0.2936958   0.31778425  1.        ]]. Action = [[0.80560696 0.02619541 0.6001824  0.86042345]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 6344. State = [[-0.07498271 -0.28667438  0.3507863   1.        ]]. Action = [[0.42252183 0.58994734 0.9336034  0.6365632 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 6345. State = [[-0.05508478 -0.26857036  0.36247844  1.        ]]. Action = [[ 0.84165263  0.41579747 -0.93269104  0.68230855]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 6346. State = [[-0.02741283 -0.24792527  0.33790714  1.        ]]. Action = [[ 0.9547522   0.5576252  -0.8946503   0.49242127]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 6347. State = [[-0.0070443  -0.23886949  0.31964898  1.        ]]. Action = [[-0.86114764  0.17097127  0.15309668  0.7296393 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 6348. State = [[-0.01285483 -0.22208598  0.31108704  1.        ]]. Action = [[-0.26678443  0.7518873  -0.747335    0.6332154 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 6349. State = [[-0.02769059 -0.21501668  0.29506984  1.        ]]. Action = [[-0.7843463  -0.37656403 -0.34039545  0.490507  ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 6350. State = [[-0.03530517 -0.21265107  0.2806207   1.        ]]. Action = [[ 0.84447896  0.2405634  -0.0975529   0.51699984]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 6351. State = [[-0.02854544 -0.20776121  0.27195397  1.        ]]. Action = [[ 0.6860528  -0.16709882 -0.50226325  0.43533754]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 6352. State = [[-0.00242437 -0.2105943   0.25608793  1.        ]]. Action = [[ 0.9036186  -0.16913241 -0.02400327  0.50589395]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 6353. State = [[ 0.02822146 -0.2147641   0.2468724   1.        ]]. Action = [[ 0.7352896  -0.11105514 -0.11293763  0.144027  ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 6354. State = [[ 0.04780418 -0.21635905  0.23384017  1.        ]]. Action = [[ 0.02740526  0.13028824 -0.6092896   0.5968443 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 6355. State = [[ 0.05381051 -0.21609206  0.21207105  1.        ]]. Action = [[ 0.1980958 -0.0733152 -0.9482171  0.6508417]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 6356. State = [[ 0.06382315 -0.22000721  0.17825094  1.        ]]. Action = [[ 0.33953333 -0.25936592 -0.7404579   0.35404694]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 6357. State = [[ 0.07228413 -0.22125717  0.14436916  1.        ]]. Action = [[-0.30858004  0.31146097 -0.9733349   0.25098467]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 6358. State = [[ 0.07191443 -0.22661024  0.12113897  1.        ]]. Action = [[-0.13829195 -0.42420506  0.01429141  0.30490303]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 6359. State = [[ 0.05999786 -0.24556324  0.11058753  1.        ]]. Action = [[-0.83652157 -0.8282399  -0.81682336  0.23723626]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 6360. State = [[ 0.0431182  -0.28052318  0.09786355  1.        ]]. Action = [[-0.7838305  -0.9345799   0.5492177   0.16347635]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 6361. State = [[ 0.03118185 -0.3020233   0.10255135  1.        ]]. Action = [[-0.99444705 -0.95793396  0.94673157 -0.05079687]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 6362. State = [[ 0.02716281 -0.30616245  0.102825    1.        ]]. Action = [[-0.98405856 -0.9798731   0.9927912   0.10728204]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 6363. State = [[ 0.02554395 -0.3083562   0.10332564  1.        ]]. Action = [[-0.9792238  -0.9769047   0.85418046  0.02776372]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 6364. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.993846   -0.98250717  0.8173473   0.05195534]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 6365. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9970941  -0.94112253  0.975665    0.08113897]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 6366. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.99021155 -0.9785013   0.8638897  -0.02206206]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 6367. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.97189575 -0.9714938   0.9868411   0.00202024]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 6368. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.99326974 -0.9498261   0.97377753 -0.00289208]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 6369. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.99712056 -0.8828577   0.97446907 -0.08812582]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 6370. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.99662775 -0.9806091   0.9853525  -0.12784386]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 6371. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9947257  -0.98966527  0.835472   -0.09194249]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 6372. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9942096  -0.97495186  0.5915654  -0.00720936]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 6373. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.64171445 -0.98954505  0.8422947  -0.05865353]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 6374. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9590287  -0.9820368   0.9100441  -0.01683629]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 6375. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.99477935 -0.9950537   0.79527044 -0.03687537]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 6376. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9935196  -0.95590174  0.6742232  -0.01021475]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 6377. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.99002504 -0.9882623   0.8640654   0.04912591]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 6378. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.93477345 -0.972567    0.90323794  0.06338954]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 6379. State = [[ 0.02552022 -0.3083954   0.10334415  1.        ]]. Action = [[-0.9962636  -0.9867481   0.37215924  0.04234278]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 6380. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.99612397 -0.9576561   0.6120019   0.1372509 ]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 6381. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.97886896 -0.9770413   0.78071165  0.12271082]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 6382. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.99412525 -0.9778064   0.7712567   0.14219832]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 6383. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.98197085 -0.8520472   0.958145    0.09108138]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 6384. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.99143606 -0.9794372   0.9423934   0.05436218]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 6385. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9944631  -0.98105145  0.9351165   0.04246056]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 6386. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9909813  -0.9903833   0.96004593 -0.11511016]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 6387. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9572331  -0.99188083  0.9846796  -0.01778823]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 6388. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9928882  -0.93574345  0.81314874  0.04060042]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 6389. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9950158  -0.9863805   0.29248905 -0.03137863]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 6390. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9643179  -0.9862064   0.89327455 -0.03313059]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 6391. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.99977607 -0.9941691   0.9831903   0.09867787]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 6392. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.99837565 -0.9252458  -0.03031647  0.13770127]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 6393. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.98876977 -0.8774421   0.98910165  0.07681465]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 6394. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.997509  -0.7774333  0.9421954  0.1693008]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 6395. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.99972993 -0.8597045   0.9528127   0.10818136]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 6396. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9901333  -0.8650996   0.95762587  0.22776306]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 6397. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.983683   -0.93239343  0.9279821   0.10401857]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 6398. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9949238  -0.9836476   0.9595008   0.19210792]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 6399. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9731151  -0.98572177  0.98884153  0.15064168]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 6400. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9962884 -0.9304056  0.970371   0.0806247]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 6401. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.97594875 -0.9886968   0.5736029   0.0654912 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 6402. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9953489  -0.9757194   0.82727253  0.09674335]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 6403. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9685988 -0.9332196  0.7101747  0.0366385]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 6404. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9966882  -0.97578984  0.97229874  0.08146429]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 6405. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9499157  -0.9374821   0.7014358   0.21618342]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 6406. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9209176  -0.9861937   0.85714006  0.11454237]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 6407. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9621672  -0.9436294   0.97759557  0.02184415]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 6408. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9600674  -0.98007196  0.53469265  0.09403312]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 6409. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9583397  -0.980182    0.9828818   0.13402736]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 6410. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.98107666 -0.8974044   0.91616154  0.09842765]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 6411. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.99528986 -0.69093895  0.24946642  0.1617918 ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 6412. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9514091  -0.9864259   0.9823451   0.09690738]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 6413. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9921868  -0.95791787  0.91738963  0.12749732]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 6414. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9816957  -0.97970784  0.49641693  0.08233404]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 6415. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9771895  -0.9800769   0.40542567  0.10727036]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 6416. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9781296  -0.9150305   0.9374769   0.12334812]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 6417. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9777008 -0.937999   0.9893036  0.0792973]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 6418. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.98060983 -0.9760479   0.9590864   0.06771958]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 6419. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9851714 -0.983069   0.992648   0.0346967]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 6420. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9875873  -0.91107416  0.8772502   0.10119903]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 6421. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.96301043 -0.9312017   0.98166656  0.09760857]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 6422. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9784388  -0.7220002   0.99321914  0.16923392]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 6423. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.95649827 -0.9790191   0.9443002   0.16224527]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 6424. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9983611  -0.9871485   0.97034097  0.11144125]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 6425. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.98275733 -0.95861655  0.9573628   0.2504561 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 6426. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.8983764  -0.9816274   0.4861548   0.10834777]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 6427. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.99693465 -0.91378736  0.9835789   0.18750072]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 6428. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9928994  -0.96394634  0.90543306  0.16624713]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 6429. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.90324086 -0.93577415  0.7266078   0.11124718]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 6430. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.98703325 -0.96865726  0.97626877  0.16975248]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 6431. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9983041  -0.81502324  0.9382105   0.21978712]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 6432. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9931504  -0.9808866   0.9643557   0.02041757]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 6433. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9890245  -0.9841757   0.93686974  0.10718751]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 6434. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.9804988 -0.7400596 -0.7904406  0.2531526]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 6435. State = [[ 0.02550437 -0.30847055  0.10334419  1.        ]]. Action = [[-0.99966794 -0.9790538   0.9854593   0.06350589]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 6436. State = [[-0.27055392  0.11980844  0.11303753  1.        ]]. Action = [[-0.9725242  -0.99470854  0.7201953   0.11499858]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 6437. State = [[-0.25910938  0.12240948  0.10753476  1.        ]]. Action = [[ 0.35750115 -0.78271085  0.9616991   0.984892  ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 6438. State = [[-0.24705558  0.09565512  0.12929963  1.        ]]. Action = [[ 0.12939262 -0.9135465   0.9389305   0.8022649 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 6439. State = [[-0.2358576   0.06638469  0.16314913  1.        ]]. Action = [[ 0.5098264  -0.72553295  0.7900038   0.9818319 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 6440. State = [[-0.22683653  0.03939597  0.19275023  1.        ]]. Action = [[ 0.06626916 -0.77834177  0.8022618   0.97236896]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 6441. State = [[-0.21438955  0.0105297   0.22086872  1.        ]]. Action = [[ 0.696218   -0.7026957   0.44218636  0.94751203]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 6442. State = [[-0.18975879 -0.01691843  0.24898721  1.        ]]. Action = [[ 0.52700806 -0.62493014  0.8778715   0.99289036]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 6443. State = [[-0.16887271 -0.04385523  0.27379167  1.        ]]. Action = [[ 0.6184828  -0.7340044   0.07002664  0.9502653 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 6444. State = [[-0.14446338 -0.06682318  0.28588986  1.        ]]. Action = [[ 0.9570761  -0.3893684   0.24319816  0.72769594]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 6445. State = [[-0.11016405 -0.08425116  0.28777894  1.        ]]. Action = [[ 0.98797345 -0.44411087 -0.36474597  0.8377688 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 6446. State = [[-0.07517362 -0.0944571   0.27425876  1.        ]]. Action = [[ 0.95705223 -0.02999127 -0.628116    0.7826457 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 6447. State = [[-0.04009329 -0.09880546  0.25342897  1.        ]]. Action = [[ 0.9383744  -0.11687768 -0.61964643  0.71678615]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 6448. State = [[-0.0017457  -0.10871848  0.2389127   1.        ]]. Action = [[ 0.8155248  -0.4216568   0.20635676  0.40333903]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 6449. State = [[ 0.01778632 -0.12139209  0.24207361  1.        ]]. Action = [[-0.48722035 -0.21420574  0.181561    0.22624397]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 6450. State = [[ 0.02230108 -0.1344687   0.25476134  1.        ]]. Action = [[ 0.5002285  -0.44678086  0.62495565  0.2547263 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 6451. State = [[ 0.03545533 -0.14760877  0.2713902   1.        ]]. Action = [[ 0.47494936 -0.34978533  0.15532088  0.33004797]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 6452. State = [[ 0.04552471 -0.16307859  0.2688329   1.        ]]. Action = [[ 0.04649627 -0.38180888 -0.5200292   0.27976513]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 6453. State = [[ 0.05559986 -0.17036857  0.2535478   1.        ]]. Action = [[ 0.6309036   0.01831281 -0.6150576   0.2817335 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 6454. State = [[ 0.07302786 -0.17966452  0.22678865  1.        ]]. Action = [[ 0.71751916 -0.5622287  -0.9458125   0.3991636 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 6455. State = [[ 0.09435175 -0.20127313  0.18875621  1.        ]]. Action = [[-0.11611837 -0.5861444  -0.6875588   0.28854346]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 6456. State = [[ 0.09575652 -0.22594668  0.16023049  1.        ]]. Action = [[-0.91548926 -0.52607626 -0.8617999   0.42632127]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 6457. State = [[ 0.08309279 -0.24368882  0.13316917  1.        ]]. Action = [[-0.48146987 -0.14128757 -0.87783945  0.70300794]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 6458. State = [[ 0.07409648 -0.24816783  0.11047561  1.        ]]. Action = [[ 0.85583556 -0.02488613 -0.43558788  0.45692682]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 6459. State = [[ 0.07239406 -0.26112062  0.11888593  1.        ]]. Action = [[-0.13246918 -0.62809306  0.85407543  0.33707   ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 6460. State = [[ 0.06226449 -0.28229183  0.13129826  1.        ]]. Action = [[-0.8317281  -0.22720057  0.13069654  0.5718634 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 6461. State = [[ 0.04654085 -0.29087257  0.1356209   1.        ]]. Action = [[-0.846542   -0.5960526   0.90928364  0.59437394]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 6462. State = [[ 0.03492463 -0.30010474  0.1384311   1.        ]]. Action = [[-0.855804   -0.25824016  0.03387499  0.45863128]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 6463. State = [[ 0.01546836 -0.30593678  0.1408513   1.        ]]. Action = [[-0.58089423 -0.36265898  0.250216    0.5389552 ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 6464. State = [[ 0.0113918  -0.30657184  0.13953553  1.        ]]. Action = [[-0.6982187  -0.5316926   0.44010663  0.53159237]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 6465. State = [[ 0.0114063  -0.30721003  0.14276752  1.        ]]. Action = [[-0.03618008 -0.03608102  0.24643719  0.37748647]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 6466. State = [[ 0.01127173 -0.30765337  0.14916666  1.        ]]. Action = [[-0.97264457 -0.3498178  -0.3371483   0.4689778 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 6467. State = [[ 0.01129031 -0.30765593  0.14923286  1.        ]]. Action = [[-0.47910213 -0.72073305  0.6630701   0.53611887]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 6468. State = [[ 0.01129031 -0.30765593  0.14923286  1.        ]]. Action = [[-0.5080201  -0.27964544  0.72192     0.3145312 ]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 6469. State = [[ 0.01129031 -0.30765593  0.14923286  1.        ]]. Action = [[-0.1617291  -0.8138026  -0.51054454  0.43052542]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 6470. State = [[ 0.01129031 -0.30765593  0.14923286  1.        ]]. Action = [[-0.73798776 -0.6332925  -0.58688325  0.46427763]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 6471. State = [[ 0.01364509 -0.30210415  0.14314102  1.        ]]. Action = [[ 0.7282953   0.18409657 -0.5859067   0.62629056]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 6472. State = [[ 0.01475843 -0.297496    0.13659224  1.        ]]. Action = [[-0.89311445 -0.3133427   0.7706609   0.46048188]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 6473. State = [[ 0.00802572 -0.2977051   0.12885371  1.        ]]. Action = [[-0.94529146  0.12343502 -0.4280457   0.29174352]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 6474. State = [[-0.00365617 -0.2966421   0.11893604  1.        ]]. Action = [[ 0.0033282  -0.93190056  0.34816837  0.3756864 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 6475. State = [[-0.00520272 -0.29645687  0.11742835  1.        ]]. Action = [[-0.08021927 -0.95770603  0.9964781   0.11412477]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 6476. State = [[-0.00523451 -0.29645646  0.11740883  1.        ]]. Action = [[-0.8899851 -0.9174255  0.9056698  0.2954216]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 6477. State = [[-0.00523451 -0.29645646  0.11740883  1.        ]]. Action = [[-0.9187909  -0.8610852   0.44036353  0.13539362]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 6478. State = [[-0.00523451 -0.29645646  0.11740883  1.        ]]. Action = [[-0.96682346 -0.9493547  -0.22207725  0.1576922 ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 6479. State = [[-0.00523451 -0.29645646  0.11740883  1.        ]]. Action = [[-0.78686416 -0.31740558  0.73810196  0.08563697]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 6480. State = [[-0.00538616 -0.2964635   0.11731893  1.        ]]. Action = [[-0.9615652  -0.7351746   0.9491093   0.26474583]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 6481. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.71414185 -0.94003     0.92249227  0.17437959]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 6482. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.95110744 -0.98142314  0.5222485   0.18736029]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 6483. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.80589646 -0.8173471   0.8831563   0.09868753]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 6484. State = [[-0.00538616 -0.2964635   0.11731893  1.        ]]. Action = [[-0.9815287  -0.9436261   0.40702796  0.12804389]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 6485. State = [[-0.00538616 -0.2964635   0.11731893  1.        ]]. Action = [[-0.7832847  -0.9508202   0.838488    0.17437184]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 6486. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.97951716 -0.8925926   0.93734455  0.04259598]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 6487. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.95121294 -0.95405185  0.5676575   0.1979214 ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 6488. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.80857325 -0.76491857  0.97909     0.24881661]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 6489. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.9722758  -0.834138    0.8555975   0.10357893]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 6490. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.84702677 -0.8954628   0.96483755  0.15938449]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 6491. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.8497658  -0.7795934   0.88533854  0.115484  ]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 6492. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.86207426 -0.44048023  0.635916    0.25061882]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 6493. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.7432786  -0.8482941   0.7838526   0.31551516]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 6494. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.990727  -0.9598722  0.8842356  0.153561 ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 6495. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.98000056 -0.6431746   0.02077341  0.25668502]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 6496. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.898199   -0.9002229   0.50778866  0.19952989]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 6497. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.8672188  -0.9461876   0.9143288   0.14288414]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 6498. State = [[-0.00538616 -0.2964635   0.11731893  1.        ]]. Action = [[-0.50757575 -0.8810653   0.905226    0.20312285]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 6499. State = [[-0.00538616 -0.2964635   0.11731893  1.        ]]. Action = [[-0.99477905 -0.8940179   0.12061286  0.24859989]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 6500. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.9359321  -0.62286663  0.9525044   0.19086659]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 6501. State = [[-0.00538616 -0.2964635   0.11731893  1.        ]]. Action = [[-0.8651012  -0.95432854  0.78464365  0.14877701]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 6502. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.9396391  -0.87434655  0.9431455   0.3139994 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 6503. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.9780841  -0.8422383   0.67883587  0.21236134]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 6504. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.8750397 -0.9217887  0.955796   0.2339009]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 6505. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.9732395  -0.84860027  0.95036316  0.0691117 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 6506. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.92500705 -0.910891    0.9782181   0.17209947]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 6507. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.9144348  -0.8486939   0.88917637  0.18754292]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 6508. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.96030015 -0.6672839  -0.70600945  0.2923292 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 6509. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.9782723  -0.70522934  0.8907695   0.15175092]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 6510. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.7372202  -0.92224634  0.9039922   0.22841704]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 6511. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.799325   -0.7246461   0.76247275  0.23395598]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 6512. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.87302065 -0.82720983  0.4101498   0.14990342]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 6513. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.7638916  -0.55716306  0.7894726   0.2399503 ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 6514. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.8797753  -0.795385    0.9832537   0.14986646]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 6515. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.79940295 -0.9632516   0.5922911   0.30401993]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 6516. State = [[-0.00538616 -0.2964635   0.11731893  1.        ]]. Action = [[-0.9170814 -0.823803  -0.1478641  0.2892015]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 6517. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.48947048 -0.8937483  -0.5598977   0.33978105]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 6518. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.8039676  -0.91404593  0.8439102   0.30365777]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 6519. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.99065816 -0.6803019   0.97368133  0.28576303]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 6520. State = [[-0.00538616 -0.2964635   0.11731893  1.        ]]. Action = [[-0.9864239  -0.8029838  -0.35804272  0.24944615]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 6521. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.09130841 -0.78054273  0.539587    0.34257495]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 6522. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.9305175  -0.41793907  0.8843982   0.28182042]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 6523. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.99752617 -0.96657723 -0.17929387  0.24438679]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 6524. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.6770879 -0.7840704  0.9749503  0.2754364]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 6525. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.9249303  -0.74744433  0.25909865  0.45535302]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 6526. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.88134843 -0.9302462   0.711957    0.22013724]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 6527. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.98057115 -0.663352   -0.4353779   0.34346473]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 6528. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.35574818 -0.9144626   0.62458754  0.2922436 ]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 6529. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.6784263  -0.62778926  0.30415344  0.25842547]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 6530. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.7054435  -0.88243014  0.5628934   0.28972864]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 6531. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.98690623 -0.9188466  -0.48811352  0.28199697]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 6532. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.8720164  -0.94470054 -0.34588462  0.2737615 ]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 6533. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.6151447  -0.75796974 -0.21746433  0.2819332 ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 6534. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.15520239 -0.6439874   0.97920895  0.20294452]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 6535. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.58787656 -0.83722734  0.95064616  0.08563268]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 6536. State = [[-0.00535666 -0.29646087  0.11733597  1.        ]]. Action = [[-0.63854104 -0.8672751   0.8267096   0.24749613]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 6537. State = [[-0.01301431 -0.30315548  0.12954707  1.        ]]. Action = [[-0.94034636 -0.2515291   0.9349452   0.17040884]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 6538. State = [[-0.26095742 -0.00580106  0.10529697  1.        ]]. Action = [[-0.9409282  -0.52636     0.7643758   0.38966823]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 6539. State = [[-0.25296795 -0.02105516  0.09853011  1.        ]]. Action = [[ 0.5601655  -0.77491343  0.8833387   0.9826739 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 6540. State = [[-0.23861116 -0.04301474  0.11788552  1.        ]]. Action = [[ 0.4266312  -0.45083934  0.84252596  0.9942262 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 6541. State = [[-0.21895209 -0.06567261  0.15048873  1.        ]]. Action = [[ 0.45545626 -0.693905    0.8443122   0.92590463]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 6542. State = [[-0.19208232 -0.08789467  0.18337262  1.        ]]. Action = [[ 0.9168968  -0.46606696  0.74137926  0.9872929 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 6543. State = [[-0.17048293 -0.10009233  0.20313731  1.        ]]. Action = [[ 0.8843049 -0.7820209  0.76843    0.9747503]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 6544. State = [[-0.15610066 -0.10875263  0.21844548  1.        ]]. Action = [[ 0.78331876 -0.4072901   0.8726516   0.91290784]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 6545. State = [[-0.1379962  -0.11819874  0.23984206  1.        ]]. Action = [[ 0.9066045  -0.5482687  -0.63113576  0.9602692 ]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 6546. State = [[-0.1238283  -0.12241443  0.25081235  1.        ]]. Action = [[ 0.9366456  -0.2974596   0.42459893  0.9592197 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 6547. State = [[-0.09343734 -0.12761682  0.27726886  1.        ]]. Action = [[ 0.93269074 -0.06729448  0.95634437  0.5363494 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 6548. State = [[-0.06284877 -0.13350436  0.29432222  1.        ]]. Action = [[ 0.9463755  -0.1896885  -0.65205956  0.8125689 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 6549. State = [[-0.0271595  -0.13641627  0.27675042  1.        ]]. Action = [[ 0.94211197  0.16293383 -0.35120738  0.49802053]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 6550. State = [[ 0.00773704 -0.13459009  0.2641428   1.        ]]. Action = [[ 0.861308    0.0689646  -0.3594594   0.18675411]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 6551. State = [[ 0.04380493 -0.14052692  0.25074348  1.        ]]. Action = [[ 0.82264805 -0.45863467 -0.12957358  0.29910445]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 6552. State = [[ 0.0692981 -0.1478455  0.2463851  1.       ]]. Action = [[ 0.39945328 -0.5332878  -0.8062614   0.04434276]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: No entry zone
Current timestep = 6553. State = [[ 0.07548497 -0.14883912  0.24695954  1.        ]]. Action = [[ 0.8854301  -0.5586978  -0.62654144  0.23180008]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 6554. State = [[ 0.07548497 -0.14883912  0.24695954  1.        ]]. Action = [[ 0.323097   -0.32291394 -0.97108644  0.28187394]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: No entry zone
Current timestep = 6555. State = [[ 0.07553093 -0.14883794  0.24701138  1.        ]]. Action = [[-0.19207227 -0.6417028  -0.82635975  0.23677576]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: No entry zone
Current timestep = 6556. State = [[ 0.07550462 -0.14882913  0.24700987  1.        ]]. Action = [[ 0.38337755 -0.24614847 -0.80899227  0.16407013]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: No entry zone
Current timestep = 6557. State = [[ 0.07550462 -0.14882913  0.24700987  1.        ]]. Action = [[ 0.7099575 -0.5890513 -0.8778333  0.2399975]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 6558. State = [[ 0.07550462 -0.14882913  0.24700987  1.        ]]. Action = [[ 0.55409575 -0.5928137  -0.8860727   0.22795331]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 6559. State = [[ 0.07304537 -0.16140695  0.24041837  1.        ]]. Action = [[ 0.04860926 -0.81409734 -0.85331035  0.26440597]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 6560. State = [[ 0.08063444 -0.17802992  0.21856378  1.        ]]. Action = [[ 0.21103156 -0.05372185 -0.7726881   0.21980345]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: No entry zone
Current timestep = 6561. State = [[ 0.08422127 -0.18003513  0.21661556  1.        ]]. Action = [[ 0.88996196 -0.40431058 -0.7762123   0.41558564]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 6562. State = [[ 0.08313585 -0.18608238  0.21125793  1.        ]]. Action = [[ 0.24704945 -0.3519923  -0.8379459   0.5916697 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 6563. State = [[ 0.08223205 -0.20010465  0.17942628  1.        ]]. Action = [[-0.83281493 -0.2848829  -0.5863327   0.3492627 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 6564. State = [[ 0.07912191 -0.20780422  0.1668717   1.        ]]. Action = [[ 0.6152594   0.20434844 -0.45387554  0.50537837]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 6565. State = [[ 0.07538424 -0.2183579   0.15902148  1.        ]]. Action = [[-0.23901016 -0.5176854  -0.48879176  0.5944619 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 6566. State = [[ 0.07282945 -0.22787641  0.14902829  1.        ]]. Action = [[ 0.6516714   0.26879573 -0.70649546  0.5814284 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 6567. State = [[ 0.07233175 -0.22900975  0.14745802  1.        ]]. Action = [[ 0.55563104 -0.2465012  -0.7400798   0.77404237]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 6568. State = [[ 0.06672264 -0.22646393  0.14640878  1.        ]]. Action = [[-0.8051816   0.4192443   0.18806732  0.56189394]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 6569. State = [[ 0.0482191  -0.23044397  0.13242526  1.        ]]. Action = [[-0.8378816  -0.34930182 -0.8833734   0.68611705]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 6570. State = [[ 0.01724728 -0.22400033  0.11619869  1.        ]]. Action = [[-0.8027833   0.7720214   0.38931274  0.51428246]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 6571. State = [[ 7.1856531e-04 -2.1167324e-01  1.2628449e-01  1.0000000e+00]]. Action = [[ 0.6504581  -0.15997791  0.2440716   0.5535923 ]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 6572. State = [[-2.4177092e-04 -2.1203713e-01  1.2683488e-01  1.0000000e+00]]. Action = [[-0.28949046 -0.08522248 -0.30222     0.14015567]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 6573. State = [[ 9.6708315e-04 -2.0338263e-01  1.2657613e-01  1.0000000e+00]]. Action = [[0.6247573  0.51856995 0.0922873  0.39366448]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 6574. State = [[ 0.00741068 -0.19734979  0.12128271  1.        ]]. Action = [[ 0.5519211  -0.3191735  -0.5690182   0.44674206]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 6575. State = [[ 0.028414   -0.20230632  0.12411129  1.        ]]. Action = [[ 0.90663314 -0.29664326  0.85488594  0.40417492]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 6576. State = [[ 0.05030218 -0.20401777  0.1400328   1.        ]]. Action = [[0.5840738  0.13961971 0.14396453 0.17914355]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 6577. State = [[ 0.06267759 -0.20306557  0.14148873  1.        ]]. Action = [[-0.30969     0.01192212 -0.06383598  0.57216   ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 6578. State = [[ 0.06104976 -0.21058492  0.15033957  1.        ]]. Action = [[-0.45436954 -0.28887105  0.7702844   0.540246  ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 6579. State = [[ 0.05595341 -0.20925055  0.15265572  1.        ]]. Action = [[-0.18218547  0.6102607  -0.88205844  0.48897266]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 6580. State = [[ 0.05471546 -0.19625022  0.14023088  1.        ]]. Action = [[ 0.42401028  0.1874646  -0.13752437  0.37136114]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 6581. State = [[ 0.05967613 -0.19074254  0.13663734  1.        ]]. Action = [[ 0.7781606  -0.22939098 -0.389696    0.45847464]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 6582. State = [[ 0.07724657 -0.19069423  0.12061115  1.        ]]. Action = [[ 0.7939067  0.2389741 -0.3232813  0.3406415]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 6583. State = [[ 0.07911971 -0.19476971  0.11913988  1.        ]]. Action = [[-0.92424375  0.02577746  0.26990306  0.39523554]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 6584. State = [[ 0.07686007 -0.19953264  0.12175264  1.        ]]. Action = [[ 0.46358705 -0.12234944  0.29900217  0.29442883]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 6585. State = [[ 0.07719224 -0.20658882  0.13239439  1.        ]]. Action = [[ 0.02078354 -0.39537644  0.6144084   0.37224317]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 6586. State = [[ 0.07622271 -0.20465556  0.13975467  1.        ]]. Action = [[ 0.03425908  0.47246993 -0.3242966   0.47296214]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 6587. State = [[ 0.06824957 -0.20918536  0.13526814  1.        ]]. Action = [[-0.5840572  -0.6411216  -0.22316468  0.42894983]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 6588. State = [[ 0.0523584  -0.21565989  0.14062546  1.        ]]. Action = [[-0.73272204  0.2641853   0.65831697  0.46189404]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 6589. State = [[ 0.03110209 -0.20713583  0.155684    1.        ]]. Action = [[-0.3579961   0.3911612   0.18741274  0.5845449 ]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 6590. State = [[ 0.02358462 -0.19756062  0.15409888  1.        ]]. Action = [[ 0.8774272  -0.04696053 -0.87682956  0.5192177 ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 6591. State = [[ 0.03776525 -0.19422945  0.14890249  1.        ]]. Action = [[0.7873912  0.04895031 0.7154386  0.500227  ]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 6592. State = [[ 0.04579359 -0.19461465  0.15350391  1.        ]]. Action = [[-0.3398332  -0.16911608 -0.2217347   0.25887024]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 6593. State = [[ 0.04508978 -0.19720729  0.14409858  1.        ]]. Action = [[ 0.6514416  -0.21491098 -0.81092465  0.42391193]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 6594. State = [[ 0.06045903 -0.20727137  0.11834662  1.        ]]. Action = [[ 0.38852906 -0.44630462 -0.32001758  0.63332033]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 6595. State = [[ 0.06671268 -0.22827138  0.10072133  1.        ]]. Action = [[-0.3296889  -0.63258386 -0.3559661   0.4783566 ]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 6596. State = [[ 0.0590586  -0.25607416  0.09413058  1.        ]]. Action = [[-0.75040114 -0.77490366 -0.10182714  0.28416467]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 6597. State = [[ 0.04710707 -0.28715777  0.10245653  1.        ]]. Action = [[-0.7052972  -0.39028418  0.82896686  0.36437201]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 6598. State = [[ 0.03572222 -0.29876825  0.11275832  1.        ]]. Action = [[-0.80235755 -0.869701    0.9490645   0.340194  ]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 6599. State = [[ 0.03267825 -0.30234772  0.11376492  1.        ]]. Action = [[-0.6454601  -0.9177685   0.33023787  0.5175648 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 6600. State = [[ 0.03189741 -0.30341858  0.11481614  1.        ]]. Action = [[-0.98179066 -0.8366039   0.7156795   0.6037657 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 6601. State = [[ 0.03189741 -0.30341858  0.11481614  1.        ]]. Action = [[-0.95709807 -0.7789936   0.95292675  0.59182477]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 6602. State = [[ 0.02612481 -0.3092578   0.12602848  1.        ]]. Action = [[-0.81497407 -0.07669359  0.78118837  0.5642829 ]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 6603. State = [[ 0.00736302 -0.3101078   0.14458461  1.        ]]. Action = [[-0.6904618  -0.70014274  0.49305964  0.6260861 ]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 6604. State = [[ 0.00356364 -0.31061566  0.1495111   1.        ]]. Action = [[-0.90339893 -0.02162254  0.10767591  0.6199651 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 6605. State = [[ 0.00744438 -0.29850975  0.1581502   1.        ]]. Action = [[0.29630053 0.8066853  0.71956635 0.6470094 ]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 6606. State = [[ 0.01113299 -0.26417342  0.16209398  1.        ]]. Action = [[ 0.30023646  0.87904525 -0.8983103   0.7360766 ]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 6607. State = [[ 0.01748548 -0.23483357  0.15160912  1.        ]]. Action = [[ 0.67922235  0.38226688 -0.14949858  0.6794956 ]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 6608. State = [[ 0.03053117 -0.21856314  0.1379854   1.        ]]. Action = [[ 0.6658118   0.10230076 -0.48982632  0.20920253]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 6609. State = [[ 0.05117431 -0.21005891  0.11551528  1.        ]]. Action = [[ 0.740793    0.00314808 -0.87722206  0.52045417]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 6610. State = [[ 0.07510206 -0.20337018  0.08845473  1.        ]]. Action = [[ 0.25796008  0.28622627 -0.01107877  0.4424361 ]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 6611. State = [[ 0.07891281 -0.21484627  0.08816924  1.        ]]. Action = [[-0.86610734 -0.7959083   0.38445854  0.3856386 ]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 6612. State = [[ 0.06541319 -0.2389276   0.09017434  1.        ]]. Action = [[-0.8483911  -0.46878242 -0.24568522  0.38884842]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 6613. State = [[ 0.04389839 -0.2538826   0.08715796  1.        ]]. Action = [[-0.5040371  -0.01116425  0.08210123  0.4712299 ]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 6614. State = [[ 0.02330334 -0.27071023  0.10262854  1.        ]]. Action = [[-0.8383068  -0.48829424  0.94215035  0.3839978 ]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 6615. State = [[ 0.00793092 -0.28349528  0.13012348  1.        ]]. Action = [[ 0.5223882  -0.40368563  0.32636142  0.2756008 ]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 6616. State = [[ 0.01189282 -0.2876797   0.13242927  1.        ]]. Action = [[ 0.5310838   0.06524944 -0.6188603   0.47145307]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 6617. State = [[ 0.01062771 -0.2876003   0.12428977  1.        ]]. Action = [[-0.4914317  -0.01976478  0.03636563  0.47992682]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 6618. State = [[ 0.00214062 -0.28896654  0.11712028  1.        ]]. Action = [[-0.48856682  0.10618138 -0.6655798   0.45556664]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 6619. State = [[-0.00687461 -0.28973168  0.1100817   1.        ]]. Action = [[-0.7046249  -0.62588173  0.716382    0.37285662]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 6620. State = [[-0.00868937 -0.290133    0.10858569  1.        ]]. Action = [[-0.86154544 -0.77972054 -0.0605877   0.32663262]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 6621. State = [[-0.0098176 -0.2903318  0.1077408  1.       ]]. Action = [[-0.89863795 -0.8434966   0.81430614  0.20647907]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 6622. State = [[-0.01075999 -0.2905271   0.10708672  1.        ]]. Action = [[-0.7830541  -0.92610687  0.88092554  0.25795662]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 6623. State = [[-0.01137763 -0.29021838  0.10658991  1.        ]]. Action = [[-0.6901483  -0.48506284  0.9098742   0.2330916 ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 6624. State = [[-0.01145203 -0.29025283  0.1064939   1.        ]]. Action = [[-0.17581874 -0.57856554  0.5564656   0.2437191 ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 6625. State = [[-0.01145203 -0.29025283  0.1064939   1.        ]]. Action = [[-0.8334639  -0.5159946   0.58597386  0.2304579 ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 6626. State = [[-0.00937451 -0.29121867  0.10937055  1.        ]]. Action = [[ 0.11535227 -0.20270604  0.43631494  0.10756648]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 6627. State = [[-0.00669911 -0.29266047  0.11190966  1.        ]]. Action = [[-0.6474239  -0.87757593  0.5763596   0.31100667]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 6628. State = [[-0.00666556 -0.29301238  0.11222491  1.        ]]. Action = [[-0.7877478  -0.6994657  -0.50738317  0.22428381]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 6629. State = [[-0.00666588 -0.29311448  0.11237591  1.        ]]. Action = [[-0.38482678 -0.4697432  -0.25933444  0.3226472 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 6630. State = [[-0.00666588 -0.29311448  0.11237591  1.        ]]. Action = [[-0.76259893 -0.7919719  -0.542942    0.283015  ]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 6631. State = [[-0.00666588 -0.29311448  0.11237591  1.        ]]. Action = [[-0.95346254 -0.65087175 -0.6448781   0.22750688]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 6632. State = [[-0.00666588 -0.29311448  0.11237591  1.        ]]. Action = [[-0.7421518  -0.6545999  -0.04223698  0.35291743]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 6633. State = [[-0.00666588 -0.29311448  0.11237591  1.        ]]. Action = [[-0.7377091  -0.47015512  0.21875942  0.17934501]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 6634. State = [[-0.01446326 -0.30173752  0.12395931  1.        ]]. Action = [[-0.85066795 -0.21600902  0.71992135  0.35136318]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 6635. State = [[-0.03182533 -0.30409116  0.14325017  1.        ]]. Action = [[-0.23371279  0.25678372  0.40867722  0.40986037]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 6636. State = [[-0.04099798 -0.29685983  0.15019251  1.        ]]. Action = [[ 0.27326417  0.08836699 -0.3265202   0.46361887]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 6637. State = [[-0.03650358 -0.28378382  0.14116606  1.        ]]. Action = [[ 0.58800423  0.48974037 -0.6898638   0.6932125 ]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 6638. State = [[-0.01897068 -0.2633407   0.12665977  1.        ]]. Action = [[ 0.7641666   0.5105188  -0.16871315  0.5801976 ]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 6639. State = [[ 6.9836742e-04 -2.5385278e-01  1.1366261e-01  1.0000000e+00]]. Action = [[ 0.4367088  -0.33791953 -0.24650836  0.4178902 ]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 6640. State = [[-0.2594637   0.09262177  0.08960723  1.        ]]. Action = [[-0.5468228  -0.24466932 -0.40421903  0.32400167]]. Reward = [0.]
Curr episode timestep = 101
Current timestep = 6641. State = [[-0.25676206  0.10347632  0.07715707  1.        ]]. Action = [[-0.3860278  -0.77170897  0.65897596  0.9940462 ]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Current timestep = 6642. State = [[-0.25676206  0.10347632  0.07715707  1.        ]]. Action = [[-0.26807618 -0.7451438   0.89246774  0.91832423]]. Reward = [0.]
Curr episode timestep = 1
Action ignored: Workspace boundary
Current timestep = 6643. State = [[-0.25084537  0.09027769  0.08242747  1.        ]]. Action = [[ 0.12798214 -0.89305806  0.780161    0.9516413 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 6644. State = [[-0.24049646  0.06529751  0.09984925  1.        ]]. Action = [[ 0.31717408 -0.68054426  0.9528396   0.912663  ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 6645. State = [[-0.22998284  0.03914992  0.13132489  1.        ]]. Action = [[ 0.31995857 -0.7769548   0.7081742   0.9714192 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 6646. State = [[-0.22365807  0.01053759  0.16156545  1.        ]]. Action = [[-0.06967932 -0.77413315  0.83364487  0.9735944 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 6647. State = [[-0.22281677 -0.01515013  0.19236419  1.        ]]. Action = [[-0.21901226 -0.52057624  0.6764784   0.9948722 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 6648. State = [[-0.21879175 -0.03674493  0.21276934  1.        ]]. Action = [[ 0.51465297 -0.5327708   0.05493355  0.95510983]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 6649. State = [[-0.20791458 -0.05820969  0.22294883  1.        ]]. Action = [[ 0.40779924 -0.5723175   0.30218112  0.84913206]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 6650. State = [[-0.19851485 -0.07711281  0.23306605  1.        ]]. Action = [[ 0.14811277 -0.35480416  0.17728996  0.963315  ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 6651. State = [[-0.18483932 -0.0951786   0.2513292   1.        ]]. Action = [[ 0.5189471  -0.52922165  0.8874681   0.95459485]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 6652. State = [[-0.17258683 -0.10789189  0.27121082  1.        ]]. Action = [[ 0.81114256 -0.4451486  -0.36015558  0.9606135 ]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: No entry zone
Current timestep = 6653. State = [[-0.15895697 -0.11261733  0.28410468  1.        ]]. Action = [[ 0.9108281  -0.29804265  0.6916919   0.92128766]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 6654. State = [[-0.1312033  -0.1246585   0.30365086  1.        ]]. Action = [[ 0.8054843  -0.35573483  0.02295351  0.8647237 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 6655. State = [[-0.09920604 -0.13019647  0.31307304  1.        ]]. Action = [[0.96808517 0.15348244 0.39276505 0.6551033 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 6656. State = [[-0.07146906 -0.137557    0.31344005  1.        ]]. Action = [[ 0.75145864 -0.5571998  -0.89222944  0.7759055 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 6657. State = [[-0.04112091 -0.14606573  0.2926879   1.        ]]. Action = [[ 0.5181978   0.21183777 -0.1289835   0.55154896]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 6658. State = [[-0.02520754 -0.14445399  0.28226966  1.        ]]. Action = [[-0.09021199  0.01059794 -0.34983343  0.49176764]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 6659. State = [[-0.01871645 -0.14452097  0.27411553  1.        ]]. Action = [[ 0.9631765  -0.15730906 -0.6287468   0.45473063]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 6660. State = [[ 0.00795307 -0.1483441   0.24819079  1.        ]]. Action = [[ 0.16622567 -0.00135332 -0.36303538  0.4752314 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 6661. State = [[ 0.02152149 -0.14854097  0.23546274  1.        ]]. Action = [[ 0.15053439 -0.19936019 -0.89588183  0.41086614]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: No entry zone
Current timestep = 6662. State = [[ 0.02435392 -0.14867547  0.23519203  1.        ]]. Action = [[ 0.6939428  -0.32488608 -0.1862948   0.41089845]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: No entry zone
Current timestep = 6663. State = [[ 0.02435392 -0.14867547  0.23519203  1.        ]]. Action = [[ 0.49174333 -0.38197    -0.6110682   0.3447497 ]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: No entry zone
Current timestep = 6664. State = [[ 0.02435392 -0.14867547  0.23519203  1.        ]]. Action = [[ 0.6164725   0.03959799 -0.467479    0.36481118]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: No entry zone
Current timestep = 6665. State = [[ 0.02435392 -0.14867547  0.23519203  1.        ]]. Action = [[ 0.789706   -0.01709253 -0.46873665  0.18649375]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: No entry zone
Current timestep = 6666. State = [[ 0.02435392 -0.14867547  0.23519203  1.        ]]. Action = [[ 0.870309   -0.4560759  -0.4454614   0.24270988]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: No entry zone
Current timestep = 6667. State = [[ 0.02435392 -0.14867547  0.23519203  1.        ]]. Action = [[ 0.94749904 -0.03231102 -0.8531167   0.35825086]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: No entry zone
Current timestep = 6668. State = [[ 0.02435392 -0.14867547  0.23519203  1.        ]]. Action = [[ 0.376029   -0.60169744 -0.92284346  0.17471838]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: No entry zone
Current timestep = 6669. State = [[ 0.02435392 -0.14867547  0.23519203  1.        ]]. Action = [[ 0.20100963 -0.08625013 -0.8376025   0.27719092]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: No entry zone
Current timestep = 6670. State = [[ 0.02435392 -0.14867547  0.23519203  1.        ]]. Action = [[ 0.1654644 -0.2106409 -0.5355451  0.3144772]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: No entry zone
Current timestep = 6671. State = [[ 0.02435392 -0.14867547  0.23519203  1.        ]]. Action = [[ 0.3393854  -0.49167395 -0.747936    0.49840295]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: No entry zone
Current timestep = 6672. State = [[ 0.02435392 -0.14867547  0.23519203  1.        ]]. Action = [[ 0.7000675  -0.29205018 -0.5348336   0.37500763]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: No entry zone
Current timestep = 6673. State = [[ 0.02435392 -0.14867547  0.23519203  1.        ]]. Action = [[ 0.37577176 -0.41467357 -0.28447413  0.34449124]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: No entry zone
Current timestep = 6674. State = [[ 0.02435392 -0.14867547  0.23519203  1.        ]]. Action = [[ 0.5994396  -0.15901452 -0.70817703  0.44591808]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: No entry zone
Current timestep = 6675. State = [[ 0.02435392 -0.14867547  0.23519203  1.        ]]. Action = [[ 0.68529344 -0.21797615 -0.03657961  0.29325402]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: No entry zone
Current timestep = 6676. State = [[ 0.02435392 -0.14867547  0.23519203  1.        ]]. Action = [[ 0.8518157   0.15633047 -0.16492927  0.3434161 ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: No entry zone
Current timestep = 6677. State = [[ 0.02435392 -0.14867547  0.23519203  1.        ]]. Action = [[ 0.9743649  -0.0957709  -0.19555646  0.40253997]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: No entry zone
Current timestep = 6678. State = [[ 0.03274571 -0.15237504  0.23567349  1.        ]]. Action = [[ 0.8552549  -0.26258504  0.02428329  0.37979484]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 6679. State = [[ 0.05132218 -0.1565009   0.23221673  1.        ]]. Action = [[-0.05951005 -0.1132226  -0.35756874  0.2943735 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: No entry zone
Current timestep = 6680. State = [[ 0.05393394 -0.15711294  0.23262416  1.        ]]. Action = [[ 0.3896147  -0.40548515 -0.6095963   0.28205884]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: No entry zone
Current timestep = 6681. State = [[ 0.05379841 -0.15724248  0.23232006  1.        ]]. Action = [[ 0.95302725 -0.4507321  -0.8294405   0.2874639 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 6682. State = [[ 0.05379841 -0.15724248  0.23232006  1.        ]]. Action = [[ 0.31004167 -0.28723395 -0.8421191   0.29308867]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: No entry zone
Current timestep = 6683. State = [[ 0.04630367 -0.16689424  0.22523735  1.        ]]. Action = [[-0.82253414 -0.509722   -0.7069249   0.22394073]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 6684. State = [[ 0.04356599 -0.17798571  0.21667445  1.        ]]. Action = [[ 0.21902609 -0.15788639 -0.8375113   0.39029586]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: No entry zone
Current timestep = 6685. State = [[ 0.0334917  -0.18698305  0.20926715  1.        ]]. Action = [[-0.7351432  -0.33876574 -0.36552203  0.5153208 ]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 6686. State = [[ 0.02629889 -0.19224778  0.19687784  1.        ]]. Action = [[ 0.8130076   0.07896364 -0.23241365  0.60436726]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 6687. State = [[ 0.0254679  -0.19255856  0.18436466  1.        ]]. Action = [[-0.9409961   0.12191951 -0.4099176   0.66531897]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 6688. State = [[ 0.01455831 -0.19616617  0.16632232  1.        ]]. Action = [[ 0.28865218 -0.30322182 -0.8875696   0.60031295]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 6689. State = [[ 0.02189782 -0.19468912  0.14388606  1.        ]]. Action = [[0.726542   0.23396945 0.09779119 0.5264447 ]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 6690. State = [[ 0.03956672 -0.192378    0.13378632  1.        ]]. Action = [[ 0.79947376 -0.12636566 -0.405235    0.3702619 ]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 6691. State = [[ 0.06143479 -0.19082557  0.1167692   1.        ]]. Action = [[ 0.3005556   0.00290215 -0.24628496  0.4238534 ]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 6692. State = [[ 0.07236248 -0.1904975   0.10893682  1.        ]]. Action = [[ 0.8323369  -0.07577252  0.19746542  0.4287119 ]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 6693. State = [[ 0.0706047  -0.19298463  0.10271779  1.        ]]. Action = [[ 0.15420079 -0.15708745 -0.73954225  0.34761178]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 6694. State = [[ 0.08037759 -0.19585697  0.07561518  1.        ]]. Action = [[ 0.4204272  -0.07298774 -0.5408578   0.4590112 ]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 6695. State = [[ 0.09497242 -0.19912148  0.05819713  1.        ]]. Action = [[ 0.40448618 -0.48416173 -0.11513525  0.3622774 ]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 6696. State = [[ 0.09675228 -0.20003238  0.05673401  1.        ]]. Action = [[ 0.44608223 -0.48106438  0.92048347  0.30404437]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 6697. State = [[ 0.09682181 -0.20013702  0.05653882  1.        ]]. Action = [[ 0.8533869  -0.7844864   0.25079358  0.2877133 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 6698. State = [[ 0.09682181 -0.20013702  0.05653882  1.        ]]. Action = [[ 0.543586   -0.67265105  0.41094756  0.3259642 ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 6699. State = [[ 0.09645059 -0.2153614   0.06998993  1.        ]]. Action = [[-0.6559509  -0.70459074  0.9690522   0.15263951]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 6700. State = [[ 0.09702464 -0.23974235  0.10060761  1.        ]]. Action = [[ 0.00839591 -0.4354877   0.97804713  0.50602007]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 6701. State = [[ 0.0879636  -0.2534883   0.11501047  1.        ]]. Action = [[-0.80321527 -0.03557241 -0.65730834  0.51615226]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 6702. State = [[ 0.07437352 -0.25750184  0.10804341  1.        ]]. Action = [[ 0.50554633 -0.16315496  0.258525    0.6901088 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 6703. State = [[ 0.07435155 -0.2536943   0.11015264  1.        ]]. Action = [[0.06574214 0.30808735 0.24314833 0.57708216]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 6704. State = [[ 0.06959556 -0.2552446   0.11860733  1.        ]]. Action = [[-0.6486243  -0.15435082  0.3632921   0.60774064]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 6705. State = [[ 0.05567749 -0.2547776   0.12178978  1.        ]]. Action = [[ 0.40483022  0.00279117 -0.6854265   0.6969602 ]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 6706. State = [[ 0.06251485 -0.24459635  0.11743508  1.        ]]. Action = [[0.75602245 0.45225334 0.1801542  0.71847534]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 6707. State = [[ 0.06875055 -0.22732052  0.11744589  1.        ]]. Action = [[-0.48574775  0.48795164  0.21509612  0.64545906]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 6708. State = [[ 0.06298427 -0.21695006  0.11421505  1.        ]]. Action = [[-0.6899408   0.10421824 -0.3005088   0.6724874 ]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 6709. State = [[ 0.0598809  -0.22035986  0.12100632  1.        ]]. Action = [[ 0.71199703 -0.46537298  0.78266954  0.65872145]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 6710. State = [[ 0.06333026 -0.21948321  0.1292066   1.        ]]. Action = [[-0.07769382  0.3768748  -0.46890247  0.6953044 ]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 6711. State = [[ 0.06708528 -0.20606741  0.13299386  1.        ]]. Action = [[0.26140153 0.51645315 0.4888029  0.62617075]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 6712. State = [[ 0.06811786 -0.1865382   0.12815006  1.        ]]. Action = [[-0.00660086  0.43413317 -0.70743805  0.5498829 ]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 6713. State = [[ 0.06559062 -0.1763815   0.1133126   1.        ]]. Action = [[ 0.21286273  0.01698935 -0.37900913  0.2962396 ]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 6714. State = [[ 0.06658661 -0.17414828  0.10458004  1.        ]]. Action = [[ 0.3589722  -0.04653931 -0.8425222   0.12570429]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: No entry zone
Current timestep = 6715. State = [[ 0.06725557 -0.17374948  0.10417335  1.        ]]. Action = [[0.84526515 0.3874961  0.52538896 0.25063515]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 6716. State = [[ 0.06787284 -0.17340559  0.10400162  1.        ]]. Action = [[ 0.84125733 -0.31926048 -0.03478473  0.23881459]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 6717. State = [[ 0.0682819  -0.17783336  0.10121087  1.        ]]. Action = [[ 0.12412643 -0.39202386 -0.15723187  0.32735968]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 6718. State = [[ 0.07124458 -0.18089503  0.0973069   1.        ]]. Action = [[ 0.95788276 -0.14759135 -0.8589271   0.3589983 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 6719. State = [[ 0.07030332 -0.1858969   0.09316561  1.        ]]. Action = [[-0.15143573 -0.19896895 -0.485973    0.2470721 ]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 6720. State = [[ 0.06761353 -0.18876146  0.08237769  1.        ]]. Action = [[ 0.8723849  -0.26270604 -0.32543856  0.23774052]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 6721. State = [[ 0.0676911  -0.18918478  0.08122144  1.        ]]. Action = [[ 0.6712723  -0.48626888  0.3538649   0.34104168]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 6722. State = [[ 0.06893437 -0.19453137  0.07479563  1.        ]]. Action = [[ 0.6015301  -0.3736456  -0.67176914  0.50953364]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 6723. State = [[ 0.08740224 -0.21152341  0.05496763  1.        ]]. Action = [[ 0.5461364  -0.6195961   0.13461852  0.26968765]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 6724. State = [[ 0.10266363 -0.22480965  0.05039883  1.        ]]. Action = [[ 0.7947469  -0.61989385  0.63829184  0.37373805]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Scene graph at timestep 6724 is [False, False, True, True, False, False, False, True, False, True]
State prediction error at timestep 6724 is tensor(0.0009, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 6724 of -1
Current timestep = 6725. State = [[ 0.10400507 -0.22674313  0.04905596  1.        ]]. Action = [[ 0.6301968  -0.3125249   0.8445636   0.40760803]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Scene graph at timestep 6725 is [False, False, True, True, False, False, False, True, False, True]
State prediction error at timestep 6725 is tensor(0.0004, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 6725 of -1
Current timestep = 6726. State = [[ 0.10400507 -0.22674313  0.04905596  1.        ]]. Action = [[ 0.2160455  -0.11200124  0.09302402  0.45125508]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Scene graph at timestep 6726 is [False, False, True, True, False, False, False, True, False, True]
State prediction error at timestep 6726 is tensor(0.0002, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 6726 of -1
Current timestep = 6727. State = [[ 0.10400507 -0.22674313  0.04905596  1.        ]]. Action = [[ 0.8389127  -0.46264172  0.71806216  0.32017696]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Scene graph at timestep 6727 is [False, False, True, True, False, False, False, True, False, True]
State prediction error at timestep 6727 is tensor(0.0005, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 6727 of -1
Current timestep = 6728. State = [[ 0.10138532 -0.2336419   0.05791279  1.        ]]. Action = [[-0.8947422  -0.08256239  0.67394376  0.38540292]]. Reward = [0.]
Curr episode timestep = 87
Scene graph at timestep 6728 is [False, False, True, True, False, False, False, True, False, True]
State prediction error at timestep 6728 is tensor(5.1248e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 6728 of 1
Current timestep = 6729. State = [[ 0.0905346  -0.25241464  0.08360762  1.        ]]. Action = [[-0.90403384 -0.37681365  0.83544636  0.44088805]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 6730. State = [[ 0.06599659 -0.26112852  0.09479697  1.        ]]. Action = [[-0.01867098 -0.24550396 -0.5566176   0.6625507 ]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 6731. State = [[ 0.06096803 -0.26220712  0.09644159  1.        ]]. Action = [[-0.17082238  0.2736652   0.44709218  0.22718215]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 6732. State = [[ 0.05926829 -0.254683    0.1077833   1.        ]]. Action = [[-0.07593364  0.3168434   0.30817747  0.60076797]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 6733. State = [[ 0.05332609 -0.24563216  0.10674325  1.        ]]. Action = [[ 0.01236475  0.10585237 -0.6954784   0.5983949 ]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 6734. State = [[ 0.05353339 -0.24065745  0.10307579  1.        ]]. Action = [[0.45335257 0.00649607 0.25474524 0.6849034 ]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 6735. State = [[ 0.05231453 -0.23948295  0.10349891  1.        ]]. Action = [[-0.567078    0.08967233  0.09616244  0.71856   ]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 6736. State = [[ 0.04400955 -0.23786928  0.10522106  1.        ]]. Action = [[-0.806533    0.24672449  0.13812828  0.6610646 ]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 6737. State = [[ 0.03332234 -0.23038499  0.11718738  1.        ]]. Action = [[ 0.88257575 -0.13249016  0.48818028  0.49986303]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 6738. State = [[ 0.04336646 -0.22265206  0.12508665  1.        ]]. Action = [[ 0.49849868  0.391932   -0.07751793  0.7095983 ]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 6739. State = [[ 0.048158   -0.20490055  0.1175803   1.        ]]. Action = [[ 0.23918545  0.5261214  -0.9493224   0.5662186 ]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 6740. State = [[ 0.06660354 -0.18661903  0.10278589  1.        ]]. Action = [[0.6484144  0.34467983 0.3509425  0.5507128 ]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 6741. State = [[ 0.07792792 -0.17857918  0.10391198  1.        ]]. Action = [[ 0.8885199  -0.24819344  0.16040206  0.32270527]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 6742. State = [[-0.25591844 -0.06605435  0.08737741  1.        ]]. Action = [[ 0.641135   -0.53822154  0.3092264   0.297019  ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 6743. State = [[-0.24948888 -0.08413009  0.07583039  1.        ]]. Action = [[ 0.39899564 -0.7158917   0.36371946  0.93383205]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 6744. State = [[-0.23633681 -0.11029727  0.08346885  1.        ]]. Action = [[ 0.39703298 -0.65182614  0.5886377   0.98895335]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 6745. State = [[-0.21779737 -0.1330595   0.10434352  1.        ]]. Action = [[ 0.69093716 -0.45907468  0.80262756  0.97322273]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 6746. State = [[-0.19032718 -0.15335573  0.12745754  1.        ]]. Action = [[ 0.77727675 -0.6277343   0.2295022   0.9856019 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 6747. State = [[-0.16133912 -0.17815657  0.14500393  1.        ]]. Action = [[ 0.5651673  -0.5870997   0.59201884  0.9727919 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 6748. State = [[-0.13585101 -0.19452283  0.1565262   1.        ]]. Action = [[ 0.7524786  -0.21634787 -0.27950913  0.87625456]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 6749. State = [[-0.11875165 -0.20876151  0.15435399  1.        ]]. Action = [[ 0.18748713 -0.50368047 -0.2383138   0.9440383 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 6750. State = [[-0.10219836 -0.22422533  0.14676708  1.        ]]. Action = [[ 0.8573127  -0.32397616 -0.4403777   0.86997175]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 6751. State = [[-0.07752729 -0.23976505  0.1424479   1.        ]]. Action = [[ 0.33609235 -0.44710988  0.45999694  0.86081743]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 6752. State = [[-0.0576131  -0.25882384  0.1463427   1.        ]]. Action = [[ 0.95798075 -0.7341214  -0.83692944  0.699028  ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 6753. State = [[-0.02860921 -0.26882946  0.11748845  1.        ]]. Action = [[ 0.8534224   0.37769878 -0.78250414  0.74098945]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 6754. State = [[-0.00535194 -0.274762    0.09522609  1.        ]]. Action = [[-0.4859199  -0.18058115  0.34738564  0.270442  ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 6755. State = [[-0.00666791 -0.27757147  0.09642461  1.        ]]. Action = [[-0.96747434 -0.81109035  0.38517416  0.39101982]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Current timestep = 6756. State = [[-0.00912158 -0.2873998   0.10285688  1.        ]]. Action = [[-0.20163834 -0.48847544  0.572562    0.16973305]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 6757. State = [[-0.01044592 -0.29757378  0.1110521   1.        ]]. Action = [[-0.7952328  -0.7834498   0.77980673  0.21270776]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 6758. State = [[-0.00811265 -0.2991992   0.11375908  1.        ]]. Action = [[-0.9194128  -0.51346505 -0.32434428  0.53314185]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 6759. State = [[-0.00825612 -0.2994465   0.11381377  1.        ]]. Action = [[-0.8951627  -0.82035553  0.7378361   0.51949406]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 6760. State = [[-0.00812563 -0.2993976   0.11407857  1.        ]]. Action = [[-0.77899724 -0.6447372   0.47071373  0.35643196]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 6761. State = [[-0.01528737 -0.3041717   0.11304404  1.        ]]. Action = [[-0.9123229  -0.05883932 -0.07887256  0.35573256]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 6762. State = [[-0.02545751 -0.3089911   0.11231443  1.        ]]. Action = [[-0.89107805 -0.3891489   0.56137586  0.49207067]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 6763. State = [[-0.02656115 -0.3089417   0.1126597   1.        ]]. Action = [[-0.91836584 -0.5854744   0.9848552   0.2767434 ]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 6764. State = [[-0.02667923 -0.3092763   0.1127859   1.        ]]. Action = [[-0.7826717  -0.30110633  0.51756644  0.2314924 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 6765. State = [[-0.02667923 -0.3092763   0.1127859   1.        ]]. Action = [[-0.7316824 -0.5251962  0.5282974  0.2650832]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 6766. State = [[-0.02667923 -0.3092763   0.1127859   1.        ]]. Action = [[-0.9252119 -0.5073356  0.8778058  0.2465179]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 6767. State = [[-0.02667923 -0.3092763   0.1127859   1.        ]]. Action = [[-0.85877544 -0.4425112   0.9318212   0.28177834]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 6768. State = [[-0.02667923 -0.3092763   0.1127859   1.        ]]. Action = [[-0.9512923  -0.7486124   0.9112356   0.27398944]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 6769. State = [[-0.02671021 -0.309341    0.11280191  1.        ]]. Action = [[-0.96935606 -0.71541965  0.8688494   0.20868099]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 6770. State = [[-0.02683184 -0.30945146  0.1127954   1.        ]]. Action = [[-0.9279482  -0.72227645  0.8466625   0.29963398]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 6771. State = [[-0.02683184 -0.30945146  0.1127954   1.        ]]. Action = [[-0.71671695 -0.7288681   0.9916508   0.26615584]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 6772. State = [[-0.02683184 -0.30945146  0.1127954   1.        ]]. Action = [[-0.86909056 -0.813423    0.9663434   0.18833923]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 6773. State = [[-0.02683184 -0.30945146  0.1127954   1.        ]]. Action = [[-0.8802571  -0.64311796  0.8224673   0.33201957]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 6774. State = [[-0.0366894  -0.30410737  0.11632407  1.        ]]. Action = [[-0.972903    0.530102    0.33838713  0.09910464]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 6775. State = [[-0.05923885 -0.29392698  0.12745456  1.        ]]. Action = [[ 0.59277844 -0.4049595   0.7237122   0.44501472]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 6776. State = [[-0.06047967 -0.2934398   0.14037138  1.        ]]. Action = [[ 0.11730087 -0.04017097  0.875021    0.3653438 ]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 6777. State = [[-0.05581121 -0.29272512  0.1555156   1.        ]]. Action = [[ 0.87949955 -0.18106091 -0.39813483  0.4038086 ]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 6778. State = [[-0.04274163 -0.27953705  0.14644772  1.        ]]. Action = [[ 0.845103   0.5479932 -0.7294444  0.7964966]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 6779. State = [[-0.00794321 -0.26579973  0.14181438  1.        ]]. Action = [[0.96595585 0.35909402 0.8708595  0.5470207 ]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 6780. State = [[ 0.02124909 -0.25310448  0.15228553  1.        ]]. Action = [[ 0.9710028   0.01113081 -0.5212216   0.73898077]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 6781. State = [[ 0.0518968  -0.24209246  0.12981997  1.        ]]. Action = [[ 0.72251785  0.56458104 -0.79548013  0.6991172 ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 6782. State = [[ 0.07667116 -0.2226382   0.11736681  1.        ]]. Action = [[-0.42170322  0.76499224  0.7240546   0.7108855 ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 6783. State = [[ 0.07520896 -0.19482782  0.1169428   1.        ]]. Action = [[-0.21275198  0.6887567  -0.7051025   0.66066384]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 6784. State = [[ 0.07321107 -0.18105313  0.10933055  1.        ]]. Action = [[-0.22033888  0.4422022   0.5705247   0.33723712]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: No entry zone
Current timestep = 6785. State = [[ 0.07292149 -0.17931211  0.10846943  1.        ]]. Action = [[ 0.82857716 -0.21829104  0.13199282  0.3434199 ]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 6786. State = [[ 0.07292397 -0.17923205  0.1084694   1.        ]]. Action = [[ 0.931113   -0.3588391  -0.01258558  0.2485137 ]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 6787. State = [[ 0.07292397 -0.17923205  0.1084694   1.        ]]. Action = [[-0.7299237   0.05090582 -0.83565855  0.4424591 ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: No entry zone
Current timestep = 6788. State = [[ 0.06551167 -0.18524791  0.09860644  1.        ]]. Action = [[-0.4896003  -0.45417285 -0.8081322   0.43348026]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 6789. State = [[ 0.05905415 -0.19177006  0.08102325  1.        ]]. Action = [[ 0.9286909   0.03834736 -0.79165214  0.5030074 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 6790. State = [[ 0.05788859 -0.19342782  0.07940223  1.        ]]. Action = [[0.8249508  0.03016031 0.73017085 0.36901903]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 6791. State = [[ 0.06006221 -0.19980264  0.08893127  1.        ]]. Action = [[-1.3852119e-04 -2.4024814e-01  8.9739203e-01  3.5254478e-01]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 6792. State = [[ 0.06346823 -0.20612513  0.09724151  1.        ]]. Action = [[ 0.36896002 -0.16561103 -0.22034264  0.37190044]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 6793. State = [[ 0.06729352 -0.20627722  0.11035535  1.        ]]. Action = [[-0.30675548  0.25325346  0.93651915  0.5282178 ]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 6794. State = [[ 0.06808656 -0.20445135  0.12509823  1.        ]]. Action = [[ 0.8047757   0.39837253 -0.6772244   0.61041737]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 6795. State = [[ 0.06741821 -0.19836147  0.11776036  1.        ]]. Action = [[ 0.41467285  0.24768114 -0.85362935  0.66658974]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 6796. State = [[ 0.06709671 -0.1938613   0.10647992  1.        ]]. Action = [[ 0.7949605 -0.271235  -0.6475961  0.4824853]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 6797. State = [[ 0.06732515 -0.19003256  0.10171521  1.        ]]. Action = [[ 0.3236375   0.08524859 -0.42567444  0.6200527 ]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 6798. State = [[ 0.06896891 -0.18806212  0.08098733  1.        ]]. Action = [[-0.8587439   0.09251535 -0.6561712   0.5063205 ]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 6799. State = [[ 0.06727335 -0.18869717  0.07814481  1.        ]]. Action = [[-0.22512305  0.07217216  0.92600405  0.41605377]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 6800. State = [[ 0.06591888 -0.18715729  0.08835354  1.        ]]. Action = [[ 0.72710466 -0.1862973  -0.34750104  0.2553004 ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 6801. State = [[ 0.06562275 -0.18641467  0.08911294  1.        ]]. Action = [[ 0.8785858  -0.43399686 -0.6490718   0.38577974]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 6802. State = [[ 0.05978017 -0.18712659  0.08193624  1.        ]]. Action = [[-0.28261292 -0.13415861 -0.6411792   0.3539455 ]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 6803. State = [[ 0.05828095 -0.19006449  0.08543577  1.        ]]. Action = [[ 0.40397096 -0.12624043  0.8170731   0.31977904]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 6804. State = [[ 0.06780679 -0.19270287  0.10716774  1.        ]]. Action = [[0.5600381  0.02071154 0.67396045 0.37455976]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 6805. State = [[ 0.07141549 -0.1925206   0.1188793   1.        ]]. Action = [[ 0.71423006 -0.18263018 -0.41673958  0.53901315]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 6806. State = [[ 0.07201862 -0.19248725  0.11975735  1.        ]]. Action = [[ 0.1290468  -0.04294503 -0.08045745  0.33183885]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 6807. State = [[ 0.07251138 -0.19246523  0.1202405   1.        ]]. Action = [[ 0.25307202  0.3597468  -0.62100774  0.43253064]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: No entry zone
Current timestep = 6808. State = [[ 0.06698768 -0.2013481   0.11730544  1.        ]]. Action = [[-0.73691267 -0.49384755 -0.33046257  0.5703516 ]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 6809. State = [[ 0.06282938 -0.20832738  0.11588436  1.        ]]. Action = [[ 0.97583675 -0.07408136  0.08824015  0.55189395]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 6810. State = [[ 0.06208504 -0.20995334  0.11577352  1.        ]]. Action = [[0.9811752  0.14076233 0.22353649 0.50496316]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 6811. State = [[ 0.0609834 -0.2084489  0.108912   1.       ]]. Action = [[ 0.5238917   0.09215236 -0.58427435  0.67704546]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 6812. State = [[ 0.06255089 -0.20512885  0.08618395  1.        ]]. Action = [[ 0.5899067  -0.12734324 -0.98588365  0.59111273]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 6813. State = [[ 0.07866864 -0.2058277   0.05871419  1.        ]]. Action = [[0.86983216 0.2965951  0.22446108 0.53379166]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 6814. State = [[ 0.08497968 -0.21713966  0.06268842  1.        ]]. Action = [[-0.2702092  -0.44875526  0.6404711   0.35365486]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 6815. State = [[ 0.0861095  -0.2263914   0.07014806  1.        ]]. Action = [[ 0.8700522  -0.04667836  0.35281038  0.43200386]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 6816. State = [[ 0.08615015 -0.22406526  0.07528071  1.        ]]. Action = [[-0.49156833  0.44128418  0.24891865  0.45392632]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 6817. State = [[ 0.08528481 -0.22018874  0.07922486  1.        ]]. Action = [[ 0.7560067   0.07626033 -0.36106998  0.61570215]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 6818. State = [[ 0.08528671 -0.22008312  0.07924878  1.        ]]. Action = [[0.7947421  0.49526942 0.87381864 0.61434484]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 6819. State = [[ 0.08517768 -0.22008683  0.0792678   1.        ]]. Action = [[ 0.70849955 -0.18415213  0.952415    0.42887783]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 6820. State = [[ 0.08546721 -0.21805322  0.08031234  1.        ]]. Action = [[0.19336307 0.07597101 0.12058592 0.6354017 ]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 6821. State = [[ 0.08705812 -0.22092552  0.09524803  1.        ]]. Action = [[-0.2877345  -0.18318623  0.7880392   0.6095395 ]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 6822. State = [[ 0.08125089 -0.22116165  0.11794728  1.        ]]. Action = [[-0.4622202   0.25115132  0.17050576  0.5477557 ]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 6823. State = [[ 0.06654353 -0.21464486  0.12595642  1.        ]]. Action = [[ 0.6364684   0.16849804 -0.3296473   0.66758037]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 6824. State = [[ 0.06561949 -0.21400389  0.1259905   1.        ]]. Action = [[0.8285775  0.7980857  0.32468617 0.5743222 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 6825. State = [[ 0.06578561 -0.2036338   0.12645213  1.        ]]. Action = [[-0.08126175  0.65394413  0.05063105  0.82244945]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 6826. State = [[ 0.06271154 -0.18955033  0.12751006  1.        ]]. Action = [[0.028759  0.5636852 0.5209043 0.5702989]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: No entry zone
Current timestep = 6827. State = [[ 0.06026545 -0.18745852  0.13069795  1.        ]]. Action = [[ 0.13203168  0.4326768  -0.54674786  0.46750033]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: No entry zone
Current timestep = 6828. State = [[ 0.06010576 -0.18702534  0.1306608   1.        ]]. Action = [[ 0.8317356   0.11719799 -0.55005723  0.36064196]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 6829. State = [[ 0.05999246 -0.18704319  0.13057175  1.        ]]. Action = [[ 0.8012351  -0.02764446 -0.6127718   0.448817  ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 6830. State = [[ 0.05338864 -0.1867168   0.12207314  1.        ]]. Action = [[-0.32261372  0.07240868 -0.7968892   0.32672215]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 6831. State = [[ 0.04686562 -0.18277675  0.10253489  1.        ]]. Action = [[ 0.89958334 -0.11572993 -0.6470268   0.52677524]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 6832. State = [[ 0.05370253 -0.1808358   0.08207101  1.        ]]. Action = [[ 0.48882663  0.15593517 -0.01861465  0.5966401 ]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: No entry zone
Current timestep = 6833. State = [[ 0.05885614 -0.1855956   0.07644545  1.        ]]. Action = [[ 0.674595   -0.41582513 -0.47677684  0.39224374]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 6834. State = [[ 0.07442686 -0.19163658  0.06130029  1.        ]]. Action = [[ 0.8085556  -0.42313206 -0.65814584  0.33693624]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 6835. State = [[ 0.07525051 -0.19239195  0.06007906  1.        ]]. Action = [[ 0.875301   -0.27286637 -0.52196324  0.27646017]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 6836. State = [[ 0.07520303 -0.19233182  0.05991032  1.        ]]. Action = [[ 0.63570845 -0.2249921  -0.15092885  0.48468852]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 6837. State = [[ 0.07520303 -0.19233182  0.05991032  1.        ]]. Action = [[0.7913612  0.16011345 0.61723614 0.35813916]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 6838. State = [[ 0.07520303 -0.19233182  0.05991032  1.        ]]. Action = [[ 0.77559924 -0.04509759  0.64465404  0.16394734]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 6839. State = [[ 0.07520303 -0.19233182  0.05991032  1.        ]]. Action = [[ 0.7128763  -0.24399799  0.94383705  0.36837912]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 6840. State = [[ 0.07665291 -0.20221445  0.06655154  1.        ]]. Action = [[-0.21210122 -0.45199144  0.5589025   0.29845273]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 6841. State = [[ 0.0781005  -0.21066375  0.07308508  1.        ]]. Action = [[ 0.89936686 -0.43912005  0.03019881  0.26839924]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 6842. State = [[ 0.07757717 -0.20674224  0.07044755  1.        ]]. Action = [[-0.1461997   0.42562258 -0.33820176  0.4326055 ]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 6843. State = [[ 0.07079303 -0.20798555  0.069261    1.        ]]. Action = [[-0.84289056 -0.18292487  0.21772146  0.40094435]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 6844. State = [[-0.26497084  0.02235183  0.10761309  1.        ]]. Action = [[0.9091387  0.05715787 0.10326421 0.3627745 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 6845. State = [[-0.26317424  0.01546989  0.09936608  1.        ]]. Action = [[ 0.13554728 -0.72216356  0.69649875  0.99483204]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 6846. State = [[-0.25500962 -0.00832627  0.11493828  1.        ]]. Action = [[ 0.3113637  -0.8914115   0.9487337   0.99695265]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 6847. State = [[-0.24550375 -0.02860462  0.1469907   1.        ]]. Action = [[ 0.27330577 -0.2311579   0.84434223  0.990118  ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 6848. State = [[-0.23046134 -0.04472325  0.17451529  1.        ]]. Action = [[ 0.5145595  -0.53857744  0.37368917  0.92562926]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 6849. State = [[-0.20732799 -0.06825604  0.18599744  1.        ]]. Action = [[ 0.75944495 -0.7842168  -0.19123232  0.88614035]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 6850. State = [[-0.19193894 -0.08516437  0.19081314  1.        ]]. Action = [[ 0.8213893  -0.707931   -0.05156302  0.9852017 ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 6851. State = [[-0.19080576 -0.08680481  0.19132483  1.        ]]. Action = [[ 0.6432688  -0.4393016  -0.34234893  0.979565  ]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 6852. State = [[-0.1906116  -0.08713423  0.19148026  1.        ]]. Action = [[ 0.7959577  -0.7050581  -0.067397    0.94293296]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 6853. State = [[-0.1906412  -0.08725755  0.19149756  1.        ]]. Action = [[ 0.9160675  -0.4044683   0.04142094  0.8955741 ]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 6854. State = [[-0.1906412  -0.08725755  0.19149756  1.        ]]. Action = [[ 0.7924129  -0.42869413 -0.4045881   0.9751384 ]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 6855. State = [[-0.19065605 -0.08731941  0.19150625  1.        ]]. Action = [[ 0.5498556  -0.30967772 -0.70665133  0.8751848 ]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 6856. State = [[-0.18657663 -0.09468277  0.19276291  1.        ]]. Action = [[ 0.27986288 -0.45017815  0.01998985  0.974095  ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 6857. State = [[-0.18123598 -0.10354768  0.19121768  1.        ]]. Action = [[ 0.647864   -0.57577014 -0.42886305  0.7672701 ]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: No entry zone
Current timestep = 6858. State = [[-0.18010426 -0.10425679  0.19140568  1.        ]]. Action = [[ 0.7368566  -0.35816252  0.1901207   0.98980737]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: No entry zone
Current timestep = 6859. State = [[-0.17977813 -0.10430448  0.19160531  1.        ]]. Action = [[ 0.79126   -0.5264018  0.6277796  0.9221668]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: No entry zone
Current timestep = 6860. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.6932986  -0.35384178  0.5084288   0.9376563 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: No entry zone
Current timestep = 6861. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.55285084 -0.39197505  0.65913486  0.5636611 ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: No entry zone
Current timestep = 6862. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.47458553 -0.4768784   0.7364365   0.96119094]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: No entry zone
Current timestep = 6863. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.89102674 -0.46581244  0.07587647  0.98364615]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: No entry zone
Current timestep = 6864. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.7057748  -0.569862    0.684628    0.88349175]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: No entry zone
Current timestep = 6865. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.8929219  -0.569158   -0.46494508  0.9896765 ]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: No entry zone
Current timestep = 6866. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.7807728  -0.4439054   0.3877499   0.95043993]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: No entry zone
Current timestep = 6867. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.8643559  -0.3007598  -0.03054196  0.95851827]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: No entry zone
Current timestep = 6868. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.86350274 -0.10416675  0.24570358  0.882601  ]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: No entry zone
Current timestep = 6869. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.5853431  -0.60832494  0.28689814  0.9876145 ]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: No entry zone
Current timestep = 6870. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.43747652 -0.43119478 -0.65420115  0.98167944]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: No entry zone
Current timestep = 6871. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.85325646 -0.35252523 -0.23151612  0.8547107 ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: No entry zone
Current timestep = 6872. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.5103593  -0.29819202  0.35663402  0.95685065]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: No entry zone
Current timestep = 6873. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.6717187  -0.6760365   0.8650255   0.95920753]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: No entry zone
Current timestep = 6874. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.8478837  -0.39532924 -0.4266206   0.8772998 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: No entry zone
Current timestep = 6875. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.65263224 -0.4304387   0.9492276   0.929193  ]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: No entry zone
Current timestep = 6876. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.87868595 -0.51639056  0.5148554   0.9601724 ]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: No entry zone
Current timestep = 6877. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.78751445 -0.50598663  0.6581104   0.8871925 ]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: No entry zone
Current timestep = 6878. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.9660939  -0.38574892 -0.21108603  0.9701141 ]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: No entry zone
Current timestep = 6879. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.9062922  -0.31989956 -0.5386366   0.927691  ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: No entry zone
Current timestep = 6880. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.8773751  -0.01771182 -0.04938316  0.96207416]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: No entry zone
Current timestep = 6881. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.86216545 -0.44051886 -0.8393692   0.9759892 ]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: No entry zone
Current timestep = 6882. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.7517922  -0.5881687   0.5722873   0.92854095]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: No entry zone
Current timestep = 6883. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.68010545 -0.48842794 -0.13845825  0.934942  ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: No entry zone
Current timestep = 6884. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.91255856 -0.5146408  -0.01365066  0.9879737 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: No entry zone
Current timestep = 6885. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.6216967  -0.454342    0.71459603  0.8924587 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: No entry zone
Current timestep = 6886. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.6856849  -0.39617598  0.12839472  0.9558048 ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: No entry zone
Current timestep = 6887. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.849442   -0.77041364  0.41259575  0.9632888 ]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: No entry zone
Current timestep = 6888. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.7491689  -0.75177956  0.5066596   0.93210196]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: No entry zone
Current timestep = 6889. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.32300687 -0.6959218  -0.89577425  0.9716699 ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: No entry zone
Current timestep = 6890. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.6251762  -0.32069618  0.08756185  0.8767283 ]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: No entry zone
Current timestep = 6891. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.75408316 -0.47495693  0.3008473   0.9467876 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: No entry zone
Current timestep = 6892. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.5168233  -0.3609631  -0.01975387  0.98201823]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: No entry zone
Current timestep = 6893. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.6836941  -0.47715056  0.92560506  0.90050805]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: No entry zone
Current timestep = 6894. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.29274917 -0.39579862 -0.68938565  0.60533524]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: No entry zone
Current timestep = 6895. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[0.5128963  0.09445333 0.21649444 0.9633132 ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: No entry zone
Current timestep = 6896. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.51894236 -0.71183616  0.45861042  0.9405694 ]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: No entry zone
Current timestep = 6897. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.60531235 -0.2821405  -0.53745955  0.89763045]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: No entry zone
Current timestep = 6898. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.93825626 -0.23655641  0.70495987  0.8936982 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: No entry zone
Current timestep = 6899. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.6599535  -0.26530278  0.6483176   0.95897865]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: No entry zone
Current timestep = 6900. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.74098396 -0.19485682  0.4671483   0.9109087 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: No entry zone
Current timestep = 6901. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.89221907 -0.09668791  0.3611064   0.89651513]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: No entry zone
Current timestep = 6902. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.48913586 -0.7451789   0.09512162  0.80853796]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: No entry zone
Current timestep = 6903. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.47073174 -0.71523416  0.75972366  0.92171025]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: No entry zone
Current timestep = 6904. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[0.8229295  0.02212286 0.19548869 0.42161727]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: No entry zone
Current timestep = 6905. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.79667616 -0.38729113  0.680078    0.97368646]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: No entry zone
Current timestep = 6906. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.52840984 -0.48987174  0.66117847  0.9705882 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: No entry zone
Current timestep = 6907. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.87378156 -0.33451056  0.10872114  0.98655295]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: No entry zone
Current timestep = 6908. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.58471525 -0.46975     0.5597143   0.9159484 ]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: No entry zone
Current timestep = 6909. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.50776136 -0.56278074  0.8267021   0.9811106 ]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: No entry zone
Current timestep = 6910. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.84229815 -0.6104536   0.17705154  0.95045996]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: No entry zone
Current timestep = 6911. State = [[-0.17965779 -0.10433324  0.19143249  1.        ]]. Action = [[ 0.81748533 -0.38749766 -0.15011322  0.9571034 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: No entry zone
Current timestep = 6912. State = [[-0.18118334 -0.11261142  0.18710513  1.        ]]. Action = [[-0.2251541  -0.45123714 -0.40910256  0.96985674]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 6913. State = [[-0.18279786 -0.12191832  0.18037865  1.        ]]. Action = [[ 0.7594316  -0.33050215  0.87182736  0.93774545]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: No entry zone
Current timestep = 6914. State = [[-0.18272263 -0.12262789  0.18040182  1.        ]]. Action = [[ 0.83624685 -0.2395184   0.16951728  0.9847672 ]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: No entry zone
Current timestep = 6915. State = [[-0.18273464 -0.12283043  0.18040109  1.        ]]. Action = [[ 0.8800771  -0.73017895  0.62922335  0.96710503]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: No entry zone
Current timestep = 6916. State = [[-0.18272115 -0.12300917  0.18041152  1.        ]]. Action = [[ 0.3589623  -0.6060885  -0.44079626  0.9875339 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: No entry zone
Current timestep = 6917. State = [[-0.18272115 -0.12300917  0.18041152  1.        ]]. Action = [[ 0.6326647  -0.52090144 -0.5031372   0.95897174]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: No entry zone
Current timestep = 6918. State = [[-0.18272115 -0.12300917  0.18041152  1.        ]]. Action = [[ 0.9011936  -0.39235115  0.5177015   0.9560857 ]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: No entry zone
Current timestep = 6919. State = [[-0.18272115 -0.12300917  0.18041152  1.        ]]. Action = [[ 0.87743306 -0.7717463  -0.47907782  0.968552  ]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: No entry zone
Current timestep = 6920. State = [[-0.18272115 -0.12300917  0.18041152  1.        ]]. Action = [[ 0.6764138  -0.20598775  0.5311785   0.9657774 ]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: No entry zone
Current timestep = 6921. State = [[-0.18272115 -0.12300917  0.18041152  1.        ]]. Action = [[ 0.90187025 -0.35678828  0.3507216   0.9830555 ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: No entry zone
Current timestep = 6922. State = [[-0.18272115 -0.12300917  0.18041152  1.        ]]. Action = [[ 0.6870942  -0.21575499  0.91055155  0.9943969 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: No entry zone
Current timestep = 6923. State = [[-0.18272115 -0.12300917  0.18041152  1.        ]]. Action = [[ 0.92364454 -0.65070903 -0.39140564  0.9792061 ]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: No entry zone
Current timestep = 6924. State = [[-0.18272115 -0.12300917  0.18041152  1.        ]]. Action = [[ 0.7511107 -0.5128875 -0.305039   0.954124 ]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: No entry zone
Current timestep = 6925. State = [[-0.18272115 -0.12300917  0.18041152  1.        ]]. Action = [[ 0.9078697  -0.4027201   0.16628194  0.9735335 ]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: No entry zone
Current timestep = 6926. State = [[-0.18371539 -0.13279788  0.18031318  1.        ]]. Action = [[-0.03440452 -0.53725743 -0.12037331  0.93092096]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 6927. State = [[-0.18354517 -0.14419694  0.18040264  1.        ]]. Action = [[ 0.67259    -0.61959547 -0.86024624  0.9781234 ]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: No entry zone
Current timestep = 6928. State = [[-0.18352441 -0.14520758  0.18040298  1.        ]]. Action = [[ 0.9578681  -0.2889815  -0.60131675  0.5877285 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: No entry zone
Current timestep = 6929. State = [[-0.18352441 -0.14520758  0.18040298  1.        ]]. Action = [[ 0.8355248  -0.18831903  0.39041042  0.98021865]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: No entry zone
Current timestep = 6930. State = [[-0.18352441 -0.14520758  0.18040298  1.        ]]. Action = [[ 0.7949257  -0.5592922   0.14832461  0.989532  ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: No entry zone
Current timestep = 6931. State = [[-0.18352441 -0.14520758  0.18040298  1.        ]]. Action = [[ 0.75381005 -0.4786011  -0.67954993  0.9877243 ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: No entry zone
Current timestep = 6932. State = [[-0.18352441 -0.14520758  0.18040298  1.        ]]. Action = [[ 0.9112134  -0.4073441   0.38800788  0.9657631 ]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: No entry zone
Current timestep = 6933. State = [[-0.17645594 -0.15605097  0.17561153  1.        ]]. Action = [[ 0.871917  -0.761702  -0.8687026  0.957495 ]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 6934. State = [[-0.1574805  -0.17272915  0.14849652  1.        ]]. Action = [[ 0.845176   -0.46636885 -0.55364895  0.81716704]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: No entry zone
Current timestep = 6935. State = [[-0.1457892  -0.18204388  0.137522    1.        ]]. Action = [[ 0.6746323  -0.4225924  -0.71733195  0.85702467]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 6936. State = [[-0.12172119 -0.20029193  0.11319573  1.        ]]. Action = [[ 0.7633469 -0.5968665 -0.7090505  0.9579984]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 6937. State = [[-0.09000313 -0.21783583  0.09573741  1.        ]]. Action = [[ 0.8667755  -0.32770562  0.1694591   0.9183147 ]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 6938. State = [[-0.06192124 -0.2285737   0.09137496  1.        ]]. Action = [[ 0.8464345  -0.30152965 -0.3856728   0.7621398 ]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 6939. State = [[-0.03072936 -0.24500468  0.07511497  1.        ]]. Action = [[ 0.75947106 -0.66524756 -0.32452738  0.6605419 ]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 6940. State = [[-0.00783882 -0.27197847  0.07441194  1.        ]]. Action = [[-0.03299314 -0.5922595   0.6791378   0.27857625]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 6941. State = [[-0.00162941 -0.284616    0.08629303  1.        ]]. Action = [[-0.8931463  -0.9287287   0.97002363  0.00988972]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 6942. State = [[-0.00148137 -0.2865701   0.08685111  1.        ]]. Action = [[-0.92799836 -0.90133554  0.48241735  0.23365438]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 6943. State = [[-9.9771924e-04 -2.8685868e-01  8.7353028e-02  1.0000000e+00]]. Action = [[-0.9305944  -0.8454856  -0.43481493  0.28592205]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 6944. State = [[-9.428154e-05 -2.873438e-01  8.773993e-02  1.000000e+00]]. Action = [[-0.8380601  -0.74963653  0.5217861   0.28787398]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 6945. State = [[ 3.7137547e-04 -2.8739449e-01  8.8042431e-02  1.0000000e+00]]. Action = [[-0.986888   -0.81740206  0.12547421  0.2318821 ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 6946. State = [[-0.26517177  0.01933742  0.11141498  1.        ]]. Action = [[-0.77793556 -0.9050091   0.68025684  0.32476056]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 6947. State = [[-0.2670304   0.02201396  0.09859608  1.        ]]. Action = [[-0.47634482 -0.7754541   0.80618     0.95249844]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Current timestep = 6948. State = [[-0.2670304   0.02201396  0.09859608  1.        ]]. Action = [[-0.29884267 -0.60125834  0.56204295  0.9911097 ]]. Reward = [0.]
Curr episode timestep = 1
Action ignored: Workspace boundary
Current timestep = 6949. State = [[-0.2607806   0.01233926  0.10506708  1.        ]]. Action = [[ 0.37306452 -0.7248971   0.8967985   0.95075035]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 6950. State = [[-0.24832302 -0.01103829  0.12421539  1.        ]]. Action = [[ 0.46517885 -0.8364504   0.7379956   0.99489236]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 6951. State = [[-0.23398517 -0.03653426  0.15026     1.        ]]. Action = [[ 0.25975227 -0.65665275  0.7248826   0.99493563]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 6952. State = [[-0.2140748  -0.06003248  0.17631109  1.        ]]. Action = [[ 0.7893281  -0.55438286  0.47513843  0.9959047 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 6953. State = [[-0.18528531 -0.08579736  0.2005695   1.        ]]. Action = [[ 0.6298318  -0.74150765  0.61588466  0.88609755]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 6954. State = [[-0.16970487 -0.10252291  0.21702431  1.        ]]. Action = [[ 0.93976927 -0.5780084   0.10377645  0.8954861 ]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 6955. State = [[-0.16747627 -0.10543865  0.219587    1.        ]]. Action = [[ 0.36257577 -0.35535645  0.0674392   0.8771372 ]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 6956. State = [[-0.16718717 -0.10604705  0.22003476  1.        ]]. Action = [[ 0.9790137  -0.35304034 -0.9251029   0.86794317]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 6957. State = [[-0.1672987  -0.10597254  0.22007684  1.        ]]. Action = [[ 0.68662894 -0.29308486 -0.06319952  0.9025526 ]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 6958. State = [[-0.16657977 -0.10610645  0.22059563  1.        ]]. Action = [[0.94584346 0.02989006 0.23551989 0.922428  ]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: No entry zone
Current timestep = 6959. State = [[-0.16621315 -0.10610888  0.22088942  1.        ]]. Action = [[ 0.8670914 -0.5684724 -0.8369365  0.925117 ]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: No entry zone
Current timestep = 6960. State = [[-0.16595455 -0.10614725  0.22103263  1.        ]]. Action = [[ 0.86685514 -0.6469875  -0.53335536  0.9099568 ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: No entry zone
Current timestep = 6961. State = [[-0.16595455 -0.10614725  0.22103263  1.        ]]. Action = [[ 0.9474788  -0.5876519  -0.05484533  0.8159857 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: No entry zone
Current timestep = 6962. State = [[-0.16595455 -0.10614725  0.22103263  1.        ]]. Action = [[0.86386585 0.02948308 0.15884125 0.9081365 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: No entry zone
Current timestep = 6963. State = [[-0.16595455 -0.10614725  0.22103263  1.        ]]. Action = [[ 0.8124602  -0.14826041  0.32411718  0.91353905]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: No entry zone
Current timestep = 6964. State = [[-0.16595455 -0.10614725  0.22103263  1.        ]]. Action = [[ 0.9724295  -0.58010364  0.04407716  0.9415579 ]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: No entry zone
Current timestep = 6965. State = [[-0.16595455 -0.10614725  0.22103263  1.        ]]. Action = [[ 0.68324494 -0.8122143  -0.82802474  0.95944977]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: No entry zone
Current timestep = 6966. State = [[-0.15687743 -0.11372416  0.22981787  1.        ]]. Action = [[ 0.58946776 -0.47312486  0.6425972   0.9664724 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 6967. State = [[-0.13206731 -0.12519248  0.2530374   1.        ]]. Action = [[ 0.9254608  -0.18331659  0.49192333  0.9585891 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 6968. State = [[-0.11291176 -0.12882435  0.26942992  1.        ]]. Action = [[ 0.59675276  0.22901726 -0.6758129   0.8971517 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: No entry zone
Current timestep = 6969. State = [[-0.10107101 -0.1263458   0.2650018   1.        ]]. Action = [[ 0.9453943   0.18616295 -0.6909992   0.7533796 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 6970. State = [[-0.07706388 -0.12803815  0.24899872  1.        ]]. Action = [[ 0.8567145  -0.08272576 -0.83337384  0.80659103]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: No entry zone
Current timestep = 6971. State = [[-0.07311209 -0.12847555  0.24701874  1.        ]]. Action = [[ 0.7848892  -0.3443246  -0.96906704  0.87201154]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: No entry zone
Current timestep = 6972. State = [[-0.07320447 -0.12840825  0.2459786   1.        ]]. Action = [[ 0.7793784  -0.22201478 -0.57230246  0.7935059 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: No entry zone
Current timestep = 6973. State = [[-0.07326189 -0.12840232  0.24593526  1.        ]]. Action = [[ 0.8828523  -0.31429946 -0.49119198  0.785321  ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: No entry zone
Current timestep = 6974. State = [[-0.06339431 -0.13329253  0.24409162  1.        ]]. Action = [[ 0.9043088  -0.39832932 -0.16127455  0.7350447 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 6975. State = [[-0.04250011 -0.1380604   0.24092282  1.        ]]. Action = [[ 0.91305137  0.26381385 -0.7226231   0.5985472 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: No entry zone
Current timestep = 6976. State = [[-0.03745109 -0.13958491  0.24213718  1.        ]]. Action = [[ 0.9172236   0.01196444 -0.31770283  0.53581965]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: No entry zone
Current timestep = 6977. State = [[-0.03738858 -0.13964601  0.2422175   1.        ]]. Action = [[ 0.82360125  0.08940005 -0.49717045  0.44886255]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: No entry zone
Current timestep = 6978. State = [[-0.03738858 -0.13964601  0.2422175   1.        ]]. Action = [[ 0.6376976  -0.14168584 -0.19247961  0.6380029 ]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: No entry zone
Current timestep = 6979. State = [[-0.03738858 -0.13964601  0.2422175   1.        ]]. Action = [[ 0.7415465  -0.09233093 -0.6300827   0.52355886]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: No entry zone
Current timestep = 6980. State = [[-0.03738858 -0.13964601  0.2422175   1.        ]]. Action = [[ 0.48142123  0.09369576 -0.61840814  0.67225957]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: No entry zone
Current timestep = 6981. State = [[-0.03740664 -0.13971381  0.24223244  1.        ]]. Action = [[ 0.99496603  0.06216621 -0.4451028   0.60822296]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: No entry zone
Current timestep = 6982. State = [[-0.02798307 -0.13905841  0.24169445  1.        ]]. Action = [[ 0.96341825  0.0306288  -0.1187008   0.4949062 ]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 6983. State = [[-0.00527702 -0.13973843  0.23664363  1.        ]]. Action = [[ 0.87038374  0.21805596 -0.6188833   0.41710782]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: No entry zone
Current timestep = 6984. State = [[-3.1191210e-04 -1.3992944e-01  2.3701319e-01  1.0000000e+00]]. Action = [[ 0.9159018   0.02323794 -0.08062667  0.4872414 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: No entry zone
Current timestep = 6985. State = [[-4.1534283e-04 -1.3992383e-01  2.3604299e-01  1.0000000e+00]]. Action = [[-0.22670329  0.03389716 -0.7613612   0.56480265]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: No entry zone
Current timestep = 6986. State = [[-4.3639925e-04 -1.4005834e-01  2.3526143e-01  1.0000000e+00]]. Action = [[ 0.6605655  -0.2680021  -0.10569054  0.5893142 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: No entry zone
Current timestep = 6987. State = [[-8.6062391e-05 -1.4013965e-01  2.3493557e-01  1.0000000e+00]]. Action = [[ 0.8718469  -0.1147452  -0.612608    0.58994985]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: No entry zone
Current timestep = 6988. State = [[-2.4713418e-05 -1.4014114e-01  2.3444016e-01  1.0000000e+00]]. Action = [[ 0.9085926  -0.36285496 -0.7414398   0.4681388 ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: No entry zone
Current timestep = 6989. State = [[-6.4292319e-05 -1.4013918e-01  2.3418964e-01  1.0000000e+00]]. Action = [[ 0.44097495 -0.16432947 -0.24122727  0.4706874 ]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: No entry zone
Current timestep = 6990. State = [[ 0.01141989 -0.1385438   0.24235822  1.        ]]. Action = [[0.85701084 0.09759593 0.45628166 0.54884446]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 6991. State = [[ 0.03056741 -0.13656023  0.252374    1.        ]]. Action = [[ 0.7647797  -0.29469103 -0.8912225   0.5276563 ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: No entry zone
Current timestep = 6992. State = [[ 0.03297036 -0.1365319   0.25319803  1.        ]]. Action = [[ 0.0741502  -0.22122705 -0.8175377   0.36355138]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: No entry zone
Current timestep = 6993. State = [[ 0.03297036 -0.1365319   0.25319803  1.        ]]. Action = [[ 0.703153   -0.56732965 -0.40604055  0.36463737]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: No entry zone
Current timestep = 6994. State = [[ 0.03297036 -0.1365319   0.25319803  1.        ]]. Action = [[ 0.06115711 -0.54385716 -0.81806177  0.3257556 ]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: No entry zone
Current timestep = 6995. State = [[ 0.03294437 -0.1365222   0.25319654  1.        ]]. Action = [[ 0.82639647 -0.44570762 -0.91857445  0.324165  ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: No entry zone
Current timestep = 6996. State = [[ 0.03294437 -0.1365222   0.25319654  1.        ]]. Action = [[ 0.6684816  -0.10787433 -0.89422333  0.3597585 ]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: No entry zone
Current timestep = 6997. State = [[ 0.03294437 -0.1365222   0.25319654  1.        ]]. Action = [[ 0.92447805 -0.3382678  -0.41381848  0.24085021]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: No entry zone
Current timestep = 6998. State = [[ 0.03294437 -0.1365222   0.25319654  1.        ]]. Action = [[ 0.8285265  -0.57556796 -0.79329026  0.3383665 ]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: No entry zone
Current timestep = 6999. State = [[ 0.03294437 -0.1365222   0.25319654  1.        ]]. Action = [[-0.48505747 -0.26637042 -0.7432548   0.2977016 ]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: No entry zone
Current timestep = 7000. State = [[ 0.03294437 -0.1365222   0.25319654  1.        ]]. Action = [[ 0.27280748 -0.21528447 -0.45431948  0.4817927 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: No entry zone
Current timestep = 7001. State = [[ 0.03294437 -0.1365222   0.25319654  1.        ]]. Action = [[ 0.6524432  -0.64491206 -0.5761841   0.4434086 ]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: No entry zone
Current timestep = 7002. State = [[ 0.03294437 -0.1365222   0.25319654  1.        ]]. Action = [[ 0.62118983 -0.19574082 -0.61687386  0.42142475]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: No entry zone
Current timestep = 7003. State = [[ 0.03294437 -0.1365222   0.25319654  1.        ]]. Action = [[ 0.509809   -0.16857845 -0.6250896   0.29716635]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: No entry zone
Current timestep = 7004. State = [[ 0.03294437 -0.1365222   0.25319654  1.        ]]. Action = [[ 0.60963607 -0.59749264 -0.70016503  0.32863867]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: No entry zone
Current timestep = 7005. State = [[ 0.03294437 -0.1365222   0.25319654  1.        ]]. Action = [[ 0.5004461  -0.47068632 -0.91063976  0.3995899 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: No entry zone
Current timestep = 7006. State = [[ 0.03294437 -0.1365222   0.25319654  1.        ]]. Action = [[ 0.81566834 -0.83145666 -0.9521381   0.32634616]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: No entry zone
Current timestep = 7007. State = [[ 0.03294437 -0.1365222   0.25319654  1.        ]]. Action = [[ 0.6673305  -0.40420067 -0.6986977   0.31977975]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: No entry zone
Current timestep = 7008. State = [[ 0.03294437 -0.1365222   0.25319654  1.        ]]. Action = [[-0.25221127 -0.3316306  -0.8868589   0.39851034]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: No entry zone
Current timestep = 7009. State = [[ 0.03294437 -0.1365222   0.25319654  1.        ]]. Action = [[ 0.5720731  -0.188896   -0.8755504   0.39192915]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: No entry zone
Current timestep = 7010. State = [[ 0.03294437 -0.1365222   0.25319654  1.        ]]. Action = [[-0.19210196 -0.52223104 -0.91193765  0.4464289 ]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: No entry zone
Current timestep = 7011. State = [[ 0.03294437 -0.1365222   0.25319654  1.        ]]. Action = [[ 0.19001555 -0.07698655 -0.6732212   0.3553146 ]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: No entry zone
Current timestep = 7012. State = [[ 0.03294437 -0.1365222   0.25319654  1.        ]]. Action = [[ 0.8645958  -0.40365803 -0.6324748   0.46772957]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: No entry zone
Current timestep = 7013. State = [[ 0.03294437 -0.1365222   0.25319654  1.        ]]. Action = [[-0.23228598 -0.36693263 -0.9547402   0.37602615]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: No entry zone
Current timestep = 7014. State = [[ 0.03949776 -0.14157705  0.26004303  1.        ]]. Action = [[ 0.4922018  -0.34347534  0.38568437  0.34905267]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 7015. State = [[ 0.05242449 -0.14633273  0.26751286  1.        ]]. Action = [[ 0.96345806 -0.5190277  -0.7206258   0.38323855]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: No entry zone
Current timestep = 7016. State = [[ 0.05631309 -0.14753084  0.26985624  1.        ]]. Action = [[-0.13882947 -0.4031136  -0.84434325  0.2600304 ]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: No entry zone
Current timestep = 7017. State = [[ 0.05744566 -0.14830573  0.2696855   1.        ]]. Action = [[ 0.83565545 -0.53467625 -0.9004425   0.3045019 ]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7018. State = [[ 0.05053334 -0.16251075  0.26297623  1.        ]]. Action = [[-0.78801674 -0.76014084 -0.6657223   0.3728683 ]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 7019. State = [[ 0.03797122 -0.18849708  0.24221963  1.        ]]. Action = [[-0.49787587 -0.66821074 -0.8541556   0.5804496 ]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 7020. State = [[ 0.03071434 -0.20499903  0.22438364  1.        ]]. Action = [[ 0.5845027   0.4973842  -0.90338683  0.63342667]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: No entry zone
Current timestep = 7021. State = [[ 0.02196246 -0.20655581  0.21928917  1.        ]]. Action = [[-0.80583286  0.22645116  0.0383476   0.78135383]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 7022. State = [[ 0.00845284 -0.20629849  0.20255515  1.        ]]. Action = [[ 0.17426181  0.06500053 -0.9739842   0.65405107]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 7023. State = [[ 0.00258619 -0.20765537  0.17667697  1.        ]]. Action = [[-0.01692814 -0.20984894 -0.6055373   0.5692526 ]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 7024. State = [[ 0.00543658 -0.1990178   0.15452568  1.        ]]. Action = [[ 0.9674287   0.4198997  -0.8959453   0.52934253]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 7025. State = [[ 0.02834466 -0.19176105  0.1349941   1.        ]]. Action = [[ 0.67183423 -0.0825398   0.7362273   0.7145314 ]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 7026. State = [[ 0.0422747  -0.19146122  0.14255647  1.        ]]. Action = [[0.7890526  0.6152582  0.20250869 0.73030376]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: No entry zone
Current timestep = 7027. State = [[ 0.04288028 -0.19153033  0.14306545  1.        ]]. Action = [[ 0.538152    0.34183657 -0.976248    0.76535773]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: No entry zone
Current timestep = 7028. State = [[ 0.04288028 -0.19153033  0.14306545  1.        ]]. Action = [[-0.01399374  0.30460262  0.04551423  0.6236739 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: No entry zone
Current timestep = 7029. State = [[ 0.04476063 -0.1883919   0.13799281  1.        ]]. Action = [[ 0.66875005 -0.05332232 -0.8811377   0.8415141 ]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 7030. State = [[ 0.06751401 -0.1877159   0.10626297  1.        ]]. Action = [[ 0.8876275   0.02296686 -0.5580071   0.7324908 ]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 7031. State = [[ 0.0940911  -0.19240509  0.07447469  1.        ]]. Action = [[ 0.2928455  -0.29507315 -0.8556539   0.441504  ]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 7032. State = [[ 0.11075579 -0.19853571  0.05072329  1.        ]]. Action = [[-0.66315955  0.18256545 -0.90463865  0.798574  ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Scene graph at timestep 7032 is [False, False, True, True, False, False, False, True, False, True]
State prediction error at timestep 7032 is tensor(0.0002, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 7032 of -1
Current timestep = 7033. State = [[ 0.11830959 -0.20081803  0.04803715  1.        ]]. Action = [[-0.18056285  0.4281447  -0.10960561  0.48151386]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Scene graph at timestep 7033 is [False, False, True, True, False, False, False, True, False, True]
State prediction error at timestep 7033 is tensor(0.0001, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 7033 of -1
Current timestep = 7034. State = [[ 0.11830959 -0.20081803  0.04803715  1.        ]]. Action = [[-0.7431917  -0.67589164 -0.87753946  0.3632133 ]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Scene graph at timestep 7034 is [False, False, True, True, False, False, False, True, False, True]
State prediction error at timestep 7034 is tensor(0.0003, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 7034 of -1
Current timestep = 7035. State = [[ 0.11830959 -0.20081803  0.04803715  1.        ]]. Action = [[ 0.17634559  0.54694533 -0.9775199   0.5527723 ]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Action ignored: No entry zone
Scene graph at timestep 7035 is [False, False, True, True, False, False, False, True, False, True]
State prediction error at timestep 7035 is tensor(0.0004, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 7035 of -1
Current timestep = 7036. State = [[ 0.11830959 -0.20081803  0.04803715  1.        ]]. Action = [[ 0.43016243  0.00234735 -0.94722736  0.4861622 ]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Scene graph at timestep 7036 is [False, False, True, True, False, False, False, True, False, True]
State prediction error at timestep 7036 is tensor(0.0002, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 7036 of -1
Current timestep = 7037. State = [[ 0.11830959 -0.20081803  0.04803715  1.        ]]. Action = [[ 0.5064441   0.09153986 -0.18017566  0.31755126]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Scene graph at timestep 7037 is [False, False, True, True, False, False, False, True, False, True]
State prediction error at timestep 7037 is tensor(6.2457e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 7037 of -1
Current timestep = 7038. State = [[ 0.11830959 -0.20081803  0.04803715  1.        ]]. Action = [[-0.12381989 -0.35038835  0.14985657  0.6246078 ]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Scene graph at timestep 7038 is [False, False, True, True, False, False, False, True, False, True]
State prediction error at timestep 7038 is tensor(3.6249e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 7038 of -1
Current timestep = 7039. State = [[ 0.11658706 -0.20177758  0.04811608  1.        ]]. Action = [[-0.9747061   0.23907363  0.08994377  0.6566336 ]]. Reward = [0.]
Curr episode timestep = 92
Scene graph at timestep 7039 is [False, False, True, True, False, False, False, True, False, True]
State prediction error at timestep 7039 is tensor(4.4878e-05, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 7039 of -1
Current timestep = 7040. State = [[ 0.11500073 -0.20434262  0.04968474  1.        ]]. Action = [[ 0.45736384 -0.34535074 -0.70258945  0.79288363]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Scene graph at timestep 7040 is [False, False, True, True, False, False, False, True, False, True]
State prediction error at timestep 7040 is tensor(0.0001, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 7040 of -1
Current timestep = 7041. State = [[ 0.11500073 -0.20434262  0.04968474  1.        ]]. Action = [[-0.13309032  0.00415766 -0.97868615  0.76765144]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Scene graph at timestep 7041 is [False, False, True, True, False, False, False, True, False, True]
State prediction error at timestep 7041 is tensor(0.0002, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 7041 of -1
Current timestep = 7042. State = [[ 0.11500073 -0.20434262  0.04968474  1.        ]]. Action = [[ 0.6545975 -0.083839  -0.736411   0.4426241]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Scene graph at timestep 7042 is [False, False, True, True, False, False, False, True, False, True]
State prediction error at timestep 7042 is tensor(0.0001, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 7042 of -1
Current timestep = 7043. State = [[ 0.11500073 -0.20434262  0.04968474  1.        ]]. Action = [[-0.6262993   0.57998025 -0.24263108  0.6724436 ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: No entry zone
Current timestep = 7044. State = [[ 0.11500073 -0.20434262  0.04968474  1.        ]]. Action = [[ 0.9268997   0.08923578 -0.8032829   0.84678245]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 7045. State = [[ 0.11500073 -0.20434262  0.04968474  1.        ]]. Action = [[-0.36209118 -0.92717856 -0.8201183   0.85715175]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 7046. State = [[ 0.11500073 -0.20434262  0.04968474  1.        ]]. Action = [[-0.37195998 -0.64295256 -0.6248913   0.5816804 ]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 7047. State = [[ 0.11500073 -0.20434262  0.04968474  1.        ]]. Action = [[ 0.9389932  -0.2661553  -0.05323398  0.8031883 ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 7048. State = [[-0.25947413 -0.0762219   0.10973586  1.        ]]. Action = [[-0.6262324   0.30995655 -0.7281134   0.7937418 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 7049. State = [[-0.25399742 -0.09511739  0.10151714  1.        ]]. Action = [[ 0.4518354  -0.5722352   0.9283724   0.98621476]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 7050. State = [[-0.23793639 -0.11540958  0.12289204  1.        ]]. Action = [[ 0.6926391  -0.57787657  0.76851416  0.98097086]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 7051. State = [[-0.21254924 -0.14058334  0.14510217  1.        ]]. Action = [[ 0.6872299  -0.7044075   0.24615788  0.9657979 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 7052. State = [[-0.19484586 -0.15574384  0.15449451  1.        ]]. Action = [[ 0.97195506 -0.7305459   0.09846926  0.9801328 ]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: No entry zone
Current timestep = 7053. State = [[-0.1799579  -0.16810292  0.16090205  1.        ]]. Action = [[ 0.9047898  -0.6905888   0.11749756  0.984282  ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 7054. State = [[-0.14814986 -0.19354224  0.17639005  1.        ]]. Action = [[ 0.97556376 -0.6672917   0.5172312   0.960479  ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 7055. State = [[-0.11527328 -0.21163937  0.18495363  1.        ]]. Action = [[ 0.9803395  -0.23740482 -0.43198878  0.8826567 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 7056. State = [[-0.08244833 -0.22786929  0.16993062  1.        ]]. Action = [[ 0.9293003  -0.60470265 -0.89884186  0.82726765]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 7057. State = [[-0.0471783  -0.23083012  0.1371689   1.        ]]. Action = [[ 0.89354825  0.57325256 -0.84356797  0.87352276]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 7058. State = [[-0.01375003 -0.23689526  0.10553589  1.        ]]. Action = [[ 0.98222256 -0.701557   -0.7027781   0.65163255]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 7059. State = [[ 0.01900453 -0.2438242   0.07445149  1.        ]]. Action = [[ 0.6435797   0.14521646 -0.9135344   0.19999349]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 7060. State = [[ 0.03342932 -0.24475436  0.03824462  1.        ]]. Action = [[-0.8351086   0.2524097  -0.46538055  0.37492287]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 7061. State = [[ 0.02520452 -0.25992003  0.03537875  1.        ]]. Action = [[-0.70385575 -0.8550788   0.876346    0.19724965]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 7062. State = [[ 0.01387455 -0.29539773  0.0575209   1.        ]]. Action = [[-0.6335963  -0.83279204  0.92348504  0.1328466 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 7063. State = [[ 0.00177484 -0.31098863  0.08104528  1.        ]]. Action = [[-0.98045784 -0.93969905  0.1409527   0.18630922]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 7064. State = [[-0.00173411 -0.31233507  0.08445846  1.        ]]. Action = [[-0.939742   -0.8476354   0.67770696  0.29268932]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 7065. State = [[-0.00297415 -0.3121811   0.08441154  1.        ]]. Action = [[-0.93583035 -0.8457017  -0.29914546  0.30235386]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 7066. State = [[-0.00289278 -0.3128059   0.08511645  1.        ]]. Action = [[-0.98925406 -0.798544   -0.14607191  0.3413043 ]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 7067. State = [[-0.00263988 -0.31272486  0.08527465  1.        ]]. Action = [[-0.235165   -0.869359   -0.53781193  0.31987262]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 7068. State = [[-0.00240721 -0.3126502   0.0854397   1.        ]]. Action = [[-0.7114956 -0.9500043  0.8217647  0.3710829]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 7069. State = [[-0.00261493 -0.312673    0.08534265  1.        ]]. Action = [[-0.4492861  -0.8932469  -0.37129015  0.26372957]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 7070. State = [[-0.00264314 -0.31267726  0.085326    1.        ]]. Action = [[-0.96650344 -0.8036151   0.91240287  0.4724977 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 7071. State = [[-0.00264314 -0.31267726  0.085326    1.        ]]. Action = [[-0.953344   -0.87824637  0.11291635  0.38097715]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 7072. State = [[-0.00264314 -0.31267726  0.085326    1.        ]]. Action = [[-0.9831705  -0.94905454  0.53047216  0.42149138]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 7073. State = [[-0.00901429 -0.31549284  0.09774949  1.        ]]. Action = [[-0.8563463   0.17780614  0.8877454   0.4297676 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 7074. State = [[-0.03056332 -0.31184283  0.11979942  1.        ]]. Action = [[-0.9825052  -0.94018245 -0.16088027  0.48429108]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 7075. State = [[-0.0352778  -0.3106395   0.12361378  1.        ]]. Action = [[-0.17240971 -0.20910025 -0.0695641   0.40653634]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 7076. State = [[-0.0475738  -0.3088199   0.11672511  1.        ]]. Action = [[-0.7884423   0.12058616 -0.92606467  0.6153035 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 7077. State = [[-0.06574856 -0.3059171   0.10272478  1.        ]]. Action = [[-0.81891537 -0.5453505  -0.32313716  0.1925075 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 7078. State = [[-0.07015454 -0.30475408  0.09934026  1.        ]]. Action = [[-0.88850445 -0.9655097   0.3399768   0.2194432 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 7079. State = [[-0.07103783 -0.30452606  0.09883542  1.        ]]. Action = [[-0.86790377 -0.8280957  -0.06973964  0.2585057 ]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 7080. State = [[-0.07128211 -0.3044658   0.0986809   1.        ]]. Action = [[-0.96643746 -0.959178    0.67880094  0.19886339]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 7081. State = [[-0.07200807 -0.30426204  0.09829895  1.        ]]. Action = [[-0.7650827  -0.7333211  -0.1094445   0.19484138]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 7082. State = [[-0.07258036 -0.30420312  0.09790002  1.        ]]. Action = [[-0.9946991  -0.8824861   0.4188311   0.23610187]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 7083. State = [[-0.07334461 -0.30399713  0.09748877  1.        ]]. Action = [[-0.8352812  -0.8735789   0.8963636   0.17889512]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 7084. State = [[-0.07368506 -0.30385464  0.09727119  1.        ]]. Action = [[-0.6482332  -0.8801188   0.92843866  0.16463888]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 7085. State = [[-0.07385207 -0.3038051   0.09722961  1.        ]]. Action = [[-0.9477928  -0.7241314   0.33623886  0.35920286]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 7086. State = [[-0.07399005 -0.30384338  0.09706286  1.        ]]. Action = [[-0.9118641  -0.74994844 -0.12015492  0.24802268]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 7087. State = [[-0.07412077 -0.30380484  0.09699471  1.        ]]. Action = [[-0.5916505  -0.7557272   0.60305595  0.36097574]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 7088. State = [[-0.07412077 -0.30380484  0.09699471  1.        ]]. Action = [[-0.89567256 -0.6140923   0.86711407  0.20263433]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 7089. State = [[-0.07412077 -0.30380484  0.09699471  1.        ]]. Action = [[-0.1401062 -0.7659496  0.7966323  0.2583393]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 7090. State = [[-0.07418421 -0.30378616  0.09696166  1.        ]]. Action = [[-0.6060313  -0.7173898   0.7024008   0.13775074]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 7091. State = [[-0.07418421 -0.30378616  0.09696166  1.        ]]. Action = [[ 0.3138795  -0.83516276  0.6044166   0.21552646]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 7092. State = [[-0.07418421 -0.30378616  0.09696166  1.        ]]. Action = [[-0.75909215 -0.75119543  0.32027173  0.24838579]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 7093. State = [[-0.07418421 -0.30378616  0.09696166  1.        ]]. Action = [[-0.8557334  -0.8811124   0.20265651  0.29133606]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 7094. State = [[-0.07418421 -0.30378616  0.09696166  1.        ]]. Action = [[-0.79799926 -0.92075145  0.7319896   0.33148026]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 7095. State = [[-0.07418421 -0.30378616  0.09696166  1.        ]]. Action = [[ 0.5292103  -0.86339396  0.44127727  0.30672967]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 7096. State = [[-0.07418421 -0.30378616  0.09696166  1.        ]]. Action = [[-0.7966405  -0.90749675  0.2565086   0.34148526]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 7097. State = [[-0.07418421 -0.30378616  0.09696166  1.        ]]. Action = [[-0.7266562  -0.54076695 -0.06491327  0.28170836]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 7098. State = [[-0.07418421 -0.30378616  0.09696166  1.        ]]. Action = [[-0.6485387  -0.84971493  0.95877326  0.31937063]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 7099. State = [[-0.07418421 -0.30378616  0.09696166  1.        ]]. Action = [[-0.9476339  -0.7870959   0.13831043  0.23447657]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 7100. State = [[-0.07418421 -0.30378616  0.09696166  1.        ]]. Action = [[-0.9298149  -0.6459677   0.12837422  0.2895596 ]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 7101. State = [[-0.07418421 -0.30378616  0.09696166  1.        ]]. Action = [[-0.03199416 -0.9422432   0.14842868  0.34675932]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 7102. State = [[-0.07418421 -0.30378616  0.09696166  1.        ]]. Action = [[-0.64727616 -0.8302936   0.7417512   0.3597834 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 7103. State = [[-0.07418421 -0.30378616  0.09696166  1.        ]]. Action = [[-0.33881986 -0.8716812   0.17144156  0.41632414]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 7104. State = [[-0.07418421 -0.30378616  0.09696166  1.        ]]. Action = [[-0.8368986 -0.8271787  0.1509912  0.4506811]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 7105. State = [[-0.07418421 -0.30378616  0.09696166  1.        ]]. Action = [[-0.24282396 -0.54759496 -0.74088717  0.43764353]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 7106. State = [[-0.07418421 -0.30378616  0.09696166  1.        ]]. Action = [[-0.62685716 -0.8169301   0.59718895  0.36781764]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 7107. State = [[-0.07418421 -0.30378616  0.09696166  1.        ]]. Action = [[-0.85505074 -0.93287355  0.71107864  0.3443513 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 7108. State = [[-0.07418421 -0.30378616  0.09696166  1.        ]]. Action = [[-0.96930486 -0.95061576  0.38669384  0.2817328 ]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 7109. State = [[-0.07418421 -0.30378616  0.09696166  1.        ]]. Action = [[-0.75715756 -0.92356795  0.57970476  0.2795074 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 7110. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.9036753  -0.8189373  -0.38194227  0.26234746]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 7111. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.59997934 -0.80551964  0.93540525  0.37125862]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 7112. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.6832209  -0.74296594  0.72869647  0.23607206]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 7113. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.0936749  -0.8721955   0.38371468  0.36242127]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 7114. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.34553635 -0.89185435  0.3313973   0.35805845]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 7115. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.8155452  -0.855953   -0.31142795  0.507239  ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 7116. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.93891686 -0.63022465  0.84420526  0.32163453]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 7117. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.876808   -0.6278831   0.8217647   0.16759157]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 7118. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.7180392  -0.7427207   0.68757606  0.25794816]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 7119. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.38613188 -0.67300457  0.82259893  0.33197176]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 7120. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.9247715 -0.8611629  0.653293   0.4321413]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 7121. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.46746743 -0.89615273  0.7556627   0.37500453]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 7122. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.93484735 -0.8523179   0.8532605   0.45078194]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 7123. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.9027264  -0.82993346  0.71593726  0.498464  ]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 7124. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[ 0.12220645 -0.69535255  0.38416648  0.36773205]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 7125. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.54703885 -0.8486618  -0.12972057  0.3267727 ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 7126. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.3047595  -0.70003396  0.7823484   0.44672596]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 7127. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.7068882  -0.74533796  0.6078265   0.24536777]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 7128. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.57067215 -0.76412934  0.15518868  0.14172626]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 7129. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.33636284 -0.9452662   0.5012791   0.2816068 ]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 7130. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.9095254  -0.6173852   0.08705544  0.3138001 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 7131. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.506441   -0.86634326  0.18402553  0.41010094]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 7132. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.46486366 -0.9028828   0.7663549   0.4625547 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 7133. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[ 0.01928914 -0.6850319   0.91054046  0.3179978 ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 7134. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.8779781  -0.73220414  0.56556964  0.26495624]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 7135. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.30783433 -0.6844622   0.5473975   0.259076  ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 7136. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.7749677  -0.7758746   0.3186338   0.39697826]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 7137. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.8593627 -0.9750535  0.4890015  0.5034033]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 7138. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.31942546 -0.68776053  0.48606563  0.3242011 ]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 7139. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.857209   -0.81441087  0.9692812   0.38171327]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 7140. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.80033624 -0.3344996   0.08441353  0.1357001 ]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 7141. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.91635925 -0.90077364  0.82274103  0.346743  ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 7142. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.56458414 -0.89480895  0.5007024   0.52907515]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 7143. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.64497095 -0.8751741   0.56764543  0.44158077]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 7144. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.6346416  -0.5866387   0.5355363   0.27979374]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 7145. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.6400746  -0.74038965  0.75503516  0.4594239 ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 7146. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.84658104 -0.6995809   0.51133585  0.34964013]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 7147. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.72258145 -0.53359866 -0.37390077  0.26696062]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 7148. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[-0.943247   -0.7938465   0.5601114   0.42192733]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 7149. State = [[-0.07416195 -0.30380255  0.09696147  1.        ]]. Action = [[ 0.24474633 -0.7519098   0.73791885  0.39872217]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 7150. State = [[-0.26074708 -0.0290219   0.11231627  1.        ]]. Action = [[ 0.29279506 -0.8391048   0.56326723  0.38959575]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 7151. State = [[-0.25686806 -0.04466815  0.10610311  1.        ]]. Action = [[ 0.23988748 -0.6456242   0.93836594  0.99224615]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 7152. State = [[-0.24982873 -0.06792662  0.12768625  1.        ]]. Action = [[ 0.26185632 -0.5871648   0.9621599   0.9963629 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 7153. State = [[-0.23433249 -0.08399372  0.16413738  1.        ]]. Action = [[ 0.69799733 -0.2470302   0.9327202   0.9504504 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 7154. State = [[-0.20963009 -0.09909851  0.19021495  1.        ]]. Action = [[ 0.5524349  -0.41521215  0.03726578  0.98974943]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 7155. State = [[-0.19631028 -0.10682061  0.19801468  1.        ]]. Action = [[ 0.8921745  -0.23984647 -0.6745811   0.943311  ]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 7156. State = [[-0.19467773 -0.10879993  0.1994627   1.        ]]. Action = [[ 0.953048   -0.6750231   0.19107056  0.9964144 ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 7157. State = [[-0.19454789 -0.10923965  0.19990192  1.        ]]. Action = [[ 0.5740721  -0.5271573   0.39825892  0.9658637 ]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 7158. State = [[-0.19407378 -0.10956278  0.2002745   1.        ]]. Action = [[ 0.6392517 -0.2415489  0.5262375  0.9513613]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 7159. State = [[-0.19387017 -0.10953642  0.20047711  1.        ]]. Action = [[ 0.9919369  -0.13919109  0.38124478  0.9180958 ]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 7160. State = [[-0.19389625 -0.10952696  0.20047574  1.        ]]. Action = [[ 0.7810519  -0.74222165  0.7732997   0.96693027]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 7161. State = [[-0.19389625 -0.10952696  0.20047574  1.        ]]. Action = [[ 0.9670646  -0.47444105  0.27183664  0.96683025]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 7162. State = [[-0.19389625 -0.10952696  0.20047574  1.        ]]. Action = [[ 0.95155823  0.03256726 -0.13466614  0.9733062 ]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: No entry zone
Current timestep = 7163. State = [[-0.19389625 -0.10952696  0.20047574  1.        ]]. Action = [[ 0.8578687  -0.18750006  0.18403924  0.89428926]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: No entry zone
Current timestep = 7164. State = [[-0.19389625 -0.10952696  0.20047574  1.        ]]. Action = [[ 0.8116708  -0.07422233  0.73803926  0.91477275]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: No entry zone
Current timestep = 7165. State = [[-0.19389625 -0.10952696  0.20047574  1.        ]]. Action = [[ 0.84160495 -0.25248802 -0.6108124   0.99202716]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: No entry zone
Current timestep = 7166. State = [[-0.19389625 -0.10952696  0.20047574  1.        ]]. Action = [[ 0.84345174 -0.4894156  -0.18565881  0.92548645]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: No entry zone
Current timestep = 7167. State = [[-0.19341044 -0.11526303  0.19956815  1.        ]]. Action = [[ 0.10035241 -0.35031134 -0.18675679  0.9742918 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 7168. State = [[-0.19218366 -0.12162346  0.19784558  1.        ]]. Action = [[ 0.56178975 -0.5133846  -0.25720417  0.9756578 ]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: No entry zone
Current timestep = 7169. State = [[-0.19203053 -0.12245499  0.19738501  1.        ]]. Action = [[ 0.9726298 -0.5582563  0.5433626  0.9231918]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: No entry zone
Current timestep = 7170. State = [[-0.19222745 -0.12267452  0.19737673  1.        ]]. Action = [[ 0.8838626  -0.46682465  0.6952412   0.9948995 ]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: No entry zone
Current timestep = 7171. State = [[-0.19228487 -0.12285468  0.19740464  1.        ]]. Action = [[ 0.9910977  -0.17267013  0.21650374  0.87382555]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: No entry zone
Current timestep = 7172. State = [[-0.19230537 -0.12291893  0.1974146   1.        ]]. Action = [[ 0.839463  -0.6834328  0.7295532  0.9469311]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: No entry zone
Current timestep = 7173. State = [[-0.19230537 -0.12291893  0.1974146   1.        ]]. Action = [[ 0.8430805  -0.36071604 -0.06868362  0.972837  ]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: No entry zone
Current timestep = 7174. State = [[-0.19234367 -0.12303888  0.19743322  1.        ]]. Action = [[ 0.958372  -0.4861189  0.4732889  0.9685538]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: No entry zone
Current timestep = 7175. State = [[-0.19236289 -0.12309905  0.19744258  1.        ]]. Action = [[ 0.83961177 -0.6791008  -0.2066772   0.9550108 ]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: No entry zone
Current timestep = 7176. State = [[-0.18704337 -0.13368908  0.19214417  1.        ]]. Action = [[ 0.4319874  -0.63618505 -0.52477264  0.9966955 ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 7177. State = [[-0.17685567 -0.14652766  0.18225062  1.        ]]. Action = [[ 0.9916817  -0.58474123  0.37748778  0.94936347]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: No entry zone
Current timestep = 7178. State = [[-0.17648844 -0.14767265  0.18219072  1.        ]]. Action = [[ 0.9152889  -0.09837753 -0.8688799   0.95234966]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: No entry zone
Current timestep = 7179. State = [[-0.17646536 -0.14771931  0.18218026  1.        ]]. Action = [[0.7791152  0.10019183 0.2132895  0.95046353]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: No entry zone
Current timestep = 7180. State = [[-0.17646304 -0.14788102  0.1821803   1.        ]]. Action = [[ 0.8986709  -0.24588758  0.76001096  0.9398254 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: No entry zone
Current timestep = 7181. State = [[-0.17646304 -0.14788102  0.1821803   1.        ]]. Action = [[ 0.98849106 -0.29885876  0.86456597  0.8604903 ]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: No entry zone
Current timestep = 7182. State = [[-0.17646304 -0.14788102  0.1821803   1.        ]]. Action = [[ 0.61773944 -0.31690764  0.5410669   0.97019327]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: No entry zone
Current timestep = 7183. State = [[-0.17646304 -0.14788102  0.1821803   1.        ]]. Action = [[ 0.77597666 -0.1713717   0.21261919  0.9756763 ]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: No entry zone
Current timestep = 7184. State = [[-0.17646304 -0.14788102  0.1821803   1.        ]]. Action = [[ 0.6171644  -0.5801632   0.24422944  0.9802823 ]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: No entry zone
Current timestep = 7185. State = [[-0.16377094 -0.15984035  0.19019096  1.        ]]. Action = [[ 0.74216413 -0.72512805  0.6689131   0.93832445]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 7186. State = [[-0.14911626 -0.17334962  0.20005864  1.        ]]. Action = [[ 0.8953817  -0.19894129  0.49090636  0.87121344]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: No entry zone
Current timestep = 7187. State = [[-0.13938992 -0.18110299  0.19637547  1.        ]]. Action = [[ 0.86329055 -0.31352353 -0.87188447  0.93685865]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 7188. State = [[-0.11833313 -0.18912306  0.17554666  1.        ]]. Action = [[ 0.81005144  0.32070065 -0.37123084  0.93846846]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: No entry zone
Current timestep = 7189. State = [[-0.10059548 -0.18795472  0.18100114  1.        ]]. Action = [[0.97760725 0.19419372 0.43146753 0.941224  ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 7190. State = [[-0.07172208 -0.18436815  0.18258269  1.        ]]. Action = [[ 0.9455397   0.01767516 -0.61213666  0.95343256]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 7191. State = [[-0.04687114 -0.18564667  0.16729654  1.        ]]. Action = [[ 0.94187856  0.14633763 -0.44152355  0.6379956 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: No entry zone
Current timestep = 7192. State = [[-0.0357602  -0.18740997  0.16301493  1.        ]]. Action = [[ 0.8421565  -0.3116963  -0.76880854  0.60873175]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 7193. State = [[-0.01158577 -0.19290449  0.13378215  1.        ]]. Action = [[ 0.7668266  -0.12911117 -0.968207    0.6777432 ]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 7194. State = [[ 0.01721394 -0.20147969  0.09670969  1.        ]]. Action = [[ 0.23506176 -0.2215082  -0.2759515   0.43181133]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 7195. State = [[ 0.02794619 -0.20633821  0.07752033  1.        ]]. Action = [[-0.04645079 -0.00814992 -0.7749918   0.5337992 ]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 7196. State = [[ 0.0339416  -0.2078719   0.05623205  1.        ]]. Action = [[ 0.9852768   0.19507825 -0.96995544  0.5970595 ]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 7197. State = [[ 0.03634394 -0.20507003  0.04893657  1.        ]]. Action = [[ 0.24817169  0.26471508 -0.49355596  0.53686786]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 7198. State = [[ 0.05186653 -0.2085826   0.03085112  1.        ]]. Action = [[ 0.9728695  -0.49780798 -0.4281752   0.6349721 ]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 7199. State = [[ 0.06394115 -0.22629248  0.01618285  1.        ]]. Action = [[-0.9328377  -0.5119134  -0.02023286  0.4419186 ]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 7200. State = [[ 0.05838329 -0.2540917   0.02534997  1.        ]]. Action = [[-0.49466765 -0.8263096   0.74949706  0.46044004]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 7201. State = [[ 0.04560878 -0.28201377  0.03911678  1.        ]]. Action = [[-0.9583635  -0.27987027  0.33633506  0.55553055]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 7202. State = [[ 0.02667196 -0.28982148  0.04928453  1.        ]]. Action = [[-0.944663   -0.80635446  0.94557846  0.67009056]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 7203. State = [[ 0.02289204 -0.29288933  0.05122154  1.        ]]. Action = [[-0.94289    -0.82654047  0.7857299   0.34791887]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 7204. State = [[ 0.02287474 -0.293226    0.05145213  1.        ]]. Action = [[-0.9926738  -0.7885495   0.7616695   0.42107248]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 7205. State = [[ 0.02287474 -0.293226    0.05145213  1.        ]]. Action = [[-0.9881093  -0.9763735   0.1814189   0.28488243]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 7206. State = [[ 0.02287474 -0.293226    0.05145213  1.        ]]. Action = [[-0.9886947  -0.884873    0.26886106  0.45700276]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 7207. State = [[ 0.02287474 -0.293226    0.05145213  1.        ]]. Action = [[-0.9556191 -0.8771992  0.6568353  0.4362861]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 7208. State = [[ 0.02287474 -0.293226    0.05145213  1.        ]]. Action = [[-0.9536132  -0.99312294  0.91440177  0.43283832]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 7209. State = [[ 0.02287474 -0.293226    0.05145213  1.        ]]. Action = [[-0.76165414 -0.76089644  0.16861546  0.39523208]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 7210. State = [[ 0.02287474 -0.293226    0.05145213  1.        ]]. Action = [[-0.92693424 -0.9377906   0.81257856  0.45827818]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 7211. State = [[ 0.02287474 -0.293226    0.05145213  1.        ]]. Action = [[-0.9608884 -0.8682555  0.5599208  0.462106 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 7212. State = [[ 0.02287474 -0.293226    0.05145213  1.        ]]. Action = [[-0.5208626  -0.95009553  0.5829773   0.42414784]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 7213. State = [[ 0.02287474 -0.293226    0.05145213  1.        ]]. Action = [[-0.9942349  -0.4827531  -0.30197108  0.5072551 ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 7214. State = [[ 0.02287474 -0.293226    0.05145213  1.        ]]. Action = [[-0.9656893  -0.54219735 -0.03295767  0.39163446]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 7215. State = [[ 0.02287474 -0.293226    0.05145213  1.        ]]. Action = [[-0.9909858  -0.9747769   0.8750019   0.49544525]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 7216. State = [[ 0.02287474 -0.293226    0.05145213  1.        ]]. Action = [[-0.9896557  -0.94124043  0.9606751   0.45399582]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 7217. State = [[ 0.02287474 -0.293226    0.05145213  1.        ]]. Action = [[-0.87106365 -0.94841653  0.81560516  0.48906863]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 7218. State = [[ 0.02287474 -0.293226    0.05145213  1.        ]]. Action = [[-0.9348911  -0.8551583   0.7621052   0.47761345]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 7219. State = [[ 0.02287474 -0.293226    0.05145213  1.        ]]. Action = [[-0.89636374 -0.9981222   0.19172037  0.4095962 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 7220. State = [[ 0.02287474 -0.293226    0.05145213  1.        ]]. Action = [[-0.12775898 -0.8325848   0.8829236   0.39739633]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 7221. State = [[ 0.0149193  -0.30134726  0.06346049  1.        ]]. Action = [[-0.8834072  -0.2100448   0.8206227   0.40288103]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 7222. State = [[-0.00693298 -0.30407944  0.08312858  1.        ]]. Action = [[-0.90667206 -0.40627968  0.3705709   0.45614886]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 7223. State = [[-0.00904292 -0.30441323  0.08528694  1.        ]]. Action = [[-0.43545514 -0.8032249   0.88332105  0.43149316]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 7224. State = [[-0.00904292 -0.30441323  0.08528694  1.        ]]. Action = [[-0.52458996 -0.82408035  0.5259243   0.56103253]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 7225. State = [[-0.00904292 -0.30441323  0.08528694  1.        ]]. Action = [[ 0.5389223  -0.87431896  0.84332705  0.46432447]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 7226. State = [[-0.00904292 -0.30441323  0.08528694  1.        ]]. Action = [[-0.8024012  -0.7698158   0.6252606   0.39412844]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 7227. State = [[-0.00904292 -0.30441323  0.08528694  1.        ]]. Action = [[-0.5094863  -0.8597296   0.6751298   0.40044641]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 7228. State = [[-0.00904292 -0.30441323  0.08528694  1.        ]]. Action = [[-0.6733032  -0.7916086   0.80482554  0.2189275 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 7229. State = [[-0.00904292 -0.30441323  0.08528694  1.        ]]. Action = [[-0.5949435  -0.6935274   0.16078222  0.43386745]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 7230. State = [[-0.00904292 -0.30441323  0.08528694  1.        ]]. Action = [[ 0.24260068 -0.9476884   0.06597269  0.32192934]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 7231. State = [[-0.00904292 -0.30441323  0.08528694  1.        ]]. Action = [[-0.5878434  -0.14992857  0.28693688  0.27096498]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 7232. State = [[-0.00904292 -0.30441323  0.08528694  1.        ]]. Action = [[-0.94481987 -0.90422416  0.40828037  0.38839304]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 7233. State = [[-0.00904292 -0.30441323  0.08528694  1.        ]]. Action = [[-0.9642057  -0.96524274  0.42256224  0.3157047 ]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 7234. State = [[-0.00904292 -0.30441323  0.08528694  1.        ]]. Action = [[-0.8105538  -0.75662076  0.05188191  0.227391  ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 7235. State = [[-0.00904292 -0.30441323  0.08528694  1.        ]]. Action = [[-0.67641467 -0.9190764   0.5978966   0.2931347 ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 7236. State = [[-0.00904292 -0.30441323  0.08528694  1.        ]]. Action = [[-0.5570238 -0.9790402  0.2982937  0.5056906]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 7237. State = [[-0.00904292 -0.30441323  0.08528694  1.        ]]. Action = [[-0.91747403 -0.98911273 -0.26210576  0.3155421 ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 7238. State = [[-0.00904292 -0.30441323  0.08528694  1.        ]]. Action = [[-0.4501208  -0.50455755 -0.28139305  0.373412  ]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 7239. State = [[-0.00904292 -0.30441323  0.08528694  1.        ]]. Action = [[-0.8187771  -0.421731    0.13727379  0.27787519]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 7240. State = [[-0.01500005 -0.30700174  0.08931444  1.        ]]. Action = [[-0.6734532   0.049366    0.29645693  0.44232762]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 7241. State = [[-0.03192538 -0.3066888   0.09812578  1.        ]]. Action = [[-0.89781696 -0.72108257  0.60703206  0.39179313]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 7242. State = [[-0.03574134 -0.3063075   0.09938254  1.        ]]. Action = [[-0.8946447  -0.76219136  0.09850037  0.28388715]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 7243. State = [[-0.03930124 -0.30603728  0.10158642  1.        ]]. Action = [[-0.9712801  -0.90939134  0.42350328  0.2977314 ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 7244. State = [[-0.0410997  -0.3059754   0.10070561  1.        ]]. Action = [[ 0.11495841 -0.6465558   0.10905659  0.28047025]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 7245. State = [[-0.04130571 -0.305957    0.10062546  1.        ]]. Action = [[-0.7677018  -0.8902986   0.17539895  0.3513987 ]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 7246. State = [[-0.04136846 -0.30594665  0.10059005  1.        ]]. Action = [[-0.9221189  -0.5967962   0.89245665  0.21859694]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 7247. State = [[-0.04143121 -0.30593634  0.10055465  1.        ]]. Action = [[-0.9074974  -0.7683804   0.5712619   0.01076388]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 7248. State = [[-0.04136771 -0.3059901   0.10055361  1.        ]]. Action = [[-0.386481   -0.29151982  0.06428111  0.1253345 ]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 7249. State = [[-0.04136771 -0.3059901   0.10055361  1.        ]]. Action = [[ 0.2926321  -0.7966129  -0.01567054  0.0486455 ]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 7250. State = [[-0.04136771 -0.3059901   0.10055361  1.        ]]. Action = [[-0.71846455 -0.91574556  0.44377124  0.05566978]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 7251. State = [[-0.04136771 -0.3059901   0.10055361  1.        ]]. Action = [[-0.6562979  -0.66518086  0.5564461   0.14052236]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 7252. State = [[-0.26643404  0.0870753   0.11096286  1.        ]]. Action = [[ 0.3243847  -0.88591266 -0.8003469   0.15041733]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 7253. State = [[-0.25846335  0.08676394  0.10605486  1.        ]]. Action = [[ 0.07219696 -0.71226716  0.9796877   0.9568949 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 7254. State = [[-0.2498428   0.06472289  0.12725809  1.        ]]. Action = [[ 0.25122058 -0.75595653  0.80598736  0.97307014]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 7255. State = [[-0.24115366  0.03750934  0.15909177  1.        ]]. Action = [[ 0.3475809  -0.7373055   0.9497075   0.95069385]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 7256. State = [[-0.22313343  0.01147299  0.19774243  1.        ]]. Action = [[ 0.79217625 -0.68347424  0.98436713  0.9703275 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 7257. State = [[-0.1941811  -0.01494893  0.22552823  1.        ]]. Action = [[ 0.8741486  -0.67699516 -0.04494286  0.9724624 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 7258. State = [[-0.17819777 -0.02947034  0.23192059  1.        ]]. Action = [[ 0.6768191  -0.6079308   0.02587974  0.8430445 ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 7259. State = [[-0.16746876 -0.03850469  0.24338223  1.        ]]. Action = [[ 0.546237   -0.3973372   0.8937161   0.80494595]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 7260. State = [[-0.14090179 -0.0580267   0.26573414  1.        ]]. Action = [[ 0.87526155 -0.68180555  0.11200428  0.8364334 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 7261. State = [[-0.11240787 -0.07688701  0.26971892  1.        ]]. Action = [[ 0.82515323 -0.2373485  -0.32960898  0.8349376 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 7262. State = [[-0.08951318 -0.0824739   0.2630786   1.        ]]. Action = [[ 0.6770978  -0.626043   -0.89839584  0.7871096 ]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 7263. State = [[-0.07644763 -0.08523038  0.25900427  1.        ]]. Action = [[ 0.94760966 -0.06917799 -0.57740045  0.393386  ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 7264. State = [[-0.04236769 -0.09441952  0.252408    1.        ]]. Action = [[ 0.95670295 -0.44181174  0.53266215  0.6195644 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 7265. State = [[-0.00602137 -0.10381678  0.2672667   1.        ]]. Action = [[ 0.9056299  -0.10430014  0.42099988  0.5320344 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 7266. State = [[ 0.01864346 -0.10703377  0.27609736  1.        ]]. Action = [[ 0.22810411 -0.35785377 -0.8930021   0.44008887]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: No entry zone
Current timestep = 7267. State = [[ 0.02918858 -0.11636208  0.27256197  1.        ]]. Action = [[ 0.84611964 -0.53626025 -0.7131376   0.24516809]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 7268. State = [[ 0.05211209 -0.13453278  0.2481623   1.        ]]. Action = [[ 0.00218391 -0.3756231  -0.25079012  0.27403903]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 7269. State = [[ 0.06102516 -0.14225684  0.24097018  1.        ]]. Action = [[-0.25192165 -0.53010726 -0.95043904  0.28018475]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: No entry zone
Current timestep = 7270. State = [[ 0.05977086 -0.15510836  0.23354833  1.        ]]. Action = [[ 0.344666   -0.8357533  -0.85461074  0.393103  ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 7271. State = [[ 0.06932468 -0.18561079  0.19984794  1.        ]]. Action = [[ 0.01446676 -0.70049155 -0.8465713   0.6464311 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 7272. State = [[ 0.07217482 -0.20935617  0.17578153  1.        ]]. Action = [[-0.9599545  -0.2476821  -0.34646273  0.7664995 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 7273. State = [[ 0.05935208 -0.21124291  0.1659355   1.        ]]. Action = [[-0.7119147   0.5637572  -0.08773541  0.95752156]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 7274. State = [[ 0.04019096 -0.20715977  0.14598824  1.        ]]. Action = [[-0.8351864   0.07307434 -0.8743008   0.91760993]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 7275. State = [[ 0.02267785 -0.19509539  0.11400267  1.        ]]. Action = [[ 0.760582    0.40840805 -0.86164343  0.79597104]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 7276. State = [[ 0.02154923 -0.18658285  0.09668274  1.        ]]. Action = [[ 0.84022427  0.50575805 -0.41808963  0.44368112]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: No entry zone
Current timestep = 7277. State = [[ 0.02815866 -0.18588431  0.09144951  1.        ]]. Action = [[ 0.99067605 -0.32493675 -0.5631197   0.718416  ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 7278. State = [[ 0.03763057 -0.18877755  0.05984075  1.        ]]. Action = [[-0.3501233  -0.05252272 -0.8549944   0.5472398 ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 7279. State = [[ 0.03823698 -0.18953088  0.03786528  1.        ]]. Action = [[-0.86984074  0.3580197  -0.74910426  0.63716173]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7280. State = [[ 0.04900721 -0.19775026  0.04260665  1.        ]]. Action = [[ 0.81210923 -0.5267557   0.41749597  0.2844268 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 7281. State = [[ 0.07031693 -0.20521276  0.04482232  1.        ]]. Action = [[ 0.8829732   0.03677309 -0.19112474  0.5393374 ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 7282. State = [[ 0.09166032 -0.20583062  0.03799468  1.        ]]. Action = [[-0.57362586 -0.7365503  -0.9301293   0.81251824]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 7283. State = [[ 0.09911663 -0.20597471  0.03802982  1.        ]]. Action = [[ 0.48431325 -0.40014362 -0.7785779   0.7386582 ]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 7284. State = [[ 0.0990822  -0.20590618  0.03799341  1.        ]]. Action = [[ 0.7218964  0.4982729 -0.8179343  0.8656403]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 7285. State = [[ 0.09904159 -0.20597765  0.03807258  1.        ]]. Action = [[ 0.91105604 -0.01786327 -0.9464542   0.9172058 ]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 7286. State = [[ 0.09904159 -0.20597765  0.03807258  1.        ]]. Action = [[-0.33092678  0.16248178 -0.9086925   0.7869247 ]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 7287. State = [[ 0.09904159 -0.20597765  0.03807258  1.        ]]. Action = [[-0.75332075 -0.6473701  -0.9949301   0.81234825]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 7288. State = [[ 0.09904159 -0.20597765  0.03807258  1.        ]]. Action = [[-0.8638661   0.9142616  -0.94481564  0.7650205 ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7289. State = [[ 0.09903112 -0.20603366  0.03809173  1.        ]]. Action = [[ 0.37678075 -0.16007161 -0.8670649   0.92072666]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 7290. State = [[ 0.09903112 -0.20603366  0.03809173  1.        ]]. Action = [[ 0.92926955  0.29236984 -0.4901383   0.55337536]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 7291. State = [[ 0.09903112 -0.20603366  0.03809173  1.        ]]. Action = [[-0.34982955  0.6977222  -0.97746164  0.9336643 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7292. State = [[ 0.09903112 -0.20603366  0.03809173  1.        ]]. Action = [[-0.10093635  0.8458772   0.06019318  0.73496675]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: No entry zone
Current timestep = 7293. State = [[ 0.09903112 -0.20603366  0.03809173  1.        ]]. Action = [[ 0.27129328  0.6773796  -0.71325743  0.8435441 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7294. State = [[ 0.09900613 -0.20602159  0.03809046  1.        ]]. Action = [[-0.21470255  0.55813813 -0.3344543   0.914799  ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 7295. State = [[ 0.09900613 -0.20602159  0.03809046  1.        ]]. Action = [[-0.6395788  -0.58228165 -0.8177212   0.75745606]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 7296. State = [[ 0.09900613 -0.20602159  0.03809046  1.        ]]. Action = [[-0.6670834  -0.50689715 -0.9963766   0.7321782 ]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 7297. State = [[ 0.09900613 -0.20602159  0.03809046  1.        ]]. Action = [[ 0.8879123  -0.6976179  -0.8590317   0.75925064]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 7298. State = [[ 0.0979978  -0.21795653  0.04635412  1.        ]]. Action = [[-0.38243473 -0.49745458  0.65280104  0.91197157]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 7299. State = [[ 0.09796423 -0.22909333  0.05578038  1.        ]]. Action = [[-0.98963124  0.96021914 -0.9513317   0.8233373 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7300. State = [[ 0.09795802 -0.23131219  0.05745554  1.        ]]. Action = [[ 0.87041867  0.45166588 -0.73639554  0.6171782 ]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 7301. State = [[ 0.09786726 -0.23162253  0.05758769  1.        ]]. Action = [[-0.3580563   0.65082157 -0.7501185   0.9124025 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 7302. State = [[ 0.09786726 -0.23162253  0.05758769  1.        ]]. Action = [[-0.07353884  0.8889954  -0.9190984   0.8173666 ]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 7303. State = [[ 0.09786726 -0.23162253  0.05758769  1.        ]]. Action = [[-0.10594183  0.94261885 -0.98312503  0.99499226]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 7304. State = [[ 0.09786726 -0.23162253  0.05758769  1.        ]]. Action = [[-0.9359023   0.94684553 -0.95740163  0.9249635 ]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 7305. State = [[ 0.09786726 -0.23162253  0.05758769  1.        ]]. Action = [[-0.9565861  -0.97743684 -0.6365283   0.9093933 ]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 7306. State = [[ 0.09786726 -0.23162253  0.05758769  1.        ]]. Action = [[-0.88775826  0.5163114  -0.9687668   0.896407  ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 7307. State = [[ 0.09786726 -0.23162253  0.05758769  1.        ]]. Action = [[-0.95345944 -0.26902127 -0.6996178   0.8926431 ]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 7308. State = [[ 0.09786726 -0.23162253  0.05758769  1.        ]]. Action = [[-0.8771645  -0.07362306 -0.68218595  0.8689252 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 7309. State = [[ 0.09786726 -0.23162253  0.05758769  1.        ]]. Action = [[-0.8258916   0.55171347 -0.9866954   0.42188442]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 7310. State = [[ 0.09776955 -0.23157044  0.05758239  1.        ]]. Action = [[-0.07559168  0.02264428 -0.9890892   0.8229449 ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 7311. State = [[ 0.09776955 -0.23157044  0.05758239  1.        ]]. Action = [[-0.35869348  0.21075273 -0.7718005   0.76767564]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 7312. State = [[ 0.09776955 -0.23157044  0.05758239  1.        ]]. Action = [[ 0.18925881  0.5082185  -0.91832954  0.7691586 ]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 7313. State = [[ 0.09563422 -0.2377881   0.06648798  1.        ]]. Action = [[-0.64765495 -0.14612669  0.5428302   0.9094682 ]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 7314. State = [[ 0.09328203 -0.24417198  0.07654315  1.        ]]. Action = [[ 0.31087387 -0.83793056 -0.49011314  0.90423584]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 7315. State = [[ 0.09305342 -0.2454671   0.07901927  1.        ]]. Action = [[-0.34865344 -0.19794458 -0.9943259   0.8903971 ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 7316. State = [[ 0.086234   -0.23428766  0.07158683  1.        ]]. Action = [[-0.5316087   0.8246248  -0.76854783  0.94321537]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 7317. State = [[ 0.07295161 -0.21729045  0.06028493  1.        ]]. Action = [[-0.9829347   0.10413826 -0.9785038   0.88591695]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 7318. State = [[ 0.07211973 -0.21525978  0.05954427  1.        ]]. Action = [[-0.33838522 -0.48582685 -0.96644396  0.9368522 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 7319. State = [[ 0.0721317  -0.21469119  0.05955038  1.        ]]. Action = [[-0.82803154  0.5498483  -0.8985509   0.8684186 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 7320. State = [[ 0.07081416 -0.22522323  0.05597539  1.        ]]. Action = [[ 0.10110915 -0.777343   -0.2882359   0.9201262 ]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 7321. State = [[ 0.06897424 -0.23591666  0.05043013  1.        ]]. Action = [[-0.8412118  -0.9251169  -0.8846458   0.89360595]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 7322. State = [[ 0.06871913 -0.23716968  0.05002145  1.        ]]. Action = [[ 0.6810833  -0.11263001 -0.884016    0.8075905 ]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 7323. State = [[ 0.06877343 -0.2376202   0.05002128  1.        ]]. Action = [[ 0.97663593 -0.46822047 -0.84156775  0.92334485]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 7324. State = [[ 0.06877343 -0.2376202   0.05002128  1.        ]]. Action = [[ 0.95042634 -0.30551267 -0.5850245   0.86760116]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 7325. State = [[ 0.06877343 -0.2376202   0.05002128  1.        ]]. Action = [[-0.4505831   0.7067547  -0.8666404   0.79479575]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 7326. State = [[ 0.06877343 -0.2376202   0.05002128  1.        ]]. Action = [[ 0.97981524 -0.153036   -0.7613205   0.85604477]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 7327. State = [[ 0.06877343 -0.2376202   0.05002128  1.        ]]. Action = [[ 0.46593845  0.24049711 -0.95452857  0.93900466]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 7328. State = [[ 0.06877343 -0.2376202   0.05002128  1.        ]]. Action = [[ 0.53133917 -0.35639513 -0.55362326  0.7207258 ]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 7329. State = [[ 0.06877343 -0.2376202   0.05002128  1.        ]]. Action = [[ 0.32978106  0.75510955 -0.9931259   0.909336  ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 7330. State = [[ 0.06877343 -0.2376202   0.05002128  1.        ]]. Action = [[-0.75839335 -0.7127834  -0.93346447  0.8167472 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 7331. State = [[ 0.06877343 -0.2376202   0.05002128  1.        ]]. Action = [[ 0.6911671 -0.6296534  0.2526766  0.9061805]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 7332. State = [[ 0.06890187 -0.24655245  0.04524507  1.        ]]. Action = [[ 0.38470936 -0.6529883  -0.36213267  0.9062588 ]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 7333. State = [[ 0.06759622 -0.25802448  0.03802043  1.        ]]. Action = [[ 0.06399953 -0.26769626 -0.65893906  0.9114083 ]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 7334. State = [[ 0.06734923 -0.25911453  0.03768218  1.        ]]. Action = [[ 0.5826187  -0.09451771 -0.52913976  0.79783106]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 7335. State = [[ 0.06734923 -0.25911453  0.03768218  1.        ]]. Action = [[ 0.4005915  -0.7123541  -0.25721586  0.89442   ]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 7336. State = [[ 0.06734923 -0.25911453  0.03768218  1.        ]]. Action = [[-0.84950125  0.45281804 -0.909498    0.8777337 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 7337. State = [[ 0.06734923 -0.25911453  0.03768218  1.        ]]. Action = [[ 0.76729536  0.78506744 -0.72022796  0.837718  ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 7338. State = [[ 0.06734923 -0.25911453  0.03768218  1.        ]]. Action = [[-0.4733793  -0.81703264 -0.6723747   0.91560173]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 7339. State = [[ 0.06734923 -0.25911453  0.03768218  1.        ]]. Action = [[-0.98377234 -0.5865706  -0.9009934   0.78812563]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 7340. State = [[ 0.06734923 -0.25911453  0.03768218  1.        ]]. Action = [[-0.33323276  0.7593465  -0.9550187   0.73202825]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 7341. State = [[ 0.06734923 -0.25911453  0.03768218  1.        ]]. Action = [[-0.13671952  0.5894532  -0.23924565  0.88278794]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 7342. State = [[ 0.06734923 -0.25911453  0.03768218  1.        ]]. Action = [[ 0.6641052  -0.55010724 -0.89149517  0.9119139 ]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 7343. State = [[ 0.06734923 -0.25911453  0.03768218  1.        ]]. Action = [[ 0.33924294  0.7875109  -0.9941847   0.82612455]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 7344. State = [[ 0.06734923 -0.25911453  0.03768218  1.        ]]. Action = [[ 0.4140345  0.5841236 -0.744212   0.8345282]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 7345. State = [[ 0.06734923 -0.25911453  0.03768218  1.        ]]. Action = [[-0.92040324 -0.517484   -0.621725    0.9277104 ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 7346. State = [[ 0.06734923 -0.25911453  0.03768218  1.        ]]. Action = [[ 0.6754701   0.67409873 -0.780407    0.78333926]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 7347. State = [[ 0.06734923 -0.25911453  0.03768218  1.        ]]. Action = [[-0.6681663  -0.612765   -0.6544607   0.89654183]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 7348. State = [[ 0.06744738 -0.26485705  0.04068647  1.        ]]. Action = [[-0.3797679  -0.16489291  0.4034847   0.8801317 ]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 7349. State = [[ 0.06935222 -0.27358615  0.04548465  1.        ]]. Action = [[ 0.3716843  -0.36696333  0.18450963  0.8684063 ]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 7350. State = [[ 0.0714873  -0.280419    0.04980514  1.        ]]. Action = [[-0.25386775 -0.88820136 -0.70626307  0.89271116]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 7351. State = [[ 0.07098403 -0.28247803  0.05077569  1.        ]]. Action = [[-0.79476774  0.8273418  -0.9818178   0.94241655]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 7352. State = [[ 0.07085909 -0.28296888  0.05094139  1.        ]]. Action = [[-0.1370427   0.39035082 -0.775531    0.87968516]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 7353. State = [[ 0.06900947 -0.27181464  0.04657031  1.        ]]. Action = [[-0.61250854  0.99170756 -0.39209926  0.9808624 ]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 7354. State = [[-0.26273072 -0.00873629  0.10849092  1.        ]]. Action = [[-0.15989041 -0.60602933 -0.82979476  0.77897143]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 7355. State = [[-0.25643548 -0.02133892  0.10359275  1.        ]]. Action = [[ 0.49299073 -0.68069816  0.99215686  0.49115396]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 7356. State = [[-0.23707585 -0.04839723  0.12792513  1.        ]]. Action = [[ 0.8196473 -0.7969083  0.9600544  0.9852309]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 7357. State = [[-0.20676579 -0.07562944  0.16473407  1.        ]]. Action = [[ 0.7643764  -0.6840248   0.97515607  0.9892019 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 7358. State = [[-0.17852464 -0.10532144  0.20334965  1.        ]]. Action = [[ 0.51920223 -0.78119487  0.9220034   0.9806702 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 7359. State = [[-0.1690353  -0.1277711   0.22312173  1.        ]]. Action = [[-0.53624475 -0.2007637  -0.31937337  0.88750696]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 7360. State = [[-0.1725442 -0.1352328  0.2235729  1.       ]]. Action = [[ 0.7121072  -0.0455991  -0.24887568  0.78402865]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 7361. State = [[-0.16159756 -0.14292552  0.22983259  1.        ]]. Action = [[ 0.95354915 -0.49417597  0.35724545  0.9407151 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 7362. State = [[-0.1347293  -0.15149684  0.2502051   1.        ]]. Action = [[ 0.9563973  -0.0787878   0.8426759   0.94723046]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 7363. State = [[-0.11319349 -0.15473083  0.27066574  1.        ]]. Action = [[ 0.77348614 -0.18826866 -0.8759541   0.8467895 ]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 7364. State = [[-0.10214574 -0.1593307   0.2671598   1.        ]]. Action = [[ 0.953035   -0.23795283 -0.749857    0.77163196]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 7365. State = [[-0.0673138  -0.16631104  0.26057497  1.        ]]. Action = [[ 0.8392062  -0.06712496  0.65971327  0.62986493]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 7366. State = [[-0.03762316 -0.16859531  0.26741362  1.        ]]. Action = [[ 0.9657769  -0.09347606 -0.5068223   0.4083743 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 7367. State = [[-0.00708343 -0.17645802  0.24891444  1.        ]]. Action = [[ 0.82119465 -0.3453263  -0.78662276  0.5904076 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 7368. State = [[ 0.02080537 -0.18447292  0.2252294   1.        ]]. Action = [[ 0.85942364  0.10167944 -0.856849    0.5369302 ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: No entry zone
Current timestep = 7369. State = [[ 0.02738506 -0.18734965  0.21549186  1.        ]]. Action = [[ 0.06762004 -0.09831649 -0.79473156  0.63742113]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 7370. State = [[ 0.03507318 -0.19227651  0.18809609  1.        ]]. Action = [[ 0.35231137 -0.19790542 -0.59901184  0.7857522 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 7371. State = [[ 0.04520681 -0.20601115  0.16210145  1.        ]]. Action = [[ 0.24358356 -0.6387964  -0.89299476  0.771294  ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 7372. State = [[ 0.06060808 -0.21258597  0.13108043  1.        ]]. Action = [[ 0.5120232  0.4880445 -0.6055321  0.910516 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 7373. State = [[ 0.07432999 -0.19993538  0.09970006  1.        ]]. Action = [[ 0.20187819  0.5380008  -0.99033797  0.93638074]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 7374. State = [[ 0.07763164 -0.20017347  0.06235277  1.        ]]. Action = [[-0.51318187 -0.5504936  -0.77593696  0.80189157]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 7375. State = [[ 0.07303166 -0.20516776  0.04288426  1.        ]]. Action = [[-0.64121807 -0.8716456  -0.7510491   0.63277745]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 7376. State = [[ 0.07497478 -0.20617855  0.04116414  1.        ]]. Action = [[ 0.36950123  0.3221885  -0.81987256  0.87377393]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 7377. State = [[ 0.07497478 -0.20617855  0.04116414  1.        ]]. Action = [[ 0.56612945  0.5252789  -0.8840973   0.75468135]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 7378. State = [[ 0.07497478 -0.20617855  0.04116414  1.        ]]. Action = [[ 0.68889916 -0.11277372  0.43782234  0.81909776]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 7379. State = [[ 0.07497478 -0.20617855  0.04116414  1.        ]]. Action = [[-0.7290923   0.19002676 -0.93407947  0.7647073 ]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 7380. State = [[ 0.07497478 -0.20617855  0.04116414  1.        ]]. Action = [[ 0.10638559  0.3836156  -0.97975135  0.9029497 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 7381. State = [[ 0.07497478 -0.20617855  0.04116414  1.        ]]. Action = [[ 0.94895613  0.3386767  -0.9544633   0.8725772 ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 7382. State = [[ 0.07497478 -0.20617855  0.04116414  1.        ]]. Action = [[-0.43454802  0.38040876 -0.983262    0.74965155]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 7383. State = [[ 0.07497478 -0.20617855  0.04116414  1.        ]]. Action = [[ 0.48440337  0.545532   -0.9372659   0.8664727 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 7384. State = [[ 0.07497478 -0.20617855  0.04116414  1.        ]]. Action = [[-0.76326215 -0.81316304 -0.8932705   0.68543077]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 7385. State = [[ 0.07497478 -0.20617855  0.04116414  1.        ]]. Action = [[ 0.44534218 -0.8025458  -0.5037786   0.94856167]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 7386. State = [[ 0.07497478 -0.20617855  0.04116414  1.        ]]. Action = [[-0.9763074   0.30484366 -0.9178818   0.8574618 ]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 7387. State = [[ 0.07497478 -0.20617855  0.04116414  1.        ]]. Action = [[ 0.5771167  -0.694401   -0.21152395  0.79336023]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 7388. State = [[ 0.07497478 -0.20617855  0.04116414  1.        ]]. Action = [[-0.16243905 -0.95764667 -0.43138206  0.8951876 ]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 7389. State = [[ 0.07497478 -0.20617855  0.04116414  1.        ]]. Action = [[-0.9648333  -0.12151355 -0.8192834   0.90292203]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 7390. State = [[ 0.07497478 -0.20617855  0.04116414  1.        ]]. Action = [[-0.39236045  0.6011584  -0.99090296  0.90044045]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7391. State = [[ 0.07497478 -0.20617855  0.04116414  1.        ]]. Action = [[ 0.54837584 -0.20797789 -0.42020637  0.89680135]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 7392. State = [[ 0.07497478 -0.20617855  0.04116414  1.        ]]. Action = [[ 0.88706875 -0.3614583  -0.30726177  0.8794501 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 7393. State = [[ 0.07497478 -0.20617855  0.04116414  1.        ]]. Action = [[ 0.5691513  -0.2740373  -0.8554304   0.94794345]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 7394. State = [[ 0.07497478 -0.20617855  0.04116414  1.        ]]. Action = [[ 0.9859574  -0.66755074 -0.51952064  0.8745196 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 7395. State = [[ 0.07497478 -0.20617855  0.04116414  1.        ]]. Action = [[ 0.00479615  0.23574758 -0.9913347   0.7057078 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 7396. State = [[ 0.07497478 -0.20617855  0.04116414  1.        ]]. Action = [[ 0.76192236  0.6852689  -0.54444265  0.75060594]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7397. State = [[ 0.07577526 -0.20797619  0.04616466  1.        ]]. Action = [[-0.6698898   0.18185198  0.568571    0.77657866]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 7398. State = [[ 0.07563737 -0.2104709   0.05035501  1.        ]]. Action = [[ 0.9728534   0.16451788 -0.8130926   0.86923003]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 7399. State = [[ 0.075262   -0.21063186  0.05141037  1.        ]]. Action = [[-0.5516687  0.7870971 -0.7839057  0.8658869]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7400. State = [[ 0.06912426 -0.20046572  0.04822874  1.        ]]. Action = [[-0.69505066  0.65972996 -0.18426472  0.92704725]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 7401. State = [[ 0.05536748 -0.18685864  0.04571674  1.        ]]. Action = [[ 0.9873953  -0.68476254 -0.538665    0.8522351 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 7402. State = [[ 0.05181619 -0.18518479  0.04494531  1.        ]]. Action = [[-0.03989613  0.73195195 -0.5762843   0.63966084]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7403. State = [[ 0.0504883  -0.18484454  0.04591241  1.        ]]. Action = [[ 0.7944907  -0.29794466 -0.53693295  0.5821904 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 7404. State = [[ 0.05024678 -0.18484552  0.04574865  1.        ]]. Action = [[ 0.97858953 -0.46562457 -0.94761026  0.7834616 ]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 7405. State = [[ 0.05030208 -0.18487294  0.04617797  1.        ]]. Action = [[ 0.940465   -0.62047243 -0.97864324  0.5605664 ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 7406. State = [[ 0.05012165 -0.18488742  0.04625181  1.        ]]. Action = [[ 0.5368886  0.6507642 -0.5870509  0.6918819]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7407. State = [[ 0.04981481 -0.18483867  0.0462656   1.        ]]. Action = [[ 0.84891105 -0.47496605 -0.9603093   0.79405594]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 7408. State = [[ 0.05062336 -0.18473412  0.04629343  1.        ]]. Action = [[ 0.4848721  -0.09636688 -0.20399272  0.43155098]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 7409. State = [[ 0.0508208  -0.18479067  0.04611918  1.        ]]. Action = [[ 0.7232872  -0.02541053 -0.96806616  0.7455789 ]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 7410. State = [[ 0.0508208  -0.18479067  0.04611918  1.        ]]. Action = [[-0.42914343 -0.19323635 -0.6262554   0.60318947]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 7411. State = [[ 0.0508208  -0.18479067  0.04611918  1.        ]]. Action = [[ 0.968714   0.4011879 -0.8935619  0.6278429]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7412. State = [[ 0.0508208  -0.18479067  0.04611918  1.        ]]. Action = [[ 0.31448698 -0.8062742  -0.82390857  0.6529999 ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 7413. State = [[ 0.0508208  -0.18479067  0.04611918  1.        ]]. Action = [[0.01710713 0.1456958  0.0888325  0.7705684 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: No entry zone
Current timestep = 7414. State = [[ 0.0508208  -0.18479067  0.04611918  1.        ]]. Action = [[ 0.9482852   0.82795    -0.79327226  0.6930001 ]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7415. State = [[ 0.0508208  -0.18479067  0.04611918  1.        ]]. Action = [[ 0.89247215 -0.01375234 -0.9136526   0.64500165]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 7416. State = [[ 0.04436846 -0.18945827  0.04044822  1.        ]]. Action = [[-0.68831533 -0.28321993 -0.32471228  0.77881765]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 7417. State = [[ 0.03547495 -0.19234973  0.03173311  1.        ]]. Action = [[ 0.8020878   0.35376596 -0.7316703   0.8015373 ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7418. State = [[ 0.02546455 -0.20706263  0.02961404  1.        ]]. Action = [[-0.6827744  -0.810623    0.01090598  0.40033948]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 7419. State = [[ 0.01395494 -0.23954242  0.04010031  1.        ]]. Action = [[-0.24793088 -0.8836483   0.95474935  0.40208483]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 7420. State = [[-0.00681839 -0.27771902  0.07557072  1.        ]]. Action = [[-0.9648853  -0.9354078   0.95974445  0.2385931 ]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 7421. State = [[-0.0331264  -0.2970016   0.10176259  1.        ]]. Action = [[-0.38865507 -0.92328125  0.9457073   0.31330895]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 7422. State = [[-0.03646925 -0.3032781   0.1060627   1.        ]]. Action = [[-0.3634888  -0.7908972   0.6988225   0.33364487]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 7423. State = [[-0.0370534  -0.30392712  0.10624581  1.        ]]. Action = [[-0.14610076 -0.85640377  0.5036105   0.2963562 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 7424. State = [[-0.03702446 -0.30392933  0.10626175  1.        ]]. Action = [[-0.85966814 -0.77383304  0.08321929  0.22647703]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 7425. State = [[-0.03702446 -0.30392933  0.10626175  1.        ]]. Action = [[-0.7287569  -0.7292345  -0.8706825   0.39039695]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 7426. State = [[-0.03702446 -0.30392933  0.10626175  1.        ]]. Action = [[-0.5569931  -0.14125186  0.3247919   0.2134763 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 7427. State = [[-0.03708807 -0.30392474  0.10622671  1.        ]]. Action = [[ 0.05624545 -0.6332915  -0.5248521   0.14450657]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 7428. State = [[-0.03708807 -0.30392474  0.10622671  1.        ]]. Action = [[-0.9114096  -0.8257349  -0.00687063  0.32198763]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 7429. State = [[-0.03708807 -0.30392474  0.10622671  1.        ]]. Action = [[-0.5425797 -0.6678051  0.5228896  0.3558421]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 7430. State = [[-0.03706516 -0.30392814  0.10628799  1.        ]]. Action = [[ 0.44364822 -0.9167739   0.4237343   0.16871643]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 7431. State = [[-0.03706516 -0.30392814  0.10628799  1.        ]]. Action = [[-0.6268001  -0.7011754   0.7164819   0.29657555]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 7432. State = [[-0.03706516 -0.30392814  0.10628799  1.        ]]. Action = [[-0.38904727 -0.8421461   0.7761234   0.25442815]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 7433. State = [[-0.03706516 -0.30392814  0.10628799  1.        ]]. Action = [[-0.02152365 -0.95577     0.4085021   0.253721  ]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 7434. State = [[-0.03706516 -0.30392814  0.10628799  1.        ]]. Action = [[-0.6708929  -0.6030614  -0.16471756  0.20861614]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 7435. State = [[-0.03706516 -0.30392814  0.10628799  1.        ]]. Action = [[-0.4572302  -0.9923878  -0.8382209   0.22425592]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 7436. State = [[-0.03706516 -0.30392814  0.10628799  1.        ]]. Action = [[-0.0831641  -0.45458508  0.8726218   0.29198396]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 7437. State = [[-0.03706516 -0.30392814  0.10628799  1.        ]]. Action = [[ 0.4374473  -0.50032234 -0.5038594   0.2044735 ]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 7438. State = [[-0.03706516 -0.30392814  0.10628799  1.        ]]. Action = [[-0.67671657 -0.89562017  0.90963936  0.26389563]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 7439. State = [[-0.03706516 -0.30392814  0.10628799  1.        ]]. Action = [[-0.42716306 -0.5794903   0.4267738   0.2030456 ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 7440. State = [[-0.03706516 -0.30392814  0.10628799  1.        ]]. Action = [[-0.61036843 -0.57328457 -0.44238347  0.31899524]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 7441. State = [[-0.03706516 -0.30392814  0.10628799  1.        ]]. Action = [[ 0.00168681 -0.9247241  -0.8355264   0.34122682]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 7442. State = [[-0.03706516 -0.30392814  0.10628799  1.        ]]. Action = [[-0.6943743  -0.9097449   0.8057883   0.23278403]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 7443. State = [[-0.03706516 -0.30392814  0.10628799  1.        ]]. Action = [[-0.07182783 -0.5449168   0.30269718  0.25765204]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 7444. State = [[-0.03706516 -0.30392814  0.10628799  1.        ]]. Action = [[-0.4759233  -0.37299597  0.6739607   0.22861433]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 7445. State = [[-0.03706516 -0.30392814  0.10628799  1.        ]]. Action = [[ 0.035797   -0.89145386  0.8199465   0.28623748]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 7446. State = [[-0.03706516 -0.30392814  0.10628799  1.        ]]. Action = [[ 0.46714973 -0.78460497 -0.11711514  0.32510328]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 7447. State = [[-0.03706516 -0.30392814  0.10628799  1.        ]]. Action = [[-0.56588644 -0.77872974 -0.46832818  0.3218782 ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 7448. State = [[-0.03706516 -0.30392814  0.10628799  1.        ]]. Action = [[ 0.10357475 -0.38982964 -0.8134474   0.38817525]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 7449. State = [[-0.04471231 -0.29913342  0.09970801  1.        ]]. Action = [[-0.43466103  0.46463454 -0.66655093  0.34170806]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 7450. State = [[-0.05766665 -0.29315764  0.08988836  1.        ]]. Action = [[-0.5164012  -0.8186447   0.04415953  0.22430432]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 7451. State = [[-0.05802813 -0.292769    0.08962464  1.        ]]. Action = [[ 0.01822567 -0.53743196  0.4674976   0.31977165]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 7452. State = [[-0.05822488 -0.29275197  0.08952841  1.        ]]. Action = [[-0.7116535  -0.9489282   0.19346106  0.31096387]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 7453. State = [[-0.05822488 -0.29275197  0.08952841  1.        ]]. Action = [[ 0.42148256 -0.72558796  0.69888544  0.38183522]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 7454. State = [[-0.05829446 -0.29274595  0.08949441  1.        ]]. Action = [[ 0.6617296  -0.44522452  0.71678495  0.2591046 ]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 7455. State = [[-0.05829446 -0.29274595  0.08949441  1.        ]]. Action = [[-0.66757774 -0.78634703  0.91934824  0.4124292 ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 7456. State = [[-0.25734502 -0.10541282  0.10361063  1.        ]]. Action = [[-0.24372613 -0.8571901   0.85612774  0.3839662 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 7457. State = [[-0.24780507 -0.12465428  0.09838753  1.        ]]. Action = [[ 0.7750318  -0.5419253   0.96195364  0.98133135]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 7458. State = [[-0.22995713 -0.14336132  0.12126842  1.        ]]. Action = [[ 0.3094946  -0.45785207  0.9547713   0.9726467 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 7459. State = [[-0.20932414 -0.15824066  0.1507673   1.        ]]. Action = [[ 0.728822   -0.32697362  0.49070656  0.96494555]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 7460. State = [[-0.19141778 -0.1672815   0.16491815  1.        ]]. Action = [[ 0.8739662  -0.36752647  0.35288513  0.96212995]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: No entry zone
Current timestep = 7461. State = [[-0.19032367 -0.16863896  0.16666785  1.        ]]. Action = [[0.904539   0.0468905  0.14385426 0.9617183 ]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 7462. State = [[-0.17535402 -0.17539074  0.17738195  1.        ]]. Action = [[ 0.95632005 -0.43494236  0.63485837  0.99556327]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 7463. State = [[-0.14118005 -0.18915105  0.20153153  1.        ]]. Action = [[ 0.9607899  -0.36452222  0.55264735  0.6581342 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 7464. State = [[-0.11093863 -0.20729996  0.21568005  1.        ]]. Action = [[ 0.98819375 -0.6077233  -0.7181521   0.95825887]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 7465. State = [[-0.07521549 -0.22422032  0.19656385  1.        ]]. Action = [[ 0.8943969  -0.2692654  -0.3026923   0.87758946]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 7466. State = [[-0.04540196 -0.24080038  0.1842749   1.        ]]. Action = [[ 0.86962223 -0.65277505 -0.9432417   0.81976795]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 7467. State = [[-0.01004723 -0.24626863  0.15110472  1.        ]]. Action = [[ 0.98998725  0.54024506 -0.47576606  0.58388567]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 7468. State = [[ 0.02611763 -0.23048472  0.12467477  1.        ]]. Action = [[ 0.8954499   0.78254116 -0.99090767  0.74649453]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 7469. State = [[ 0.05408818 -0.21034354  0.08717035  1.        ]]. Action = [[ 0.57517576  0.29786897 -0.9411605   0.9142258 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 7470. State = [[ 0.07880247 -0.21154468  0.04960375  1.        ]]. Action = [[ 0.58000386 -0.67954826 -0.7940837   0.929538  ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 7471. State = [[ 0.10031178 -0.22325666  0.0244626   1.        ]]. Action = [[ 0.6780828  -0.13113475 -0.8790123   0.95835733]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 7472. State = [[ 0.11167345 -0.22700365  0.02110156  1.        ]]. Action = [[ 0.4291731  -0.03448224 -0.9307934   0.9543698 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 7473. State = [[ 0.1158221  -0.22854635  0.01991865  1.        ]]. Action = [[-0.04966718  0.94200945 -0.9828206   0.93816805]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 7474. State = [[ 0.11656275 -0.22897154  0.0204399   1.        ]]. Action = [[-0.44497478 -0.9218408  -0.9311216   0.9539113 ]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 7475. State = [[ 0.11780209 -0.2295851   0.02185928  1.        ]]. Action = [[-0.0681501   0.9889426  -0.41750956  0.9107628 ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 7476. State = [[ 0.1178664  -0.2301355   0.02207878  1.        ]]. Action = [[-0.20509243 -0.90678066 -0.6912653   0.9082215 ]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 7477. State = [[ 0.11762388 -0.2303835   0.02189411  1.        ]]. Action = [[-0.62544537  0.8380308  -0.8073796   0.9232497 ]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 7478. State = [[ 0.11766994 -0.23051786  0.02165315  1.        ]]. Action = [[-0.9661526  0.8036661 -0.9295424  0.9607434]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 7479. State = [[ 0.11744099 -0.23044507  0.02144252  1.        ]]. Action = [[-0.36249948  0.02493107 -0.906085    0.90133893]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 7480. State = [[ 0.11736023 -0.23057128  0.02140926  1.        ]]. Action = [[-0.79870206  0.6117103  -0.9588923   0.9094411 ]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 7481. State = [[ 0.11736023 -0.23057128  0.02140926  1.        ]]. Action = [[-0.75500184  0.61312413 -0.42928493  0.9340179 ]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 7482. State = [[ 0.11732928 -0.23056374  0.02133423  1.        ]]. Action = [[ 0.8086724   0.10919654 -0.900464    0.9403472 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 7483. State = [[ 0.11728608 -0.23072724  0.02136574  1.        ]]. Action = [[-0.987663   -0.9765613  -0.98700136  0.8856406 ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 7484. State = [[ 0.11722856 -0.23094484  0.02140779  1.        ]]. Action = [[-0.286304    0.17013705 -0.97941893  0.8237262 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 7485. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.385567   -0.09993941 -0.6851946   0.9109454 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 7486. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.97849905 -0.3771875  -0.9385811   0.85875237]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 7487. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.6705155  -0.24152613 -0.9695275   0.96260977]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 7488. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.5701728   0.36784577 -0.99284303  0.93386734]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 7489. State = [[ 0.11725976 -0.23084705  0.02142964  1.        ]]. Action = [[ 0.86379254 -0.966461   -0.9056595   0.9054887 ]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 7490. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.6133972 -0.7997965 -0.6605573  0.9689598]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 7491. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.468359    0.6760638  -0.65281516  0.9482558 ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 7492. State = [[ 0.11725976 -0.23084705  0.02142964  1.        ]]. Action = [[ 0.43251562  0.2655921  -0.8387345   0.7568412 ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 7493. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.8380748 -0.9052989 -0.8453007  0.9237442]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 7494. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.9911301   0.21888518 -0.89132637  0.7445266 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 7495. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.09598851 -0.16840613 -0.29721463  0.903332  ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 7496. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.47806358  0.87552404 -0.5794509   0.85225904]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 7497. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.38518333 -0.4979155  -0.56560904  0.82863307]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 7498. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.8311212 -0.7882902 -0.6920303  0.9659184]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 7499. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.93468606 -0.7142111  -0.5296895   0.9629376 ]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 7500. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.59378695  0.6571821  -0.30263186  0.9057565 ]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 7501. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.43652368  0.8673651  -0.962959    0.91243625]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 7502. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.9844703  0.8002269 -0.8833955  0.9571712]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 7503. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.89076567  0.38124955 -0.98380303  0.92951345]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 7504. State = [[ 0.11725976 -0.23084705  0.02142964  1.        ]]. Action = [[ 0.5770726   0.74041116 -0.96665305  0.7715068 ]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 7505. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.9853021   0.7037914  -0.97233284  0.7668779 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 7506. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.12736082 -0.38321352 -0.86058676  0.8567147 ]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 7507. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.44353056  0.5305028  -0.66181886  0.9606757 ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 7508. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.34392655 -0.0049482  -0.93147826  0.9022653 ]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 7509. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.6189352   0.99013376 -0.8304223   0.97394145]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 7510. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.9917315   0.89528847  0.01030123  0.83944845]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 7511. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.09186411  0.55252385 -0.24394554  0.94867516]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 7512. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.7419534  -0.0393579  -0.82730573  0.9057448 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 7513. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.5303273  -0.3492626   0.03236353  0.93603396]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 7514. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.0620634   0.6703119  -0.9012883   0.94088054]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 7515. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.93150723 -0.99024737 -0.9898116   0.91284335]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 7516. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.9959311   0.11130166 -0.73260576  0.9858558 ]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 7517. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.32114375  0.1406213  -0.96413577  0.7296319 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 7518. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.32943112  0.21562457 -0.98319596  0.9240005 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 7519. State = [[ 0.11725976 -0.23084705  0.02142964  1.        ]]. Action = [[-0.0860815  0.5911164 -0.8753422  0.9548397]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 7520. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.68257755 -0.9160424  -0.9881625   0.82711506]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 7521. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.6369851   0.457662    0.00741088  0.9725299 ]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 7522. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.9868231   0.5375273  -0.97552747  0.9727944 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 7523. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.22207469  0.9978051  -0.8697826   0.9449202 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 7524. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.64096093 -0.29308188 -0.79163873  0.9680244 ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 7525. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.8570789   0.37339687 -0.887436    0.84207535]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 7526. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.24457747 -0.9882406  -0.9946926   0.9481685 ]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 7527. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.2945112   0.3836658  -0.98121077  0.8168459 ]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 7528. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.81521535 -0.7051911  -0.78802294  0.88424397]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 7529. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.96891296  0.6853299  -0.9143433   0.98964524]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 7530. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.93730533 -0.26748407 -0.70596945  0.94556546]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 7531. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.53216374 -0.7119553  -0.7157594   0.89449   ]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 7532. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.8967409   0.8660896  -0.23775816  0.63566923]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 7533. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.79592705 -0.34066498 -0.9827005   0.96189165]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 7534. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.9222063   0.70799756 -0.9656764   0.9425398 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 7535. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.60973525  0.7253102  -0.8581203   0.95711243]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 7536. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.5914326  0.3259194 -0.9739124  0.9467976]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 7537. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.11881161  0.25314474 -0.90078473  0.8674593 ]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 7538. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.21730328 -0.14881623 -0.4211796   0.9055532 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 7539. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.6108421  -0.98609746 -0.82041204  0.9782082 ]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 7540. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.211173   -0.96752906 -0.9013271   0.9547212 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 7541. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[0.94806504 0.0375104  0.75315106 0.9711565 ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 7542. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.33014524  0.9368751  -0.6960619   0.89664936]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 7543. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.6467552  -0.801007    0.17044902  0.986362  ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 7544. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.46129966  0.7546686  -0.43442714  0.95280254]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 7545. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.1260364   0.8985295  -0.94028175  0.8565514 ]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 7546. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.2488296  -0.5114733  -0.74482113  0.90483975]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 7547. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.9015717   0.8056724  -0.88242173  0.93015194]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 7548. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.62754184  0.9601879  -0.7532936   0.92573726]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 7549. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.63140446  0.79651165 -0.9236538   0.8450184 ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 7550. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.43578362 -0.5529347  -0.9717332   0.68637466]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 7551. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[-0.45874697  0.9574988  -0.64055336  0.9894004 ]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 7552. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.73140156  0.931257   -0.80207896  0.90904534]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 7553. State = [[ 0.11723631 -0.23086098  0.02140775  1.        ]]. Action = [[ 0.5096357  0.9954896 -0.9746943  0.8289062]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 7554. State = [[ 0.11615432 -0.24676342  0.02865562  1.        ]]. Action = [[-0.4446118 -0.902597   0.5965669  0.9688641]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 7555. State = [[ 0.11394988 -0.2632114   0.03759626  1.        ]]. Action = [[ 0.6573372   0.95731115 -0.99467677  0.9404968 ]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 7556. State = [[ 0.11376495 -0.26667574  0.04025646  1.        ]]. Action = [[-0.5577172   0.70733523 -0.570223    0.99064755]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 7557. State = [[ 0.11427781 -0.26649186  0.04081193  1.        ]]. Action = [[ 0.854192   0.9866121 -0.2038989  0.9722712]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 7558. State = [[-0.261688   -0.08540528  0.11115713  1.        ]]. Action = [[-0.84427     0.12376416 -0.69838536  0.9817021 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 7559. State = [[-0.25233182 -0.09930782  0.10400303  1.        ]]. Action = [[ 0.82213485 -0.29919958  0.9642658   0.98946214]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 7560. State = [[-0.22941746 -0.11424316  0.12783918  1.        ]]. Action = [[ 0.8190477  -0.5859399   0.97673154  0.9895828 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 7561. State = [[-0.19684386 -0.13728757  0.16299424  1.        ]]. Action = [[ 0.91410446 -0.670757    0.8354958   0.9917327 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 7562. State = [[-0.170875   -0.15410267  0.18583964  1.        ]]. Action = [[ 0.9676578  -0.7712206   0.97688305  0.9899068 ]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: No entry zone
Current timestep = 7563. State = [[-0.16866888 -0.15779068  0.18858834  1.        ]]. Action = [[ 0.9767859  -0.3043238   0.20256281  0.96045494]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 7564. State = [[-0.1684988  -0.15819561  0.18887988  1.        ]]. Action = [[ 0.94921994 -0.2147125  -0.78032374  0.966087  ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 7565. State = [[-0.1686916  -0.15830866  0.18895791  1.        ]]. Action = [[ 0.9920248  -0.21376717  0.90535223  0.87861943]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 7566. State = [[-0.1686916  -0.15830866  0.18895791  1.        ]]. Action = [[ 0.9405103  -0.32911873  0.2667228   0.9701866 ]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 7567. State = [[-0.1686916  -0.15830866  0.18895791  1.        ]]. Action = [[ 0.97059035 -0.23770273  0.923573    0.9491515 ]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 7568. State = [[-0.1686916  -0.15830866  0.18895791  1.        ]]. Action = [[ 0.94513416 -0.39722466  0.76654696  0.92053676]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 7569. State = [[-0.1686916  -0.15830866  0.18895791  1.        ]]. Action = [[ 0.94078994 -0.39616972  0.8619163   0.9226005 ]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 7570. State = [[-0.1686916  -0.15830866  0.18895791  1.        ]]. Action = [[0.90338206 0.33787763 0.589241   0.9052434 ]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: No entry zone
Current timestep = 7571. State = [[-0.1686916  -0.15830866  0.18895791  1.        ]]. Action = [[ 0.982198   -0.2941302  -0.5285441   0.87788844]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: No entry zone
Current timestep = 7572. State = [[-0.15563206 -0.16585137  0.19096132  1.        ]]. Action = [[ 0.9238312  -0.51850873 -0.17587304  0.96531546]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 7573. State = [[-0.12424631 -0.18184908  0.20338163  1.        ]]. Action = [[ 0.9644091  -0.47602302  0.6838541   0.93546414]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 7574. State = [[-0.09436437 -0.19418083  0.21562137  1.        ]]. Action = [[ 0.8215215  -0.15557611 -0.41825175  0.7862861 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 7575. State = [[-0.07046648 -0.20023598  0.20745449  1.        ]]. Action = [[ 0.8963227   0.38421178 -0.5923105   0.7956443 ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: No entry zone
Current timestep = 7576. State = [[-0.06518527 -0.20121512  0.20863874  1.        ]]. Action = [[ 0.97098243  0.71197486 -0.95495516  0.8613188 ]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: No entry zone
Current timestep = 7577. State = [[-0.06009087 -0.20227832  0.20470472  1.        ]]. Action = [[ 0.9785944  -0.20215589 -0.9023924   0.6627469 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 7578. State = [[-0.02517465 -0.20679313  0.17470685  1.        ]]. Action = [[ 0.9860568   0.09853756 -0.25759286  0.73617566]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 7579. State = [[ 0.01177487 -0.20046271  0.15486021  1.        ]]. Action = [[ 0.9460881   0.42290318 -0.8285274   0.34107637]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 7580. State = [[ 0.0431654  -0.18801522  0.12440159  1.        ]]. Action = [[ 0.6277807   0.4331665  -0.43575978  0.4690025 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 7581. State = [[ 0.07807458 -0.17576188  0.11418347  1.        ]]. Action = [[0.9922726  0.16209388 0.21612549 0.838514  ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 7582. State = [[ 0.10566516 -0.17314093  0.11530004  1.        ]]. Action = [[ 0.81688225  0.33921742 -0.8681086   0.8891351 ]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7583. State = [[ 0.1162326  -0.17359066  0.11510961  1.        ]]. Action = [[ 0.06583583  0.67983925 -0.84626406  0.8289821 ]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7584. State = [[ 0.11864784 -0.17376286  0.11721457  1.        ]]. Action = [[ 0.4886657  -0.32920694 -0.9651639   0.84263587]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 7585. State = [[ 0.11929944 -0.1739088   0.11832116  1.        ]]. Action = [[ 0.06367147 -0.22403151 -0.7636749   0.91027856]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 7586. State = [[ 0.11915027 -0.17402397  0.11815602  1.        ]]. Action = [[-0.6990095  -0.04675728 -0.976825    0.69104195]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: No entry zone
Current timestep = 7587. State = [[ 0.11915027 -0.17402397  0.11815602  1.        ]]. Action = [[ 0.24589336 -0.22823727 -0.9357326   0.88604677]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 7588. State = [[ 0.1138691  -0.1800624   0.10958161  1.        ]]. Action = [[-0.4204206  -0.40868556 -0.87557673  0.86957145]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 7589. State = [[ 0.10944618 -0.18623786  0.08765941  1.        ]]. Action = [[ 0.01936018 -0.63883656 -0.9791875   0.82374024]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 7590. State = [[ 0.10872016 -0.18782586  0.0870175   1.        ]]. Action = [[ 0.45562494  0.9664438  -0.73562306  0.9076059 ]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7591. State = [[ 0.10861334 -0.18803144  0.08686098  1.        ]]. Action = [[-0.3278998   0.79522157 -0.97999775  0.9449055 ]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: No entry zone
Current timestep = 7592. State = [[ 0.10845851 -0.188393    0.08675567  1.        ]]. Action = [[-0.40883517  0.75006604 -0.990072    0.9290912 ]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: No entry zone
Current timestep = 7593. State = [[ 0.10845851 -0.188393    0.08675567  1.        ]]. Action = [[-0.28741056  0.9643562  -0.74979126  0.93660915]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: No entry zone
Current timestep = 7594. State = [[ 0.10845851 -0.188393    0.08675567  1.        ]]. Action = [[ 0.3134266 -0.5228032 -0.9106935  0.7509843]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 7595. State = [[ 0.10100573 -0.19597602  0.07651506  1.        ]]. Action = [[-0.6590563  -0.47014087 -0.93880254  0.95664155]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 7596. State = [[ 0.09378899 -0.20410483  0.05223273  1.        ]]. Action = [[ 0.32968736  0.49438465 -0.889013    0.9360211 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7597. State = [[ 0.09340637 -0.20552012  0.05090982  1.        ]]. Action = [[ 0.79516363  0.50079155 -0.96834326  0.94297695]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 7598. State = [[ 0.09297531 -0.2063132   0.05066963  1.        ]]. Action = [[-0.5049401  0.9221957 -0.9095013  0.8373623]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7599. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[-0.9056199  0.9686737 -0.9596858  0.8545971]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7600. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.7584957   0.8882444  -0.49319088  0.7354779 ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7601. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.9514377   0.63317347 -0.85608244  0.85336626]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7602. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[-0.6012869   0.81092036 -0.5462865   0.9697164 ]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7603. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[-0.37253416  0.97005606 -0.38400173  0.9053707 ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: No entry zone
Current timestep = 7604. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.6658267   0.6888039  -0.8754052   0.83600473]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7605. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[-0.03189749  0.22735345 -0.88176614  0.89009523]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 7606. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.60332954  0.4758246  -0.09916615  0.85293055]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 7607. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.98199606 -0.32937318 -0.9783825   0.91404533]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 7608. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.52366436  0.7294489  -0.7603751   0.52510333]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7609. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.4234953   0.60341644 -0.9379789   0.9025383 ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7610. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.2991135   0.62011504 -0.56190616  0.93471146]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7611. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.5629029   0.7476623  -0.39824963  0.9237474 ]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7612. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.5469849   0.86325717 -0.70221424  0.93789375]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7613. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.5694623   0.671121   -0.55681074  0.903672  ]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7614. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.46725821  0.83364654 -0.9454494   0.9256818 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7615. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.88537335  0.6520808  -0.9682909   0.9775853 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7616. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.97166145 -0.5848368  -0.81769085  0.896224  ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 7617. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.13631594  0.6185787  -0.70074815  0.90512705]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7618. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.14267182  0.9417912  -0.9755579   0.94716024]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7619. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.6340107  -0.18949652  0.49250662  0.976805  ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 7620. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.44557488 -0.40606284  0.0522573   0.9738052 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 7621. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.9769819   0.92011976 -0.99313533  0.8588407 ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7622. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.9721341   0.95276666 -0.17947602  0.8969884 ]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7623. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[-0.5927019   0.80489063 -0.8691458   0.94295454]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7624. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.8543079   0.42733133 -0.71869814  0.9484422 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 7625. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.6966754   0.43471873 -0.50954145  0.9484713 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 7626. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.9649612   0.7470877  -0.92744654  0.9603983 ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7627. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.8645241   0.4391216  -0.71184456  0.85103965]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 7628. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.8090029   0.7631645  -0.79976606  0.88760364]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7629. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.280586    0.96712756 -0.5417357   0.84275055]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7630. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[-0.20713693  0.12705886 -0.97670394  0.9614723 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 7631. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.5126803   0.67285955 -0.93882066  0.8796835 ]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7632. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.8368633   0.14474142 -0.9887082   0.9291167 ]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 7633. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.7225449   0.8063948  -0.91227     0.96940255]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7634. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[-0.0785408   0.81807566 -0.9634291   0.8595545 ]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7635. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.17640567  0.8803284  -0.7916002   0.8791473 ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7636. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.18216622  0.88210523 -0.88554865  0.8529872 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7637. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.05939734  0.48425102 -0.9172154   0.8573296 ]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 7638. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.5917909  0.9336386 -0.9784563  0.8290354]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7639. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.09442317  0.8326564  -0.8651735   0.94189835]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7640. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.12619054  0.8823432  -0.9305781   0.9701712 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7641. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.47519803  0.59163177 -0.9297652   0.97171164]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7642. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.24408591  0.6279329  -0.8803044   0.9201093 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7643. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.8048185   0.21868229 -0.98463994  0.9302664 ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 7644. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.2307893  0.9002423 -0.8862592  0.9268968]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7645. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.9595928   0.92905796 -0.9626912   0.9096366 ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7646. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.93864524  0.33186734 -0.6819408   0.8449956 ]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 7647. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.92661905  0.68480015 -0.70110416  0.9824579 ]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7648. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.92524767 -0.53397    -0.96363395  0.949983  ]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 7649. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.77027035  0.6189598  -0.9517997   0.8489218 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7650. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.07171178  0.40972924 -0.6728292   0.9312513 ]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 7651. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.7942221   0.9151108  -0.59398973  0.8117237 ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7652. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.5710803   0.9681449  -0.5752346   0.86272514]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7653. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.85064936  0.98306227 -0.5315001   0.9531977 ]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7654. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[-0.55214155  0.86077976 -0.98388314  0.82329035]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7655. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.9387944  -0.2108283  -0.9078465   0.84520936]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 7656. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.8967961   0.96752286 -0.98619753  0.9520415 ]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7657. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.3152734   0.4899826  -0.21669608  0.91422904]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 7658. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.7672503   0.853899   -0.95552313  0.9379624 ]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7659. State = [[ 0.0930104  -0.20648113  0.05077393  1.        ]]. Action = [[ 0.9777787  -0.44645035  0.13564873  0.88031006]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 7660. State = [[-0.25875437 -0.1324162   0.1099154   1.        ]]. Action = [[ 0.6038194   0.82193017 -0.70307106  0.9482286 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7661. State = [[-0.25790343 -0.14912874  0.10193757  1.        ]]. Action = [[ 0.01877272 -0.16553289  0.8523642   0.9866799 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 7662. State = [[-0.25331992 -0.1578014   0.11837873  1.        ]]. Action = [[ 0.19335186 -0.33784783  0.66078377  0.9799814 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 7663. State = [[-0.24130122 -0.17081924  0.14759706  1.        ]]. Action = [[ 0.7686753  -0.41440952  0.9786086   0.95927143]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 7664. State = [[-0.21345815 -0.18074384  0.17559822  1.        ]]. Action = [[ 0.9065449  -0.18268532  0.21811938  0.9449228 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 7665. State = [[-0.18080084 -0.1878411   0.1946706   1.        ]]. Action = [[0.8485124  0.04526114 0.6038903  0.928357  ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 7666. State = [[-0.14977759 -0.18819094  0.20373914  1.        ]]. Action = [[ 0.9084562   0.11189723 -0.669014    0.9217725 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 7667. State = [[-0.11564691 -0.18100743  0.2069005   1.        ]]. Action = [[0.96056557 0.4247911  0.8523809  0.94682956]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 7668. State = [[-0.09089331 -0.17541037  0.22537225  1.        ]]. Action = [[ 0.86406016  0.40352607 -0.6615336   0.88769627]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 7669. State = [[-0.08248253 -0.17331736  0.22173336  1.        ]]. Action = [[ 0.81121373 -0.17278624 -0.9701221   0.70317674]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 7670. State = [[-0.05953687 -0.17699708  0.1982319   1.        ]]. Action = [[ 0.87488544  0.02517104 -0.6566636   0.7368139 ]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 7671. State = [[-0.05548379 -0.17812426  0.19386223  1.        ]]. Action = [[ 0.838951    0.23759675 -0.23729616  0.4881568 ]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 7672. State = [[-0.04244561 -0.17958862  0.1991715   1.        ]]. Action = [[ 0.97263193 -0.11618954  0.26388907  0.819011  ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 7673. State = [[-0.01586084 -0.1811076   0.19865175  1.        ]]. Action = [[ 0.8088001  -0.02034521 -0.4542483   0.3369832 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 7674. State = [[ 0.01599491 -0.18303023  0.18059698  1.        ]]. Action = [[ 0.91148543 -0.02787209 -0.47573602  0.64193726]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 7675. State = [[ 0.04401214 -0.18599163  0.165549    1.        ]]. Action = [[ 0.99402595  0.08441138 -0.24863446  0.7122748 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: No entry zone
Current timestep = 7676. State = [[ 0.05370506 -0.187168    0.16530232  1.        ]]. Action = [[ 0.95187426  0.68975174 -0.9309617   0.64998484]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: No entry zone
Current timestep = 7677. State = [[ 0.05352048 -0.18742569  0.16509882  1.        ]]. Action = [[0.8084457  0.45279193 0.35758924 0.8120961 ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: No entry zone
Current timestep = 7678. State = [[ 0.05347332 -0.18745188  0.16505562  1.        ]]. Action = [[ 0.6497576   0.71120477 -0.8254178   0.84752476]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: No entry zone
Current timestep = 7679. State = [[ 0.05345638 -0.18744838  0.16498688  1.        ]]. Action = [[ 0.5891743   0.64173317 -0.9606809   0.80457854]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: No entry zone
Current timestep = 7680. State = [[ 0.05345638 -0.18744838  0.16498688  1.        ]]. Action = [[0.95063305 0.6588801  0.14038229 0.67707586]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7681. State = [[ 0.0534302  -0.18743922  0.16498542  1.        ]]. Action = [[ 0.8607459   0.6813656  -0.70301855  0.82769275]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: No entry zone
Current timestep = 7682. State = [[ 0.05340656 -0.18745236  0.16496377  1.        ]]. Action = [[0.9678006  0.10814095 0.7995672  0.7781627 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 7683. State = [[ 0.05340656 -0.18745236  0.16496377  1.        ]]. Action = [[ 0.4126327   0.5218551  -0.21588463  0.82821727]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: No entry zone
Current timestep = 7684. State = [[ 0.05340656 -0.18745236  0.16496377  1.        ]]. Action = [[ 0.87017107  0.30899143 -0.07218575  0.8048811 ]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: No entry zone
Current timestep = 7685. State = [[ 0.05333037 -0.18534334  0.1599676   1.        ]]. Action = [[ 0.5860176  -0.08752429 -0.95753646  0.7715092 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 7686. State = [[ 0.06923224 -0.18717112  0.13230462  1.        ]]. Action = [[ 0.8730687   0.34509718 -0.67860186  0.8215463 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: No entry zone
Current timestep = 7687. State = [[ 0.0784172  -0.18900499  0.12691873  1.        ]]. Action = [[ 0.5275065   0.21178079 -0.9463533   0.91835356]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: No entry zone
Current timestep = 7688. State = [[ 0.07819331 -0.18892619  0.12681179  1.        ]]. Action = [[0.80968094 0.7042748  0.03108418 0.81045985]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7689. State = [[ 0.07819331 -0.18892619  0.12681179  1.        ]]. Action = [[ 0.4823904   0.8075123  -0.73523337  0.9328959 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7690. State = [[ 0.07819331 -0.18892619  0.12681179  1.        ]]. Action = [[ 0.92833376  0.5529964  -0.92302155  0.81821847]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7691. State = [[ 0.07819331 -0.18892619  0.12681179  1.        ]]. Action = [[ 0.91077185  0.8124231  -0.9896352   0.765154  ]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7692. State = [[ 0.07819331 -0.18892619  0.12681179  1.        ]]. Action = [[ 0.60705066  0.85104036 -0.9163349   0.86142623]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7693. State = [[ 0.07819331 -0.18892619  0.12681179  1.        ]]. Action = [[ 0.2992885   0.8572054  -0.81015396  0.86219144]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: No entry zone
Current timestep = 7694. State = [[ 0.07819331 -0.18892619  0.12681179  1.        ]]. Action = [[ 0.77466834  0.31968808 -0.9400046   0.78318405]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7695. State = [[ 0.07819331 -0.18892619  0.12681179  1.        ]]. Action = [[-0.3068123   0.9283612  -0.02264088  0.6991062 ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: No entry zone
Current timestep = 7696. State = [[ 0.07819331 -0.18892619  0.12681179  1.        ]]. Action = [[ 0.5344578   0.29427207 -0.9605349   0.9461179 ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7697. State = [[ 0.07819331 -0.18892619  0.12681179  1.        ]]. Action = [[ 0.8293934  0.3816564 -0.9276824  0.8873539]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7698. State = [[ 0.07819331 -0.18892619  0.12681179  1.        ]]. Action = [[ 0.28910935  0.82114863 -0.8327744   0.8698096 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: No entry zone
Current timestep = 7699. State = [[ 0.07819331 -0.18892619  0.12681179  1.        ]]. Action = [[ 0.2820431   0.57827973 -0.98964095  0.81511354]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: No entry zone
Current timestep = 7700. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[ 0.83765435  0.512213   -0.6785171   0.8700495 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7701. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[-0.15925974  0.67377687 -0.19952273  0.84583616]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: No entry zone
Current timestep = 7702. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[ 0.5740839   0.05959952 -0.96573365  0.62861705]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 7703. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[ 0.96066713  0.25162494 -0.81828046  0.9293573 ]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7704. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[ 0.89229727  0.6755283  -0.30291367  0.80213857]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7705. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[ 0.93706334  0.155411   -0.87060463  0.86169946]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 7706. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[ 0.7127713  -0.29833895 -0.8274943   0.67712986]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 7707. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[ 0.79980755  0.25927997 -0.8111453   0.84985805]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7708. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[ 0.9343574   0.74528205 -0.6293046   0.8190968 ]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7709. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[ 0.98333955  0.72099245 -0.48486513  0.83461666]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7710. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[ 0.9316982   0.45587325 -0.0967679   0.87325203]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7711. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[ 0.9525167  -0.06048453 -0.9924676   0.88294077]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 7712. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[ 0.6590345  -0.12627923 -0.7952461   0.8748753 ]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 7713. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[ 0.2716434   0.42841244 -0.84870005  0.7895124 ]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: No entry zone
Current timestep = 7714. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[ 0.87393236  0.9174552  -0.9604119   0.86394644]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7715. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[ 0.91417325  0.43646204 -0.76248264  0.9016826 ]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7716. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[0.80009866 0.5657654  0.39498973 0.8583441 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7717. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[ 0.31306803  0.8744179  -0.9207757   0.83468735]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: No entry zone
Current timestep = 7718. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[ 0.6680075   0.7367933  -0.86537844  0.70391965]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7719. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[ 0.9907882   0.95184875 -0.44728148  0.82544684]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7720. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[ 0.0336889   0.9046092  -0.9582686   0.89698017]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: No entry zone
Current timestep = 7721. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[ 0.5116193  -0.43938386 -0.03504598  0.7667918 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 7722. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[ 0.3064854   0.37581825 -0.82906556  0.78550196]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: No entry zone
Current timestep = 7723. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[ 0.9017122   0.3687315  -0.69473267  0.86316276]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7724. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[ 0.2859602   0.6441647  -0.6338838   0.48639333]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: No entry zone
Current timestep = 7725. State = [[ 0.07808992 -0.18889156  0.1268064   1.        ]]. Action = [[ 0.9194181  -0.07574022  0.7876711   0.6615788 ]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 7726. State = [[ 0.07572083 -0.19295622  0.12194421  1.        ]]. Action = [[-0.06130201 -0.32589293 -0.73844445  0.77669287]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 7727. State = [[ 0.08027875 -0.19652909  0.09815996  1.        ]]. Action = [[ 0.3585099   0.08897829 -0.20583254  0.9163437 ]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 7728. State = [[ 0.0905948  -0.19771974  0.08989878  1.        ]]. Action = [[ 0.12986362  0.69982004 -0.8921642   0.8160243 ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: No entry zone
Current timestep = 7729. State = [[ 0.09059109 -0.19805436  0.08955554  1.        ]]. Action = [[0.8728895  0.6267414  0.49545705 0.9254918 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7730. State = [[ 0.09051763 -0.19803877  0.08933823  1.        ]]. Action = [[0.95963573 0.40953636 0.25987482 0.95557785]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7731. State = [[ 0.09049328 -0.1980336   0.08926626  1.        ]]. Action = [[ 0.77262187  0.4042833  -0.80124027  0.8403481 ]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7732. State = [[ 0.09049328 -0.1980336   0.08926626  1.        ]]. Action = [[0.6957016  0.8816756  0.04405558 0.8098283 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7733. State = [[ 0.09049328 -0.1980336   0.08926626  1.        ]]. Action = [[ 0.92305136  0.25776517 -0.76299876  0.8433567 ]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 7734. State = [[ 0.09049328 -0.1980336   0.08926626  1.        ]]. Action = [[ 0.95479846  0.806612   -0.43802118  0.7961254 ]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7735. State = [[ 0.09046892 -0.19802843  0.08919429  1.        ]]. Action = [[ 0.6598387   0.44184995 -0.05231529  0.7254472 ]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7736. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[ 0.9785557   0.8237865  -0.84607875  0.6512449 ]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7737. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[ 0.25059354  0.40732718 -0.5007817   0.90704393]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7738. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[ 0.98233056  0.9332068  -0.6445536   0.9022461 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7739. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[ 0.82279825  0.9621788  -0.94223076  0.8078538 ]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7740. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[ 0.9401703   0.6201997  -0.83567727  0.93098736]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7741. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[ 0.9523988   0.5061667  -0.94818395  0.85420287]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7742. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[ 0.80039406  0.7902545  -0.37632275  0.8411131 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7743. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[ 0.548028   -0.19184184 -0.5073602   0.8211471 ]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 7744. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[ 0.5684018   0.09275579 -0.65936744  0.79349446]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 7745. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[ 0.91863346  0.6563965  -0.5262811   0.8852258 ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7746. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[ 0.12635434  0.9093058  -0.81746167  0.8431628 ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: No entry zone
Current timestep = 7747. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[ 0.9836519   0.81066763 -0.7974289   0.89179564]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7748. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[0.9296473  0.7970009  0.728518   0.81497526]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7749. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[ 0.9073422  -0.05739325 -0.691792    0.86617947]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 7750. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[ 0.8497145   0.21113122 -0.8599867   0.9441993 ]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 7751. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[ 0.5718194   0.35730553 -0.66845554  0.9331105 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 7752. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[ 0.8383548   0.07178414 -0.9383099   0.96720195]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 7753. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[ 0.8298979   0.89052725 -0.9841417   0.90578413]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7754. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[ 0.641564    0.5475035  -0.96933806  0.75092196]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7755. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[ 0.8235812   0.91715646 -0.41352463  0.84791553]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7756. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[ 0.81100583  0.9807553  -0.7775899   0.77877426]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7757. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[ 0.5594988   0.5281515  -0.9852011   0.87680244]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7758. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[-0.44946283  0.48319316 -0.8790342   0.8473332 ]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: No entry zone
Current timestep = 7759. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[ 0.19602263  0.39554763 -0.94283485  0.849576  ]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 7760. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[ 0.8457868  0.2738192 -0.9268193  0.8638756]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 7761. State = [[ 0.09044433 -0.19802321  0.08912163  1.        ]]. Action = [[0.7897141  0.6243644  0.37453294 0.7702439 ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7762. State = [[-0.26210883 -0.00893245  0.11131956  1.        ]]. Action = [[ 0.93790567  0.95449185 -0.93358266  0.8706393 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7763. State = [[-0.25223577 -0.02341774  0.10346784  1.        ]]. Action = [[ 0.7068418  -0.72242427  0.7019316   0.9381529 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 7764. State = [[-0.24237192 -0.04990126  0.11973003  1.        ]]. Action = [[-0.18976152 -0.7113685   0.955304    0.9852927 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 7765. State = [[-0.23602672 -0.07551813  0.1538161   1.        ]]. Action = [[ 0.41037643 -0.640556    0.9799495   0.9777812 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 7766. State = [[-0.21556802 -0.09859057  0.18594581  1.        ]]. Action = [[ 0.8734288  -0.55712855  0.46861959  0.91484   ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 7767. State = [[-0.18410552 -0.12225278  0.20212053  1.        ]]. Action = [[ 0.83830976 -0.63207895 -0.15732312  0.98199356]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 7768. State = [[-0.16664392 -0.13668996  0.20547324  1.        ]]. Action = [[ 0.6753702  -0.5971683   0.41882348  0.9038842 ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 7769. State = [[-0.15199791 -0.14224045  0.21596827  1.        ]]. Action = [[ 0.90350103 -0.2983687   0.7957127   0.96084714]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 7770. State = [[-0.1310091  -0.1487435   0.23446617  1.        ]]. Action = [[ 0.88546777 -0.4218998  -0.8623114   0.8922715 ]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 7771. State = [[-0.12752196 -0.14980382  0.2378818   1.        ]]. Action = [[ 0.92451    -0.20423025 -0.917408    0.6489606 ]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 7772. State = [[-0.12736581 -0.15009159  0.2381001   1.        ]]. Action = [[ 0.89141417  0.0983572  -0.88144857  0.8576436 ]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 7773. State = [[-0.12724346 -0.1500635   0.23826785  1.        ]]. Action = [[ 0.9591062   0.06441915 -0.1838001   0.92749023]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 7774. State = [[-0.11487277 -0.15863675  0.24555458  1.        ]]. Action = [[ 0.9445436  -0.5502779   0.41343975  0.84585893]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 7775. State = [[-0.08234442 -0.17401129  0.25752908  1.        ]]. Action = [[ 0.94950175 -0.25903428  0.20187664  0.7430761 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 7776. State = [[-0.04978818 -0.1824117   0.25951055  1.        ]]. Action = [[ 0.8899646  -0.13592309 -0.2999612   0.7297653 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 7777. State = [[-0.01389725 -0.18359415  0.255001    1.        ]]. Action = [[0.97889495 0.266019   0.07720375 0.48041725]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 7778. State = [[ 0.01888538 -0.18925619  0.25250396  1.        ]]. Action = [[ 0.9659269  -0.49828386 -0.5403004   0.53316283]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 7779. State = [[ 0.04803009 -0.19688107  0.23581326  1.        ]]. Action = [[ 0.93977976  0.2951237  -0.6258522   0.46796596]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: No entry zone
Current timestep = 7780. State = [[ 0.06055166 -0.1916196   0.22697526  1.        ]]. Action = [[ 0.6874597   0.3394127  -0.96821725  0.56433856]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 7781. State = [[ 0.08160762 -0.18919837  0.19288567  1.        ]]. Action = [[ 0.72172487 -0.13333023 -0.76327085  0.68322897]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 7782. State = [[ 0.10847139 -0.19076884  0.16720992  1.        ]]. Action = [[ 0.13372469  0.6663885  -0.83519906  0.8044429 ]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: No entry zone
Current timestep = 7783. State = [[ 0.11735338 -0.19264954  0.16535002  1.        ]]. Action = [[ 0.25975716 -0.03773767 -0.80523187  0.78780556]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 7784. State = [[ 0.11839184 -0.19299792  0.16458787  1.        ]]. Action = [[ 0.2452836  0.9483135 -0.888349   0.8407912]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7785. State = [[ 0.11848339 -0.19296156  0.16406372  1.        ]]. Action = [[ 0.32024896  0.4475944  -0.98975223  0.8524766 ]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7786. State = [[ 0.11848339 -0.19296156  0.16406372  1.        ]]. Action = [[ 0.65230465  0.2584604  -0.9980701   0.78646517]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 7787. State = [[ 0.11848339 -0.19296156  0.16406372  1.        ]]. Action = [[-0.504482    0.50671554 -0.8895888   0.7894949 ]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: No entry zone
Current timestep = 7788. State = [[ 0.11848339 -0.19296156  0.16406372  1.        ]]. Action = [[ 0.75141776  0.91667724 -0.43003058  0.7740669 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7789. State = [[ 0.11848339 -0.19296156  0.16406372  1.        ]]. Action = [[0.6272857  0.7036942  0.5826404  0.83873713]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7790. State = [[ 0.11843208 -0.19295385  0.16383699  1.        ]]. Action = [[0.90665543 0.43559253 0.01258099 0.7525345 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7791. State = [[ 0.11843208 -0.19295385  0.16383699  1.        ]]. Action = [[ 0.5251484  -0.5302941  -0.30182016  0.65548825]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 7792. State = [[ 0.11843208 -0.19295385  0.16383699  1.        ]]. Action = [[ 0.4239831   0.24558282 -0.34411472  0.9304509 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 7793. State = [[ 0.11843208 -0.19295385  0.16383699  1.        ]]. Action = [[ 0.84279037 -0.19540632 -0.9421834   0.7978989 ]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 7794. State = [[ 0.11843208 -0.19295385  0.16383699  1.        ]]. Action = [[ 0.4208455   0.4501834  -0.73056245  0.8643882 ]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7795. State = [[ 0.11843208 -0.19295385  0.16383699  1.        ]]. Action = [[ 0.80368304  0.8351977  -0.8878801   0.72041225]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7796. State = [[ 0.11843208 -0.19295385  0.16383699  1.        ]]. Action = [[ 0.69479585 -0.18085086 -0.9421964   0.84689295]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 7797. State = [[ 0.11843208 -0.19295385  0.16383699  1.        ]]. Action = [[ 0.5147698  -0.61218405 -0.4936037   0.7812556 ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 7798. State = [[ 0.11843208 -0.19295385  0.16383699  1.        ]]. Action = [[0.81651163 0.9425031  0.88972116 0.7624409 ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7799. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[-0.12550986  0.7215979  -0.81178933  0.8699651 ]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7800. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[-0.4522698   0.72938967 -0.9825789   0.8312061 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: No entry zone
Current timestep = 7801. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[-0.442482    0.7991488  -0.9726657   0.82893395]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: No entry zone
Current timestep = 7802. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[-0.10786617  0.57367873 -0.7130514   0.7354343 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7803. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[ 0.32628882  0.53441286 -0.89587915  0.8365061 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7804. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[-0.26770222 -0.22226477 -0.912957    0.8804591 ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 7805. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[-0.4984954   0.47347307 -0.23978007  0.94481266]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: No entry zone
Current timestep = 7806. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[ 0.7197976   0.97278893 -0.09829849  0.6074505 ]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7807. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[-0.3094136   0.9157052  -0.9827475   0.81619334]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7808. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[ 0.5793493  0.2910534 -0.9073762  0.9012575]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 7809. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[ 0.4307983   0.79366064 -0.50837135  0.77187896]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7810. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[ 0.9631221   0.54891396 -0.8895868   0.76194215]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7811. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[ 0.8657236   0.2134     -0.35003245  0.88597584]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 7812. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[ 0.31593716  0.62483764 -0.27939498  0.8694482 ]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7813. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[0.5944874  0.57489586 0.04671788 0.64503765]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7814. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[-0.42381227  0.8096628  -0.9585855   0.8480208 ]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: No entry zone
Current timestep = 7815. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[ 0.9434881  -0.23634756 -0.95316046  0.9043597 ]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 7816. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[ 0.30399966 -0.628694   -0.90616775  0.90289927]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 7817. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[-0.63061863  0.548038   -0.59133714  0.89988923]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: No entry zone
Current timestep = 7818. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[-0.6062268   0.72267425 -0.8229551   0.83465624]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: No entry zone
Current timestep = 7819. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[-0.19928592 -0.36216927 -0.9256633   0.8551947 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 7820. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[ 0.68550897 -0.21280253 -0.51718783  0.83214617]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 7821. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[ 0.4279095  -0.03554416 -0.8051725   0.7741704 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 7822. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[ 0.37883723 -0.47008687 -0.9147252   0.8461677 ]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 7823. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[ 0.6550586   0.37222838 -0.93693227  0.9125253 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7824. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[ 0.6723294   0.65296435 -0.63186675  0.9114227 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7825. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[ 0.8734822  -0.08024561  0.05045986  0.9024575 ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 7826. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[ 0.9080701   0.8790095  -0.5692872   0.73109066]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7827. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[ 0.62953806  0.66504717 -0.9642456   0.7907666 ]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7828. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[ 0.24670732 -0.26687157 -0.10381258  0.8704287 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 7829. State = [[ 0.11841502 -0.19295129  0.16376165  1.        ]]. Action = [[0.8450134  0.04740334 0.14741421 0.6809726 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 7830. State = [[ 0.11839779 -0.19294871  0.16368559  1.        ]]. Action = [[ 0.2145617   0.25924957 -0.7011713   0.66856503]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 7831. State = [[ 0.11839779 -0.19294871  0.16368559  1.        ]]. Action = [[ 0.37138152  0.04636431 -0.98351985  0.8239107 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 7832. State = [[ 0.11839779 -0.19294871  0.16368559  1.        ]]. Action = [[ 0.45782328  0.49596238 -0.3431573   0.82117033]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7833. State = [[ 0.11839779 -0.19294871  0.16368559  1.        ]]. Action = [[ 0.67382073 -0.6986527  -0.51907575  0.8506696 ]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 7834. State = [[ 0.11379192 -0.1918473   0.15552     1.        ]]. Action = [[-0.6662543   0.18498445 -0.77381986  0.77560174]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 7835. State = [[ 0.11022035 -0.19117254  0.14112449  1.        ]]. Action = [[-0.3431387   0.28649056  0.11609483  0.83901906]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: No entry zone
Current timestep = 7836. State = [[ 0.10997361 -0.1911719   0.13994615  1.        ]]. Action = [[ 0.89661694 -0.16349816 -0.7311565   0.9129815 ]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 7837. State = [[ 0.10991494 -0.19116317  0.13972205  1.        ]]. Action = [[ 0.25269794  0.7971623  -0.57588536  0.5104997 ]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7838. State = [[ 0.10989524 -0.19116023  0.13964689  1.        ]]. Action = [[ 0.24085784  0.6218476  -0.96475816  0.8546562 ]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7839. State = [[ 0.10987572 -0.19115733  0.13957243  1.        ]]. Action = [[ 0.80894923  0.62064993 -0.6337536   0.8524934 ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7840. State = [[ 0.109856   -0.19115439  0.13949727  1.        ]]. Action = [[ 0.4747827 -0.311799  -0.6034135  0.897557 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 7841. State = [[ 0.109856   -0.19115439  0.13949727  1.        ]]. Action = [[ 0.7185559  0.5578182 -0.9787274  0.7818327]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7842. State = [[ 0.109856   -0.19115439  0.13949727  1.        ]]. Action = [[ 0.9279175  -0.11814505 -0.06082499  0.79763734]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 7843. State = [[ 0.109856   -0.19115439  0.13949727  1.        ]]. Action = [[ 0.43378758  0.87037134 -0.76391685  0.75647116]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7844. State = [[ 0.109856   -0.19115439  0.13949727  1.        ]]. Action = [[ 0.8603625   0.81249726 -0.8744475   0.8654629 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7845. State = [[ 0.109856   -0.19115439  0.13949727  1.        ]]. Action = [[-0.1548487 -0.1759246 -0.6199454  0.9064796]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 7846. State = [[ 0.109856   -0.19115439  0.13949727  1.        ]]. Action = [[-0.24745816  0.919744   -0.55333763  0.85376287]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: No entry zone
Current timestep = 7847. State = [[ 0.109856   -0.19115439  0.13949727  1.        ]]. Action = [[ 0.91880107  0.45637536 -0.35824144  0.8712702 ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7848. State = [[ 0.109856   -0.19115439  0.13949727  1.        ]]. Action = [[0.88652277 0.88377047 0.40700853 0.85114574]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7849. State = [[ 0.109856   -0.19115439  0.13949727  1.        ]]. Action = [[ 0.16905057  0.70824313 -0.9856624   0.80512106]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7850. State = [[ 0.109856   -0.19115439  0.13949727  1.        ]]. Action = [[ 0.8127065   0.16674757 -0.42671764  0.89969385]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 7851. State = [[ 0.109856   -0.19115439  0.13949727  1.        ]]. Action = [[ 0.5544858  -0.5516502  -0.84146154  0.83001447]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 7852. State = [[ 0.109856   -0.19115439  0.13949727  1.        ]]. Action = [[ 7.6111770e-01 -5.3310394e-04 -1.0950172e-01  9.3576288e-01]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 7853. State = [[ 0.10537632 -0.18825907  0.13078226  1.        ]]. Action = [[-0.3037727   0.20092857 -0.8084478   0.7124126 ]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 7854. State = [[ 0.10294991 -0.18667199  0.11368653  1.        ]]. Action = [[ 0.78577757 -0.3144591  -0.9358966   0.8428812 ]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 7855. State = [[ 0.10273448 -0.18642037  0.11250679  1.        ]]. Action = [[ 0.76307607 -0.24341702  0.6340575   0.6660185 ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 7856. State = [[ 0.09511843 -0.18724254  0.10019657  1.        ]]. Action = [[-0.40538    -0.05504745 -0.94748044  0.6674831 ]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 7857. State = [[ 0.09113826 -0.18801998  0.07523984  1.        ]]. Action = [[ 0.9059688 -0.5828994 -0.2192452  0.7523092]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 7858. State = [[ 0.09089982 -0.1880552   0.0737088   1.        ]]. Action = [[ 0.84490967  0.0686332  -0.09222049  0.71532226]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 7859. State = [[ 0.090845   -0.18802853  0.07351047  1.        ]]. Action = [[ 0.9011923 -0.5652038 -0.9503174  0.5750675]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 7860. State = [[ 0.09094668 -0.1880832   0.07329073  1.        ]]. Action = [[ 0.65258217 -0.23075926 -0.54619163  0.89500153]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 7861. State = [[ 0.09094668 -0.1880832   0.07329073  1.        ]]. Action = [[ 0.35357797 -0.3907349  -0.36981964  0.90865815]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 7862. State = [[ 0.09089413 -0.18807568  0.07314565  1.        ]]. Action = [[ 0.44786584  0.1944493  -0.8387917   0.66191256]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7863. State = [[ 0.09089413 -0.18807568  0.07314565  1.        ]]. Action = [[ 0.9896643   0.6239667  -0.18662572  0.7498815 ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7864. State = [[-0.26862758  0.14311682  0.12004121  1.        ]]. Action = [[ 0.84866476 -0.18902755 -0.29431665  0.6768402 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 7865. State = [[-0.25312003  0.13202739  0.12684831  1.        ]]. Action = [[ 0.9447266  -0.8511603   0.85510397  0.8952856 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 7866. State = [[-0.22516946  0.10757187  0.14535731  1.        ]]. Action = [[ 0.5871897  -0.70096576  0.76422703  0.9851644 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 7867. State = [[-0.20134613  0.08373363  0.17582439  1.        ]]. Action = [[ 0.5180769  -0.6158359   0.95237064  0.9291191 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 7868. State = [[-0.18060988  0.06183243  0.19499725  1.        ]]. Action = [[ 0.59779644 -0.5561028  -0.50115     0.9606246 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 7869. State = [[-0.17067254  0.05019951  0.19390532  1.        ]]. Action = [[ 0.32191026 -0.6607073  -0.22816622  0.92726326]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 7870. State = [[-0.16882046  0.04836359  0.19408098  1.        ]]. Action = [[ 0.24081898 -0.71867913  0.88165855  0.9603052 ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 7871. State = [[-0.16842249  0.04786875  0.1935286   1.        ]]. Action = [[ 0.9891739  -0.49066246 -0.5766632   0.9344673 ]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 7872. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.91032624 -0.60380435  0.5540041   0.91359174]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 7873. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.3989104 -0.4695958 -0.1318056  0.8441775]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 7874. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.6490514  -0.48384506 -0.12952757  0.9558556 ]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 7875. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.8025633  -0.52056044  0.6231828   0.8931303 ]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 7876. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.21963453 -0.4329759   0.80015993  0.9726975 ]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: No entry zone
Current timestep = 7877. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.2910651  -0.41967773  0.81010795  0.9370768 ]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: No entry zone
Current timestep = 7878. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.9110091  -0.51621896 -0.40131104  0.9690404 ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: No entry zone
Current timestep = 7879. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.82030904 -0.5506083   0.63197947  0.9822972 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: No entry zone
Current timestep = 7880. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.9881846  -0.6161015   0.27981257  0.8762491 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: No entry zone
Current timestep = 7881. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.2553873 -0.7782501  0.7343085  0.8991903]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: No entry zone
Current timestep = 7882. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.9656638  -0.4631189  -0.23687863  0.9120543 ]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: No entry zone
Current timestep = 7883. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.96005344 -0.5118061   0.85517406  0.9752605 ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: No entry zone
Current timestep = 7884. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.9727719  -0.4323212   0.6774311   0.93497396]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: No entry zone
Current timestep = 7885. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.7206336  -0.63515496  0.73607993  0.916955  ]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: No entry zone
Current timestep = 7886. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.9446074 -0.8280899  0.8940538  0.9598913]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: No entry zone
Current timestep = 7887. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.7324486  -0.7571295   0.18459511  0.9030485 ]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: No entry zone
Current timestep = 7888. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.7965381  -0.47548264  0.83770204  0.926895  ]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: No entry zone
Current timestep = 7889. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.9432585  -0.5362285   0.35727584  0.9190626 ]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: No entry zone
Current timestep = 7890. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.969543   -0.57104146  0.9271406   0.8878288 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: No entry zone
Current timestep = 7891. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.50315785 -0.55723006  0.6305933   0.8985667 ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: No entry zone
Current timestep = 7892. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.05527091 -0.7402124   0.32165575  0.8679757 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: No entry zone
Current timestep = 7893. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.9688487  -0.768814    0.72617674  0.9040277 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: No entry zone
Current timestep = 7894. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.8976153  -0.5526438  -0.04534632  0.8466692 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: No entry zone
Current timestep = 7895. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.85505974 -0.53764915 -0.00429124  0.98310614]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: No entry zone
Current timestep = 7896. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.45327818 -0.4510888   0.7580068   0.9161098 ]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: No entry zone
Current timestep = 7897. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.8332379 -0.7350491  0.3812058  0.7782881]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: No entry zone
Current timestep = 7898. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.41342056 -0.62593323 -0.4764105   0.9316546 ]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: No entry zone
Current timestep = 7899. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.90210414 -0.4638685   0.7888713   0.8990854 ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: No entry zone
Current timestep = 7900. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.83448637 -0.49178016  0.69911563  0.8260987 ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: No entry zone
Current timestep = 7901. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.47087884 -0.718225    0.4434775   0.97635126]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: No entry zone
Current timestep = 7902. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.9416094  -0.656119    0.5734848   0.96357465]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: No entry zone
Current timestep = 7903. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.9726095  -0.82281536  0.50828457  0.9268892 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: No entry zone
Current timestep = 7904. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.8159424  -0.69642127  0.34408474  0.90547323]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: No entry zone
Current timestep = 7905. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 3.1991923e-01 -4.3271834e-01  2.8109550e-04  8.5195231e-01]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: No entry zone
Current timestep = 7906. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.77412915 -0.6344651   0.4781872   0.94712913]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: No entry zone
Current timestep = 7907. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.6052482  -0.6519964   0.15663385  0.96052694]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: No entry zone
Current timestep = 7908. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.5203091  -0.38710594 -0.28888786  0.9297707 ]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: No entry zone
Current timestep = 7909. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.6941445  -0.63899106 -0.06673801  0.9316354 ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: No entry zone
Current timestep = 7910. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.69014347 -0.45417547  0.5008929   0.8405243 ]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: No entry zone
Current timestep = 7911. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.61915255 -0.6491358   0.3683889   0.9372437 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: No entry zone
Current timestep = 7912. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.689661   -0.5354946   0.60442066  0.93506074]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: No entry zone
Current timestep = 7913. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.03229582 -0.66675425  0.71083593  0.95490146]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: No entry zone
Current timestep = 7914. State = [[-0.16841042  0.04779788  0.19337459  1.        ]]. Action = [[ 0.652905  -0.6138775  0.396837   0.9283124]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: No entry zone
Current timestep = 7915. State = [[-0.15360628  0.03737709  0.20563273  1.        ]]. Action = [[ 0.8707814  -0.61298025  0.93766236  0.62246644]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 7916. State = [[-0.13425632  0.025868    0.2246445   1.        ]]. Action = [[ 0.9393829  -0.53567225  0.40048742  0.88733363]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: No entry zone
Current timestep = 7917. State = [[-0.13176984  0.02465205  0.22701108  1.        ]]. Action = [[ 0.85323095 -0.7786448  -0.46207023  0.8973167 ]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: No entry zone
Current timestep = 7918. State = [[-0.11925694  0.01233082  0.23732679  1.        ]]. Action = [[ 0.8890431 -0.7532303  0.582124   0.6677201]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 7919. State = [[-0.09026145 -0.01471745  0.2579077   1.        ]]. Action = [[ 0.81271553 -0.6710073   0.27512097  0.77366316]]. Reward = [0.]
Curr episode timestep = 54
Above hoop
Scene graph at timestep 7919 is [False, True, False, False, True, False, True, False, False, True]
State prediction error at timestep 7919 is tensor(0.0003, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 7919 of 1
Current timestep = 7920. State = [[-0.06761135 -0.03057068  0.26528028  1.        ]]. Action = [[ 0.02329552 -0.6007465  -0.66970485  0.46400476]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: No entry zone
Above hoop
Current timestep = 7921. State = [[-0.06132187 -0.03717501  0.26264217  1.        ]]. Action = [[ 0.54545546 -0.33876783 -0.20219874  0.35086644]]. Reward = [0.]
Curr episode timestep = 56
Above hoop
Current timestep = 7922. State = [[-0.03515059 -0.05396665  0.2712653   1.        ]]. Action = [[ 0.9088141  -0.6145344   0.6832514   0.39101446]]. Reward = [0.]
Curr episode timestep = 57
Above hoop
Current timestep = 7923. State = [[-0.00835891 -0.07532809  0.28077447  1.        ]]. Action = [[ 0.9507482  -0.5098066  -0.64783204  0.375965  ]]. Reward = [0.]
Curr episode timestep = 58
Scene graph at timestep 7923 is [False, True, False, True, False, False, True, False, False, True]
State prediction error at timestep 7923 is tensor(0.0004, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 7923 of -1
Current timestep = 7924. State = [[ 0.03331947 -0.08899907  0.25970685  1.        ]]. Action = [[ 0.82864904 -0.5469292  -0.6434233   0.23610628]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: No entry zone
Current timestep = 7925. State = [[ 0.03648302 -0.09690112  0.25700948  1.        ]]. Action = [[ 0.70398927 -0.44660127 -0.42211747  0.09949219]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 7926. State = [[ 0.05466518 -0.10457825  0.24392894  1.        ]]. Action = [[ 0.82357025 -0.29552722 -0.76155823  0.08381116]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: No entry zone
Current timestep = 7927. State = [[ 0.05960948 -0.1057035   0.2428586   1.        ]]. Action = [[ 0.83619666 -0.7046628  -0.8441053   0.02309883]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: No entry zone
Current timestep = 7928. State = [[ 0.0595316  -0.10583305  0.24278384  1.        ]]. Action = [[ 0.9171231  -0.54646784 -0.24144858  0.09319031]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7929. State = [[ 0.0595316  -0.10583305  0.24278384  1.        ]]. Action = [[ 0.7492913  -0.511389   -0.7953343   0.01067841]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: No entry zone
Current timestep = 7930. State = [[ 0.0595316  -0.10583305  0.24278384  1.        ]]. Action = [[ 0.96217144 -0.56584185 -0.9409919   0.06444538]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7931. State = [[ 0.0595316  -0.10583305  0.24278384  1.        ]]. Action = [[ 0.81745434 -0.4677282  -0.49469173  0.10550499]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7932. State = [[ 0.0595316  -0.10583305  0.24278384  1.        ]]. Action = [[ 0.9516398  -0.7533421  -0.8336292   0.11091578]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7933. State = [[ 0.05952244 -0.10583311  0.24271414  1.        ]]. Action = [[ 0.68669283 -0.7309286  -0.49619007  0.1015259 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: No entry zone
Current timestep = 7934. State = [[ 0.05952244 -0.10583311  0.24271414  1.        ]]. Action = [[ 0.6653731  -0.70287144 -0.82961446  0.09298205]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: No entry zone
Current timestep = 7935. State = [[ 0.06645287 -0.11529659  0.25007084  1.        ]]. Action = [[ 0.7179326  -0.5876619   0.45495915  0.09197569]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 7936. State = [[ 0.08408641 -0.12767619  0.25815538  1.        ]]. Action = [[ 0.7888864 -0.6742686 -0.8533153  0.0508728]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7937. State = [[ 0.08803615 -0.12902008  0.2607797   1.        ]]. Action = [[ 0.85886383 -0.5530892  -0.9053438   0.06144333]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7938. State = [[ 0.08799546 -0.12901056  0.2606333   1.        ]]. Action = [[ 0.8756249  -0.7402396  -0.53101546 -0.02904481]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 7939. State = [[ 0.08799546 -0.12901056  0.2606333   1.        ]]. Action = [[ 0.94582665 -0.6447912  -0.779751    0.00820351]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7940. State = [[ 0.08799546 -0.12901056  0.2606333   1.        ]]. Action = [[ 0.849246   -0.8161497  -0.9206389  -0.03900844]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7941. State = [[ 0.08815835 -0.12906112  0.2607      1.        ]]. Action = [[ 0.90245116 -0.62974656 -0.7016063  -0.05711973]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7942. State = [[ 0.08815104 -0.12906094  0.2606275   1.        ]]. Action = [[ 0.95299983 -0.51063913 -0.6634819   0.03207457]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7943. State = [[ 0.08815104 -0.12906094  0.2606275   1.        ]]. Action = [[ 0.9045234  -0.83297217 -0.83593255  0.05627394]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7944. State = [[ 0.08815104 -0.12906094  0.2606275   1.        ]]. Action = [[ 0.80056393 -0.7129276  -0.86832887  0.0289278 ]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7945. State = [[ 0.08815104 -0.12906094  0.2606275   1.        ]]. Action = [[ 0.8603449  -0.78278685 -0.7792959   0.05415976]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7946. State = [[ 0.08815104 -0.12906094  0.2606275   1.        ]]. Action = [[ 0.77583003 -0.6004041  -0.7832848  -0.02305818]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7947. State = [[ 0.08815104 -0.12906094  0.2606275   1.        ]]. Action = [[ 0.9122102  -0.2949677  -0.95735854  0.10788476]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7948. State = [[ 0.08815104 -0.12906094  0.2606275   1.        ]]. Action = [[ 0.93560255 -0.75931036 -0.89410955  0.03503561]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7949. State = [[ 0.08815104 -0.12906094  0.2606275   1.        ]]. Action = [[ 0.8526218  -0.8060596   0.0775125   0.07952261]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 7950. State = [[ 0.08815104 -0.12906094  0.2606275   1.        ]]. Action = [[ 0.78107214 -0.4383456  -0.80477893  0.01365793]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7951. State = [[ 0.08815104 -0.12906094  0.2606275   1.        ]]. Action = [[ 0.6122608  -0.62992096 -0.9197848   0.02011204]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7952. State = [[ 0.08815104 -0.12906094  0.2606275   1.        ]]. Action = [[ 0.88226676 -0.79141885 -0.8963751   0.03652179]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7953. State = [[ 0.08815104 -0.12906094  0.2606275   1.        ]]. Action = [[ 0.8375113  -0.7547817  -0.9078079   0.05370736]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7954. State = [[ 0.08815104 -0.12906094  0.2606275   1.        ]]. Action = [[ 0.85607433 -0.73502135 -0.92724866  0.02476215]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7955. State = [[ 0.08815104 -0.12906094  0.2606275   1.        ]]. Action = [[ 0.9271529  -0.77476037 -0.8677234   0.02503514]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7956. State = [[ 0.08815104 -0.12906094  0.2606275   1.        ]]. Action = [[ 0.85148215 -0.57233214 -0.7314889   0.04562962]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7957. State = [[ 0.08815104 -0.12906094  0.2606275   1.        ]]. Action = [[ 0.8407966  -0.6233186  -0.92066234  0.04304457]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7958. State = [[ 0.08815104 -0.12906094  0.2606275   1.        ]]. Action = [[ 0.9324502  -0.7296435  -0.8369816   0.05246174]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7959. State = [[ 0.08815104 -0.12906094  0.2606275   1.        ]]. Action = [[ 0.78041744 -0.6585237  -0.91742206  0.00499022]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7960. State = [[ 0.08815104 -0.12906094  0.2606275   1.        ]]. Action = [[ 0.7784884  -0.6494427  -0.73072153  0.07549107]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7961. State = [[ 0.08815104 -0.12906094  0.2606275   1.        ]]. Action = [[ 0.81286013 -0.70748514 -0.9737233   0.05382836]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7962. State = [[ 0.08815104 -0.12906094  0.2606275   1.        ]]. Action = [[ 0.70510983 -0.7245877  -0.6787918   0.03559506]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7963. State = [[ 0.08815104 -0.12906094  0.2606275   1.        ]]. Action = [[ 0.7357831  -0.8367189  -0.11830252  0.06191337]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 7964. State = [[ 0.08815104 -0.12906094  0.2606275   1.        ]]. Action = [[ 0.8623948  -0.60284245 -0.62155354  0.00326741]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7965. State = [[ 0.08815104 -0.12906094  0.2606275   1.        ]]. Action = [[ 0.7748029  -0.7256223  -0.9315806   0.03927553]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7966. State = [[-0.2705956   0.11355279  0.11424512  1.        ]]. Action = [[ 0.53395927 -0.68482786 -0.8037671   0.0776428 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 7967. State = [[-0.2554816   0.11588074  0.10318755  1.        ]]. Action = [[ 0.82723045 -0.77425194  0.04747224  0.9927213 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 7968. State = [[-0.23061956  0.09182619  0.11070812  1.        ]]. Action = [[ 0.7624605  -0.7734355   0.81453717  0.9832313 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 7969. State = [[-0.19877519  0.0640808   0.12944852  1.        ]]. Action = [[ 0.7822752  -0.71464705  0.78624177  0.98359585]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 7970. State = [[-0.17123467  0.03709428  0.15371218  1.        ]]. Action = [[ 0.5244653  -0.7839888   0.409773    0.98503995]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 7971. State = [[-0.15602629  0.02171767  0.1662653   1.        ]]. Action = [[ 0.8171021  -0.5468835   0.8136296   0.93971336]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 7972. State = [[-0.15431176  0.01825198  0.16815755  1.        ]]. Action = [[ 0.37862706 -0.64969116  0.96486354  0.9682541 ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 7973. State = [[-0.15431406  0.01724606  0.16850473  1.        ]]. Action = [[ 0.83519936 -0.6256739   0.01033008  0.9567802 ]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 7974. State = [[-0.15441461  0.01683356  0.1685934   1.        ]]. Action = [[ 0.80448484 -0.62948394 -0.42747402  0.9187901 ]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 7975. State = [[-0.15439732  0.01650112  0.16864662  1.        ]]. Action = [[ 0.6983677  -0.591471    0.77182674  0.8834789 ]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 7976. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.89983964 -0.34747756  0.9851502   0.93715084]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 7977. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.49390936 -0.4649601   0.7869427   0.95157933]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 7978. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.9606366  -0.57756215  0.08503509  0.9216416 ]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: No entry zone
Current timestep = 7979. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.72149813 -0.54136866  0.93681     0.9077518 ]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: No entry zone
Current timestep = 7980. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.83803344 -0.63239866  0.9598706   0.6735369 ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: No entry zone
Current timestep = 7981. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.94489264 -0.4864375   0.95385134  0.9204378 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: No entry zone
Current timestep = 7982. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.8950434  -0.6580135   0.79332376  0.9645283 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: No entry zone
Current timestep = 7983. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.8625593  -0.49110097  0.7721405   0.8991158 ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: No entry zone
Current timestep = 7984. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.8440969  -0.50612575  0.31774092  0.97545505]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: No entry zone
Current timestep = 7985. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.78119373 -0.5073659   0.36273158  0.9573462 ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: No entry zone
Current timestep = 7986. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.64232254 -0.67343473  0.9108975   0.9822862 ]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: No entry zone
Current timestep = 7987. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.21961856 -0.6882141   0.16847432  0.9590342 ]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: No entry zone
Current timestep = 7988. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.87587714 -0.5445296   0.7524514   0.979913  ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: No entry zone
Current timestep = 7989. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.76938474 -0.47135323  0.7391751   0.91553605]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: No entry zone
Current timestep = 7990. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.9186419  -0.5323129   0.6120322   0.98258996]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: No entry zone
Current timestep = 7991. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.6442466  -0.7217776   0.97499466  0.8849306 ]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: No entry zone
Current timestep = 7992. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.88686204 -0.54901016  0.3084905   0.8881862 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: No entry zone
Current timestep = 7993. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.34830558 -0.6422167   0.03703511  0.98644614]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: No entry zone
Current timestep = 7994. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.7081559  -0.48992455  0.9363136   0.93071437]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: No entry zone
Current timestep = 7995. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.9541867  -0.62851727  0.9515641   0.9423921 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: No entry zone
Current timestep = 7996. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.9359449  -0.6876585   0.5661738   0.96198344]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: No entry zone
Current timestep = 7997. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.9340863  -0.4849918   0.29862642  0.96100545]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: No entry zone
Current timestep = 7998. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.7584634  -0.59922135  0.431046    0.92167234]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: No entry zone
Current timestep = 7999. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.7286558  -0.69311136 -0.26116985  0.89758134]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: No entry zone
Current timestep = 8000. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.7459688  -0.6686531   0.64181495  0.87891984]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: No entry zone
Current timestep = 8001. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.9779594  -0.56048876 -0.1583187   0.9289973 ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: No entry zone
Current timestep = 8002. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.8311479  -0.6723064  -0.18872851  0.9764291 ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: No entry zone
Current timestep = 8003. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.9221096 -0.7692035  0.9333594  0.8825221]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: No entry zone
Current timestep = 8004. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.8610065  -0.6709018   0.74243593  0.90665543]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: No entry zone
Current timestep = 8005. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.98414433 -0.64239836  0.92910457  0.9730489 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: No entry zone
Current timestep = 8006. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.7118063  -0.7255547  -0.29280168  0.8160529 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: No entry zone
Current timestep = 8007. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.93953097 -0.6840701   0.75701976  0.9455373 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: No entry zone
Current timestep = 8008. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.69892466 -0.7565504   0.67643833  0.90640926]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: No entry zone
Current timestep = 8009. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.11550796 -0.46681154  0.60954535  0.93511915]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: No entry zone
Current timestep = 8010. State = [[-0.1543978   0.01629467  0.16868651  1.        ]]. Action = [[ 0.9560342  -0.6855337  -0.0308122   0.95749307]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: No entry zone
Current timestep = 8011. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.6228168  -0.55433816  0.85456324  0.931396  ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: No entry zone
Current timestep = 8012. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.33271348 -0.5038118   0.21153641  0.9706856 ]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: No entry zone
Current timestep = 8013. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.36464524 -0.41015053 -0.4908123   0.79014826]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: No entry zone
Current timestep = 8014. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.50834346 -0.6804445   0.8570396   0.96907544]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: No entry zone
Current timestep = 8015. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.43733597 -0.6713437   0.23457444  0.7236433 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: No entry zone
Current timestep = 8016. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.10830522 -0.71254027  0.9253483   0.9154961 ]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: No entry zone
Current timestep = 8017. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.60476303 -0.6283444   0.44152808  0.86818254]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: No entry zone
Current timestep = 8018. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.795913   -0.61717206  0.9740007   0.8658314 ]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: No entry zone
Current timestep = 8019. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.64009833 -0.35100496  0.8890128   0.93797684]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: No entry zone
Current timestep = 8020. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.38221633 -0.5752102   0.5885253   0.8231132 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: No entry zone
Current timestep = 8021. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.77609205 -0.63743025  0.32118654  0.87007356]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: No entry zone
Current timestep = 8022. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.41099072 -0.7954869   0.1302042   0.93045616]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: No entry zone
Current timestep = 8023. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.8960681 -0.4390204  0.9566362  0.9606478]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: No entry zone
Current timestep = 8024. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.74278235 -0.64987034  0.86515427  0.9885684 ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: No entry zone
Current timestep = 8025. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.8027599  -0.66270036  0.929495    0.9685085 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: No entry zone
Current timestep = 8026. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.84904504 -0.81466913  0.93436337  0.9530573 ]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: No entry zone
Current timestep = 8027. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.8588977  -0.43444407  0.7436938   0.8978424 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: No entry zone
Current timestep = 8028. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.96982217 -0.56407505  0.934674    0.84757876]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: No entry zone
Current timestep = 8029. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.7526555  -0.4145097   0.87722003  0.9342966 ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: No entry zone
Current timestep = 8030. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.56481266 -0.518873    0.9780519   0.90529716]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: No entry zone
Current timestep = 8031. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.8438616  -0.39086956  0.72198176  0.98590064]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: No entry zone
Current timestep = 8032. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.9280441  -0.5610513   0.43033338  0.97816956]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: No entry zone
Current timestep = 8033. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.73253596 -0.5957842   0.9665184   0.94321537]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: No entry zone
Current timestep = 8034. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.8246014  -0.14790201  0.8519528   0.8782463 ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: No entry zone
Current timestep = 8035. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.7917427 -0.435632   0.7919011  0.9748248]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: No entry zone
Current timestep = 8036. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.79389834 -0.28379852  0.66613436  0.91725135]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: No entry zone
Current timestep = 8037. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.04134476 -0.7535405   0.5725796   0.9005039 ]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: No entry zone
Current timestep = 8038. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.93389916 -0.659506    0.10893369  0.9801016 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: No entry zone
Current timestep = 8039. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.85437274 -0.73914015 -0.24994749  0.83643687]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: No entry zone
Current timestep = 8040. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.57299006 -0.49893075  0.23206198  0.9371767 ]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: No entry zone
Current timestep = 8041. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.9247589 -0.6779643  0.9411628  0.8621006]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: No entry zone
Current timestep = 8042. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.9205195  -0.45095372 -0.08345467  0.9113978 ]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: No entry zone
Current timestep = 8043. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.8692465  -0.71164435  0.75232327  0.8166938 ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: No entry zone
Current timestep = 8044. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.5278065  -0.52535975  0.5427511   0.9661546 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: No entry zone
Current timestep = 8045. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.9187827  -0.7995821   0.28481698  0.90879536]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: No entry zone
Current timestep = 8046. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.89915776 -0.7109521   0.94071627  0.9488909 ]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: No entry zone
Current timestep = 8047. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.56708646 -0.5710888  -0.7078248   0.9289082 ]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: No entry zone
Current timestep = 8048. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.77190554 -0.6258526   0.55399203  0.8994292 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: No entry zone
Current timestep = 8049. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.9302285  -0.662592    0.9330735   0.90553474]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: No entry zone
Current timestep = 8050. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.9405415  -0.7639412   0.34142303  0.96593356]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: No entry zone
Current timestep = 8051. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.7331705  -0.71886295  0.3497349   0.8854209 ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: No entry zone
Current timestep = 8052. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.6972697  -0.6534592   0.13497281  0.9041774 ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: No entry zone
Current timestep = 8053. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.8778949  -0.63077796  0.11620569  0.95408416]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: No entry zone
Current timestep = 8054. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.62736917 -0.71047753  0.48990893  0.85392976]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: No entry zone
Current timestep = 8055. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.7179532 -0.5568923  0.8716564  0.8676877]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: No entry zone
Current timestep = 8056. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.2676531  -0.80354524 -0.02620602  0.9656875 ]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: No entry zone
Current timestep = 8057. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.4913714  -0.5592744   0.36130512  0.9242542 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: No entry zone
Current timestep = 8058. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.51202583 -0.6474901   0.6187333   0.97533   ]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: No entry zone
Current timestep = 8059. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.8996699  -0.6088006   0.69057226  0.93979645]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: No entry zone
Current timestep = 8060. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.65256095 -0.6084182   0.76601696  0.9587195 ]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: No entry zone
Current timestep = 8061. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.836995   -0.57488555  0.6762459   0.84778714]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: No entry zone
Current timestep = 8062. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.84375334 -0.57969457 -0.11435395  0.96287346]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: No entry zone
Current timestep = 8063. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.39826643 -0.5159307  -0.09346235  0.9207058 ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: No entry zone
Current timestep = 8064. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.41632736 -0.59852785 -0.68035436  0.9805038 ]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: No entry zone
Current timestep = 8065. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.43249047 -0.6137214   0.47098255  0.89039874]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: No entry zone
Current timestep = 8066. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.776008   -0.44871175  0.3152932   0.9239056 ]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: No entry zone
Current timestep = 8067. State = [[-0.15439798  0.0162257   0.16869986  1.        ]]. Action = [[ 0.48426104 -0.5128798  -0.27305126  0.9506681 ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: No entry zone
Current timestep = 8068. State = [[-0.27119938  0.13534719  0.14523815  1.        ]]. Action = [[ 0.92612386 -0.6845913   0.04375458  0.92394257]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: No entry zone
Current timestep = 8069. State = [[-0.27016643  0.13797365  0.14525324  1.        ]]. Action = [[-0.03987348 -0.603995    0.9612489   0.9645301 ]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Current timestep = 8070. State = [[-0.27016643  0.13797365  0.14525324  1.        ]]. Action = [[-0.624677   -0.6218636   0.9725666   0.94639885]]. Reward = [0.]
Curr episode timestep = 1
Action ignored: Workspace boundary
Current timestep = 8071. State = [[-0.25442654  0.13356858  0.15401988  1.        ]]. Action = [[ 0.9375522  -0.35082865  0.98641217  0.9865649 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 8072. State = [[-0.22700825  0.11821713  0.17755024  1.        ]]. Action = [[ 0.5148289 -0.6803618  0.9588866  0.9940039]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 8073. State = [[-0.20312886  0.09618279  0.21153751  1.        ]]. Action = [[ 0.6356486  -0.5799608   0.74962664  0.97175515]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 8074. State = [[-0.18733142  0.08478252  0.23137408  1.        ]]. Action = [[ 0.8347995  -0.06473488 -0.17194802  0.9546956 ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Scene graph at timestep 8074 is [True, False, False, False, False, True, True, False, False, True]
State prediction error at timestep 8074 is tensor(0.0024, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 8074 of 1
Current timestep = 8075. State = [[-0.17573726  0.06932998  0.23946023  1.        ]]. Action = [[ 0.516032   -0.78317493  0.05031061  0.8786583 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 8076. State = [[-0.17123169  0.05665812  0.24354938  1.        ]]. Action = [[ 0.83489954 -0.5047217  -0.17742431  0.90498745]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 8077. State = [[-0.17040603  0.05364055  0.2445686   1.        ]]. Action = [[ 0.820894   -0.6711225  -0.32961214  0.74460363]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 8078. State = [[-0.16999082  0.05297958  0.24492824  1.        ]]. Action = [[ 0.6057757  -0.6553859  -0.53721887  0.9422872 ]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 8079. State = [[-0.1580786   0.04677681  0.25006208  1.        ]]. Action = [[ 0.8946711  -0.37244886  0.2524674   0.8800608 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 8080. State = [[-0.12575361  0.0333501   0.2625523   1.        ]]. Action = [[ 0.9383006  -0.41065335  0.39588225  0.93411756]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 8081. State = [[-0.0922748   0.01512749  0.27709708  1.        ]]. Action = [[ 0.91408515 -0.6089439   0.45670843  0.73280096]]. Reward = [0.]
Curr episode timestep = 12
Above hoop
Current timestep = 8082. State = [[-0.05945899 -0.00502326  0.28605998  1.        ]]. Action = [[ 0.7858212  -0.35931075 -0.25329202  0.62474775]]. Reward = [0.]
Curr episode timestep = 13
Above hoop
Current timestep = 8083. State = [[-0.03162485 -0.02552479  0.27556562  1.        ]]. Action = [[ 0.6969223  -0.6952784  -0.71110845  0.2744516 ]]. Reward = [0.]
Curr episode timestep = 14
Above hoop
Current timestep = 8084. State = [[-0.00344136 -0.05196712  0.25212303  1.        ]]. Action = [[ 0.8924645 -0.7025186 -0.6344665  0.2737881]]. Reward = [0.]
Curr episode timestep = 15
Above hoop
Current timestep = 8085. State = [[ 0.02504873 -0.06707635  0.23130871  1.        ]]. Action = [[ 0.8153871  -0.48835802 -0.90975016  0.1884067 ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: No entry zone
Current timestep = 8086. State = [[ 0.0331972  -0.06833877  0.22934584  1.        ]]. Action = [[ 0.8873439  -0.8280007  -0.79945654  0.16341162]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: No entry zone
Current timestep = 8087. State = [[ 0.0340148  -0.06912062  0.2290875   1.        ]]. Action = [[ 0.70771074 -0.5677073  -0.6020651  -0.02215445]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: No entry zone
Current timestep = 8088. State = [[ 0.03402198 -0.06927227  0.22902025  1.        ]]. Action = [[ 0.90810204 -0.7384376  -0.66029793 -0.02274019]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: No entry zone
Current timestep = 8089. State = [[ 0.03402198 -0.06927227  0.22902025  1.        ]]. Action = [[ 0.9700599  -0.6381677  -0.7469939   0.06275558]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: No entry zone
Current timestep = 8090. State = [[-0.27245855  0.10599558  0.1520034   1.        ]]. Action = [[ 0.95996046 -0.66192484  0.21712744 -0.0758056 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 8091. State = [[-0.25992084  0.11018855  0.14856443  1.        ]]. Action = [[ 0.6239631 -0.7068468  0.9713203  0.8335427]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 8092. State = [[-0.23646332  0.0899634   0.17180513  1.        ]]. Action = [[ 0.67500234 -0.61262023  0.9451411   0.9885905 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 8093. State = [[-0.20983842  0.06638443  0.20480078  1.        ]]. Action = [[ 0.68307614 -0.71152717  0.720871    0.9734421 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 8094. State = [[-0.18527976  0.04543138  0.23642127  1.        ]]. Action = [[ 0.48703337 -0.44262326  0.92292595  0.882113  ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 8095. State = [[-0.17017469  0.03427647  0.25965843  1.        ]]. Action = [[ 0.6700597 -0.468184  -0.4288026  0.8921325]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 8096. State = [[-0.1588141   0.02648114  0.27006394  1.        ]]. Action = [[ 0.6287582 -0.3515365  0.3801639  0.8138126]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 8097. State = [[-0.14276657  0.01246208  0.2843241   1.        ]]. Action = [[ 0.36371124 -0.4381386   0.04328728  0.70684266]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 8098. State = [[-0.12727621 -0.00174572  0.2875789   1.        ]]. Action = [[ 0.78245497 -0.35370678 -0.21292818  0.83856714]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 8099. State = [[-0.09878566 -0.01691653  0.29309514  1.        ]]. Action = [[ 0.6672636  -0.38298953  0.6483576   0.5533061 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 8100. State = [[-0.07936305 -0.03441038  0.31293702  1.        ]]. Action = [[ 0.00124419 -0.4987731   0.45983613  0.52726984]]. Reward = [0.]
Curr episode timestep = 9
Above hoop
Current timestep = 8101. State = [[-0.0671977  -0.04529614  0.3209232   1.        ]]. Action = [[ 0.8174689  -0.0518133  -0.1672827   0.43520498]]. Reward = [0.]
Curr episode timestep = 10
Above hoop
Current timestep = 8102. State = [[-0.0455758  -0.05025636  0.31323594  1.        ]]. Action = [[ 0.85715914 -0.09624308 -0.77157503  0.44320786]]. Reward = [0.]
Curr episode timestep = 11
Above hoop
Current timestep = 8103. State = [[-0.01788867 -0.05965634  0.29146898  1.        ]]. Action = [[ 0.15494466 -0.3879131  -0.22905475  0.36313128]]. Reward = [0.]
Curr episode timestep = 12
Above hoop
Current timestep = 8104. State = [[ 2.2407420e-04 -7.5824298e-02  2.8460357e-01  1.0000000e+00]]. Action = [[ 0.8473097  -0.5216456  -0.09090459  0.15371525]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 8105. State = [[ 0.03163872 -0.09403314  0.2906507   1.        ]]. Action = [[ 0.86243486 -0.46171546  0.69671464  0.25321126]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 8106. State = [[ 0.05627166 -0.11443572  0.29564777  1.        ]]. Action = [[ 0.7020128  -0.6088091  -0.73818195  0.18188488]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 8107. State = [[ 0.08362167 -0.13706629  0.2701536   1.        ]]. Action = [[ 0.8120818  -0.6273259  -0.587616    0.02501166]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 8108. State = [[ 0.11336226 -0.15178984  0.252197    1.        ]]. Action = [[ 0.9027358  -0.64847034 -0.5297988   0.10510969]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 8109. State = [[ 0.12322078 -0.15388355  0.2513985   1.        ]]. Action = [[ 0.6795647  -0.69463456 -0.7356903   0.26993203]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 8110. State = [[ 0.12353414 -0.15389007  0.25125936  1.        ]]. Action = [[ 0.5420401  -0.4318205  -0.8048104   0.41231823]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8111. State = [[ 0.12350775 -0.15391019  0.2511575   1.        ]]. Action = [[ 0.5662315  -0.85440725 -0.745123    0.31795645]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 8112. State = [[ 0.12350775 -0.15391019  0.2511575   1.        ]]. Action = [[ 0.8783773  -0.52133465 -0.9253644   0.39570165]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8113. State = [[ 0.12350775 -0.15391019  0.2511575   1.        ]]. Action = [[ 0.8260652  -0.70012033 -0.9339988   0.36908185]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 8114. State = [[ 0.12350775 -0.15391019  0.2511575   1.        ]]. Action = [[ 0.91054153 -0.6460054  -0.88675684  0.35360456]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 8115. State = [[ 0.12354868 -0.1538819   0.25108445  1.        ]]. Action = [[ 0.54840064 -0.67834073 -0.8730629   0.42366314]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 8116. State = [[ 0.12354868 -0.1538819   0.25108445  1.        ]]. Action = [[ 0.8002348 -0.8284797 -0.4796666  0.3901527]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 8117. State = [[ 0.12350433 -0.15389434  0.25105783  1.        ]]. Action = [[ 0.8079871  -0.8209841  -0.2648803   0.36393583]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 8118. State = [[ 0.12410969 -0.15414284  0.25134316  1.        ]]. Action = [[ 0.4251367  -0.64499336 -0.48635155  0.3827691 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 8119. State = [[ 0.12598187 -0.15383334  0.25356454  1.        ]]. Action = [[ 0.872514   -0.8005381  -0.92794377  0.3919778 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 8120. State = [[ 0.12606324 -0.15368403  0.25363836  1.        ]]. Action = [[ 0.8830707  -0.8545226  -0.6751977   0.36274242]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 8121. State = [[ 0.12606324 -0.15368403  0.25363836  1.        ]]. Action = [[ 0.6447933  -0.7553026  -0.89347184  0.39144993]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 8122. State = [[ 0.1260208  -0.1536742   0.25348404  1.        ]]. Action = [[ 0.3621695  -0.6474909  -0.76055384  0.46041954]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 8123. State = [[ 0.1260208  -0.1536742   0.25348404  1.        ]]. Action = [[ 0.9566033  -0.9053447  -0.73617357  0.4683802 ]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 8124. State = [[ 0.1260208  -0.1536742   0.25348404  1.        ]]. Action = [[ 0.5619917  -0.84288865 -0.4274786   0.50518584]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 8125. State = [[ 0.1260208  -0.1536742   0.25348404  1.        ]]. Action = [[ 0.74529743 -0.3470357  -0.87536395  0.41209507]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8126. State = [[ 0.1260208  -0.1536742   0.25348404  1.        ]]. Action = [[ 0.56631804 -0.7871242  -0.78707546  0.41328728]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 8127. State = [[ 0.1260208  -0.1536742   0.25348404  1.        ]]. Action = [[ 0.51015496 -0.73846656 -0.84852463  0.4541328 ]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 8128. State = [[ 0.1260208  -0.1536742   0.25348404  1.        ]]. Action = [[ 0.7739873  -0.5997753  -0.90702015  0.5442233 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 8129. State = [[ 0.1260208  -0.1536742   0.25348404  1.        ]]. Action = [[ 0.7453718  -0.852558   -0.78618294  0.49527788]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 8130. State = [[ 0.1260208  -0.1536742   0.25348404  1.        ]]. Action = [[ 0.78427625 -0.35394132 -0.5350274   0.35796404]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8131. State = [[ 0.1260208  -0.1536742   0.25348404  1.        ]]. Action = [[ 0.54202604 -0.6645335  -0.6909953   0.47739363]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 8132. State = [[ 0.12591515 -0.15364066  0.25347847  1.        ]]. Action = [[ 0.8942052  -0.8222675  -0.6858776   0.43620086]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 8133. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.895537   -0.30880117 -0.57417053  0.49922812]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8134. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.7242229  -0.41344708 -0.74874     0.43185592]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8135. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.8331032 -0.6930064 -0.9875129  0.4763986]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 8136. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.72002184 -0.52412355 -0.93778586  0.4897585 ]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8137. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.4933927  -0.6837413  -0.8750478   0.41461742]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 8138. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.5964854  -0.3546865   0.20018387  0.45765364]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 8139. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.60271525 -0.8600753  -0.30006003  0.4457456 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 8140. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.7692611  -0.81887156 -0.98166037  0.5339124 ]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 8141. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.9075155  -0.14960784 -0.95266354  0.5257163 ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8142. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.68080163 -0.7645698  -0.89496213  0.5928484 ]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 8143. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.66315675 -0.6197187  -0.7951646   0.56219125]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 8144. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.6060138  -0.3623767  -0.56121194  0.5632775 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8145. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.46126354 -0.6717431  -0.25433815  0.5271692 ]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 8146. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.55292153 -0.810396   -0.36786622  0.3383807 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 8147. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.6674483  -0.4819256  -0.7531244   0.57083714]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8148. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[-0.00893682 -0.521047   -0.7598569   0.5049162 ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8149. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.8112724  -0.35318577 -0.8315436   0.5611079 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8150. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.3754295  -0.67195666 -0.0740844   0.5463519 ]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 8151. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.4228567 -0.3611015 -0.9778552  0.5016881]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8152. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.56949425 -0.5967326  -0.8531909   0.4749738 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 8153. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.3885324  -0.847302   -0.35590398  0.61518955]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 8154. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.48388588 -0.35949594 -0.9281637   0.5669718 ]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8155. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.43175793 -0.22397393 -0.974627    0.62248886]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8156. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.746536   -0.794715   -0.21333969  0.57255185]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 8157. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.75308895 -0.87970066 -0.23086405  0.5591874 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 8158. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.56749105 -0.6117781  -0.48095888  0.5893656 ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 8159. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.5679407 -0.774294  -0.6710387  0.5725672]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 8160. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.16961086 -0.7768974  -0.74782306  0.47918153]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 8161. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.47478366 -0.6203409   0.08584666  0.62303925]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 8162. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.21754432 -0.67496777 -0.8013939   0.6021116 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 8163. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.55022216 -0.85756356 -0.990923    0.5524156 ]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 8164. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.45060074 -0.60180986 -0.71184266  0.56687284]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 8165. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[-0.14459985 -0.89295286 -0.55559695  0.5687599 ]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 8166. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.2891295  -0.6306742  -0.6163053   0.65994716]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 8167. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.6604266  -0.5019987  -0.74601203  0.68810165]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8168. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.32860732 -0.38385075 -0.8686291   0.6110594 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8169. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[-0.07099658 -0.65511596 -0.73135805  0.5895288 ]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 8170. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.7885201  -0.38032663 -0.6155358   0.6290628 ]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8171. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[-0.01293272 -0.8215944  -0.90923154  0.6365869 ]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 8172. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[-0.05998373 -0.64597285 -0.81998146  0.5782602 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 8173. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[-0.12440747 -0.6855877  -0.5320846   0.5829971 ]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 8174. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.05783784 -0.2965237  -0.8962072   0.6236192 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8175. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.60785997 -0.61706185 -0.44967532  0.60729825]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 8176. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.84531593 -0.56844467  0.29430687  0.5990826 ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 8177. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.21848953 -0.57543945 -0.67939997  0.5594547 ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 8178. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.85845876 -0.57930464 -0.7925281   0.5919876 ]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 8179. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.44749236 -0.45865119 -0.5170538   0.6083255 ]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8180. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.45293736 -0.6830665  -0.10815167  0.53568184]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 8181. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.46178555 -0.21471703 -0.9530647   0.6761184 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8182. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.6017964  -0.5376298  -0.78113836  0.62496614]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8183. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.41817868  0.17395604 -0.42640972  0.6160674 ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8184. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.6149658  -0.78825444 -0.15936792  0.490551  ]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 8185. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.87063575 -0.2575866  -0.6964536   0.63599455]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8186. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.37237668 -0.3271485   0.10665286  0.51846004]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 8187. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[-0.3765874  -0.24959809 -0.85830486  0.5627923 ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8188. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.41903782 -0.7628855  -0.60668665  0.60217094]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 8189. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.62243235 -0.6777252  -0.9471592   0.6025485 ]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 8190. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.12464678 -0.72794086 -0.1418333   0.5928159 ]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 8191. State = [[ 0.12572248 -0.1535813   0.25339293  1.        ]]. Action = [[ 0.77234197  0.06259799 -0.6525626   0.53004706]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8192. State = [[-0.25911498 -0.1011331   0.11369815  1.        ]]. Action = [[ 0.39825213 -0.3584355  -0.94701904  0.66661704]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Action ignored: No entry zone
Current timestep = 8193. State = [[-0.24855302 -0.11555824  0.10786338  1.        ]]. Action = [[ 0.8916855  -0.24001205  0.92614293  0.8939669 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 8194. State = [[-0.22350928 -0.12573525  0.121107    1.        ]]. Action = [[ 0.81647706 -0.37755227  0.34817648  0.9869337 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 8195. State = [[-0.19539534 -0.14078274  0.1434057   1.        ]]. Action = [[ 0.5170653  -0.40894997  0.92769194  0.9912319 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 8196. State = [[-0.17452379 -0.15895124  0.17825732  1.        ]]. Action = [[ 0.3809439  -0.4701749   0.8505242   0.94082296]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 8197. State = [[-0.153208   -0.17774567  0.20366971  1.        ]]. Action = [[ 0.7509868  -0.4794578   0.02178729  0.8747966 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 8198. State = [[-0.12865147 -0.18726197  0.20913771  1.        ]]. Action = [[ 0.9231454  -0.05299503 -0.27246428  0.8767545 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 8199. State = [[-0.0986395  -0.19518773  0.20092832  1.        ]]. Action = [[ 0.73263    -0.2323345  -0.30096698  0.49335933]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 8200. State = [[-0.06992457 -0.20586722  0.18915404  1.        ]]. Action = [[ 0.93718517 -0.41284686 -0.8048542   0.88756037]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 8201. State = [[-0.03670208 -0.20854178  0.1619308   1.        ]]. Action = [[ 0.8652723   0.4194759  -0.46551514  0.6186254 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 8202. State = [[ 6.5309089e-04 -2.0368664e-01  1.5150057e-01  1.0000000e+00]]. Action = [[0.90283227 0.16505921 0.3205731  0.68092275]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 8203. State = [[ 0.03410553 -0.2059684   0.15176181  1.        ]]. Action = [[ 0.9699042  -0.43885994 -0.5097329   0.7958152 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 8204. State = [[ 0.07206158 -0.21638034  0.14883372  1.        ]]. Action = [[ 0.9367933  -0.4067124   0.71712756  0.91932154]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 8205. State = [[ 0.1004715  -0.22661114  0.159591    1.        ]]. Action = [[0.83044314 0.21029127 0.32121396 0.9642694 ]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: Workspace boundary
Scene graph at timestep 8205 is [False, False, True, True, False, False, False, True, False, True]
State prediction error at timestep 8205 is tensor(0.0003, grad_fn=<MseLossBackward0>)
Human Feedback received at timestep 8205 of -1
Current timestep = 8206. State = [[ 0.11699804 -0.23129803  0.16426314  1.        ]]. Action = [[-0.16777623 -0.54790986  0.7870394   0.9897176 ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Current timestep = 8207. State = [[ 0.11699804 -0.23129803  0.16426314  1.        ]]. Action = [[ 0.62550306  0.16986394 -0.9525351   0.97929144]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 8208. State = [[ 0.11699804 -0.23129803  0.16426314  1.        ]]. Action = [[0.5840354  0.08001459 0.98053646 0.7921283 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 8209. State = [[ 0.11699804 -0.23129803  0.16426314  1.        ]]. Action = [[0.20636642 0.78698885 0.4368248  0.9867811 ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 8210. State = [[ 0.11699804 -0.23129803  0.16426314  1.        ]]. Action = [[ 0.7633976 -0.2872128 -0.538893   0.8523598]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 8211. State = [[ 0.11699804 -0.23129803  0.16426314  1.        ]]. Action = [[-0.29413283 -0.4841429  -0.91718495  0.96849465]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 8212. State = [[ 0.10982907 -0.23313905  0.15438466  1.        ]]. Action = [[-0.7797599  -0.05350471 -0.92647564  0.9735532 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 8213. State = [[ 0.10382603 -0.23684947  0.13778163  1.        ]]. Action = [[0.7744949  0.26145494 0.94110465 0.9411497 ]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 8214. State = [[ 0.10219688 -0.23863046  0.13450468  1.        ]]. Action = [[0.88158894 0.4054582  0.9999552  0.9081855 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 8215. State = [[ 0.10157627 -0.23859961  0.1327888   1.        ]]. Action = [[ 0.6237767  -0.1352132  -0.9998724   0.95877934]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 8216. State = [[ 0.10138374 -0.23852639  0.13234     1.        ]]. Action = [[ 0.43479443  0.43780446 -0.8582547   0.9691484 ]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 8217. State = [[ 0.10126302 -0.23849984  0.13189477  1.        ]]. Action = [[ 0.96478605 -0.05004889 -0.03390974  0.94857466]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 8218. State = [[ 0.10120266 -0.23848656  0.13167252  1.        ]]. Action = [[0.24745882 0.61078525 0.9939401  0.7469655 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 8219. State = [[ 0.09512072 -0.23021804  0.11883876  1.        ]]. Action = [[-0.4683261   0.54280484 -0.94909376  0.98636043]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 8220. State = [[ 0.09288295 -0.2237669   0.10079838  1.        ]]. Action = [[ 0.90415514  0.6621094  -0.9645885   0.90920544]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 8221. State = [[ 0.09294585 -0.22282447  0.09963866  1.        ]]. Action = [[ 0.92720616 -0.39523613  0.7690568   0.9556893 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 8222. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[0.8385017 0.7369056 0.9984238 0.7346561]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 8223. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[ 0.9755616   0.39064825 -0.38302457  0.5263519 ]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 8224. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[ 0.3429253   0.49165773 -0.3440466   0.92233133]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 8225. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[ 0.28725803 -0.22752345 -0.7305677   0.9057982 ]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 8226. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[ 0.52882266  0.21936202 -0.33794552  0.9100168 ]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 8227. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[ 0.92908     0.77396834 -0.7645434   0.88900995]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 8228. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[ 0.790498   -0.17324525 -0.9974968   0.99130654]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 8229. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[0.99220204 0.29607844 0.5124619  0.9108262 ]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 8230. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[ 0.9114115  -0.580822   -0.53598785  0.98443925]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 8231. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[ 0.83423793 -0.07500631  0.59221387  0.9025029 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 8232. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[ 0.9835514   0.709975   -0.83381855  0.9799454 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 8233. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[0.5160825  0.11110437 0.63707805 0.8676082 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 8234. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[ 0.92338085 -0.21667159 -0.964572    0.9882424 ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 8235. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[0.67809236 0.89719915 0.28391266 0.91192245]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 8236. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[ 0.38217688 -0.0940491   0.7847568   0.98550487]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 8237. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[ 0.4140706   0.87045336 -0.34297365  0.9722605 ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 8238. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[ 0.95862436  0.1720171  -0.4728368   0.92791224]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 8239. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[0.8451638  0.81769216 0.9244628  0.7673534 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 8240. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[ 0.79574966 -0.25320196  0.99196064  0.90150523]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 8241. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[ 0.9604931  -0.09101331 -0.9728194   0.9598291 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 8242. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[0.96401024 0.7180426  0.20513284 0.96069264]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 8243. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[ 0.8368628  -0.37339747  0.9739845   0.98560524]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 8244. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[ 0.7624624  -0.34165323  0.9523785   0.86546385]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 8245. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[0.95792985 0.2995304  0.99055207 0.96190524]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 8246. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[ 0.5458138   0.75574255 -0.59070647  0.9724152 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 8247. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[0.8335134  0.24440455 0.6602855  0.98721313]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 8248. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[0.93805337 0.7049689  0.97698474 0.7938237 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 8249. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[ 0.9390862   0.18537033 -0.9798901   0.9772842 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 8250. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[ 0.7579894   0.22898304 -0.90184665  0.9324999 ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 8251. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[0.5671545  0.48848093 0.9265468  0.8132224 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 8252. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[ 0.46722567 -0.39122313 -0.22893995  0.9482713 ]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 8253. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[ 0.5107963  -0.17312217  0.866519    0.816337  ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 8254. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[ 0.50938475 -0.6445145   0.9915719   0.88048744]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 8255. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[0.72065496 0.1565628  0.41031253 0.8690611 ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 8256. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[ 0.70138264  0.63862634 -0.19705117  0.9442451 ]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 8257. State = [[ 0.09295901 -0.2225159   0.09955054  1.        ]]. Action = [[0.94751    0.6973398  0.9759879  0.95211506]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 8258. State = [[ 0.09271533 -0.21922863  0.09715062  1.        ]]. Action = [[ 0.04334068  0.18748951 -0.2251429   0.8842076 ]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 8259. State = [[ 0.09198391 -0.21577495  0.08824781  1.        ]]. Action = [[ 0.9225862  -0.69400615  0.8423016   0.5135819 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 8260. State = [[ 0.09179613 -0.21488668  0.08657157  1.        ]]. Action = [[ 0.98665905 -0.07624519  0.9943204   0.9295566 ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 8261. State = [[ 0.09174641 -0.21487726  0.08642551  1.        ]]. Action = [[0.9415338 0.6703155 0.2415905 0.9709666]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 8262. State = [[ 0.09174641 -0.21487726  0.08642551  1.        ]]. Action = [[ 0.6050476 -0.8072872  0.9816649  0.9123347]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 8263. State = [[ 0.09175251 -0.21479602  0.08642548  1.        ]]. Action = [[ 0.98187125 -0.4910518   0.9516456   0.97513413]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 8264. State = [[ 0.09175251 -0.21479602  0.08642548  1.        ]]. Action = [[0.8293874  0.69403815 0.57257485 0.9172777 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 8265. State = [[ 0.09175251 -0.21479602  0.08642548  1.        ]]. Action = [[ 0.23759723 -0.7507866   0.9587357   0.9721546 ]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 8266. State = [[ 0.09175251 -0.21479602  0.08642548  1.        ]]. Action = [[0.8358824  0.25944877 0.90750146 0.9008297 ]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 8267. State = [[ 0.09175251 -0.21479602  0.08642548  1.        ]]. Action = [[0.9890344  0.08034813 0.74064815 0.9455073 ]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 8268. State = [[ 0.09175251 -0.21479602  0.08642548  1.        ]]. Action = [[0.89121175 0.26526117 0.759202   0.955343  ]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 8269. State = [[ 0.09175251 -0.21479602  0.08642548  1.        ]]. Action = [[ 0.9830693   0.37214994 -0.07860523  0.87069345]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 8270. State = [[ 0.09175251 -0.21479602  0.08642548  1.        ]]. Action = [[0.8052479  0.57929635 0.9387028  0.9399085 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 8271. State = [[ 0.09175251 -0.21479602  0.08642548  1.        ]]. Action = [[ 0.79401374 -0.01580626 -0.02637261  0.9602653 ]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 8272. State = [[ 0.09175251 -0.21479602  0.08642548  1.        ]]. Action = [[ 0.57641816 -0.09882718  0.9559488   0.9481702 ]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 8273. State = [[ 0.09175251 -0.21479602  0.08642548  1.        ]]. Action = [[0.17164803 0.2793734  0.94442797 0.90906405]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 8274. State = [[ 0.09175251 -0.21479602  0.08642548  1.        ]]. Action = [[0.9447851  0.73323464 0.9602611  0.9791012 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 8275. State = [[ 0.09172776 -0.21479133  0.0863528   1.        ]]. Action = [[0.94384134 0.39081156 0.19025028 0.9715638 ]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 8276. State = [[ 0.09172776 -0.21479133  0.0863528   1.        ]]. Action = [[ 0.5509629   0.40897942 -0.70264286  0.89705145]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 8277. State = [[ 0.09172776 -0.21479133  0.0863528   1.        ]]. Action = [[ 0.6105169   0.33988857 -0.9287461   0.8725867 ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 8278. State = [[ 0.09172776 -0.21479133  0.0863528   1.        ]]. Action = [[ 0.92280746 -0.22795701  0.51923037  0.95380425]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 8279. State = [[ 0.09172776 -0.21479133  0.0863528   1.        ]]. Action = [[ 0.82194185 -0.01157284 -0.2697804   0.92600095]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 8280. State = [[ 0.09172776 -0.21479133  0.0863528   1.        ]]. Action = [[ 0.5458163  -0.75788355  0.96723616  0.96486795]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 8281. State = [[ 0.09172776 -0.21479133  0.0863528   1.        ]]. Action = [[0.8961835  0.46737993 0.99759626 0.93017983]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 8282. State = [[ 0.09172776 -0.21479133  0.0863528   1.        ]]. Action = [[ 0.45874357  0.073282   -0.20255601  0.96573865]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 8283. State = [[ 0.09172776 -0.21479133  0.0863528   1.        ]]. Action = [[ 0.9822619  -0.15079719  0.9681423   0.9393029 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 8284. State = [[ 0.09172776 -0.21479133  0.0863528   1.        ]]. Action = [[0.4719305  0.09747362 0.6485846  0.88237405]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 8285. State = [[ 0.09172776 -0.21479133  0.0863528   1.        ]]. Action = [[0.82498026 0.08911836 0.99962974 0.88184404]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 8286. State = [[ 0.09172776 -0.21479133  0.0863528   1.        ]]. Action = [[ 0.45997357  0.6774349  -0.54501057  0.696604  ]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 8287. State = [[ 0.09172776 -0.21479133  0.0863528   1.        ]]. Action = [[ 0.94097924 -0.38170898 -0.2039175   0.9185188 ]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 8288. State = [[ 0.09172776 -0.21479133  0.0863528   1.        ]]. Action = [[ 0.6201694  -0.47438467  0.9967792   0.836298  ]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 8289. State = [[ 0.09172776 -0.21479133  0.0863528   1.        ]]. Action = [[ 0.73025024 -0.04488212  0.52185774  0.9658828 ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 8290. State = [[ 0.09172776 -0.21479133  0.0863528   1.        ]]. Action = [[ 0.9887295 -0.5994254  0.5410603  0.9085381]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 8291. State = [[ 0.09172776 -0.21479133  0.0863528   1.        ]]. Action = [[ 0.7334707  -0.3755902   0.29568982  0.89194655]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 8292. State = [[ 0.09172776 -0.21479133  0.0863528   1.        ]]. Action = [[ 0.8848021   0.13877714 -0.9492598   0.9462042 ]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 8293. State = [[ 0.09172776 -0.21479133  0.0863528   1.        ]]. Action = [[ 0.90411854  0.23375165 -0.79672116  0.93168855]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 8294. State = [[-0.25858992 -0.10793696  0.11145506  1.        ]]. Action = [[ 0.94323206 -0.11678708  0.88817406  0.98731756]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 8295. State = [[-0.24969588 -0.1285457   0.1021516   1.        ]]. Action = [[ 0.8160727 -0.6467847  0.8098514  0.9447317]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 8296. State = [[-0.23530221 -0.14724046  0.11667629  1.        ]]. Action = [[ 0.18303359 -0.40313447  0.65437627  0.97808886]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 8297. State = [[-0.21468808 -0.16698562  0.14597867  1.        ]]. Action = [[ 0.9115726  -0.5549346   0.90181696  0.9360728 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 8298. State = [[-0.18354794 -0.18380077  0.1784784   1.        ]]. Action = [[ 0.606544   -0.2918539   0.64117515  0.94881105]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 8299. State = [[-0.1540133  -0.19634125  0.20336232  1.        ]]. Action = [[ 0.9380106  -0.18446577  0.33016658  0.9257175 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 8300. State = [[-0.13081348 -0.2043137   0.22123784  1.        ]]. Action = [[ 0.28465438 -0.24466455  0.12624466  0.924307  ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 8301. State = [[-0.11249009 -0.21486853  0.22289632  1.        ]]. Action = [[ 0.9371904  -0.40462822 -0.4136709   0.6246915 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 8302. State = [[-0.08077592 -0.23244011  0.2080803   1.        ]]. Action = [[ 0.8893802  -0.5425806  -0.63622576  0.9160657 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 8303. State = [[-0.05093564 -0.24175781  0.18407114  1.        ]]. Action = [[ 0.8218148   0.0265739  -0.899406    0.77900076]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 8304. State = [[-0.01598884 -0.25108773  0.15440924  1.        ]]. Action = [[ 0.9372933  -0.3521632  -0.29163706  0.756274  ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 8305. State = [[ 0.02135795 -0.25661865  0.14336774  1.        ]]. Action = [[0.9479923  0.11288619 0.04840505 0.6208961 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 8306. State = [[ 0.06031923 -0.25406     0.1539902   1.        ]]. Action = [[0.899986   0.32278478 0.71644974 0.94695544]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 8307. State = [[ 0.09220419 -0.24682644  0.16729464  1.        ]]. Action = [[0.6446059  0.14080715 0.01384997 0.9060708 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 8308. State = [[ 0.11165661 -0.24242859  0.16443336  1.        ]]. Action = [[-0.32715642  0.20303774 -0.24393547  0.8403615 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 8309. State = [[ 0.11261342 -0.23962417  0.16191308  1.        ]]. Action = [[0.44423902 0.8673459  0.93657744 0.9946705 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 8310. State = [[ 0.11250019 -0.23854563  0.16088638  1.        ]]. Action = [[ 0.48706913 -0.04385322  0.54675424  0.96932125]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 8311. State = [[ 0.11008596 -0.2506282   0.16648977  1.        ]]. Action = [[-0.2857728  -0.6452088   0.5484607   0.90343916]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 8312. State = [[ 0.10923757 -0.2620018   0.17538182  1.        ]]. Action = [[0.81416225 0.72790456 0.80186856 0.9934375 ]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 8313. State = [[ 0.10965659 -0.26267806  0.17834571  1.        ]]. Action = [[0.04619956 0.9486344  0.9977982  0.9909494 ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 8314. State = [[ 0.10948499 -0.26286572  0.17843512  1.        ]]. Action = [[ 0.3163427  -0.23578829  0.7359731   0.9626987 ]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 8315. State = [[ 0.10992509 -0.25289366  0.17998053  1.        ]]. Action = [[-0.60372126  0.8562522   0.05284536  0.98999834]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 8316. State = [[ 0.10894092 -0.23915717  0.18334067  1.        ]]. Action = [[0.53797436 0.4153527  0.33946037 0.9750104 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 8317. State = [[ 0.10776721 -0.23493351  0.19596569  1.        ]]. Action = [[-0.44028157  0.21914375  0.81404436  0.9613868 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 8318. State = [[ 0.09875581 -0.228991    0.21435098  1.        ]]. Action = [[0.77102447 0.88124204 0.7793449  0.96955514]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 8319. State = [[ 0.09547452 -0.22289224  0.2230318   1.        ]]. Action = [[-0.38651013  0.32880354  0.3481115   0.94066477]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 8320. State = [[ 0.08649265 -0.20990872  0.24281402  1.        ]]. Action = [[0.04988801 0.33492613 0.71638536 0.9525099 ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 8321. State = [[ 0.07991815 -0.19547465  0.27047136  1.        ]]. Action = [[-0.5881919   0.42363262  0.8311224   0.93817806]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 8322. State = [[ 0.05582156 -0.17530105  0.3035094   1.        ]]. Action = [[-0.7146398   0.55312634  0.580783    0.77275443]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 8323. State = [[ 0.02853722 -0.15716282  0.32615602  1.        ]]. Action = [[-0.4602291   0.2295655   0.29025984  0.5961381 ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 8324. State = [[ 0.01582986 -0.15270324  0.3289354   1.        ]]. Action = [[ 0.5006411  -0.27062804 -0.514521    0.5265442 ]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 8325. State = [[ 0.01843082 -0.1560554   0.3206182   1.        ]]. Action = [[ 0.6229446  -0.18332046 -0.5624763   0.54044056]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 8326. State = [[ 0.03165163 -0.15791439  0.30220535  1.        ]]. Action = [[ 0.7122891  -0.01000094  0.22848237  0.46503067]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 8327. State = [[ 0.04567888 -0.1563858   0.29644176  1.        ]]. Action = [[ 0.08567393  0.21148396 -0.21709281  0.49643767]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 8328. State = [[ 0.0599571  -0.15489937  0.2927068   1.        ]]. Action = [[ 0.73776317 -0.14932883  0.14457333  0.29018903]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 8329. State = [[ 0.0798146  -0.15346597  0.2880389   1.        ]]. Action = [[ 0.5590825   0.15196729 -0.21042949  0.3735373 ]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 8330. State = [[ 0.09872903 -0.1579346   0.2865078   1.        ]]. Action = [[ 0.25481474 -0.4339502   0.29746985  0.58796334]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 8331. State = [[ 0.10752018 -0.16576542  0.2930369   1.        ]]. Action = [[ 0.33280766 -0.22383606 -0.8330056   0.54235005]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 8332. State = [[ 0.10775388 -0.1653253   0.29730102  1.        ]]. Action = [[-0.5511815   0.24980569  0.20797908  0.6691139 ]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 8333. State = [[ 0.10610164 -0.16506091  0.29994577  1.        ]]. Action = [[ 0.36772025  0.07395267 -0.38273847  0.7245655 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 8334. State = [[ 0.10507568 -0.16534783  0.29441977  1.        ]]. Action = [[-0.20429873 -0.04303205 -0.6929065   0.67295146]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 8335. State = [[ 0.09795516 -0.16553997  0.28114662  1.        ]]. Action = [[-0.63382673  0.10927093 -0.5717087   0.65340304]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 8336. State = [[ 0.089169   -0.15789382  0.26788643  1.        ]]. Action = [[-0.02588546  0.36191213 -0.06020015  0.68675447]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 8337. State = [[ 0.08791983 -0.15273115  0.270146    1.        ]]. Action = [[ 0.17334521 -0.12079412  0.64553344  0.45142472]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 8338. State = [[ 0.08760294 -0.15460557  0.2746898   1.        ]]. Action = [[ 0.653106   -0.12321502 -0.3897453   0.5767275 ]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 8339. State = [[ 0.08635226 -0.1664262   0.28048223  1.        ]]. Action = [[-0.14149368 -0.73474723  0.1364237   0.48192775]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 8340. State = [[ 0.08632574 -0.1762253   0.28840905  1.        ]]. Action = [[ 0.22072232 -0.10697794  0.19668508  0.69925165]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 8341. State = [[ 0.08325735 -0.17471008  0.290183    1.        ]]. Action = [[-0.53121805  0.4410162  -0.20640266  0.71379733]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 8342. State = [[ 0.07524322 -0.16436093  0.28047624  1.        ]]. Action = [[-0.24550015  0.34292054 -0.59910816  0.7604798 ]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 8343. State = [[ 0.067316   -0.16358149  0.27109808  1.        ]]. Action = [[ 0.07471216 -0.44263363  0.10424602  0.4476093 ]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 8344. State = [[ 0.06375805 -0.16971515  0.2633745   1.        ]]. Action = [[-0.03813189 -0.13871908 -0.5859962   0.47742188]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 8345. State = [[ 0.06126908 -0.1740432   0.2553199   1.        ]]. Action = [[ 0.7921492  -0.23501354 -0.16277957  0.6306176 ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 8346. State = [[ 0.06349993 -0.17204046  0.25754744  1.        ]]. Action = [[0.39077222 0.14175844 0.52051497 0.6523781 ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 8347. State = [[ 0.06917188 -0.16606139  0.25653544  1.        ]]. Action = [[ 0.4891659   0.23457098 -0.39895356  0.7312796 ]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 8348. State = [[ 0.0771554  -0.16659175  0.2525846   1.        ]]. Action = [[ 0.26105213 -0.37156117  0.12103224  0.5231881 ]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 8349. State = [[ 0.08115756 -0.16952279  0.25430596  1.        ]]. Action = [[0.6894659  0.21024466 0.20937467 0.70055723]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 8350. State = [[ 0.08179627 -0.170115    0.25350168  1.        ]]. Action = [[ 0.6582731  -0.34432316  0.5332619   0.77331877]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 8351. State = [[ 0.08191036 -0.17025231  0.25328514  1.        ]]. Action = [[0.5276401  0.37389684 0.77929807 0.7749884 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 8352. State = [[ 0.08186971 -0.17025335  0.2529242   1.        ]]. Action = [[ 0.6284418  -0.20180231  0.7789693   0.64257324]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 8353. State = [[ 0.08186971 -0.17025335  0.2529242   1.        ]]. Action = [[ 0.5565028   0.4321035  -0.05334449  0.7271577 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 8354. State = [[ 0.08251453 -0.17716876  0.25539613  1.        ]]. Action = [[-0.16071057 -0.3867225   0.24235487  0.7360966 ]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 8355. State = [[ 0.08332681 -0.18391968  0.25701237  1.        ]]. Action = [[0.3793267  0.22120607 0.4518553  0.6327406 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 8356. State = [[ 0.08318239 -0.17958635  0.25649434  1.        ]]. Action = [[-0.29388     0.47664285 -0.27970958  0.8621805 ]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 8357. State = [[ 0.08231173 -0.17415085  0.25056806  1.        ]]. Action = [[ 0.00421917  0.11588192 -0.42679703  0.82468414]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 8358. State = [[ 0.0783025  -0.17132206  0.24168351  1.        ]]. Action = [[-0.4860317   0.06298161 -0.16133738  0.8310249 ]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 8359. State = [[ 0.07450458 -0.1687587   0.2370477   1.        ]]. Action = [[0.39764428 0.01620078 0.12008846 0.63761914]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 8360. State = [[ 0.07510284 -0.17003727  0.24113692  1.        ]]. Action = [[-0.04586107 -0.19822615  0.46507823  0.6830416 ]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 8361. State = [[ 0.07508671 -0.17316726  0.2443112   1.        ]]. Action = [[ 0.7087865   0.11140835 -0.05213922  0.7524313 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 8362. State = [[ 0.07557765 -0.17831849  0.25324476  1.        ]]. Action = [[ 0.04953718 -0.25816238  0.52634394  0.7060313 ]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 8363. State = [[ 0.07322276 -0.1810229   0.27257097  1.        ]]. Action = [[-0.7080842   0.22418833  0.4916556   0.7720797 ]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 8364. State = [[ 0.05875271 -0.17492078  0.28353798  1.        ]]. Action = [[-0.6172823   0.1876638  -0.28263724  0.76133275]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 8365. State = [[ 0.0470573  -0.17083314  0.28262737  1.        ]]. Action = [[0.86742663 0.14863193 0.47033668 0.580518  ]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 8366. State = [[ 0.04946307 -0.16871275  0.28854325  1.        ]]. Action = [[ 0.8313408  -0.06732464  0.6222738   0.6706257 ]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 8367. State = [[ 0.05837715 -0.16689199  0.30770886  1.        ]]. Action = [[0.43162966 0.08567131 0.8207097  0.63176036]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 8368. State = [[ 0.0681975  -0.16143297  0.32961753  1.        ]]. Action = [[0.4517262  0.05755293 0.21591103 0.6525103 ]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 8369. State = [[ 0.07123224 -0.16031545  0.33044413  1.        ]]. Action = [[-0.4897672  -0.03964347 -0.68827385  0.4680084 ]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 8370. State = [[ 0.07040043 -0.1621207   0.31774923  1.        ]]. Action = [[ 0.23074472 -0.11700857 -0.39902395  0.65247965]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 8371. State = [[ 0.07296295 -0.16169536  0.3013256   1.        ]]. Action = [[ 0.37889588  0.04222107 -0.30931628  0.49362922]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 8372. State = [[ 0.07853184 -0.16566591  0.289196    1.        ]]. Action = [[-0.02285177 -0.24215353 -0.17673814  0.6294451 ]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 8373. State = [[ 0.07754197 -0.17618704  0.2884677   1.        ]]. Action = [[-0.7260415  -0.21304333  0.18228245  0.4450724 ]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 8374. State = [[ 0.07102929 -0.18233575  0.29709592  1.        ]]. Action = [[-0.5560315   0.14988458  0.33970356  0.70540404]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 8375. State = [[ 0.06004317 -0.17753883  0.30210507  1.        ]]. Action = [[-0.13585043  0.3011911  -0.14922619  0.6571963 ]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 8376. State = [[ 0.05619955 -0.16750191  0.30369863  1.        ]]. Action = [[0.05881047 0.23535943 0.29124403 0.6624944 ]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 8377. State = [[ 0.05748535 -0.15997636  0.30740282  1.        ]]. Action = [[ 0.34155643  0.1299969  -0.22153324  0.56409645]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 8378. State = [[ 0.0609809  -0.15786827  0.31493425  1.        ]]. Action = [[ 0.31830537 -0.1327644   0.7589376   0.42362583]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 8379. State = [[ 0.06836203 -0.1546979   0.33350137  1.        ]]. Action = [[0.3798921  0.20613265 0.7701616  0.40879858]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 8380. State = [[ 0.07610542 -0.14889617  0.34434295  1.        ]]. Action = [[ 0.56830823 -0.00516135 -0.5880194   0.46049094]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 8381. State = [[ 0.0840311  -0.14896916  0.33031756  1.        ]]. Action = [[-0.15791374 -0.16082078 -0.32732856  0.3100611 ]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 8382. State = [[ 0.08402816 -0.1506665   0.3272213   1.        ]]. Action = [[ 0.38609266  0.10942996 -0.5485473   0.48581684]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 8383. State = [[ 0.08402181 -0.15091038  0.32621258  1.        ]]. Action = [[ 0.38321662 -0.04180783 -0.47254425  0.46070278]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 8384. State = [[ 0.08401675 -0.15091106  0.32563642  1.        ]]. Action = [[ 0.35229325  0.03278279 -0.66886157  0.5743222 ]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 8385. State = [[ 0.08554923 -0.1495836   0.32079467  1.        ]]. Action = [[ 0.29442596  0.08146691 -0.30738735  0.5292194 ]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 8386. State = [[ 0.08919901 -0.14952461  0.30613342  1.        ]]. Action = [[-0.308753   -0.10503221 -0.4091667   0.47801673]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 8387. State = [[ 0.08830319 -0.15096244  0.2985722   1.        ]]. Action = [[-0.19350326  0.12453818 -0.31531286  0.5186727 ]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 8388. State = [[ 0.0860947  -0.1522727   0.28637242  1.        ]]. Action = [[-0.2385807  -0.02216917 -0.5643789   0.5864847 ]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 8389. State = [[ 0.08142329 -0.15731585  0.2710395   1.        ]]. Action = [[-0.51289904 -0.12933654 -0.26881415  0.47939742]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 8390. State = [[ 0.07284264 -0.1590419   0.26242685  1.        ]]. Action = [[-0.01934481  0.08233619  0.24553967  0.40111506]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 8391. State = [[ 0.06739272 -0.159711    0.25813806  1.        ]]. Action = [[-0.5262192   0.01924622 -0.46403897  0.722893  ]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 8392. State = [[ 0.053573   -0.16039903  0.24569625  1.        ]]. Action = [[-0.1609968  -0.10340291 -0.1352284   0.78214884]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 8393. State = [[ 0.0533873  -0.15688835  0.24152638  1.        ]]. Action = [[ 0.83249545  0.23848689 -0.00813687  0.55384755]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 8394. State = [[ 0.06424652 -0.15020268  0.24766028  1.        ]]. Action = [[ 0.4639151  -0.00546622  0.57409596  0.59153533]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 8395. State = [[ 0.07449445 -0.15271522  0.26288864  1.        ]]. Action = [[ 0.24691236 -0.3402354   0.6685535   0.66389847]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 8396. State = [[-0.25676042 -0.1171044   0.09393296  1.        ]]. Action = [[-0.8225127   0.08747303 -0.13665664  0.63884175]]. Reward = [0.]
Curr episode timestep = 101
Current timestep = 8397. State = [[-0.2461226  -0.13724038  0.08737054  1.        ]]. Action = [[ 0.8786688  -0.5265035   0.981022    0.97774684]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 8398. State = [[-0.22323059 -0.15755957  0.1093503   1.        ]]. Action = [[ 0.3609779  -0.5696338   0.70393157  0.9765762 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 8399. State = [[-0.2025806  -0.18161191  0.13514258  1.        ]]. Action = [[ 0.76003814 -0.746696    0.6648176   0.91980946]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 8400. State = [[-0.17865841 -0.21015762  0.15494668  1.        ]]. Action = [[ 0.3356253  -0.6593981   0.03999054  0.9704591 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 8401. State = [[-0.15655419 -0.22572152  0.16731243  1.        ]]. Action = [[ 0.9327874  -0.04871607  0.2990787   0.85837793]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 8402. State = [[-0.1258588  -0.23943233  0.18311764  1.        ]]. Action = [[ 0.9681964  -0.6404075   0.25921547  0.6175771 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 8403. State = [[-0.0898859  -0.2616193   0.18744609  1.        ]]. Action = [[ 0.8817179  -0.6871247  -0.19576603  0.74617267]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 8404. State = [[-0.05949145 -0.28596014  0.18108249  1.        ]]. Action = [[ 0.9966018  -0.67205197 -0.8512261   0.5736759 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 8405. State = [[-0.02434096 -0.3021274   0.15131074  1.        ]]. Action = [[ 0.9921557  -0.04485935 -0.48262548  0.8046621 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 8406. State = [[ 0.01959708 -0.31131706  0.14196889  1.        ]]. Action = [[ 0.9910673  -0.06643444  0.532655    0.71211386]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 8407. State = [[ 0.04883113 -0.31741565  0.14950494  1.        ]]. Action = [[ 0.9878416  -0.07256687 -0.25280178  0.93948364]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: Workspace boundary
Current timestep = 8408. State = [[ 0.05721458 -0.3197839   0.15243213  1.        ]]. Action = [[0.98842394 0.1311481  0.9543141  0.9975039 ]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: Workspace boundary
Current timestep = 8409. State = [[ 0.06909849 -0.31159663  0.16397734  1.        ]]. Action = [[0.76716566 0.63983834 0.90983343 0.94356847]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 8410. State = [[ 0.08679616 -0.29867905  0.1835661   1.        ]]. Action = [[ 0.70800924 -0.7143334   0.9161171   0.95571566]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: Workspace boundary
Current timestep = 8411. State = [[ 0.09257069 -0.29793915  0.18666175  1.        ]]. Action = [[ 0.09743011 -0.26676357  0.9967904   0.9994166 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 8412. State = [[ 0.09463812 -0.291067    0.19659692  1.        ]]. Action = [[-0.41522938  0.61388445  0.7331183   0.9997709 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 8413. State = [[ 0.09414615 -0.26711294  0.22095217  1.        ]]. Action = [[-0.20448875  0.8405957   0.8700905   0.9384407 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 8414. State = [[ 0.09020606 -0.24364829  0.25753114  1.        ]]. Action = [[-0.36988306  0.34183776  0.8432498   0.97493076]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 8415. State = [[ 0.08613434 -0.22147213  0.29415995  1.        ]]. Action = [[0.03539801 0.68149495 0.88963354 0.9906759 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 8416. State = [[ 0.07776161 -0.20181112  0.32788634  1.        ]]. Action = [[-0.6275706   0.32201314  0.68114114  0.9411011 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 8417. State = [[ 0.06940125 -0.18035673  0.354121    1.        ]]. Action = [[0.27023137 0.63141274 0.4750557  0.7654952 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 8418. State = [[ 0.0622201  -0.16255985  0.36896938  1.        ]]. Action = [[-0.6442079   0.25427306  0.01749814  0.74226797]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 8419. State = [[ 0.04481859 -0.16003601  0.37233326  1.        ]]. Action = [[-0.5731688  -0.25422812 -0.1586262   0.50507545]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 8420. State = [[ 0.02614618 -0.16105457  0.37743384  1.        ]]. Action = [[-0.49255526  0.11450171  0.30977356  0.469231  ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 8421. State = [[ 0.01199394 -0.15612626  0.3852441   1.        ]]. Action = [[0.17699325 0.0839715  0.00141156 0.481395  ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 8422. State = [[ 0.01177727 -0.15053791  0.38421264  1.        ]]. Action = [[ 0.16393936  0.28058994 -0.32944947  0.435673  ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 8423. State = [[ 0.01062369 -0.13989416  0.37163383  1.        ]]. Action = [[ 0.22174764  0.27465796 -0.6067971   0.32950568]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 8424. State = [[ 0.01587978 -0.1335209   0.35361025  1.        ]]. Action = [[ 0.16131115  0.09009826 -0.20852304  0.52079475]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 8425. State = [[ 0.01639196 -0.12642728  0.34740296  1.        ]]. Action = [[-0.2295034   0.2696427  -0.19256365  0.43388915]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 8426. State = [[ 0.01923642 -0.11788396  0.34769174  1.        ]]. Action = [[0.7354282  0.11637366 0.38331747 0.28562498]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 8427. State = [[ 0.02548765 -0.11574216  0.35003105  1.        ]]. Action = [[ 0.31174922 -0.2266736   0.29247952  0.25212955]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 8428. State = [[ 0.03173763 -0.11766037  0.34712926  1.        ]]. Action = [[ 0.4151231  -0.12458384 -0.41458142  0.19446898]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 8429. State = [[ 0.04687824 -0.12488855  0.33807614  1.        ]]. Action = [[ 0.03235483 -0.28593338  0.06428456  0.19291055]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 8430. State = [[ 0.05518899 -0.13460132  0.33551598  1.        ]]. Action = [[ 0.6995027  -0.24699682 -0.13133371  0.144176  ]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 8431. State = [[ 0.07752547 -0.14275442  0.32410502  1.        ]]. Action = [[ 0.6088972  -0.15445566 -0.43416142  0.15605164]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 8432. State = [[ 0.10011549 -0.1495536   0.30814987  1.        ]]. Action = [[ 0.30718887 -0.16736728 -0.20204568  0.38348663]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 8433. State = [[ 0.11198357 -0.15343684  0.3018754   1.        ]]. Action = [[ 0.06257629 -0.43492138 -0.52521807  0.47836125]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 8434. State = [[ 0.11279948 -0.16060852  0.29608947  1.        ]]. Action = [[-0.36893898 -0.37308073 -0.5729271   0.5528164 ]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 8435. State = [[ 0.10815453 -0.16823585  0.28361952  1.        ]]. Action = [[-0.5735858   0.10311437 -0.4501444   0.6417682 ]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 8436. State = [[ 0.09952164 -0.17440343  0.2744597   1.        ]]. Action = [[-0.2976243  -0.2589184  -0.01625675  0.6539124 ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 8437. State = [[ 0.0933077  -0.18326695  0.2732197   1.        ]]. Action = [[-0.3186398  -0.24528319  0.12111926  0.76906514]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 8438. State = [[ 0.08118619 -0.18456523  0.28436196  1.        ]]. Action = [[-0.95092773  0.4497316   0.5759983   0.73102653]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 8439. State = [[ 0.04935036 -0.17057732  0.30706397  1.        ]]. Action = [[-0.7303149   0.36843586  0.5983169   0.77835333]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 8440. State = [[ 0.03200376 -0.16054763  0.3171329   1.        ]]. Action = [[ 0.5967827  -0.00083697 -0.28613102  0.5410559 ]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 8441. State = [[ 0.02967335 -0.16240434  0.30988467  1.        ]]. Action = [[-0.2823645  -0.14775956 -0.49610794  0.47371578]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 8442. State = [[ 0.02806949 -0.16705686  0.29753393  1.        ]]. Action = [[ 0.44078267 -0.22514749 -0.3824017   0.5278809 ]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 8443. State = [[ 0.03998432 -0.16422041  0.28345528  1.        ]]. Action = [[0.8519964  0.15823197 0.08210254 0.52339435]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 8444. State = [[ 0.05155508 -0.16707322  0.26905847  1.        ]]. Action = [[ 0.45807433 -0.3689466  -0.6245077   0.4804896 ]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 8445. State = [[ 0.06423822 -0.17946328  0.25473467  1.        ]]. Action = [[-0.1801213  -0.29355866  0.10585141  0.49057317]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 8446. State = [[ 0.06506833 -0.18157387  0.25577694  1.        ]]. Action = [[-0.1799196   0.3399402   0.28934503  0.7814121 ]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 8447. State = [[ 0.06723341 -0.17703913  0.2601085   1.        ]]. Action = [[0.02473652 0.16418433 0.21430242 0.8171158 ]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 8448. State = [[ 0.06590012 -0.17394122  0.27481896  1.        ]]. Action = [[-0.6824989   0.16166341  0.48406947  0.72436285]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 8449. State = [[ 0.0581472  -0.16699578  0.2817666   1.        ]]. Action = [[ 0.24658751  0.11047125 -0.53928465  0.6461743 ]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 8450. State = [[ 0.05957574 -0.16284452  0.27253112  1.        ]]. Action = [[ 0.6647415  -0.03637689 -0.43313527  0.45041728]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 8451. State = [[ 0.06438681 -0.16085954  0.25481817  1.        ]]. Action = [[-0.12078798 -0.0682205  -0.21695799  0.53111625]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 8452. State = [[ 0.06737705 -0.16176657  0.25045893  1.        ]]. Action = [[ 0.3758409  -0.11162686  0.07924044  0.5148529 ]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 8453. State = [[ 0.07178365 -0.16304667  0.25139144  1.        ]]. Action = [[ 0.7936809  -0.10490555 -0.02930516  0.7267709 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 8454. State = [[ 0.07229131 -0.16371544  0.25118223  1.        ]]. Action = [[0.6954589  0.12710834 0.29971445 0.67768955]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 8455. State = [[ 0.07644068 -0.16534291  0.24962287  1.        ]]. Action = [[ 3.6990023e-01 -1.4228958e-01  1.4269352e-04  6.1084616e-01]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 8456. State = [[ 0.08622108 -0.1688062   0.24836834  1.        ]]. Action = [[0.57312155 0.37123275 0.34176564 0.58247614]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 8457. State = [[ 0.08683944 -0.17058751  0.25120866  1.        ]]. Action = [[-0.4051354   0.05209744  0.2805586   0.84458494]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 8458. State = [[ 0.08538433 -0.16936001  0.26317415  1.        ]]. Action = [[-0.44061744  0.25297642  0.6030781   0.7501123 ]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 8459. State = [[ 0.07224394 -0.1702762   0.27807558  1.        ]]. Action = [[-0.90160227 -0.13214576 -0.07271814  0.7386124 ]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 8460. State = [[ 0.04908097 -0.17478783  0.28705394  1.        ]]. Action = [[-0.39520252 -0.1598441   0.42363906  0.570693  ]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 8461. State = [[ 0.03776732 -0.1763346   0.29712087  1.        ]]. Action = [[0.09555376 0.04491806 0.04323709 0.7088001 ]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 8462. State = [[ 0.03939109 -0.17593387  0.3001724   1.        ]]. Action = [[ 0.43573773 -0.15120685  0.11381638  0.7165762 ]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 8463. State = [[ 0.04657352 -0.1731371   0.30755043  1.        ]]. Action = [[0.5463288  0.13353765 0.50725603 0.5956197 ]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 8464. State = [[ 0.05005602 -0.17086469  0.3233884   1.        ]]. Action = [[-0.19953239  0.11164713  0.6633282   0.3708086 ]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 8465. State = [[ 0.04943607 -0.17080538  0.35316458  1.        ]]. Action = [[-0.09755152 -0.01339233  0.8614254   0.5630691 ]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 8466. State = [[ 0.04567404 -0.16923419  0.37595224  1.        ]]. Action = [[-0.04921484  0.1332463   0.22697759  0.4579028 ]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 8467. State = [[ 0.04326733 -0.16084763  0.37960777  1.        ]]. Action = [[-0.26017892  0.32940435 -0.55724365  0.6322522 ]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 8468. State = [[ 0.04058545 -0.14975962  0.37682024  1.        ]]. Action = [[-0.21981305  0.23461878  0.02566516  0.41368127]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 8469. State = [[ 0.03672341 -0.14865208  0.37664008  1.        ]]. Action = [[-0.24517387 -0.30377674  0.08509159  0.29921758]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 8470. State = [[ 0.03063997 -0.15374267  0.37544733  1.        ]]. Action = [[ 0.2757647  -0.10206085 -0.21075988  0.26949716]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 8471. State = [[ 0.02892796 -0.15462434  0.37360767  1.        ]]. Action = [[-0.19111097  0.11849809 -0.15907454  0.31567645]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 8472. State = [[ 0.02654802 -0.15146287  0.37348574  1.        ]]. Action = [[-0.17889267  0.24216366  0.30112886  0.40669656]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 8473. State = [[ 0.02096459 -0.14810629  0.3703853   1.        ]]. Action = [[-0.2856596  -0.0865525  -0.3332616   0.38480592]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 8474. State = [[ 0.0160474  -0.14822419  0.36613944  1.        ]]. Action = [[-0.22676194  0.0550257  -0.24531639  0.24542058]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 8475. State = [[ 0.0067991  -0.14486955  0.3580891   1.        ]]. Action = [[-0.15078712  0.10565948 -0.09734517  0.39161444]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 8476. State = [[ 0.003836   -0.14290294  0.35501587  1.        ]]. Action = [[ 0.21786332 -0.00713068 -0.06429398  0.3558147 ]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 8477. State = [[ 0.00516708 -0.14134243  0.35448942  1.        ]]. Action = [[ 0.3280635   0.10440791 -0.05692959  0.44394052]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 8478. State = [[ 0.00777858 -0.13863723  0.35163897  1.        ]]. Action = [[ 0.27621508  0.02850401 -0.07727945  0.41277218]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 8479. State = [[ 0.00936665 -0.13774863  0.34313872  1.        ]]. Action = [[-0.34095907  0.03381503 -0.51813704  0.43252742]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 8480. State = [[ 0.01120014 -0.13725209  0.33747795  1.        ]]. Action = [[ 0.31344354 -0.10918868  0.19026923  0.40502906]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 8481. State = [[ 0.01333802 -0.13694832  0.3361061   1.        ]]. Action = [[ 0.09156084 -0.06915462 -0.27122223  0.4499699 ]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 8482. State = [[ 0.01780943 -0.13664421  0.33456028  1.        ]]. Action = [[0.36509764 0.0149951  0.36226404 0.4309566 ]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 8483. State = [[ 0.02196818 -0.13573517  0.33734506  1.        ]]. Action = [[1.9256032e-01 3.0159950e-04 1.8338108e-01 3.7290502e-01]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 8484. State = [[ 0.02880886 -0.1369706   0.34268168  1.        ]]. Action = [[ 0.1665411  -0.11877894  0.2408377   0.35322547]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 8485. State = [[ 0.03525596 -0.13947167  0.34207147  1.        ]]. Action = [[ 0.23906541 -0.04027629 -0.4802171   0.1747489 ]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 8486. State = [[ 0.0414049  -0.1452626   0.32283953  1.        ]]. Action = [[-0.281587   -0.23353928 -0.529469    0.3279854 ]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 8487. State = [[ 0.0462772 -0.1561078  0.315898   1.       ]]. Action = [[ 0.57066774 -0.39407265  0.15928662  0.15721095]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 8488. State = [[ 0.05479464 -0.16789928  0.31527123  1.        ]]. Action = [[-0.27577555 -0.13459772  0.24424672  0.36547184]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 8489. State = [[ 0.05982504 -0.16383944  0.3207315   1.        ]]. Action = [[0.29066372 0.46798623 0.29218006 0.4589175 ]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 8490. State = [[ 0.06713413 -0.16082728  0.32956722  1.        ]]. Action = [[ 0.2489357  -0.20293987  0.38119817  0.6043732 ]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 8491. State = [[ 0.06799697 -0.16471307  0.33924946  1.        ]]. Action = [[-0.3867587  -0.16233623  0.04608572  0.5056026 ]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 8492. State = [[ 0.06570909 -0.16385496  0.3430969   1.        ]]. Action = [[-0.14412689  0.2814933  -0.1055218   0.54566383]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 8493. State = [[ 0.06246509 -0.16086002  0.34461877  1.        ]]. Action = [[-0.37160718  0.13962638  0.07918561  0.41668296]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 8494. State = [[ 0.05014993 -0.16203707  0.3512224   1.        ]]. Action = [[-0.6079464  -0.15977746  0.20218468  0.3432989 ]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 8495. State = [[ 0.02949398 -0.16292404  0.36458346  1.        ]]. Action = [[-0.41206253  0.08745861  0.49756598  0.51068807]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 8496. State = [[ 0.01275762 -0.15752704  0.3683688   1.        ]]. Action = [[-0.2854163   0.18718731 -0.57632256  0.5242642 ]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 8497. State = [[ 0.00907466 -0.15124081  0.3628048   1.        ]]. Action = [[ 0.2704637   0.17821383 -0.23266345  0.30641842]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 8498. State = [[-0.2581936  -0.05061668  0.08866961  1.        ]]. Action = [[0.36107588 0.11531377 0.08860862 0.4576471 ]]. Reward = [0.]
Curr episode timestep = 101
Current timestep = 8499. State = [[-0.2566492  -0.0642484   0.07579584  1.        ]]. Action = [[ 0.08428693 -0.5189616   0.2839384   0.96237993]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 8500. State = [[-0.24948028 -0.08235982  0.08525206  1.        ]]. Action = [[ 0.20198786 -0.41322482  0.9912002   0.9820485 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 8501. State = [[-0.24142137 -0.09652369  0.11533584  1.        ]]. Action = [[ 0.2936573  -0.21983814  0.99756324  0.98284376]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 8502. State = [[-0.23725708 -0.11328821  0.14898404  1.        ]]. Action = [[-0.22094804 -0.69299984  0.6816474   0.9877726 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 8503. State = [[-0.22835854 -0.13646922  0.17805962  1.        ]]. Action = [[ 0.7822993  -0.5536066   0.711602    0.93981385]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 8504. State = [[-0.20096324 -0.1596568   0.21062107  1.        ]]. Action = [[ 0.7409768 -0.5997679  0.9253094  0.8662069]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 8505. State = [[-0.1818569  -0.1754895   0.23485692  1.        ]]. Action = [[0.7190238  0.13505197 0.44713807 0.82706976]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 8506. State = [[-0.17973016 -0.17826922  0.23786323  1.        ]]. Action = [[ 0.9228215   0.07051802 -0.6260509   0.87106824]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 8507. State = [[-0.17980918 -0.17881513  0.23812625  1.        ]]. Action = [[ 0.67687106 -0.01453865 -0.28804624  0.9211955 ]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 8508. State = [[-0.16904458 -0.18155505  0.24321784  1.        ]]. Action = [[ 0.841521   -0.26128364  0.14392519  0.88007116]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 8509. State = [[-0.14801343 -0.19173585  0.24727404  1.        ]]. Action = [[ 0.7370573  -0.4237423  -0.5663572   0.97985804]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 8510. State = [[-0.11832854 -0.20479728  0.22800988  1.        ]]. Action = [[ 0.9344175  -0.30533075 -0.7252486   0.80676365]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 8511. State = [[-0.08254883 -0.21320413  0.20663834  1.        ]]. Action = [[ 0.84124994  0.0341177  -0.14628237  0.83554816]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 8512. State = [[-0.05132702 -0.21056525  0.19536723  1.        ]]. Action = [[ 0.8691776   0.21519947 -0.59580606  0.5450585 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 8513. State = [[-0.02055672 -0.21360295  0.17490807  1.        ]]. Action = [[ 0.965763   -0.41628528 -0.63857776  0.59584415]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 8514. State = [[ 0.01424812 -0.22781612  0.14725803  1.        ]]. Action = [[ 0.9073452  -0.5822415  -0.7936182   0.65733886]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 8515. State = [[ 0.05258282 -0.24594973  0.11955117  1.        ]]. Action = [[ 0.98198426 -0.43798375 -0.23592246  0.77988076]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 8516. State = [[ 0.0910928  -0.25814626  0.12202533  1.        ]]. Action = [[ 0.66247153 -0.067047    0.72423995  0.9485934 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 8517. State = [[ 0.11356458 -0.26187554  0.13364488  1.        ]]. Action = [[0.78196263 0.5730729  0.8448155  0.9758899 ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 8518. State = [[ 0.12133457 -0.26498824  0.13494088  1.        ]]. Action = [[ 0.2664826  -0.00483823  0.90761805  0.9645617 ]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 8519. State = [[ 0.12419801 -0.26276615  0.1511858   1.        ]]. Action = [[-0.89975953  0.5568943   0.97705996  0.75244284]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 8520. State = [[ 0.12140306 -0.25837338  0.16953556  1.        ]]. Action = [[-0.24798334 -0.07510185  0.90326226  0.98802054]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 8521. State = [[ 0.12192749 -0.2471085   0.18688461  1.        ]]. Action = [[-0.57012296  0.84745383  0.963608    0.9727316 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 8522. State = [[ 0.10841349 -0.21729918  0.22600058  1.        ]]. Action = [[-0.4767446   0.73746896  0.9234301   0.9569092 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 8523. State = [[ 0.08109818 -0.19088493  0.2527432   1.        ]]. Action = [[-0.8193373   0.34247375  0.11949623  0.78120923]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 8524. State = [[ 0.05866802 -0.18373264  0.2788238   1.        ]]. Action = [[-0.36798078 -0.14300269  0.9300568   0.90679073]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 8525. State = [[ 0.04582244 -0.18229732  0.30364943  1.        ]]. Action = [[ 0.33032525 -0.00136012  0.38984025  0.5279584 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 8526. State = [[ 0.04633182 -0.17912859  0.30980012  1.        ]]. Action = [[ 0.24724388  0.15372789 -0.162548    0.6966703 ]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 8527. State = [[ 0.04714878 -0.17776355  0.3084237   1.        ]]. Action = [[ 0.09429991 -0.14024949 -0.19904715  0.547323  ]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 8528. State = [[ 0.04756498 -0.18131581  0.3121756   1.        ]]. Action = [[ 0.00800931 -0.21127146  0.50517774  0.6395923 ]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 8529. State = [[ 0.05332635 -0.18436556  0.32433408  1.        ]]. Action = [[ 0.68330526 -0.09329474  0.63973844  0.52738523]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 8530. State = [[ 0.0581179  -0.18664628  0.33914283  1.        ]]. Action = [[-0.00288725 -0.03787959  0.25425863  0.6856464 ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 8531. State = [[ 0.05822523 -0.18536498  0.35879058  1.        ]]. Action = [[-0.34916472  0.22809732  0.7428924   0.73607135]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 8532. State = [[ 0.05059699 -0.18088084  0.37811333  1.        ]]. Action = [[-0.6245867   0.25415325  0.11275256  0.7567513 ]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 8533. State = [[ 0.03958575 -0.16653647  0.39514133  1.        ]]. Action = [[-0.45559365  0.50828767  0.26714957  0.73158574]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 8534. State = [[ 0.02455881 -0.15309577  0.3978916   1.        ]]. Action = [[-0.3262657   0.12484312 -0.36279428  0.4726398 ]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 8535. State = [[ 0.01696166 -0.15264314  0.39798576  1.        ]]. Action = [[-0.24288535 -0.14582801  0.19796622  0.40298438]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 8536. State = [[ 0.01170021 -0.15195009  0.4014749   1.        ]]. Action = [[-0.18012202  0.15009832  0.01064932  0.41249967]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 8537. State = [[ 0.0044253  -0.1483488   0.40164164  1.        ]]. Action = [[0.10533369 0.08473063 0.45402622 0.4084009 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 8538. State = [[-8.4555527e-04 -1.4811884e-01  4.0057889e-01  1.0000000e+00]]. Action = [[ 0.07681882  0.05530739 -0.2612731   0.33166623]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 8539. State = [[-0.00611982 -0.14467421  0.39331988  1.        ]]. Action = [[-0.41446358  0.15055299 -0.5268783   0.3805561 ]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 8540. State = [[-0.01357174 -0.13691302  0.3810173   1.        ]]. Action = [[0.21677339 0.19087505 0.15310776 0.3974049 ]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 8541. State = [[-0.01298101 -0.13459314  0.3811438   1.        ]]. Action = [[ 0.3267715  -0.11337614 -0.05637127  0.47164106]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 8542. State = [[-0.00918446 -0.13195415  0.37955862  1.        ]]. Action = [[0.4562428  0.12016392 0.0535841  0.27500987]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 8543. State = [[-0.00385957 -0.12971188  0.373844    1.        ]]. Action = [[ 0.0385741   0.04920769 -0.10943812  0.3576572 ]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 8544. State = [[-0.00326682 -0.1308523   0.3733261   1.        ]]. Action = [[-0.05898321 -0.17258441  0.02839911  0.37137604]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 8545. State = [[-0.00180325 -0.13234015  0.37092635  1.        ]]. Action = [[ 0.37342548 -0.04930848 -0.14476687  0.3114388 ]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 8546. State = [[ 1.3415604e-04 -1.3378441e-01  3.6713973e-01  1.0000000e+00]]. Action = [[-0.3489716  -0.07584572  0.19160604  0.42394233]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 8547. State = [[ 0.00332738 -0.13662869  0.3671229   1.        ]]. Action = [[ 0.51508796 -0.11934572 -0.05054843  0.36077607]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 8548. State = [[ 0.01384823 -0.14478196  0.3730191   1.        ]]. Action = [[ 0.14254463 -0.34463537  0.49938285  0.40319896]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 8549. State = [[ 0.02312209 -0.1519282   0.38122267  1.        ]]. Action = [[0.3709309  0.00176096 0.07116628 0.27752137]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 8550. State = [[ 0.02818422 -0.15360232  0.38180536  1.        ]]. Action = [[-0.26493895 -0.05592835 -0.1184088   0.3820883 ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 8551. State = [[ 0.02541946 -0.15373436  0.37852633  1.        ]]. Action = [[-0.630245    0.18979728 -0.37309468  0.35349584]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 8552. State = [[ 0.01832401 -0.15088394  0.37060484  1.        ]]. Action = [[-0.30203182  0.20505595 -0.23318416  0.34839952]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 8553. State = [[ 0.01464093 -0.14645049  0.36691496  1.        ]]. Action = [[-0.11869037  0.0911665  -0.05190295  0.31826496]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 8554. State = [[ 0.00995506 -0.14495948  0.36136872  1.        ]]. Action = [[ 0.07915258 -0.00177509 -0.29681063  0.31601107]]. Reward = [0.]
Curr episode timestep = 55
Current timestep = 8555. State = [[ 0.00922489 -0.14479093  0.35923216  1.        ]]. Action = [[ 0.2111448  -0.07001257 -0.01112843  0.44937897]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 8556. State = [[ 0.00959662 -0.14511386  0.35857454  1.        ]]. Action = [[ 0.03330195 -0.05775553 -0.04180479  0.36287892]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 8557. State = [[ 0.00910705 -0.14515078  0.35193726  1.        ]]. Action = [[-0.00179785  0.01221347 -0.4956305   0.3211515 ]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 8558. State = [[ 0.01232882 -0.14483866  0.33413422  1.        ]]. Action = [[ 0.40012515  0.13016152 -0.24576056  0.376104  ]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 8559. State = [[ 0.01795814 -0.14343306  0.3166072   1.        ]]. Action = [[ 0.37315607 -0.11605316 -0.5392934   0.5290153 ]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 8560. State = [[ 0.02743548 -0.141461    0.29864272  1.        ]]. Action = [[ 0.04019117  0.02492487 -0.02992249  0.34869695]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 8561. State = [[ 0.03062104 -0.14397994  0.29703507  1.        ]]. Action = [[ 0.2711681  -0.18661046  0.05464792  0.3982693 ]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 8562. State = [[ 0.04454204 -0.1479432   0.30344123  1.        ]]. Action = [[ 0.6156647  -0.10187495  0.5764363   0.3959577 ]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 8563. State = [[ 0.0531956  -0.15360348  0.30759367  1.        ]]. Action = [[-0.20762503 -0.17122209 -0.51784825  0.48538482]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 8564. State = [[ 0.05438631 -0.15527587  0.29343748  1.        ]]. Action = [[-0.41236144  0.21041775 -0.4358251   0.2982216 ]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 8565. State = [[ 0.05335643 -0.15760013  0.2930714   1.        ]]. Action = [[-0.27056658 -0.09979951  0.47046185  0.44531465]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 8566. State = [[ 0.05474828 -0.16097073  0.30454925  1.        ]]. Action = [[ 0.47386456 -0.21347809  0.7253485   0.32687402]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 8567. State = [[ 0.05373776 -0.16711652  0.32301927  1.        ]]. Action = [[-0.12549818 -0.0716536   0.513458    0.4105966 ]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 8568. State = [[ 0.05302748 -0.16590217  0.3326479   1.        ]]. Action = [[ 0.15505004  0.23956454 -0.14930224  0.6336813 ]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 8569. State = [[ 0.05109692 -0.16273502  0.33382356  1.        ]]. Action = [[-0.6096108   0.07041585 -0.04677886  0.49714315]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 8570. State = [[ 0.04576278 -0.1625943   0.33890697  1.        ]]. Action = [[-0.3640797  -0.0821054   0.08977532  0.43693602]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 8571. State = [[ 0.03540314 -0.16419928  0.34721348  1.        ]]. Action = [[-0.3154279   0.01013541  0.26032186  0.4681394 ]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 8572. State = [[ 0.02132068 -0.16327731  0.35506356  1.        ]]. Action = [[-0.24345696  0.00680852  0.15597737  0.3259492 ]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 8573. State = [[ 0.01638977 -0.16242045  0.35908738  1.        ]]. Action = [[ 0.20145488  0.02151883 -0.08115399  0.50963616]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 8574. State = [[ 0.01502829 -0.16290367  0.3577938   1.        ]]. Action = [[-0.16099662 -0.04494125 -0.17953992  0.3999877 ]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 8575. State = [[ 0.01271199 -0.16413023  0.35550565  1.        ]]. Action = [[ 0.07165265 -0.10352099  0.01007152  0.45859456]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 8576. State = [[ 0.01221325 -0.16441667  0.3542886   1.        ]]. Action = [[ 0.13200843  0.00054467 -0.19112319  0.22018635]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 8577. State = [[ 0.01372907 -0.16402128  0.35504782  1.        ]]. Action = [[ 0.514616   -0.02604854  0.30489874  0.4651662 ]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 8578. State = [[ 0.02636364 -0.16273089  0.35872948  1.        ]]. Action = [[ 0.9061893  -0.03590792  0.28637552  0.43645775]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 8579. State = [[ 0.04798979 -0.16205853  0.36810955  1.        ]]. Action = [[ 0.19267917 -0.0237813   0.5330275   0.51184106]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 8580. State = [[ 0.05877752 -0.15864564  0.3829404   1.        ]]. Action = [[0.19780862 0.20852065 0.3429278  0.46497   ]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 8581. State = [[ 0.06197476 -0.15558758  0.3893314   1.        ]]. Action = [[-0.577301    0.07921684 -0.2525947   0.401397  ]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 8582. State = [[ 0.0582016  -0.15761794  0.3847148   1.        ]]. Action = [[-0.23802328 -0.0749656  -0.38121533  0.3588525 ]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 8583. State = [[ 0.04865629 -0.16501759  0.37598395  1.        ]]. Action = [[-0.70212746 -0.31919384 -0.4104498   0.37813723]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 8584. State = [[ 0.03189157 -0.17109892  0.3758986   1.        ]]. Action = [[-0.38179696  0.18679237  0.6057626   0.4349854 ]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 8585. State = [[ 0.0201939  -0.16702066  0.3828988   1.        ]]. Action = [[ 0.03759515  0.02053487 -0.07544863  0.5058253 ]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 8586. State = [[ 0.01871315 -0.16557877  0.3814968   1.        ]]. Action = [[-0.04500121  0.0868758  -0.12646013  0.53226495]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 8587. State = [[ 0.01246392 -0.16279502  0.37528944  1.        ]]. Action = [[-0.36197495  0.07986808 -0.31314456  0.516881  ]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 8588. State = [[ 0.01095702 -0.16037755  0.37004545  1.        ]]. Action = [[ 0.54059887  0.03846109 -0.13883007  0.34841514]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 8589. State = [[ 0.01535576 -0.15752332  0.36543375  1.        ]]. Action = [[ 0.410187    0.08528781 -0.15674555  0.47460103]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 8590. State = [[ 0.01922374 -0.15406077  0.35680363  1.        ]]. Action = [[-0.4520049   0.1069926  -0.37033367  0.35029638]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 8591. State = [[ 0.01847754 -0.15399933  0.35772958  1.        ]]. Action = [[ 0.23084724 -0.2347818   0.562323    0.31938112]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 8592. State = [[ 0.01974873 -0.15622823  0.3643789   1.        ]]. Action = [[ 0.10778809 -0.1114406   0.38968337  0.25610912]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 8593. State = [[ 0.02268392 -0.15789735  0.36676943  1.        ]]. Action = [[ 0.32111287 -0.06517369 -0.24906969  0.35334492]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 8594. State = [[ 0.02379531 -0.15861224  0.36853454  1.        ]]. Action = [[-0.16804028  0.08261073  0.3143109   0.3565457 ]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 8595. State = [[ 0.02436512 -0.1558431   0.36746043  1.        ]]. Action = [[ 0.00775945  0.2508242  -0.43469828  0.31155086]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 8596. State = [[ 0.02458194 -0.15043642  0.36407223  1.        ]]. Action = [[-0.08808959  0.2249676  -0.18924004  0.3085208 ]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 8597. State = [[ 0.02153352 -0.14584294  0.36386773  1.        ]]. Action = [[-0.6695904   0.06841671  0.3027662   0.36353147]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 8598. State = [[ 0.01267196 -0.14385135  0.36551687  1.        ]]. Action = [[-0.16121745 -0.05655247 -0.12002802  0.30903733]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 8599. State = [[ 0.010382   -0.14438315  0.3645553   1.        ]]. Action = [[ 0.36341918 -0.01089728 -0.01098186  0.32851386]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 8600. State = [[-0.25940174 -0.05753015  0.09371784  1.        ]]. Action = [[ 0.05859792  0.04600537 -0.28814524  0.42788124]]. Reward = [0.]
Curr episode timestep = 101
Current timestep = 8601. State = [[-0.25653398 -0.07139453  0.08621262  1.        ]]. Action = [[ 0.1738118  -0.45075643  0.9399333   0.9810009 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 8602. State = [[-0.24591638 -0.08958906  0.10799937  1.        ]]. Action = [[ 0.50860333 -0.4911095   0.9229691   0.9765434 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 8603. State = [[-0.22652313 -0.10832383  0.14343356  1.        ]]. Action = [[ 0.70252514 -0.52327245  0.9746853   0.90706575]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 8604. State = [[-0.19673914 -0.12864326  0.17666014  1.        ]]. Action = [[ 0.8693595  -0.55208284  0.57350516  0.9732864 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 8605. State = [[-0.17406261 -0.1424497   0.19553447  1.        ]]. Action = [[ 0.68377376 -0.3471082   0.8663206   0.9651692 ]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 8606. State = [[-0.17118713 -0.14546797  0.19867522  1.        ]]. Action = [[ 0.8112087  -0.38314587  0.85736775  0.96333945]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 8607. State = [[-0.17131847 -0.14576398  0.1987242   1.        ]]. Action = [[ 0.7141844  -0.24767643  0.60610175  0.9128765 ]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 8608. State = [[-0.17134003 -0.14582528  0.19873427  1.        ]]. Action = [[ 0.7879436  -0.5065279   0.39323294  0.94698906]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 8609. State = [[-0.17134003 -0.14582528  0.19873427  1.        ]]. Action = [[ 0.87863517 -0.42777395  0.06960201  0.90832186]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 8610. State = [[-0.17144194 -0.14578198  0.19872883  1.        ]]. Action = [[ 0.24723017 -0.35452175  0.68900037  0.8939285 ]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 8611. State = [[-0.16683786 -0.1586062   0.20490277  1.        ]]. Action = [[ 0.30318093 -0.79322404  0.3405373   0.86720455]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 8612. State = [[-0.14923413 -0.18561843  0.22251399  1.        ]]. Action = [[ 0.82871175 -0.8204695   0.3553412   0.8644798 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 8613. State = [[-0.12092453 -0.20835815  0.24234404  1.        ]]. Action = [[ 0.90895534 -0.34290946  0.6692864   0.92083836]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 8614. State = [[-0.08690279 -0.22459592  0.2610667   1.        ]]. Action = [[ 0.96334696 -0.38255477  0.0837183   0.53823566]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 8615. State = [[-0.05377558 -0.23101297  0.25832617  1.        ]]. Action = [[ 0.9855468   0.01748347 -0.8087802   0.7719202 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 8616. State = [[-0.01922667 -0.24078345  0.23224038  1.        ]]. Action = [[ 0.885561  -0.3885008 -0.509453   0.6232735]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 8617. State = [[ 0.01997332 -0.25497887  0.2156893   1.        ]]. Action = [[ 0.9766462  -0.45383465  0.00764954  0.67162895]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 8618. State = [[ 0.05880353 -0.26509     0.2142061   1.        ]]. Action = [[ 0.9567858  -0.0700261   0.12443686  0.88201547]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 8619. State = [[ 0.09356969 -0.26337424  0.23246284  1.        ]]. Action = [[0.48804665 0.43308902 0.95708394 0.98270106]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 8620. State = [[ 0.11014035 -0.25799555  0.2662185   1.        ]]. Action = [[-0.2707739   0.2732725   0.9464698   0.96476364]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 8621. State = [[ 0.11094699 -0.2500198   0.30228728  1.        ]]. Action = [[-0.90432197  0.5018176   0.8835466   0.72575164]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 8622. State = [[ 0.0980455  -0.23039144  0.34544566  1.        ]]. Action = [[-0.9466246  0.7450559  0.9785582  0.9641669]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 8623. State = [[ 0.06936044 -0.19986849  0.3916888   1.        ]]. Action = [[-0.9232482   0.7744355   0.95894825  0.864326  ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 8624. State = [[ 0.03656127 -0.17809425  0.41535717  1.        ]]. Action = [[-0.95124406  0.64801407  0.92235804  0.67801714]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 8625. State = [[ 0.03004958 -0.17503649  0.4203847   1.        ]]. Action = [[-0.5337208   0.37240076  0.19288647  0.38634467]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 8626. State = [[ 0.02940847 -0.17470735  0.4209666   1.        ]]. Action = [[-0.49676907  0.36171257  0.32468033  0.36728513]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 8627. State = [[ 0.02466701 -0.16865358  0.4195239   1.        ]]. Action = [[-0.5483591   0.37011635 -0.18802607  0.40193105]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 8628. State = [[ 0.01447975 -0.16060105  0.4174876   1.        ]]. Action = [[-0.5636899   0.20531368  0.06620741  0.45651948]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 8629. State = [[ 0.01231236 -0.15969236  0.4161517   1.        ]]. Action = [[-0.6947828   0.2521609   0.22318697  0.3988104 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 8630. State = [[ 0.01170101 -0.15968373  0.4156845   1.        ]]. Action = [[-0.36671805  0.13454723  0.18701279  0.27398586]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 8631. State = [[ 0.00863598 -0.15532573  0.4132486   1.        ]]. Action = [[-0.29004973  0.26108086 -0.12819093  0.23448288]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 8632. State = [[ 0.00312958 -0.14939523  0.40769956  1.        ]]. Action = [[ 0.13039029 -0.00245893 -0.48962772  0.37689543]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 8633. State = [[-2.6962810e-04 -1.4668852e-01  3.9688647e-01  1.0000000e+00]]. Action = [[0.02587342 0.13069081 0.002738   0.38093197]]. Reward = [0.]
Curr episode timestep = 32
Current timestep = 8634. State = [[-0.00277639 -0.13803068  0.39107993  1.        ]]. Action = [[-0.18937814  0.3615836  -0.34885168  0.37560308]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 8635. State = [[-0.00591624 -0.13060948  0.3844832   1.        ]]. Action = [[-0.0185495   0.00835562  0.14701223  0.38813353]]. Reward = [0.]
Curr episode timestep = 34
Current timestep = 8636. State = [[-0.00588591 -0.12770507  0.38378063  1.        ]]. Action = [[ 0.18679261  0.12682998 -0.17166841  0.4130957 ]]. Reward = [0.]
Curr episode timestep = 35
Current timestep = 8637. State = [[-0.00526639 -0.12527451  0.38360944  1.        ]]. Action = [[ 0.27891588 -0.01819837  0.1427561   0.41217065]]. Reward = [0.]
Curr episode timestep = 36
Current timestep = 8638. State = [[-0.00227353 -0.12327696  0.37783524  1.        ]]. Action = [[ 0.41956007  0.01812136 -0.33806813  0.31694937]]. Reward = [0.]
Curr episode timestep = 37
Current timestep = 8639. State = [[ 0.00420856 -0.12332743  0.36284593  1.        ]]. Action = [[-0.24093854 -0.13552088 -0.53367627  0.34084344]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 8640. State = [[ 0.00640202 -0.12444746  0.3490374   1.        ]]. Action = [[ 0.11796796  0.0307678  -0.19714129  0.36741018]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 8641. State = [[ 0.00979269 -0.12766789  0.33901963  1.        ]]. Action = [[ 0.1534357  -0.23135608 -0.13377106  0.26552916]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 8642. State = [[ 0.01012789 -0.1333563   0.33438778  1.        ]]. Action = [[-0.02131981 -0.20007509 -0.2953629   0.36021936]]. Reward = [0.]
Curr episode timestep = 41
Current timestep = 8643. State = [[ 0.01183689 -0.13919476  0.32835323  1.        ]]. Action = [[ 0.17493856 -0.14126086  0.05706608  0.3816222 ]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 8644. State = [[ 0.01694042 -0.14646344  0.32033446  1.        ]]. Action = [[ 0.37142372 -0.21098834 -0.11830807  0.28171813]]. Reward = [0.]
Curr episode timestep = 43
Current timestep = 8645. State = [[ 0.02406317 -0.15809174  0.31128293  1.        ]]. Action = [[ 0.5770142  -0.44321197 -0.44814658  0.42760205]]. Reward = [0.]
Curr episode timestep = 44
Current timestep = 8646. State = [[ 0.04652451 -0.17275406  0.2985656   1.        ]]. Action = [[ 0.650429   -0.33987343  0.27110314  0.37873006]]. Reward = [0.]
Curr episode timestep = 45
Current timestep = 8647. State = [[ 0.06008009 -0.18710539  0.3020585   1.        ]]. Action = [[-0.52126056 -0.2582367   0.26567888  0.5274018 ]]. Reward = [0.]
Curr episode timestep = 46
Current timestep = 8648. State = [[ 0.0567541  -0.19255337  0.31584534  1.        ]]. Action = [[-0.11984438  0.14127839  0.68082905  0.60716677]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 8649. State = [[ 0.05121262 -0.19070648  0.34219134  1.        ]]. Action = [[-0.35221636  0.17107713  0.7624192   0.6446469 ]]. Reward = [0.]
Curr episode timestep = 48
Current timestep = 8650. State = [[ 0.04540538 -0.18360357  0.36888134  1.        ]]. Action = [[0.00876462 0.25571775 0.5417261  0.45274162]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 8651. State = [[ 0.04242765 -0.17251489  0.38885236  1.        ]]. Action = [[-0.08729947  0.33804095  0.50094557  0.4596715 ]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 8652. State = [[ 0.03336725 -0.16315353  0.40350786  1.        ]]. Action = [[-0.864789    0.18885934 -0.1288023   0.36968327]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 8653. State = [[ 0.016468   -0.15540701  0.41289613  1.        ]]. Action = [[-0.29030383  0.09193063  0.20639539  0.46270406]]. Reward = [0.]
Curr episode timestep = 52
Current timestep = 8654. State = [[ 0.00196718 -0.15411201  0.41415817  1.        ]]. Action = [[-0.47355658 -0.04146564 -0.25920552  0.3345574 ]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 8655. State = [[-0.00975168 -0.14819388  0.411555    1.        ]]. Action = [[-0.2333669   0.30817986 -0.00280851  0.2397877 ]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 8656. State = [[-0.01912269 -0.14242323  0.41414252  1.        ]]. Action = [[0.00612748 0.27696872 0.32196927 0.37394857]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 8657. State = [[-0.02003482 -0.13914241  0.41286036  1.        ]]. Action = [[ 0.17785227  0.19273484 -0.21001387  0.3934331 ]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 8658. State = [[-0.02077005 -0.13251911  0.41112763  1.        ]]. Action = [[ 0.0758847   0.1714127  -0.07395136  0.28921187]]. Reward = [0.]
Curr episode timestep = 57
Current timestep = 8659. State = [[-0.02010879 -0.12857606  0.40774417  1.        ]]. Action = [[ 0.18998814  0.00954282 -0.10188884  0.3207364 ]]. Reward = [0.]
Curr episode timestep = 58
Current timestep = 8660. State = [[-0.01757989 -0.1264697   0.4022229   1.        ]]. Action = [[ 0.36869764 -0.00927114 -0.02292848  0.24369621]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 8661. State = [[-0.01207016 -0.12636966  0.39632994  1.        ]]. Action = [[-0.01822823 -0.14547348 -0.15937173  0.36772084]]. Reward = [0.]
Curr episode timestep = 60
Current timestep = 8662. State = [[-0.01112378 -0.12871224  0.3962483   1.        ]]. Action = [[ 0.07117057 -0.1347453   0.17119288  0.36730468]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 8663. State = [[-0.01051914 -0.12959804  0.39433613  1.        ]]. Action = [[ 0.09220803  0.12946498 -0.23138434  0.32950997]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 8664. State = [[-0.00867997 -0.12948407  0.393737    1.        ]]. Action = [[ 0.1690669  -0.10958028  0.28974771  0.2189362 ]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 8665. State = [[-0.00381087 -0.13366029  0.39722824  1.        ]]. Action = [[ 0.34596038 -0.18708897  0.15456903  0.30276096]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 8666. State = [[ 0.00230074 -0.13655807  0.39310133  1.        ]]. Action = [[ 0.00097883 -0.00868231 -0.3123927   0.35546875]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 8667. State = [[ 0.00582132 -0.13658239  0.3876831   1.        ]]. Action = [[-0.31269342  0.02614951  0.00499487  0.27593994]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 8668. State = [[ 0.00307497 -0.1401209   0.3846902   1.        ]]. Action = [[-0.3020444  -0.18924564 -0.32692856  0.30527318]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 8669. State = [[ 0.00308465 -0.14412181  0.3783941   1.        ]]. Action = [[ 0.32774198 -0.08992308 -0.32823753  0.31908453]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 8670. State = [[ 0.00878263 -0.15066038  0.37270606  1.        ]]. Action = [[ 0.64309156 -0.2187177   0.13897312  0.42409396]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 8671. State = [[ 0.02648106 -0.15487881  0.37109545  1.        ]]. Action = [[0.44052637 0.01699054 0.3098836  0.38845217]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 8672. State = [[ 0.03264311 -0.15885505  0.37753788  1.        ]]. Action = [[-0.51289797 -0.14283413  0.20240319  0.30281174]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 8673. State = [[ 0.03478923 -0.16255854  0.3847281   1.        ]]. Action = [[ 0.39740193 -0.07772362  0.33828926  0.38450134]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 8674. State = [[ 0.03652135 -0.16917525  0.38568717  1.        ]]. Action = [[-0.13725573 -0.28811264 -0.43617857  0.3232447 ]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 8675. State = [[ 0.03832881 -0.17733206  0.38617167  1.        ]]. Action = [[ 0.31729686 -0.15059215  0.36164355  0.36961627]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 8676. State = [[ 0.04012066 -0.1792785   0.3914992   1.        ]]. Action = [[-0.15836829  0.0933578   0.2765261   0.49230647]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 8677. State = [[ 0.03922974 -0.17966948  0.39655784  1.        ]]. Action = [[-0.56358194  0.05125773 -0.21888268  0.54447865]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 8678. State = [[ 0.03750851 -0.18046167  0.40069443  1.        ]]. Action = [[0.21308935 0.04537368 0.33437634 0.3468064 ]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 8679. State = [[ 0.0325483  -0.17876141  0.39856863  1.        ]]. Action = [[-0.6182654   0.13874912 -0.5233944   0.43417788]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 8680. State = [[ 0.01921006 -0.17778032  0.39006022  1.        ]]. Action = [[-0.55507463  0.00984716 -0.37079358  0.43806005]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 8681. State = [[ 0.00700552 -0.17795078  0.38328412  1.        ]]. Action = [[-0.02202487 -0.05640709 -0.00123179  0.33083892]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 8682. State = [[ 0.00621241 -0.1796243   0.38119197  1.        ]]. Action = [[ 0.30025196 -0.13568723 -0.3073094   0.39114594]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 8683. State = [[ 0.01027346 -0.17923565  0.37128502  1.        ]]. Action = [[ 0.5958574  -0.00585097 -0.517754    0.37051463]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 8684. State = [[ 0.02274316 -0.17970198  0.34595537  1.        ]]. Action = [[ 0.66600585 -0.10621029 -0.47729003  0.5121484 ]]. Reward = [0.]
Curr episode timestep = 83
Current timestep = 8685. State = [[ 0.04238356 -0.18515505  0.33202073  1.        ]]. Action = [[ 0.6464894  -0.32789445  0.3375497   0.5156779 ]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 8686. State = [[ 0.05538332 -0.19220504  0.3353951   1.        ]]. Action = [[-0.3995229   0.10659468  0.10294437  0.39515257]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 8687. State = [[ 0.05247321 -0.19366685  0.34830952  1.        ]]. Action = [[-0.5303313   0.057634    0.6907494   0.63649917]]. Reward = [0.]
Curr episode timestep = 86
Current timestep = 8688. State = [[ 0.04105936 -0.19391412  0.36745197  1.        ]]. Action = [[-0.660529    0.11738503  0.17880261  0.5630499 ]]. Reward = [0.]
Curr episode timestep = 87
Current timestep = 8689. State = [[ 0.02100041 -0.18606798  0.37984255  1.        ]]. Action = [[-0.5735333   0.34081507  0.24995267  0.5724083 ]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 8690. State = [[ 0.00412033 -0.17679268  0.37952614  1.        ]]. Action = [[ 0.00217068  0.07495224 -0.6007758   0.35610318]]. Reward = [0.]
Curr episode timestep = 89
Current timestep = 8691. State = [[-0.00189048 -0.17712201  0.38158873  1.        ]]. Action = [[-0.34039629 -0.10534948  0.5039971   0.46161342]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 8692. State = [[-0.00787991 -0.17854491  0.38675368  1.        ]]. Action = [[-0.39643896  0.06661379 -0.04952991  0.3828522 ]]. Reward = [0.]
Curr episode timestep = 91
Current timestep = 8693. State = [[-0.01669941 -0.17618997  0.38514507  1.        ]]. Action = [[ 0.8041525  -0.06361765 -0.00682175  0.5395931 ]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 8694. State = [[-0.01255114 -0.17549363  0.37665927  1.        ]]. Action = [[ 0.47690248 -0.11509246 -0.6389512   0.35753226]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 8695. State = [[-0.00180036 -0.17599007  0.3585926   1.        ]]. Action = [[ 0.22903836 -0.08145326 -0.2208488   0.3643242 ]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 8696. State = [[ 0.00394246 -0.17622966  0.3435395   1.        ]]. Action = [[-0.17231649  0.14835441 -0.48070556  0.3108555 ]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 8697. State = [[ 0.00805583 -0.17691647  0.34011817  1.        ]]. Action = [[ 0.46827555 -0.15895784  0.13591433  0.39695835]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 8698. State = [[ 0.01492045 -0.17708798  0.33432284  1.        ]]. Action = [[ 0.10566783  0.02806187 -0.29472554  0.44279146]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 8699. State = [[ 0.02476769 -0.17522597  0.32413518  1.        ]]. Action = [[0.32031476 0.01957726 0.02647209 0.45886505]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 8700. State = [[ 0.0318219  -0.180328    0.31944776  1.        ]]. Action = [[-0.04928255 -0.21941018 -0.30293047  0.4020548 ]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 8701. State = [[ 0.03363491 -0.18732916  0.30934504  1.        ]]. Action = [[ 0.02370071 -0.19611222 -0.15395302  0.42066455]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 8702. State = [[-0.26624107  0.12242078  0.09000366  1.        ]]. Action = [[ 0.3855189  -0.17025399  0.5367091   0.3447137 ]]. Reward = [0.]
Curr episode timestep = 101
Current timestep = 8703. State = [[-0.2529246   0.1238135   0.08502658  1.        ]]. Action = [[ 0.6806066 -0.8001718  0.9882958  0.9079069]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 8704. State = [[-0.23349872  0.09826581  0.10407105  1.        ]]. Action = [[ 0.5157136  -0.8179258   0.47294474  0.99414337]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 8705. State = [[-0.20758346  0.06952638  0.12846413  1.        ]]. Action = [[ 0.87809753 -0.8304961   0.9622545   0.98936296]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 8706. State = [[-0.17619017  0.03954771  0.16270082  1.        ]]. Action = [[ 0.67612326 -0.78052235  0.75985885  0.9239261 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 8707. State = [[-0.15726756  0.02234343  0.1831      1.        ]]. Action = [[ 0.89752316 -0.5963831   0.94216347  0.9882339 ]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 8708. State = [[-0.15500131  0.02038498  0.1853535   1.        ]]. Action = [[ 0.6205423 -0.5747387  0.7883401  0.9864538]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 8709. State = [[-0.15492293  0.01953814  0.18550465  1.        ]]. Action = [[ 0.7174982  -0.27771437 -0.57494175  0.8765662 ]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 8710. State = [[-0.15505548  0.01940843  0.18563376  1.        ]]. Action = [[ 0.8616067  -0.75264156  0.07811654  0.86097026]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 8711. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.77720225 -0.72657895  0.41100883  0.72179365]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 8712. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.5388119  -0.65883917 -0.41080177  0.7023835 ]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 8713. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.61571527 -0.74226266  0.34285557  0.86946034]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 8714. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.78577757 -0.71673256  0.68382394  0.91728187]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: No entry zone
Current timestep = 8715. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.8534087  -0.67044944  0.15048671  0.9494077 ]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: No entry zone
Current timestep = 8716. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.15440309 -0.6619231  -0.01385987  0.9121108 ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: No entry zone
Current timestep = 8717. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.19359422 -0.82871306  0.9199406   0.9355726 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: No entry zone
Current timestep = 8718. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.28967583 -0.61991876  0.6874589   0.90991926]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: No entry zone
Current timestep = 8719. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.8256154  -0.6677368   0.5223812   0.91158164]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: No entry zone
Current timestep = 8720. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.5704267 -0.6770444  0.0557555  0.8324866]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: No entry zone
Current timestep = 8721. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.4666469  -0.682932    0.14855838  0.9471724 ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: No entry zone
Current timestep = 8722. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.87726307 -0.4950586   0.30762148  0.95463395]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: No entry zone
Current timestep = 8723. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.35260618 -0.7010651   0.16070604  0.97353053]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: No entry zone
Current timestep = 8724. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.4078002  -0.56685674 -0.0767501   0.77514267]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: No entry zone
Current timestep = 8725. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.33682954 -0.51264554  0.69782925  0.9803827 ]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: No entry zone
Current timestep = 8726. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.9710367  -0.68823963  0.91254354  0.9362575 ]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: No entry zone
Current timestep = 8727. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.9715462  -0.5373988   0.2367444   0.87253785]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: No entry zone
Current timestep = 8728. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.23793411 -0.8286364  -0.27562904  0.98743725]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: No entry zone
Current timestep = 8729. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.7991142  -0.7355976   0.94020176  0.84041536]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: No entry zone
Current timestep = 8730. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.66862965 -0.7172447  -0.13480413  0.9330659 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: No entry zone
Current timestep = 8731. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.88154924 -0.6866716   0.8155956   0.90901756]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: No entry zone
Current timestep = 8732. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.22171521 -0.4608388   0.43838966  0.9278549 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: No entry zone
Current timestep = 8733. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.8660451  -0.5625745   0.86924326  0.9441141 ]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: No entry zone
Current timestep = 8734. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.7174723  -0.5171525  -0.57472706  0.9517726 ]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: No entry zone
Current timestep = 8735. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.4764501  -0.55838656  0.59841716  0.86933386]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: No entry zone
Current timestep = 8736. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.63075876 -0.67571086  0.65052795  0.9320134 ]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: No entry zone
Current timestep = 8737. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.8135419  -0.5844447   0.30234325  0.9576739 ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: No entry zone
Current timestep = 8738. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.88881814 -0.61830604  0.6712458   0.9207456 ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: No entry zone
Current timestep = 8739. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.9002416  -0.6987056   0.2753563   0.94565856]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: No entry zone
Current timestep = 8740. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.81673956 -0.6562837   0.9276364   0.5827668 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: No entry zone
Current timestep = 8741. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.84085894 -0.5398666   0.58564305  0.9616127 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: No entry zone
Current timestep = 8742. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.60078573 -0.6590011   0.67156935  0.9027171 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: No entry zone
Current timestep = 8743. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.8101826  -0.4920025   0.96263266  0.9888127 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: No entry zone
Current timestep = 8744. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.31725383 -0.69258505  0.01048768  0.9309101 ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: No entry zone
Current timestep = 8745. State = [[-0.15470672  0.01948181  0.18587214  1.        ]]. Action = [[ 0.8267195  -0.7625445   0.9134489   0.96140575]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: No entry zone
Current timestep = 8746. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.07296133 -0.6485751   0.6025424   0.9462905 ]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: No entry zone
Current timestep = 8747. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[-0.21015286 -0.44255185  0.75364506  0.9657031 ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: No entry zone
Current timestep = 8748. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.9689083  -0.6875659   0.8399428   0.88272023]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: No entry zone
Current timestep = 8749. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.8521004  -0.71874875  0.80869913  0.59509444]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: No entry zone
Current timestep = 8750. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.54434204 -0.767365   -0.22768492  0.892679  ]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: No entry zone
Current timestep = 8751. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.3798213  -0.5342074   0.91584194  0.8738967 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: No entry zone
Current timestep = 8752. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.8329158  -0.6647797   0.8764875   0.96391034]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: No entry zone
Current timestep = 8753. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.02421856 -0.4448632   0.37451434  0.67263246]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: No entry zone
Current timestep = 8754. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.85940385 -0.75103575  0.7407253   0.91878915]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: No entry zone
Current timestep = 8755. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.7064581  -0.68477935  0.04326081  0.87414956]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: No entry zone
Current timestep = 8756. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.7227688 -0.6333258  0.275666   0.9264308]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: No entry zone
Current timestep = 8757. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.5596843  -0.6656833   0.64802504  0.90337837]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: No entry zone
Current timestep = 8758. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.42922664 -0.5855769  -0.7921323   0.9239073 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: No entry zone
Current timestep = 8759. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.8512676  -0.3557937   0.8861377   0.95007515]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: No entry zone
Current timestep = 8760. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.305112  -0.7461093  0.8384348  0.9809036]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: No entry zone
Current timestep = 8761. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.36468732 -0.46917927  0.8932736   0.9442363 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: No entry zone
Current timestep = 8762. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.947736   -0.62356997 -0.03464913  0.9119302 ]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: No entry zone
Current timestep = 8763. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.4565823 -0.7769771  0.7780036  0.9314451]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: No entry zone
Current timestep = 8764. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.6406871  -0.62991613  0.6908188   0.9161607 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: No entry zone
Current timestep = 8765. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.67602396 -0.6182752   0.88977873  0.92140985]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: No entry zone
Current timestep = 8766. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.49319315 -0.7519906   0.19552243  0.925334  ]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: No entry zone
Current timestep = 8767. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.887794   -0.6713721  -0.25097054  0.79531264]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: No entry zone
Current timestep = 8768. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.8651297 -0.4691205  0.870877   0.851895 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: No entry zone
Current timestep = 8769. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.8731451  -0.3953197   0.89856184  0.9310038 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: No entry zone
Current timestep = 8770. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.4550159  -0.47371435  0.9460995   0.9692805 ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: No entry zone
Current timestep = 8771. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.592185   -0.68862677  0.9916626   0.89647126]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: No entry zone
Current timestep = 8772. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.28467834 -0.69560695  0.91867566  0.908389  ]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: No entry zone
Current timestep = 8773. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.54617095 -0.65182155  0.7029108   0.95655763]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: No entry zone
Current timestep = 8774. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.85399866 -0.66413283  0.89531636  0.8780656 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: No entry zone
Current timestep = 8775. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.85903203 -0.8436061   0.6764884   0.9190192 ]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: No entry zone
Current timestep = 8776. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.38971376 -0.65285814  0.7719238   0.9575727 ]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: No entry zone
Current timestep = 8777. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.7275338  -0.74903494  0.611331    0.82608676]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: No entry zone
Current timestep = 8778. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.4802804  -0.71890515  0.6042137   0.8748028 ]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: No entry zone
Current timestep = 8779. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.31399918 -0.03799969  0.8613608   0.9625555 ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: No entry zone
Current timestep = 8780. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.8097031  -0.7284969   0.34058988  0.96178377]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: No entry zone
Current timestep = 8781. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.9421742  -0.7988605   0.7510935   0.96673894]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: No entry zone
Current timestep = 8782. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.3738513  -0.80544376  0.34397292  0.9522581 ]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: No entry zone
Current timestep = 8783. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.7555566  -0.43530494  0.7567172   0.92081106]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: No entry zone
Current timestep = 8784. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.83643985 -0.7089852   0.08846664  0.9556434 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: No entry zone
Current timestep = 8785. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.01369727 -0.6970423   0.8682759   0.79785705]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: No entry zone
Current timestep = 8786. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.9424958 -0.7710585  0.8200977  0.9318981]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: No entry zone
Current timestep = 8787. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.8266704  -0.71850693  0.87318754  0.9439378 ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: No entry zone
Current timestep = 8788. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.97274315 -0.740317   -0.1954279   0.7313459 ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: No entry zone
Current timestep = 8789. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.757262   -0.65182    -0.18876493  0.94027996]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: No entry zone
Current timestep = 8790. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.5392275 -0.781206   0.8702254  0.9231043]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: No entry zone
Current timestep = 8791. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.65657496 -0.71685785  0.575261    0.96471643]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: No entry zone
Current timestep = 8792. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.22543764 -0.564308    0.96105015  0.8068371 ]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: No entry zone
Current timestep = 8793. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.7687323  -0.70653     0.14658558  0.90355563]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: No entry zone
Current timestep = 8794. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.925895   -0.65338296  0.05016422  0.91046476]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: No entry zone
Current timestep = 8795. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.8381138 -0.6790771  0.6438017  0.9453025]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: No entry zone
Current timestep = 8796. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.72171795 -0.75008714  0.04484797  0.8883755 ]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: No entry zone
Current timestep = 8797. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.9456942  -0.7040406   0.79266894  0.390607  ]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: No entry zone
Current timestep = 8798. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.8850868 -0.7411385  0.801744   0.8704778]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: No entry zone
Current timestep = 8799. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.6526699  -0.7526286   0.00932753  0.88645256]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: No entry zone
Current timestep = 8800. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.87629807 -0.5766812   0.91919684  0.94797146]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: No entry zone
Current timestep = 8801. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.8875996  -0.7338731   0.97374916  0.9591987 ]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: No entry zone
Current timestep = 8802. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.35901725 -0.49873304  0.987231    0.896014  ]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: No entry zone
Current timestep = 8803. State = [[-0.15473413  0.01948611  0.18587084  1.        ]]. Action = [[ 0.571949   -0.6581026   0.85179996  0.84965086]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: No entry zone
Current timestep = 8804. State = [[-0.25935748 -0.10598473  0.11877948  1.        ]]. Action = [[ 0.7426765  -0.69466275  0.68738866  0.9187882 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: No entry zone
Current timestep = 8805. State = [[-0.25162905 -0.12074009  0.11254618  1.        ]]. Action = [[ 0.7492167  -0.23272198  0.96612835  0.96129906]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 8806. State = [[-0.22922662 -0.1322708   0.13686292  1.        ]]. Action = [[ 0.90149474 -0.48575616  0.9548061   0.97528195]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 8807. State = [[-0.20375116 -0.14565864  0.1720175   1.        ]]. Action = [[ 0.27032018 -0.13142556  0.9652171   0.9845959 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 8808. State = [[-0.19208643 -0.1512001   0.19722188  1.        ]]. Action = [[ 0.9703429  -0.24392843  0.7787088   0.8277677 ]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: No entry zone
Current timestep = 8809. State = [[-0.19155152 -0.15150383  0.19985662  1.        ]]. Action = [[ 0.5109563  -0.3128156  -0.20666027  0.9368236 ]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 8810. State = [[-0.19131881 -0.15196204  0.20037517  1.        ]]. Action = [[ 0.86250424 -0.5594632   0.30564332  0.9615538 ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 8811. State = [[-0.1815385  -0.15467109  0.21193905  1.        ]]. Action = [[ 0.5637605 -0.1530596  0.8133342  0.9199536]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 8812. State = [[-0.16801627 -0.15974998  0.22981055  1.        ]]. Action = [[ 0.6485064  -0.3919443  -0.37871742  0.9729605 ]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 8813. State = [[-0.16535175 -0.16118963  0.23226124  1.        ]]. Action = [[ 0.8060906  -0.11436248 -0.05807519  0.846529  ]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 8814. State = [[-0.15225868 -0.16478619  0.23978068  1.        ]]. Action = [[ 0.9875102  -0.31636655  0.21375811  0.843245  ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 8815. State = [[-0.13606553 -0.1690577   0.25101498  1.        ]]. Action = [[ 0.97662735 -0.24985725 -0.9442967   0.9403578 ]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 8816. State = [[-0.12314662 -0.17336775  0.25081488  1.        ]]. Action = [[ 0.80679476 -0.24309361 -0.19933093  0.62194514]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 8817. State = [[-0.09269089 -0.18524896  0.2551615   1.        ]]. Action = [[ 0.9586389 -0.474411   0.5603883  0.634025 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 8818. State = [[-0.06186872 -0.19469148  0.26006782  1.        ]]. Action = [[ 0.9927994  -0.08488435 -0.84542793  0.52233744]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 8819. State = [[-0.02336149 -0.21021299  0.23938851  1.        ]]. Action = [[ 0.9506053  -0.6080984  -0.02448726  0.5236329 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 8820. State = [[ 0.00689201 -0.23229781  0.22910938  1.        ]]. Action = [[ 0.5450907  -0.69392574 -0.61295456  0.69901145]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 8821. State = [[ 0.03603457 -0.26017255  0.21314925  1.        ]]. Action = [[ 0.88748777 -0.7957741   0.01831675  0.6490773 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 8822. State = [[ 0.07188337 -0.29243237  0.22650369  1.        ]]. Action = [[ 0.9798254  -0.8857915   0.9955934   0.85538304]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 8823. State = [[ 0.09384688 -0.3170514   0.25978917  1.        ]]. Action = [[-0.7256342   0.00688267  0.9903188   0.8001263 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 8824. State = [[ 0.0893859  -0.32808688  0.29972905  1.        ]]. Action = [[-0.87162715  0.1576209   0.9983485   0.5603831 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 8825. State = [[ 0.07547651 -0.31813878  0.34581655  1.        ]]. Action = [[-0.9825683   0.84729683  0.9308367   0.85669637]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 8826. State = [[ 0.04420824 -0.29602477  0.3881843   1.        ]]. Action = [[-0.9719037   0.34310997  0.98235464  0.9372715 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 8827. State = [[ 0.01128269 -0.2812228   0.41516417  1.        ]]. Action = [[-0.73725677  0.50230217  0.79174566  0.90329695]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 8828. State = [[ 0.0057579  -0.27999678  0.41944116  1.        ]]. Action = [[-0.722049    0.55478656  0.6635791   0.83301127]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 8829. State = [[ 0.00492741 -0.2796191   0.41931543  1.        ]]. Action = [[-0.71265656  0.3538586   0.51771235  0.80497634]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 8830. State = [[ 0.00485187 -0.27955505  0.41929132  1.        ]]. Action = [[-0.6796481   0.5507058   0.46231854  0.8060231 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 8831. State = [[ 0.00485187 -0.27955505  0.41929132  1.        ]]. Action = [[0.32147706 0.7628374  0.7419777  0.93669987]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 8832. State = [[ 0.00485187 -0.27955505  0.41929132  1.        ]]. Action = [[-0.35779256  0.8213242   0.8328626   0.7928505 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 8833. State = [[ 0.00485187 -0.27955505  0.41929132  1.        ]]. Action = [[0.19762242 0.48658323 0.7764962  0.8044462 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 8834. State = [[ 0.00485187 -0.27955505  0.41929132  1.        ]]. Action = [[-0.2656964   0.62883186  0.83331525  0.7921238 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 8835. State = [[ 0.00485187 -0.27955505  0.41929132  1.        ]]. Action = [[-0.40351754  0.7485777   0.45101833  0.88686514]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 8836. State = [[ 0.00485187 -0.27955505  0.41929132  1.        ]]. Action = [[0.04537737 0.74214983 0.6802423  0.76829994]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 8837. State = [[ 0.00485187 -0.27955505  0.41929132  1.        ]]. Action = [[-0.63697374  0.5783887   0.88496494  0.8054831 ]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 8838. State = [[ 0.00485187 -0.27955505  0.41929132  1.        ]]. Action = [[0.2348392 0.8196709 0.6441848 0.8737986]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 8839. State = [[ 0.00485187 -0.27955505  0.41929132  1.        ]]. Action = [[-0.44661766  0.76474166  0.5005343   0.8336339 ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 8840. State = [[ 0.00485187 -0.27955505  0.41929132  1.        ]]. Action = [[-0.3505429   0.8384099   0.25225472  0.8648286 ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 8841. State = [[ 0.00485187 -0.27955505  0.41929132  1.        ]]. Action = [[0.01580894 0.4297489  0.76324236 0.80449426]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 8842. State = [[ 0.00485187 -0.27955505  0.41929132  1.        ]]. Action = [[-0.49483478  0.5815548   0.40125632  0.83327746]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 8843. State = [[ 0.00430938 -0.27365485  0.41828412  1.        ]]. Action = [[-0.15129173  0.35986602 -0.10797703  0.76764274]]. Reward = [0.]
Curr episode timestep = 38
Current timestep = 8844. State = [[ 0.00380679 -0.2669788   0.41790307  1.        ]]. Action = [[0.14020324 0.70563185 0.6613436  0.8294158 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 8845. State = [[ 0.00385169 -0.266434    0.4179452   1.        ]]. Action = [[-0.3970698   0.83112335  0.3542049   0.81582737]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 8846. State = [[ 0.00385169 -0.266434    0.4179452   1.        ]]. Action = [[-0.48020077  0.4939778   0.61385417  0.7839458 ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 8847. State = [[ 0.00385169 -0.266434    0.4179452   1.        ]]. Action = [[-0.5607018  0.2959963  0.4709772  0.7433895]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 8848. State = [[ 0.00385169 -0.266434    0.4179452   1.        ]]. Action = [[0.24455237 0.71464455 0.5146569  0.84209824]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 8849. State = [[ 0.00385169 -0.266434    0.4179452   1.        ]]. Action = [[-0.29454958  0.41184223  0.77736616  0.7538781 ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 8850. State = [[ 0.00385169 -0.266434    0.4179452   1.        ]]. Action = [[0.00648749 0.4814775  0.87494326 0.7708391 ]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 8851. State = [[ 0.00385169 -0.266434    0.4179452   1.        ]]. Action = [[-0.45911598  0.4978335   0.8537159   0.84759736]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 8852. State = [[ 0.00296711 -0.2589222   0.41585386  1.        ]]. Action = [[-0.20674145  0.48173952 -0.18753439  0.803826  ]]. Reward = [0.]
Curr episode timestep = 47
Current timestep = 8853. State = [[-0.00321719 -0.24753585  0.4136003   1.        ]]. Action = [[-0.1790356   0.4199016   0.17395985  0.76280403]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 8854. State = [[-0.00493529 -0.23756991  0.41220316  1.        ]]. Action = [[-0.00803667  0.46733105  0.0152179   0.7450259 ]]. Reward = [0.]
Curr episode timestep = 49
Current timestep = 8855. State = [[-0.00542788 -0.2192016   0.41197222  1.        ]]. Action = [[ 0.30431354  0.4444747  -0.0053581   0.62233925]]. Reward = [0.]
Curr episode timestep = 50
Current timestep = 8856. State = [[-0.00364059 -0.20467235  0.41188425  1.        ]]. Action = [[ 0.05596519  0.23189938 -0.1578911   0.60584116]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 8857. State = [[-0.00348826 -0.19913006  0.41095382  1.        ]]. Action = [[0.07866967 0.25577247 0.18742323 0.58450675]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 8858. State = [[-0.00471043 -0.19517793  0.4082618   1.        ]]. Action = [[-0.16594768  0.17870319 -0.11331946  0.5409123 ]]. Reward = [0.]
Curr episode timestep = 53
Current timestep = 8859. State = [[-0.00577181 -0.18722142  0.40501368  1.        ]]. Action = [[-0.08345455  0.24342585 -0.07516569  0.36089754]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 8860. State = [[-0.00601269 -0.18234074  0.40399194  1.        ]]. Action = [[0.5627402  0.1406188  0.2648518  0.33405292]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 8861. State = [[-0.0060144  -0.18141472  0.4039394   1.        ]]. Action = [[0.4755906  0.10807812 0.4376124  0.4526763 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 8862. State = [[-0.00600902 -0.18127169  0.40393934  1.        ]]. Action = [[0.48223174 0.07061601 0.4040935  0.3027743 ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 8863. State = [[-0.00600902 -0.18127169  0.40393934  1.        ]]. Action = [[0.33088636 0.05521929 0.2486521  0.44025302]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 8864. State = [[-0.00375849 -0.18116929  0.39947703  1.        ]]. Action = [[ 0.47762203 -0.09981692 -0.22838825  0.4978578 ]]. Reward = [0.]
Curr episode timestep = 59
Current timestep = 8865. State = [[ 3.1055647e-04 -1.8054934e-01  3.9435259e-01  1.0000000e+00]]. Action = [[0.39292753 0.2261374  0.49390256 0.34779537]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 8866. State = [[ 0.00449853 -0.17538518  0.38810003  1.        ]]. Action = [[ 0.61973715  0.31510627 -0.17172515  0.4487245 ]]. Reward = [0.]
Curr episode timestep = 61
Current timestep = 8867. State = [[ 0.01433756 -0.1684012   0.37755603  1.        ]]. Action = [[ 0.43370533  0.11659503 -0.05029845  0.3341365 ]]. Reward = [0.]
Curr episode timestep = 62
Current timestep = 8868. State = [[ 0.0256203  -0.16443166  0.3740438   1.        ]]. Action = [[ 0.24733245 -0.06198251  0.11290383  0.36105227]]. Reward = [0.]
Curr episode timestep = 63
Current timestep = 8869. State = [[ 0.02972195 -0.16406596  0.37460253  1.        ]]. Action = [[-0.42292845  0.08893871 -0.02242446  0.4185431 ]]. Reward = [0.]
Curr episode timestep = 64
Current timestep = 8870. State = [[ 0.02895161 -0.16170755  0.3759293   1.        ]]. Action = [[-0.3954572   0.1872896  -0.00903791  0.25944424]]. Reward = [0.]
Curr episode timestep = 65
Current timestep = 8871. State = [[ 0.02406988 -0.15753728  0.37922496  1.        ]]. Action = [[-0.47181726  0.14230478  0.05034518  0.20478427]]. Reward = [0.]
Curr episode timestep = 66
Current timestep = 8872. State = [[ 0.01172281 -0.15264674  0.37995616  1.        ]]. Action = [[-0.1388495   0.04818475 -0.04210448  0.29250872]]. Reward = [0.]
Curr episode timestep = 67
Current timestep = 8873. State = [[ 0.00703986 -0.14687316  0.3753226   1.        ]]. Action = [[ 0.07466626  0.20991671 -0.43733907  0.26379263]]. Reward = [0.]
Curr episode timestep = 68
Current timestep = 8874. State = [[ 0.00647545 -0.1459587   0.36775962  1.        ]]. Action = [[ 0.17006874 -0.22260815 -0.40399218  0.3340038 ]]. Reward = [0.]
Curr episode timestep = 69
Current timestep = 8875. State = [[ 0.00785762 -0.14799927  0.3574472   1.        ]]. Action = [[-0.27830964 -0.02656972  0.05747461  0.31296504]]. Reward = [0.]
Curr episode timestep = 70
Current timestep = 8876. State = [[ 0.0045509  -0.14979868  0.35133198  1.        ]]. Action = [[ 0.11863661 -0.03812355 -0.21606731  0.16749   ]]. Reward = [0.]
Curr episode timestep = 71
Current timestep = 8877. State = [[ 0.00484737 -0.15048917  0.3527433   1.        ]]. Action = [[ 0.25379777 -0.03500181  0.5926337   0.19809663]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 8878. State = [[ 0.00864764 -0.15171918  0.36469844  1.        ]]. Action = [[ 0.15295637 -0.01776588  0.6096747   0.20776081]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 8879. State = [[ 0.00895383 -0.15608068  0.37154156  1.        ]]. Action = [[ 0.29243946 -0.27049768 -0.28807187  0.33329642]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 8880. State = [[ 0.01049293 -0.15842505  0.37150025  1.        ]]. Action = [[ 0.22949314 -0.00989294  0.05752063  0.24556065]]. Reward = [0.]
Curr episode timestep = 75
Current timestep = 8881. State = [[ 0.01273823 -0.15798597  0.36855626  1.        ]]. Action = [[-0.10625333  0.12568283 -0.13687706  0.35874557]]. Reward = [0.]
Curr episode timestep = 76
Current timestep = 8882. State = [[ 0.01300898 -0.15563065  0.36689818  1.        ]]. Action = [[-0.08873498  0.17172813  0.10392642  0.390517  ]]. Reward = [0.]
Curr episode timestep = 77
Current timestep = 8883. State = [[ 0.01634266 -0.15361431  0.3650703   1.        ]]. Action = [[ 0.4288149  -0.07680351 -0.18327999  0.31168818]]. Reward = [0.]
Curr episode timestep = 78
Current timestep = 8884. State = [[ 0.01902978 -0.15593265  0.36933634  1.        ]]. Action = [[-0.36099917 -0.17342365  0.33180785  0.1894573 ]]. Reward = [0.]
Curr episode timestep = 79
Current timestep = 8885. State = [[ 0.01623853 -0.16045044  0.3799014   1.        ]]. Action = [[-0.34062254  0.00368643  0.5199505   0.3384757 ]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 8886. State = [[ 0.01400643 -0.15698195  0.3901561   1.        ]]. Action = [[0.24228644 0.3063351  0.06695187 0.44546938]]. Reward = [0.]
Curr episode timestep = 81
Current timestep = 8887. State = [[ 0.01444149 -0.15223663  0.3989829   1.        ]]. Action = [[ 0.00794053 -0.00125921  0.46086884  0.34286904]]. Reward = [0.]
Curr episode timestep = 82
Current timestep = 8888. State = [[ 0.01616103 -0.1511768   0.40793914  1.        ]]. Action = [[-0.11722058  0.1328094   0.50480986  0.28988743]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 8889. State = [[ 0.01308606 -0.14965476  0.41418555  1.        ]]. Action = [[-0.53874457  0.13096023  0.1520493   0.29128718]]. Reward = [0.]
Curr episode timestep = 84
Current timestep = 8890. State = [[ 0.00645075 -0.14476903  0.42130095  1.        ]]. Action = [[-0.22275692  0.12128747 -0.04560363  0.3020296 ]]. Reward = [0.]
Curr episode timestep = 85
Current timestep = 8891. State = [[ 0.00339285 -0.14233533  0.42468694  1.        ]]. Action = [[-0.4635198   0.26520133  0.45663893  0.30166233]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 8892. State = [[ 0.00271309 -0.141867    0.4249207   1.        ]]. Action = [[-0.26829457  0.29966557  0.27264977  0.31751156]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 8893. State = [[-4.6005446e-04 -1.3735577e-01  4.2284009e-01  1.0000000e+00]]. Action = [[-0.379642    0.25903773 -0.17998898  0.25078428]]. Reward = [0.]
Curr episode timestep = 88
Current timestep = 8894. State = [[-0.00836105 -0.13173468  0.419923    1.        ]]. Action = [[-0.19270676  0.1300788  -0.00954145  0.25617397]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 8895. State = [[-0.01056141 -0.12788641  0.4200035   1.        ]]. Action = [[ 0.05779672  0.19893062 -0.29576057  0.18055642]]. Reward = [0.]
Curr episode timestep = 90
Current timestep = 8896. State = [[-0.01296872 -0.12439218  0.41681227  1.        ]]. Action = [[0.34598947 0.3052938  0.06663203 0.25789165]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 8897. State = [[-0.0134577  -0.12138291  0.41365162  1.        ]]. Action = [[ 0.133546    0.14822543 -0.21240318  0.26237154]]. Reward = [0.]
Curr episode timestep = 92
Current timestep = 8898. State = [[-0.01148355 -0.11670236  0.40502036  1.        ]]. Action = [[ 0.31338418  0.08104074 -0.41484034  0.2605933 ]]. Reward = [0.]
Curr episode timestep = 93
Current timestep = 8899. State = [[-0.00743911 -0.11460965  0.39158517  1.        ]]. Action = [[-0.10830086  0.07052267 -0.21046889  0.20686638]]. Reward = [0.]
Curr episode timestep = 94
Current timestep = 8900. State = [[-0.00350802 -0.10934802  0.38029557  1.        ]]. Action = [[ 0.53467906  0.19217658 -0.22589147  0.21883559]]. Reward = [0.]
Curr episode timestep = 95
Current timestep = 8901. State = [[ 0.00257946 -0.10610776  0.37146172  1.        ]]. Action = [[-0.0831055  -0.14166844 -0.06832153  0.16339934]]. Reward = [0.]
Curr episode timestep = 96
Current timestep = 8902. State = [[ 0.00458698 -0.10906666  0.366986    1.        ]]. Action = [[ 0.14227653 -0.19298983 -0.30663955  0.17894268]]. Reward = [0.]
Curr episode timestep = 97
Current timestep = 8903. State = [[ 0.00939904 -0.11547538  0.3509543   1.        ]]. Action = [[ 0.28810883 -0.24808967 -0.36801404  0.20687997]]. Reward = [0.]
Curr episode timestep = 98
Current timestep = 8904. State = [[ 0.01641018 -0.11809483  0.3422428   1.        ]]. Action = [[0.1372683  0.02005875 0.247895   0.290138  ]]. Reward = [0.]
Curr episode timestep = 99
Current timestep = 8905. State = [[ 0.01875364 -0.1193412   0.34223714  1.        ]]. Action = [[ 0.17042387 -0.06842929 -0.00053102  0.1257416 ]]. Reward = [0.]
Curr episode timestep = 100
Current timestep = 8906. State = [[-0.25769615 -0.09234692  0.10635985  1.        ]]. Action = [[ 0.3110826   0.0310452  -0.20750284  0.21869981]]. Reward = [0.]
Curr episode timestep = 101
Current timestep = 8907. State = [[-0.25897005 -0.10148732  0.09276236  1.        ]]. Action = [[-0.4212277  -0.38187915  0.8225627   0.8345206 ]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Current timestep = 8908. State = [[-0.25897005 -0.10148732  0.09276236  1.        ]]. Action = [[-0.646434   -0.47828674  0.84764266  0.98911226]]. Reward = [0.]
Curr episode timestep = 1
Action ignored: Workspace boundary
Current timestep = 8909. State = [[-0.24692938 -0.10669174  0.10085436  1.        ]]. Action = [[ 0.9021437  -0.30501056  0.9390991   0.9940896 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 8910. State = [[-0.22693382 -0.11738781  0.1231192   1.        ]]. Action = [[ 0.41372824 -0.29660678  0.8172562   0.96261907]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 8911. State = [[-0.20431583 -0.12556463  0.15465318  1.        ]]. Action = [[ 0.7034204  -0.14877516  0.9443271   0.98102784]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 8912. State = [[-0.17958145 -0.1378732   0.19129813  1.        ]]. Action = [[ 0.39896762 -0.43240786  0.8759961   0.9015434 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 8913. State = [[-0.16704878 -0.14797242  0.21465203  1.        ]]. Action = [[ 0.26011288 -0.42704916  0.0422368   0.850611  ]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 8914. State = [[-0.16560213 -0.15026529  0.2172854   1.        ]]. Action = [[ 0.6286336  -0.51666665  0.2714424   0.78221285]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 8915. State = [[-0.15376034 -0.14986987  0.22571816  1.        ]]. Action = [[0.90246785 0.15351725 0.44456315 0.8589982 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 8916. State = [[-0.13568668 -0.1502626   0.24015708  1.        ]]. Action = [[ 0.89040065 -0.19233197 -0.28314602  0.92242944]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 8917. State = [[-0.12288003 -0.15925674  0.23771669  1.        ]]. Action = [[ 0.9432926  -0.6704633  -0.5726513   0.82985854]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 8918. State = [[-0.10142456 -0.1676448   0.22597587  1.        ]]. Action = [[ 0.89919436 -0.2500521  -0.24868345  0.7742183 ]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: No entry zone
Current timestep = 8919. State = [[-0.08377782 -0.1781915   0.23397523  1.        ]]. Action = [[ 0.9729285  -0.5753938   0.556962    0.70615876]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 8920. State = [[-0.05446664 -0.20093928  0.25283664  1.        ]]. Action = [[ 0.7561692  -0.7228529   0.45776606  0.60908985]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 8921. State = [[-0.02574843 -0.22543915  0.26381558  1.        ]]. Action = [[ 0.9008179  -0.6164608   0.01858819  0.59506845]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 8922. State = [[ 0.00802516 -0.25255853  0.2633855   1.        ]]. Action = [[ 0.9612509  -0.76797444 -0.21799624  0.561357  ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 8923. State = [[ 0.04187636 -0.2709552   0.25894457  1.        ]]. Action = [[ 0.4923923  -0.09942055  0.21309721  0.57318354]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 8924. State = [[ 0.06247378 -0.27742368  0.26292273  1.        ]]. Action = [[ 0.6750462  -0.81625     0.10834265  0.7283225 ]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 8925. State = [[ 0.06311596 -0.2842206   0.27760738  1.        ]]. Action = [[-0.90631413  0.0754385   0.94323194  0.65612316]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 8926. State = [[ 0.05527524 -0.28803012  0.2979188   1.        ]]. Action = [[0.8299885  0.5560982  0.9479544  0.91194034]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 8927. State = [[ 0.05243369 -0.27919498  0.31462738  1.        ]]. Action = [[-0.78326154  0.7442421   0.8466456   0.98095155]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 8928. State = [[ 0.02887436 -0.2633225   0.35159102  1.        ]]. Action = [[-0.87589896  0.17457068  0.6934285   0.9652612 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 8929. State = [[-0.00168196 -0.25172827  0.38491324  1.        ]]. Action = [[-0.47410166  0.20925832  0.87421083  0.7377994 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 8930. State = [[-0.02277289 -0.24503005  0.40079606  1.        ]]. Action = [[-0.24906456 -0.00573784 -0.29783309  0.6832371 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 8931. State = [[-0.0269193  -0.24526352  0.39937493  1.        ]]. Action = [[0.65232825 0.4693179  0.30849826 0.5153649 ]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 8932. State = [[-0.02337958 -0.23725556  0.39150265  1.        ]]. Action = [[ 0.89284575  0.3205793  -0.41562903  0.64994776]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 8933. State = [[-0.01391658 -0.22754318  0.3750895   1.        ]]. Action = [[ 0.83109546 -0.05627865 -0.80964184  0.5077919 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 8934. State = [[ 0.007989   -0.22744885  0.3488061   1.        ]]. Action = [[ 0.30505097 -0.1253758  -0.06382614  0.48881054]]. Reward = [0.]
Curr episode timestep = 27
Current timestep = 8935. State = [[ 0.02775768 -0.23254797  0.34768385  1.        ]]. Action = [[ 0.8179829  -0.3060242   0.3253585   0.58194864]]. Reward = [0.]
Curr episode timestep = 28
Current timestep = 8936. State = [[ 0.04797411 -0.23100467  0.3549503   1.        ]]. Action = [[0.12608731 0.5217875  0.36269927 0.5408907 ]]. Reward = [0.]
Curr episode timestep = 29
Current timestep = 8937. State = [[ 0.05102571 -0.22656849  0.37758282  1.        ]]. Action = [[-0.4990667  0.0710305  0.9339727  0.7939471]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 8938. State = [[ 0.04500772 -0.22045088  0.40755668  1.        ]]. Action = [[-0.527125    0.32218206  0.6121917   0.577391  ]]. Reward = [0.]
Curr episode timestep = 31
Current timestep = 8939. State = [[ 0.03759599 -0.21456023  0.42454323  1.        ]]. Action = [[-0.8917662   0.37081945  0.852489    0.8235971 ]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 8940. State = [[ 0.03646453 -0.21306469  0.42785248  1.        ]]. Action = [[-0.64405245  0.30200386  0.48505855  0.7608043 ]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 8941. State = [[ 0.03638269 -0.21311176  0.4282751   1.        ]]. Action = [[-0.83679193  0.64460397  0.54898524  0.64147234]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 8942. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.6325138   0.6494088   0.83583045  0.6998961 ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 8943. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.37978137  0.54391634  0.7150711   0.70306444]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 8944. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.89572567  0.68469393  0.55299115  0.68244815]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 8945. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.93849015  0.76759505  0.642467    0.7769017 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 8946. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.90031326  0.39467967  0.88705873  0.7721715 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 8947. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.9184004   0.62976193  0.40748692  0.8027967 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 8948. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.47758812  0.72145677  0.4511584   0.6916981 ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 8949. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.7399354   0.62337756  0.5299401   0.74057794]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 8950. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.57285625  0.7454009   0.65613794  0.75717664]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 8951. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.9511037  0.6260514  0.8154378  0.7728039]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 8952. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.93700594  0.4990046   0.82150733  0.74111414]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 8953. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.8444924   0.73725724  0.71876526  0.77349305]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 8954. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.8615664   0.7731292   0.24173939  0.80065393]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 8955. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.77635676  0.6198448   0.79180384  0.7646581 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 8956. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.91370636  0.47480214  0.31678295  0.74771476]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 8957. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.8516      0.5960529   0.7416265   0.69225955]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 8958. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.88168514  0.7525215   0.16812861  0.78984976]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 8959. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.853041    0.4871893   0.76809597  0.7953341 ]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 8960. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.71146244  0.45313382  0.8157246   0.77828574]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 8961. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.907226    0.43978333  0.77170205  0.82251906]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 8962. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.86522394  0.5577462   0.5946667   0.8134483 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 8963. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.8771198  0.5112121  0.7057879  0.7981125]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 8964. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.81048656  0.31992662  0.6643119   0.7072277 ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 8965. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.785023    0.48008096  0.66669726  0.7640946 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 8966. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.8320334   0.68008494  0.61389863  0.74224114]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 8967. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.8017668   0.6358886   0.75722027  0.72014594]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 8968. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.8473873   0.42923725  0.93950975  0.7818316 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 8969. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.59915304  0.4272945   0.54332185  0.75460434]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 8970. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.9078344   0.37833643  0.721316    0.76232266]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 8971. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.81443715  0.4673996   0.8891401   0.7514818 ]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 8972. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.9084184   0.45604563  0.8412516   0.80601704]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 8973. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.7566688   0.7069428   0.20932245  0.7672576 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 8974. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.917631   0.5534651  0.8732475  0.7581966]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 8975. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.8324119   0.51705647  0.6701062   0.7333648 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 8976. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.81561995  0.62454224  0.7787279   0.7780683 ]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 8977. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.9173914   0.54877996  0.78630257  0.8063667 ]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 8978. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.6125139   0.37443328  0.8028643   0.82288635]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 8979. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.85516155  0.64325786  0.72324467  0.7635267 ]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 8980. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.8116754   0.70397186  0.90732336  0.76553214]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 8981. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.89950716  0.55359423  0.7924069   0.65750074]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 8982. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.9234941   0.23894024  0.8639771   0.78803873]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 8983. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.86372745  0.38601422  0.7191813   0.7777127 ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 8984. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.8704771  0.4635111  0.9337745  0.844074 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 8985. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.9724357  0.7258295  0.8478682  0.7071973]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 8986. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.8772581   0.61343217  0.78358555  0.7631967 ]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 8987. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.58381903  0.67232275  0.94392085  0.723284  ]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 8988. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.87156093  0.47132862  0.69110286  0.7634821 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 8989. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.94940764  0.65942395  0.6766455   0.7793286 ]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 8990. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.91103166  0.7796432   0.8913057   0.737056  ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 8991. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.7428548   0.60923207  0.80763113  0.78958416]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 8992. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.655983    0.30389595  0.82032704  0.6829648 ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 8993. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.49619424  0.37308693  0.2048775   0.76728904]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 8994. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.85886306  0.36330664  0.8381014   0.84426296]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 8995. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.8907459   0.6355207   0.8177966   0.80488706]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 8996. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.94688994  0.38765073  0.8359691   0.7323489 ]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 8997. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.8134923   0.43862438  0.8040247   0.7389915 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 8998. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.7261695  0.4678899  0.8763999  0.8209412]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 8999. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.90885776  0.05881345  0.9455521   0.79919815]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 9000. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.93567926  0.45252204  0.86592364  0.8331423 ]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 9001. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.6970516   0.45072114  0.795815    0.7632017 ]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 9002. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.97882503  0.3126241   0.93856287  0.60234904]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 9003. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.75889957  0.7166145   0.2781825   0.74315274]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 9004. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.54772997  0.32050407  0.7935617   0.75547457]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 9005. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.7240501   0.6607683   0.8087648   0.56180716]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 9006. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.7368322   0.5461669   0.7630553   0.69954324]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 9007. State = [[ 0.03636237 -0.21310915  0.42841515  1.        ]]. Action = [[-0.7623781  0.5108361  0.8822653  0.7536397]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 9008. State = [[-0.26108885 -0.00360768  0.11193538  1.        ]]. Action = [[-0.9664516  0.7298591  0.7712009  0.7389574]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 9009. State = [[-0.2521187  -0.01550846  0.10688991  1.        ]]. Action = [[ 0.69765735 -0.6507753   0.9841473   0.85190725]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 9010. State = [[-0.23704952 -0.03804402  0.1307909   1.        ]]. Action = [[ 0.31705916 -0.66542155  0.9728861   0.95110726]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 9011. State = [[-0.22019523 -0.05630253  0.15546885  1.        ]]. Action = [[ 0.56995034 -0.30754322 -0.01119745  0.9927826 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 9012. State = [[-0.2062827  -0.07490172  0.17081374  1.        ]]. Action = [[-0.08815593 -0.6139634   0.86236215  0.84483194]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 9013. State = [[-0.20395757 -0.08878218  0.1889093   1.        ]]. Action = [[ 0.8135289 -0.534777   0.0534395  0.9695163]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 9014. State = [[-0.19184838 -0.0936319   0.20126943  1.        ]]. Action = [[ 0.7270243  -0.183748    0.73428047  0.96539974]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 9015. State = [[-0.17051044 -0.10628455  0.22449161  1.        ]]. Action = [[ 0.37621808 -0.47772646  0.38666868  0.8655503 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 9016. State = [[-0.15972786 -0.11646677  0.23724349  1.        ]]. Action = [[ 0.57097816 -0.7305771  -0.05403745  0.89809525]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 9017. State = [[-0.15911466 -0.11890434  0.23915362  1.        ]]. Action = [[ 0.5194473  -0.19911516 -0.33089584  0.92117465]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 9018. State = [[-0.1591902  -0.11915383  0.23919444  1.        ]]. Action = [[ 0.8651949  -0.5390762  -0.27267718  0.93374324]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 9019. State = [[-0.14675331 -0.12588218  0.24168645  1.        ]]. Action = [[ 0.9182074  -0.44121027 -0.06214821  0.8366356 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 9020. State = [[-0.13111407 -0.13203874  0.24431293  1.        ]]. Action = [[ 0.9479786 -0.3991452 -0.2582575  0.8268318]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: No entry zone
Current timestep = 9021. State = [[-0.13033664 -0.13279691  0.2450233   1.        ]]. Action = [[ 0.8670049  -0.16951698 -0.6191571   0.9326513 ]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: No entry zone
Current timestep = 9022. State = [[-0.13036697 -0.13289604  0.2450981   1.        ]]. Action = [[ 0.9654474  -0.56945306 -0.41997635  0.9092294 ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: No entry zone
Current timestep = 9023. State = [[-0.13036697 -0.13289604  0.2450981   1.        ]]. Action = [[ 0.88254476 -0.46982998 -0.54971385  0.821542  ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: No entry zone
Current timestep = 9024. State = [[-0.13039246 -0.13288549  0.2450965   1.        ]]. Action = [[ 0.8538972  -0.3957262  -0.33973885  0.8322493 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: No entry zone
Current timestep = 9025. State = [[-0.13039246 -0.13288549  0.2450965   1.        ]]. Action = [[ 0.8594949  -0.7553254  -0.8844693   0.80286646]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: No entry zone
Current timestep = 9026. State = [[-0.11856944 -0.1367645   0.25539038  1.        ]]. Action = [[ 0.77676964 -0.27298295  0.7286022   0.5826968 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 9027. State = [[-0.08923995 -0.1495264   0.27917734  1.        ]]. Action = [[ 0.88639355 -0.44034576  0.423113    0.5537405 ]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 9028. State = [[-0.05504783 -0.16306712  0.28850758  1.        ]]. Action = [[ 0.91194284 -0.2375263   0.02123809  0.5225179 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 9029. State = [[-0.02140283 -0.17701426  0.29487     1.        ]]. Action = [[ 0.96617174 -0.4782617   0.22275484  0.5618119 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 9030. State = [[ 0.00935758 -0.19863209  0.29565072  1.        ]]. Action = [[ 0.6598284  -0.70285684 -0.41043723  0.5421939 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 9031. State = [[ 0.04271076 -0.22363417  0.2901826   1.        ]]. Action = [[ 0.93478394 -0.58392555  0.3307724   0.49729943]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 9032. State = [[ 0.06689603 -0.24046963  0.30686268  1.        ]]. Action = [[-0.31451333 -0.08017862  0.71305466  0.7533393 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 9033. State = [[ 0.06354325 -0.25623378  0.33791643  1.        ]]. Action = [[-0.6131035 -0.4821322  0.9574735  0.8802997]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 9034. State = [[ 0.04976483 -0.26142403  0.37373397  1.        ]]. Action = [[-0.92322385  0.54948807  0.9176955   0.9167416 ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 9035. State = [[ 0.03712625 -0.25446355  0.4044714   1.        ]]. Action = [[-0.8002534   0.73565507  0.91880393  0.92518973]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 9036. State = [[ 0.03561172 -0.2535782   0.40640903  1.        ]]. Action = [[-0.72424936  0.7452328   0.936404    0.7844107 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 9037. State = [[ 0.03510172 -0.25354227  0.4066291   1.        ]]. Action = [[-0.65831333  0.61817956  0.95216393  0.8702848 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 9038. State = [[ 0.03510172 -0.25354227  0.4066291   1.        ]]. Action = [[-0.2976706   0.48750615  0.78772104  0.8801074 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 9039. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.6900075  0.5661577  0.7365663  0.8213837]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 9040. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.52833045  0.23093557  0.93839073  0.9015839 ]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 9041. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.79337704  0.65796185  0.9091785   0.91237235]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 9042. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.38578856  0.46936047  0.49660397  0.85304   ]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 9043. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.7101601   0.49444127  0.8062402   0.8109057 ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 9044. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.18007958  0.76290166  0.95339     0.8078346 ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 9045. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.14045787  0.6210518   0.8676982   0.8852987 ]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 9046. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.28821462  0.72100115  0.8635045   0.8453162 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 9047. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.6963474   0.57909584  0.8938478   0.8587805 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 9048. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.93686146  0.70450306  0.8011292   0.9203521 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 9049. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.6242126   0.50877476  0.92462564  0.8817296 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 9050. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.6782132  0.2755748  0.8005042  0.8340876]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 9051. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.7075603   0.49817228  0.90859175  0.8795363 ]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 9052. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.75203246  0.507643    0.87082124  0.872334  ]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 9053. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.6115654   0.62222123  0.9700459   0.8085215 ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 9054. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[0.0521847  0.6624377  0.98220253 0.86258185]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 9055. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.31215513  0.67917347  0.71191585  0.888492  ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 9056. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[0.2745452  0.47619498 0.95699406 0.88348985]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 9057. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.8178231   0.6535392   0.74083495  0.8887284 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 9058. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.40422356  0.45452714  0.9108224   0.9310012 ]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 9059. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[0.38463092 0.4129703  0.92868686 0.8536135 ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 9060. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.3513738   0.55918527  0.873476    0.93255544]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 9061. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.26773107  0.19525087  0.9621415   0.8929436 ]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 9062. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.4637543   0.3907634   0.8007947   0.88490856]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 9063. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.04720813  0.03552926  0.35653138  0.7220726 ]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 9064. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.50548047  0.28059363  0.88882613  0.8005266 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 9065. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.56583863  0.36698043  0.94472075  0.7095134 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 9066. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.33769977  0.7378156   0.6369555   0.7991314 ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 9067. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.47516072  0.1795013   0.90332127  0.87572265]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 9068. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[0.05262733 0.50333154 0.7933599  0.8391967 ]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 9069. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.11052054  0.06506109  0.48587167  0.93845284]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 9070. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.7634731   0.5808476   0.87988436  0.85227656]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 9071. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.22941351  0.11890531  0.8895638   0.8011204 ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 9072. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.20135695  0.6808858   0.8087559   0.8558202 ]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 9073. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.11004299  0.35689497  0.6847093   0.78312516]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 9074. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.9644171   0.33682084  0.8892348   0.89328647]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 9075. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[0.03454483 0.57545936 0.7748071  0.7841809 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 9076. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.8460377   0.63185656  0.85884535  0.8134892 ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 9077. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.7132587   0.33276272  0.5884447   0.85292554]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 9078. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.37020743  0.36028492  0.82296     0.72433686]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 9079. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.64947104  0.58621013  0.5977895   0.7526481 ]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 9080. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.27018058  0.4242195   0.9343786   0.7991102 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 9081. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.84564644  0.27246737  0.9746256   0.8378886 ]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 9082. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.7962871   0.4427681   0.3213762   0.90304637]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 9083. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.6142323   0.19175231  0.8136785   0.781909  ]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 9084. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.3368907   0.20316994  0.9780898   0.8161758 ]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 9085. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.7726542   0.78979385  0.79949653  0.8440664 ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 9086. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.9221913   0.6101644   0.94965506  0.8632678 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 9087. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[0.3907374 0.4784963 0.942801  0.8073313]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 9088. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.2552511   0.6285615   0.96607447  0.8984995 ]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 9089. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.6343781   0.24698663  0.94539404  0.8689439 ]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 9090. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.31336498  0.5312488   0.9912889   0.829245  ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 9091. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.29453325  0.5336616   0.88976204  0.79919815]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 9092. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.5517361   0.24339736  0.80470157  0.82287526]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 9093. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.36558104  0.64068127  0.869401    0.91863954]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 9094. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.6156546   0.68052626  0.9216322   0.8170246 ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 9095. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[0.00783134 0.56882644 0.948025   0.8836764 ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 9096. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.95761085  0.6353357   0.80289197  0.79583466]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 9097. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.6028278  0.5637162  0.9597548  0.9082594]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 9098. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.8952322   0.45823884  0.8055557   0.7365618 ]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 9099. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.02574664  0.50166726  0.7510202   0.871521  ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 9100. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.47837973  0.47812402  0.8577353   0.92043495]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 9101. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[0.10594451 0.43925416 0.94962215 0.8368304 ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 9102. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.8528686   0.41237605  0.6867987   0.83047605]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 9103. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.2602285  0.3779571  0.9074204  0.7740518]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 9104. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.69118345  0.6584575   0.7698109   0.8658141 ]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 9105. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.33220017  0.5080941   0.97357965  0.85480964]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 9106. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.48595214  0.4615394   0.67842865  0.8042486 ]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 9107. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.75713366  0.36628366  0.95387983  0.9809452 ]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 9108. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.8322218   0.18842971  0.97449136  0.84586763]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 9109. State = [[ 0.03502867 -0.25350255  0.40662584  1.        ]]. Action = [[-0.15187114 -0.02860701  0.9100231   0.8980918 ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 9110. State = [[-0.2636923   0.00125481  0.11335145  1.        ]]. Action = [[-0.8821946   0.31927562  0.9015901   0.88695574]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 9111. State = [[-0.25753266 -0.00823189  0.10744557  1.        ]]. Action = [[ 0.51362944 -0.5463258   0.9929892   0.9873494 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 9112. State = [[-0.24996744 -0.02492921  0.13079391  1.        ]]. Action = [[-0.05287945 -0.35192227  0.96854997  0.98167086]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 9113. State = [[-0.24568658 -0.03934811  0.16629903  1.        ]]. Action = [[ 0.14392436 -0.417553    0.9424144   0.9958985 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 9114. State = [[-0.24449922 -0.04805649  0.19044201  1.        ]]. Action = [[-0.55261695 -0.41605031  0.92699385  0.98122203]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: Workspace boundary
Current timestep = 9115. State = [[-0.23239338 -0.05899539  0.19960204  1.        ]]. Action = [[ 0.8048742  -0.65987     0.54009867  0.77436733]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 9116. State = [[-0.20248552 -0.07863085  0.22884049  1.        ]]. Action = [[ 0.7219151  -0.34897673  0.95231295  0.9847226 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 9117. State = [[-0.17268163 -0.09739503  0.25992486  1.        ]]. Action = [[ 0.71444654 -0.55208075  0.4687096   0.7006949 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 9118. State = [[-0.14596376 -0.11297157  0.28770444  1.        ]]. Action = [[ 0.84922624 -0.30523032  0.696012    0.8602427 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 9119. State = [[-0.11517369 -0.11896511  0.31914824  1.        ]]. Action = [[0.8864975  0.05434954 0.7046484  0.4461509 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 9120. State = [[-0.08443308 -0.1254052   0.32989356  1.        ]]. Action = [[ 0.8364371  -0.27596354 -0.51853395  0.5334048 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 9121. State = [[-0.05136097 -0.13581337  0.31763303  1.        ]]. Action = [[ 0.8952298 -0.3417343 -0.2878114  0.4498036]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 9122. State = [[-0.01750801 -0.14972775  0.3071593   1.        ]]. Action = [[ 0.9032049 -0.3926885 -0.2504841  0.5472803]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 9123. State = [[ 0.01736288 -0.1681038   0.3031544   1.        ]]. Action = [[ 0.82721806 -0.62142974  0.13343096  0.47790384]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 9124. State = [[ 0.05052623 -0.190191    0.31016442  1.        ]]. Action = [[ 0.8951422  -0.52621925  0.42524886  0.4782927 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 9125. State = [[ 0.08337221 -0.20708115  0.31679764  1.        ]]. Action = [[ 0.8496922  -0.31399786 -0.05535978  0.64220774]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 9126. State = [[ 0.103352   -0.21718816  0.33427307  1.        ]]. Action = [[-0.91229457  0.10262358  0.9702691   0.88381505]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 9127. State = [[ 0.09645227 -0.22048104  0.36654052  1.        ]]. Action = [[-0.89023983  0.19877839  0.99530005  0.94573164]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 9128. State = [[ 0.08379745 -0.21648872  0.4015434   1.        ]]. Action = [[-0.93189234  0.57688713  0.99259436  0.94557667]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 9129. State = [[ 0.08251944 -0.21587203  0.40628248  1.        ]]. Action = [[-0.9686692   0.32813823  0.99471235  0.9754813 ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 9130. State = [[ 0.08231457 -0.21577463  0.40661734  1.        ]]. Action = [[-0.98416036  0.5000546   0.9375324   0.9098731 ]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 9131. State = [[ 0.08231457 -0.21577463  0.40661734  1.        ]]. Action = [[-0.9618877   0.58824134  0.98436105  0.9291899 ]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 9132. State = [[ 0.08229069 -0.21576457  0.4066161   1.        ]]. Action = [[-0.97673315  0.633306    0.9890194   0.8955201 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 9133. State = [[ 0.08218866 -0.21572155  0.40661076  1.        ]]. Action = [[-0.97347283  0.4590081   0.9763453   0.9391005 ]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 9134. State = [[ 0.08193357 -0.21561396  0.40659782  1.        ]]. Action = [[-0.9630407   0.33038235  0.96674     0.93786216]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 9135. State = [[ 0.08193357 -0.21561396  0.40659782  1.        ]]. Action = [[-0.9772747   0.38684344  0.8861408   0.856693  ]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 9136. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9747548   0.74483776  0.9197328   0.9226291 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 9137. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.98779494  0.5480825   0.9896076   0.90999055]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 9138. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9831274   0.33938217  0.9776689   0.9229796 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 9139. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9266232   0.28723967  0.99714494  0.9075414 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 9140. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9100152   0.15070665  0.9669628   0.93061197]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 9141. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.99313366  0.53180695  0.9848392   0.86767554]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 9142. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.98011494  0.19373512  0.93861413  0.9121988 ]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 9143. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.91936517  0.40732455  0.9910493   0.89246476]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 9144. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9564734   0.33109713  0.97910476  0.87178266]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 9145. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9606198   0.29245114  0.9459647   0.9405329 ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 9146. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.78729546  0.26784873  0.9781562   0.85738516]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 9147. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.969731    0.51943636  0.9193735   0.8703277 ]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 9148. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9048992   0.47109067  0.87001455  0.8807982 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 9149. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.98442525  0.28535438  0.9729419   0.89530635]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 9150. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.91601485  0.40862656  0.8733859   0.9180255 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 9151. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.82508206  0.40018606  0.9374478   0.894928  ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 9152. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9444782   0.70481706  0.98951125  0.8181598 ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 9153. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.96249044  0.5075878   0.97400606  0.8828163 ]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 9154. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.91590464  0.45338082  0.9937117   0.9250052 ]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 9155. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9501913   0.63338184  0.98014116  0.906744  ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 9156. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9589062   0.60939     0.99458706  0.84946454]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 9157. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.96121824  0.4158734   0.96922874  0.8728199 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 9158. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9838936   0.38859236  0.9568598   0.94188106]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 9159. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9705047  0.6905141  0.96542    0.907856 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 9160. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.8977849   0.57160544  0.9910531   0.82427883]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 9161. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.98848414  0.3334273   0.9329541   0.9042145 ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 9162. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.89859277  0.56082284  0.96278095  0.91980195]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 9163. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9141309   0.42718792  0.9065201   0.8634238 ]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 9164. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9297093   0.48148608  0.9669702   0.82054496]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 9165. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.8037717  0.5056938  0.9887538  0.9174261]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 9166. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.93428147  0.21375203  0.95684767  0.91311   ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 9167. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9623753   0.18571198  0.9839227   0.87891054]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 9168. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.96583205  0.6625445   0.92995167  0.9360596 ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 9169. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9842574   0.41049707  0.99565303  0.9383166 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 9170. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.7755155   0.49822772  0.9739795   0.90724444]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 9171. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.75652593  0.41355848  0.94576883  0.9347837 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 9172. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.92528296  0.6127875   0.9349053   0.67018855]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 9173. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.7847554   0.2872994   0.89036953  0.8311279 ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 9174. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9411738   0.44867992  0.9878496   0.929168  ]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 9175. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.541378    0.45090842  0.99176073  0.8879585 ]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 9176. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.8940486  0.5940666  0.9656038  0.7879145]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 9177. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9064658   0.28290164  0.96313715  0.9266045 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 9178. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.8463556   0.23684645  0.9860327   0.9019301 ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 9179. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.81761426 -0.32464838  0.96974564  0.9129126 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 9180. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.7773295  -0.16332984  0.86229193  0.8213577 ]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 9181. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.89623404  0.2497263   0.99658024  0.97218394]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 9182. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9665174   0.30738497  0.9689102   0.87523675]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 9183. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.96676904  0.22260141  0.990083    0.9197061 ]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 9184. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.93521553  0.20088899  0.9845909   0.9521091 ]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 9185. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.8376385   0.19983041  0.9932258   0.9036772 ]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 9186. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.98828334  0.13584423  0.9897835   0.9319935 ]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 9187. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9094752   0.35657787  0.99910426  0.9551672 ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 9188. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.97648364  0.5423819   0.98623085  0.9319798 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 9189. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.96349275  0.26560712  0.99622536  0.9522033 ]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 9190. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9020864   0.6186013   0.99655986  0.93423724]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 9191. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9440116   0.23447633  0.979779    0.94466245]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 9192. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9691094  0.5746815  0.957175   0.9154382]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 9193. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9493331  0.5284126  0.7524569  0.8535888]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 9194. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9178331   0.49730492  0.9880998   0.9424721 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 9195. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.8514567   0.38642442  0.98357964  0.89681506]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 9196. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.93738556  0.30978823  0.9887047   0.9400524 ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 9197. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9208747   0.22466373  0.98130894  0.9066355 ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 9198. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9440843   0.5983254   0.993783    0.91492414]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 9199. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.89722776  0.35941052  0.9811568   0.9493667 ]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 9200. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.927302   0.5106268  0.9159317  0.9354192]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 9201. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.93248004  0.6244681   0.9388683   0.9191092 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 9202. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9247338  0.2935779  0.9833846  0.8327029]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 9203. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.89142543  0.1078645   0.9954212   0.92562866]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 9204. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9227284   0.34422636  0.97918415  0.9442105 ]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 9205. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9166299   0.5496352   0.97230625  0.96804714]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 9206. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.8391799   0.56285167  0.9570929   0.9689331 ]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 9207. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.9626274   0.12012625  0.97570443  0.9485483 ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 9208. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.81324345  0.2593577   0.9523852   0.84796906]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 9209. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.7524821   0.36207438  0.989794    0.9300567 ]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 9210. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.86564577  0.22045779  0.992182    0.85880876]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 9211. State = [[ 0.081908   -0.21560317  0.40659657  1.        ]]. Action = [[-0.8790019   0.56102824  0.92921567  0.7822809 ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 9212. State = [[-0.2698327   0.1436263   0.11501414  1.        ]]. Action = [[-0.7815384   0.4258976   0.96737385  0.9404497 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 9213. State = [[-0.25803265  0.14888278  0.10887412  1.        ]]. Action = [[ 0.28526902 -0.83296335  0.9374325   0.95958114]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 9214. State = [[-0.23792297  0.12060761  0.13334252  1.        ]]. Action = [[ 0.9179263  -0.9019059   0.96877074  0.9645504 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 9215. State = [[-0.20919365  0.08987968  0.17054117  1.        ]]. Action = [[ 0.8765048  -0.84627867  0.97949076  0.9835367 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 9216. State = [[-0.18871304  0.07269195  0.19544537  1.        ]]. Action = [[ 0.8247981  -0.7902286   0.72971106  0.94662213]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: No entry zone
Current timestep = 9217. State = [[-0.18509935  0.06946229  0.19890754  1.        ]]. Action = [[ 0.7444527 -0.8020396  0.563854   0.9754797]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 9218. State = [[-0.18442339  0.06808397  0.19983271  1.        ]]. Action = [[ 0.8053396  -0.7205173   0.7038735   0.93541336]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 9219. State = [[-0.17144068  0.05732245  0.21415515  1.        ]]. Action = [[ 0.70422626 -0.6254286   0.9151201   0.8838351 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 9220. State = [[-0.14660276  0.0340948   0.24593839  1.        ]]. Action = [[ 0.6842525  -0.7297099   0.78757095  0.84233093]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 9221. State = [[-0.12178181  0.00869312  0.27843398  1.        ]]. Action = [[ 0.71642494 -0.57984084  0.61988854  0.80698967]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 9222. State = [[-0.09679798 -0.01472549  0.30255163  1.        ]]. Action = [[ 0.66818786 -0.57497966  0.33257985  0.71682096]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 9223. State = [[-0.07314743 -0.03727848  0.30939263  1.        ]]. Action = [[ 0.7337432  -0.57461655 -0.29479122  0.45659208]]. Reward = [0.]
Curr episode timestep = 10
Above hoop
Current timestep = 9224. State = [[-0.04701921 -0.0575095   0.2988428   1.        ]]. Action = [[ 0.5127795  -0.36125195 -0.3135268   0.47987854]]. Reward = [0.]
Curr episode timestep = 11
Above hoop
Current timestep = 9225. State = [[-0.02162094 -0.07565895  0.29111663  1.        ]]. Action = [[ 0.86541367 -0.6036088  -0.07267207  0.5203111 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 9226. State = [[ 0.00954946 -0.09887912  0.29352772  1.        ]]. Action = [[ 0.84028494 -0.65888715  0.38261712  0.4475901 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 9227. State = [[ 0.03862163 -0.12127565  0.30345917  1.        ]]. Action = [[ 0.44387984 -0.4308492   0.21468115  0.22203374]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 9228. State = [[ 0.06026423 -0.14240193  0.31909496  1.        ]]. Action = [[ 0.53982043 -0.65565765  0.6260687   0.25369728]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 9229. State = [[ 0.07899239 -0.16859168  0.3453532   1.        ]]. Action = [[ 0.46206415 -0.8196981   0.9609585   0.34042203]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 9230. State = [[ 0.0887929  -0.20048003  0.38251102  1.        ]]. Action = [[-0.4807567  -0.6489547   0.9290414   0.70032287]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 9231. State = [[ 0.08675608 -0.21403998  0.4038807   1.        ]]. Action = [[-0.7142599  -0.06540728  0.97079074  0.874768  ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 9232. State = [[ 0.08713886 -0.21632384  0.40745327  1.        ]]. Action = [[-0.9454987  -0.07146645  0.9975376   0.9302106 ]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 9233. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.98296     0.24053597  0.99510837  0.91568756]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 9234. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.88218457  0.34582043  0.97140324  0.9629481 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 9235. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.25403494  0.46502066  0.98693657  0.95649457]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 9236. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.8566276   0.15726125  0.9841987   0.9271567 ]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 9237. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.8196012   0.29787374  0.9868802   0.91487956]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 9238. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.9664802  0.5577574  0.9675076  0.8901458]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 9239. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.71000755 -0.20112824  0.98142767  0.8778939 ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 9240. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.9206219   0.21603668  0.9237249   0.9234052 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 9241. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.9866831  -0.05482411  0.95664334  0.8909428 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 9242. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.73072714  0.11535001  0.9978802   0.9559262 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 9243. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.7297439   0.60174274  0.99258935  0.97049665]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 9244. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.9141849   0.11249292  0.988513    0.93570995]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 9245. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.976533    0.11759293  0.98723364  0.96006906]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 9246. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.8428093   0.23196173  0.9934412   0.8153713 ]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 9247. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.578217    0.11575866  0.99653435  0.95626545]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 9248. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.97495615  0.54782414  0.9937432   0.9799299 ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 9249. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.9350221   0.38494778  0.98680794  0.95235896]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 9250. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.8890249  -0.10809922  0.92973316  0.91876745]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 9251. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.92964846  0.15420902  0.9964366   0.92945623]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 9252. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.99638176  0.27361727  0.93654156  0.9512713 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 9253. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.9668767   0.28280437  0.9716954   0.89836526]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 9254. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.90286916  0.23891401  0.9872701   0.9322376 ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 9255. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.8762591   0.00549984  0.9980011   0.93888557]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 9256. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.73394334  0.16023731  0.8567748   0.95551634]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 9257. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.9261145   0.16032398  0.98366714  0.88697135]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 9258. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.81355995 -0.24471658  0.9987292   0.9051385 ]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 9259. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.87827986  0.27108157  0.96589494  0.7903588 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 9260. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.87840414  0.10039151  0.9723728   0.9280164 ]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 9261. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.3816679   0.16231477  0.9148755   0.8950546 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 9262. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.9337423   0.1816907   0.99409056  0.9300132 ]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 9263. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.68259805  0.10433877  0.8610294   0.8965868 ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 9264. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-7.2300553e-01 -1.7046928e-05  9.7940242e-01  9.0849876e-01]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 9265. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.9484567   0.52009666  0.9788227   0.9209546 ]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 9266. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.9794705   0.18605804  0.98887956  0.91683245]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 9267. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.57514185  0.4225514   0.9272158   0.94138134]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 9268. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.9674565   0.40724003  0.9801333   0.77952385]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 9269. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.09902793  0.4299159   0.9749143   0.83577394]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 9270. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.60522634  0.58199954  0.9527409   0.930995  ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 9271. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.44461548  0.3653587   0.9564438   0.95277774]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 9272. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.8487362   0.28660822  0.9791769   0.936329  ]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 9273. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.82688403  0.30193162  0.9893199   0.93850493]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 9274. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.96962106  0.5184816   0.99740005  0.92383575]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 9275. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.5793258   0.1723119   0.99179053  0.94587445]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 9276. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.9662857   0.38826346  0.99507093  0.85307634]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 9277. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.8075288  -0.05067408  0.9959146   0.8671731 ]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 9278. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.8974956   0.25804257  0.9491447   0.9759269 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 9279. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.5948822   0.25499678  0.98249865  0.90375376]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 9280. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.6613571   0.26454878  0.99761796  0.90509224]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 9281. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.84644645  0.16286922  0.9682789   0.9275372 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 9282. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.9551119   0.48415625  0.9550545   0.7731743 ]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 9283. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.936436   0.4893087  0.9100801  0.9464086]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 9284. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.9418835  -0.03290975  0.98607373  0.9096141 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 9285. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.9604051  -0.02825862  0.97168803  0.96020937]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 9286. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.9597043   0.36243343  0.9992056   0.85616505]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 9287. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.9331741 -0.2863292  0.9823195  0.9361712]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 9288. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.95600754  0.3088827   0.9665978   0.91853106]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 9289. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.8517754   0.22481966  0.9738362   0.9336678 ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 9290. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.76777357  0.12825525  0.95571876  0.92590964]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 9291. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.844714    0.5488428   0.96992064  0.95496833]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 9292. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.928106    0.34153557  0.99126625  0.95250106]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 9293. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.9046725   0.5303929   0.99397373  0.9590858 ]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 9294. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.5112893   0.21297562  0.94664574  0.92360735]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 9295. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.3405406   0.26145697  0.99907565  0.9481003 ]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 9296. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.79607415  0.4592197   0.94238496  0.95635843]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 9297. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.5479669   0.3706076   0.97996044  0.85911155]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 9298. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.6977161   0.05749738  0.9952047   0.86981153]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 9299. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.96026754  0.131441    0.98910093  0.9082527 ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 9300. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.78235763 -0.13699335  0.97489786  0.9807682 ]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 9301. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.9671115   0.6697955   0.9854853   0.92876196]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 9302. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.93782824 -0.27558804  0.9409939   0.83466816]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 9303. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.88969576  0.31631827  0.99556494  0.96907353]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 9304. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.8573383  -0.25325227  0.9916842   0.9340911 ]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 9305. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.9321057  -0.00617135  0.99074125  0.92944145]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 9306. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.95496434  0.1245321   0.989781    0.9361602 ]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 9307. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.8407743  -0.03005069  0.98799014  0.9471257 ]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 9308. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.93505424  0.30573535  0.9989387   0.92211413]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 9309. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.8501373   0.07788873  0.981689    0.9215379 ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 9310. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.6650954   0.2403009   0.9972818   0.93063045]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 9311. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.6708551  -0.03045589  0.9417491   0.96523404]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 9312. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.89201033  0.28707218  0.958122    0.9285846 ]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 9313. State = [[ 0.08784393 -0.21648216  0.40942335  1.        ]]. Action = [[-0.9467865   0.3230058   0.99402106  0.9279828 ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 9314. State = [[-0.2575401  -0.10752915  0.1111999   1.        ]]. Action = [[-0.41503072  0.5184114   0.94606745  0.913414  ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 9315. State = [[-0.25495145 -0.12115568  0.10470884  1.        ]]. Action = [[ 0.13434172 -0.20450604  0.99316     0.97584605]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 9316. State = [[-0.24481387 -0.12753448  0.1281624   1.        ]]. Action = [[ 0.5672574  -0.16741621  0.97617173  0.9834094 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 9317. State = [[-0.22414522 -0.13664426  0.15818305  1.        ]]. Action = [[ 0.91787803 -0.3876137   0.3235848   0.9824443 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 9318. State = [[-0.198042   -0.14670138  0.18321286  1.        ]]. Action = [[ 0.25312662 -0.034895    0.94925284  0.95826507]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 9319. State = [[-0.18826501 -0.14983945  0.2037207   1.        ]]. Action = [[0.94965935 0.07378507 0.8038287  0.8532605 ]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 9320. State = [[-0.18554786 -0.15094587  0.20583534  1.        ]]. Action = [[ 0.9333159  -0.49441653  0.6948068   0.9109322 ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 9321. State = [[-0.18474562 -0.15133806  0.2064688   1.        ]]. Action = [[ 0.5398873  -0.25936455  0.00112045  0.91031337]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 9322. State = [[-0.18399467 -0.15149707  0.2070147   1.        ]]. Action = [[ 0.94951093 -0.16834879 -0.72142965  0.96732235]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 9323. State = [[-0.18406005 -0.15147917  0.20698239  1.        ]]. Action = [[ 0.94818854 -0.3348602   0.05291581  0.8694333 ]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 9324. State = [[-0.18406005 -0.15147917  0.20698239  1.        ]]. Action = [[ 0.76287127 -0.22046459 -0.5577321   0.82253945]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 9325. State = [[-0.18406005 -0.15147917  0.20698239  1.        ]]. Action = [[ 0.95598626 -0.49177814 -0.23002505  0.90320086]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 9326. State = [[-0.1708163  -0.15824527  0.22107124  1.        ]]. Action = [[ 0.9222616  -0.48381352  0.9108007   0.8834586 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 9327. State = [[-0.15160476 -0.1694379   0.24321747  1.        ]]. Action = [[ 0.75565004 -0.13882649 -0.7120545   0.93598366]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: No entry zone
Current timestep = 9328. State = [[-0.15004109 -0.17058156  0.24493177  1.        ]]. Action = [[ 0.91448617 -0.15617639 -0.21392721  0.9003607 ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: No entry zone
Current timestep = 9329. State = [[-0.14025751 -0.17277889  0.23867492  1.        ]]. Action = [[ 0.9902799 -0.2063663 -0.8755256  0.5920738]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 9330. State = [[-0.11813707 -0.17882933  0.22430128  1.        ]]. Action = [[ 0.9761305  0.2147752 -0.6432468  0.7033591]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: No entry zone
Current timestep = 9331. State = [[-0.10641132 -0.18146135  0.22111772  1.        ]]. Action = [[ 0.94690514 -0.24736935 -0.556887    0.81804085]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 9332. State = [[-0.07190034 -0.19207697  0.20468648  1.        ]]. Action = [[ 0.923404   -0.39180648 -0.00965387  0.80816305]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 9333. State = [[-0.04343492 -0.19432457  0.19462515  1.        ]]. Action = [[ 0.87299204  0.1688106  -0.9591413   0.62857497]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 9334. State = [[-0.01076224 -0.20313445  0.16372377  1.        ]]. Action = [[ 0.9975102  -0.53019065 -0.68083334  0.45416164]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 9335. State = [[ 0.02894067 -0.22580953  0.13555138  1.        ]]. Action = [[ 0.9508929  -0.9131359  -0.37039667  0.48734486]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 9336. State = [[ 0.06814335 -0.26196346  0.13806319  1.        ]]. Action = [[ 0.84587836 -0.95363706  0.93320954  0.3283372 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 9337. State = [[ 0.09452312 -0.2833021   0.15279265  1.        ]]. Action = [[ 0.8623742  -0.96313643  0.8306      0.5472467 ]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 9338. State = [[ 0.10486084 -0.28959498  0.15482716  1.        ]]. Action = [[ 0.94065714 -0.9575694   0.994807    0.523973  ]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 9339. State = [[ 0.10850252 -0.2923401   0.15639178  1.        ]]. Action = [[ 0.9598384  -0.91640466  0.9845576   0.8032447 ]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 9340. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.9892192 -0.9880372  0.9940052  0.6378827]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 9341. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.17655921 -0.57842267  0.8939047   0.7856021 ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 9342. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.9953153 -0.7786178  0.9920449  0.8297558]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 9343. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.66885984 -0.9734791   0.99126554  0.41504145]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 9344. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.75399137 -0.57146895  0.797572    0.8238028 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 9345. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.15819144 -0.5775319   0.97637856  0.75826657]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 9346. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.56230617 -0.8544578   0.9888902   0.45577025]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 9347. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.8838477  -0.97814316  0.9790571   0.7811146 ]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 9348. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.6625252  -0.89319897  0.830572    0.9004773 ]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 9349. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.6722754  -0.8690902   0.99806404  0.76052666]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 9350. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.9259151 -0.7718815  0.9782461  0.7868043]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 9351. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.8480656  -0.973253    0.99843776  0.887849  ]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 9352. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.98563886 -0.76755875  0.99839044  0.8749113 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 9353. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.9587817  -0.9075446   0.91041446  0.692395  ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 9354. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.90729403 -0.7760627   0.9672129   0.6896024 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 9355. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.20085597 -0.8305381   0.99105084  0.49106598]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 9356. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.94094515 -0.88055384  0.99318767  0.75921655]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 9357. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.98862696 -0.5562581  -0.34747827  0.7061715 ]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 9358. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.9282069  -0.7996098   0.9744592   0.65537477]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 9359. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.6945293  -0.93457806  0.95047617  0.6832936 ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 9360. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.95964015 -0.81417006  0.9828396   0.45522022]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 9361. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.7094443  -0.84215707  0.9958782   0.7886841 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 9362. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.5759251  -0.7909906   0.94187427  0.75030684]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 9363. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.7220504  -0.1836561   0.9407954   0.62300587]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 9364. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.79494    -0.6143658   0.5847957   0.70025444]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 9365. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.9112115  -0.95537335  0.95764685  0.6501725 ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 9366. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.81697917 -0.93498737  0.98295283  0.76183033]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 9367. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.7117028 -0.8620714  0.9702976  0.7958534]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 9368. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.9918487  -0.9345019   0.9963566   0.69914985]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 9369. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.4222945 -0.9847767  0.985517   0.7132261]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 9370. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.9236088  -0.89396864  0.78851986  0.86309063]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 9371. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.27348924 -0.7676844   0.9997406   0.7739022 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 9372. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.939167   -0.7699146   0.9072784   0.84238243]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 9373. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.8649547  -0.94528854  0.51353693  0.45397615]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 9374. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.8268368  -0.8351408   0.9583192   0.53205705]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 9375. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.9444573  -0.6768494   0.9946246   0.68570507]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 9376. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.7635181  -0.75676394  0.7045007   0.6771486 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 9377. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.70366454 -0.8265886   0.28637075  0.848593  ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 9378. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.9471531  -0.94762725  0.8201821   0.829358  ]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 9379. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.7328832  -0.7146877   0.63471746  0.8222072 ]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 9380. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.52617157 -0.5816646   0.90973437  0.91585827]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 9381. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.8644537  -0.7900223   0.8333719   0.84246063]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 9382. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.7975682 -0.75916    0.998255   0.9069691]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 9383. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.8986707  -0.83673465  0.9983392   0.7555897 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 9384. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.38052773 -0.77438295  0.99752426  0.6461692 ]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 9385. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.9208703  -0.823221    0.9157331   0.80448747]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 9386. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.74825716 -0.96295726  0.99807036  0.8426995 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 9387. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.9738997  -0.9822364   0.982851    0.77106667]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 9388. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.9845662  -0.4401496   0.80974126  0.8279475 ]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 9389. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.86553204 -0.9666632   0.9794376   0.7425386 ]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 9390. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.87516713 -0.9781118   0.98032     0.7863964 ]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 9391. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.8106766  -0.9841292   0.6272962   0.87316394]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 9392. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.5758996  -0.73953104  0.9878663   0.71451926]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 9393. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.86927986 -0.7577116   0.9807131   0.83210444]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 9394. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.9590777 -0.9748519  0.6831677  0.6783922]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 9395. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.97403383 -0.8497821   0.91059613  0.609509  ]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 9396. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.992682   -0.95448244  0.63166237  0.55090857]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 9397. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.98517346 -0.8798059   0.9973061   0.55395174]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 9398. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[-0.18140459 -0.8592593   0.50203514  0.7452785 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 9399. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.98639274 -0.9590757   0.93880904  0.4514451 ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 9400. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.98475385 -0.88018537  0.83112264  0.8811774 ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 9401. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.9741094  -0.9747487   0.92035913  0.42506826]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 9402. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.99695754 -0.89897203  0.9795549   0.55597854]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 9403. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.79728365 -0.89749396  0.9608612   0.6530279 ]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 9404. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.91306996 -0.8751122   0.97892785  0.6072922 ]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 9405. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.67706203 -0.9759583   0.5242796   0.76030624]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 9406. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.83222866 -0.95960426  0.2922833   0.5416204 ]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 9407. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.44975448 -0.30927908  0.77614427  0.70208013]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 9408. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.985996   -0.96761775  0.6529801   0.64254   ]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 9409. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.7357929  -0.93118453  0.9986012   0.7852924 ]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 9410. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.9600427  -0.88907844  0.9943633   0.5755465 ]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 9411. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.9584999 -0.7999248  0.987515   0.7985828]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 9412. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.9668509 -0.9087554  0.9834237  0.8991034]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 9413. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.40746558 -0.9698205   0.99301815  0.6861025 ]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 9414. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.9592056  -0.77292156  0.99867463  0.5555346 ]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 9415. State = [[ 0.10850837 -0.29230574  0.15616588  1.        ]]. Action = [[ 0.9669316  -0.9032447   0.83951473  0.5284411 ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 9416. State = [[-0.2639464  -0.00996895  0.1128215   1.        ]]. Action = [[ 0.28023684 -0.32837313  0.9843044   0.7292533 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 9417. State = [[-0.26563    -0.0107188   0.09948289  1.        ]]. Action = [[-0.16929442 -0.47328526  0.80001473  0.9671109 ]]. Reward = [0.]
Curr episode timestep = 0
Action ignored: Workspace boundary
Current timestep = 9418. State = [[-0.26563504 -0.01077877  0.09948757  1.        ]]. Action = [[-0.7039022  -0.49211454  0.9970257   0.9556109 ]]. Reward = [0.]
Curr episode timestep = 1
Action ignored: Workspace boundary
Current timestep = 9419. State = [[-0.2628467  -0.02157222  0.10538469  1.        ]]. Action = [[-0.00280976 -0.5865836   0.89726794  0.9968436 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 9420. State = [[-0.25992748 -0.03400336  0.11548347  1.        ]]. Action = [[-0.14376712 -0.562472    0.97880065  0.8927902 ]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: Workspace boundary
Current timestep = 9421. State = [[-0.25788468 -0.04015079  0.12850612  1.        ]]. Action = [[-0.01073509 -0.21141148  0.9984584   0.91655076]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 9422. State = [[-0.25066063 -0.05458867  0.1586778   1.        ]]. Action = [[ 0.6297178  -0.60156614  0.53107476  0.9686347 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 9423. State = [[-0.24237806 -0.07601725  0.18529764  1.        ]]. Action = [[ 0.11492598 -0.68887275  0.9781853   0.8848562 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 9424. State = [[-0.23334594 -0.09536389  0.22360957  1.        ]]. Action = [[ 0.22714329 -0.2484889   0.95709634  0.85285556]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 9425. State = [[-0.21527088 -0.1075682   0.25689662  1.        ]]. Action = [[ 0.75006914 -0.26104593  0.46150708  0.9708538 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 9426. State = [[-0.18715574 -0.11070639  0.28504935  1.        ]]. Action = [[0.90815806 0.30204666 0.8651669  0.9273553 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 9427. State = [[-0.15765119 -0.10720412  0.31149328  1.        ]]. Action = [[0.7242079  0.11955345 0.11109042 0.46818542]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 9428. State = [[-0.12972596 -0.10335606  0.31752813  1.        ]]. Action = [[ 0.7501358   0.0484134  -0.16157311  0.5523715 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 9429. State = [[-0.10452615 -0.10828181  0.31096217  1.        ]]. Action = [[ 0.5972583  -0.43938136 -0.34429717  0.65204453]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 9430. State = [[-0.08041682 -0.11937086  0.29765964  1.        ]]. Action = [[ 0.82665205 -0.3596903  -0.62308043  0.52079046]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 9431. State = [[-0.04686539 -0.12620616  0.28174058  1.        ]]. Action = [[ 0.8095641  -0.01368523 -0.00995874  0.58831143]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 9432. State = [[-0.01823869 -0.13756344  0.27475414  1.        ]]. Action = [[ 0.9396223  -0.5748013  -0.5336627   0.56034756]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 9433. State = [[ 0.01901055 -0.16020092  0.2672619   1.        ]]. Action = [[ 0.9497776  -0.76643044  0.38793838  0.6820581 ]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 9434. State = [[ 0.04897088 -0.18859394  0.26623678  1.        ]]. Action = [[ 0.94033813 -0.89268154 -0.7356406   0.41912973]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 9435. State = [[ 0.08355668 -0.22248472  0.23993142  1.        ]]. Action = [[ 0.9307418  -0.8512289  -0.44680297  0.18177986]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 9436. State = [[ 0.11686311 -0.2441051   0.22436573  1.        ]]. Action = [[ 0.57774293 -0.79173636  0.7405715   0.3159256 ]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 9437. State = [[ 0.12991719 -0.24812157  0.22454558  1.        ]]. Action = [[ 0.12945187 -0.91133994  0.9907807   0.97951555]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 9438. State = [[ 0.1337336  -0.24906558  0.22432938  1.        ]]. Action = [[ 0.19989955 -0.81800115  0.9940927   0.78990686]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 9439. State = [[ 0.13466288 -0.24940223  0.22408009  1.        ]]. Action = [[-0.35505223 -0.8990651   0.99601746  0.7346196 ]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 9440. State = [[ 0.13468257 -0.24938275  0.2241054   1.        ]]. Action = [[ 0.71015596 -0.14283508  0.99848247  0.8742783 ]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 9441. State = [[ 0.13468257 -0.24938275  0.2241054   1.        ]]. Action = [[-0.35645294 -0.789145    0.8331491   0.9654205 ]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 9442. State = [[ 0.13468257 -0.24938275  0.2241054   1.        ]]. Action = [[-0.17470115 -0.8766708   0.9995992   0.90179443]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 9443. State = [[ 0.13468257 -0.24938275  0.2241054   1.        ]]. Action = [[ 0.94887495 -0.86318314  0.97264254  0.83334875]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 9444. State = [[ 0.13467175 -0.24938035  0.224028    1.        ]]. Action = [[ 0.9231725  -0.6012538   0.92255294  0.7494061 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 9445. State = [[ 0.13467175 -0.24938035  0.224028    1.        ]]. Action = [[-0.18873215 -0.97446203  0.9812608   0.9759929 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 9446. State = [[ 0.13467175 -0.24938035  0.224028    1.        ]]. Action = [[ 0.30413103 -0.8314605   0.9929304   0.9926865 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 9447. State = [[ 0.13465208 -0.24939983  0.22400269  1.        ]]. Action = [[ 0.57889676 -0.9342036   0.8746698   0.94519186]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 9448. State = [[ 0.13467175 -0.24938035  0.224028    1.        ]]. Action = [[ 0.5761399 -0.8982509  0.9932227  0.8517225]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 9449. State = [[ 0.13467175 -0.24938035  0.224028    1.        ]]. Action = [[-0.18963128 -0.83313924  0.97420955  0.88240814]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 9450. State = [[ 0.13052532 -0.26447976  0.23905547  1.        ]]. Action = [[-0.7323292 -0.7030476  0.9971535  0.9515226]]. Reward = [0.]
Curr episode timestep = 33
Current timestep = 9451. State = [[ 0.12456422 -0.28130588  0.25950465  1.        ]]. Action = [[-0.18854237 -0.6962509   0.9956343   0.9921372 ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 9452. State = [[ 0.12299717 -0.28316098  0.2612647   1.        ]]. Action = [[-0.58423036 -0.79613847  0.99972594  0.8233197 ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 9453. State = [[ 0.12289844 -0.2831108   0.26126     1.        ]]. Action = [[ 0.5388117  -0.19366062  0.9956676   0.7344811 ]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 9454. State = [[ 0.122709   -0.28362343  0.2615369   1.        ]]. Action = [[ 0.36972308  0.24480605 -0.16606337  0.96430945]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 9455. State = [[ 0.122709   -0.28362343  0.2615369   1.        ]]. Action = [[ 0.9521291  -0.7510238   0.96622324  0.9242258 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 9456. State = [[ 0.12251814 -0.28413883  0.2618165   1.        ]]. Action = [[ 0.9276483  -0.28238344  0.95116925  0.8019717 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 9457. State = [[ 0.12251814 -0.28413883  0.2618165   1.        ]]. Action = [[ 0.8424586  -0.51645947  0.94312537  0.73908997]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 9458. State = [[ 0.12251814 -0.28413883  0.2618165   1.        ]]. Action = [[ 0.5567646  -0.6182056   0.99988234  0.9162924 ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 9459. State = [[ 0.12251814 -0.28413883  0.2618165   1.        ]]. Action = [[ 0.51353645 -0.7558329   0.9762461   0.9054272 ]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 9460. State = [[ 0.12251814 -0.28413883  0.2618165   1.        ]]. Action = [[-0.8239044  -0.5147088   0.90231144  0.97271657]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 9461. State = [[ 0.12251814 -0.28413883  0.2618165   1.        ]]. Action = [[ 0.833086   -0.9735074   0.99841917  0.26796007]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 9462. State = [[ 0.12251814 -0.28413883  0.2618165   1.        ]]. Action = [[ 0.48538375 -0.802361    0.9993154   0.98168755]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 9463. State = [[ 0.12251814 -0.28413883  0.2618165   1.        ]]. Action = [[-0.13211763 -0.9554282   0.9988227   0.9426651 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 9464. State = [[ 0.12251814 -0.28413883  0.2618165   1.        ]]. Action = [[ 0.9160719  -0.83155346  0.98130226  0.98773754]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 9465. State = [[ 0.12251814 -0.28413883  0.2618165   1.        ]]. Action = [[ 0.9828253  -0.07922626  0.99809885  0.8552835 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 9466. State = [[ 0.12251814 -0.28413883  0.2618165   1.        ]]. Action = [[ 0.526911   -0.64441174  0.9961542   0.9499457 ]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 9467. State = [[ 0.12251814 -0.28413883  0.2618165   1.        ]]. Action = [[ 0.4898038  -0.20306134  0.96784604  0.7428148 ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 9468. State = [[ 0.12251814 -0.28413883  0.2618165   1.        ]]. Action = [[ 0.2841103  -0.51883346  0.9522213   0.99687135]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 9469. State = [[ 0.12251814 -0.28413883  0.2618165   1.        ]]. Action = [[ 0.91209805 -0.5671906   0.9920449   0.98224735]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 9470. State = [[ 0.12251814 -0.28413883  0.2618165   1.        ]]. Action = [[ 0.08957827 -0.07627451  0.7621659   0.8739563 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 9471. State = [[ 0.12251814 -0.28413883  0.2618165   1.        ]]. Action = [[ 0.1535765  -0.89997697  0.84352124  0.893193  ]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 9472. State = [[ 0.12241945 -0.28408852  0.2618118   1.        ]]. Action = [[ 0.820536   -0.8255072   0.96127295  0.9630561 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 9473. State = [[ 0.12241945 -0.28408852  0.2618118   1.        ]]. Action = [[ 0.98797536 -0.5230121   0.99916565  0.9383249 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 9474. State = [[ 0.12241945 -0.28408852  0.2618118   1.        ]]. Action = [[ 0.9640894  -0.4314304   0.9720609   0.96358514]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 9475. State = [[ 0.12241945 -0.28408852  0.2618118   1.        ]]. Action = [[0.6569319  0.09553027 0.98736703 0.99190235]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 9476. State = [[ 0.12241945 -0.28408852  0.2618118   1.        ]]. Action = [[ 0.21460962 -0.40784943  0.75238705  0.9828315 ]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 9477. State = [[ 0.12241945 -0.28408852  0.2618118   1.        ]]. Action = [[ 0.9390863  -0.03080904  0.79784226  0.96048594]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 9478. State = [[ 0.12241945 -0.28408852  0.2618118   1.        ]]. Action = [[0.28310502 0.2733953  0.9984391  0.95651674]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 9479. State = [[ 0.12241945 -0.28408852  0.2618118   1.        ]]. Action = [[-0.8286368 -0.6591268  0.9810132  0.9849632]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 9480. State = [[ 0.12241945 -0.28408852  0.2618118   1.        ]]. Action = [[ 6.7330861e-01 -8.7887090e-01  9.6618533e-01 -7.7366829e-05]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 9481. State = [[ 0.12241945 -0.28408852  0.2618118   1.        ]]. Action = [[ 0.44469643 -0.5288682   0.99967766  0.8143699 ]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 9482. State = [[ 0.12241945 -0.28408852  0.2618118   1.        ]]. Action = [[ 0.28734803 -0.08598113  0.99845994  0.97968626]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 9483. State = [[ 0.12241945 -0.28408852  0.2618118   1.        ]]. Action = [[0.21733022 0.15667272 0.9898901  0.9915663 ]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 9484. State = [[ 0.12241945 -0.28408852  0.2618118   1.        ]]. Action = [[ 0.8707328  -0.8117592   0.96685576  0.9853425 ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 9485. State = [[ 0.12241945 -0.28408852  0.2618118   1.        ]]. Action = [[ 0.46374726 -0.90746737  0.9526726   0.99641407]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 9486. State = [[ 0.12241945 -0.28408852  0.2618118   1.        ]]. Action = [[ 0.84738433 -0.29897106  0.9969573   0.960464  ]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 9487. State = [[ 0.12241945 -0.28408852  0.2618118   1.        ]]. Action = [[0.2725618  0.6242938  0.9500768  0.97134745]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 9488. State = [[ 0.12241945 -0.28408852  0.2618118   1.        ]]. Action = [[0.03245318 0.11418474 0.97934866 0.98126745]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 9489. State = [[ 0.12241945 -0.28408852  0.2618118   1.        ]]. Action = [[0.8436351  0.45011783 0.8162737  0.98416734]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 9490. State = [[ 0.12241945 -0.28408852  0.2618118   1.        ]]. Action = [[ 0.7854805  -0.42199516  0.99739695  0.9529487 ]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 9491. State = [[ 0.11921342 -0.2897115   0.27821282  1.        ]]. Action = [[-0.8440571  -0.07363081  0.9892552   0.9205618 ]]. Reward = [0.]
Curr episode timestep = 74
Current timestep = 9492. State = [[ 0.10953482 -0.2935126   0.30656445  1.        ]]. Action = [[ 0.66315246 -0.9002412   0.9545653   0.99617934]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 9493. State = [[ 0.1088549 -0.2941736  0.3087362  1.       ]]. Action = [[ 0.84720266 -0.57148653  0.58076215  0.99225223]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 9494. State = [[ 0.10866289 -0.29430163  0.30900124  1.        ]]. Action = [[0.6055789  0.51812077 0.94528913 0.999081  ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 9495. State = [[ 0.10866289 -0.29430163  0.30900124  1.        ]]. Action = [[ 0.4695971 -0.7771427  0.9858923  0.9531884]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 9496. State = [[ 0.10866289 -0.29430163  0.30900124  1.        ]]. Action = [[0.63313913 0.07617772 0.9706222  0.99656665]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 9497. State = [[-0.25997815 -0.07375147  0.1126311   1.        ]]. Action = [[-0.25370157  0.475358    0.97040534 -0.14528173]]. Reward = [0.]
Curr episode timestep = 80
Current timestep = 9498. State = [[-0.25315624 -0.08653707  0.10711555  1.        ]]. Action = [[ 0.5655997  -0.25220507  0.9883044   0.90167725]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 9499. State = [[-0.23768523 -0.09514046  0.12865695  1.        ]]. Action = [[ 0.65473175 -0.26892626  0.8428831   0.9613416 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 9500. State = [[-0.21712059 -0.1103552   0.16162413  1.        ]]. Action = [[ 0.24868572 -0.5097366   0.9182805   0.9333484 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 9501. State = [[-0.19307588 -0.1268318   0.20038836  1.        ]]. Action = [[ 0.9423888  -0.34488547  0.97902584  0.85629916]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 9502. State = [[-0.17166178 -0.13682915  0.22490717  1.        ]]. Action = [[ 0.94117284  0.20317554 -0.9041076   0.86974955]]. Reward = [0.]
Curr episode timestep = 4
Action ignored: No entry zone
Current timestep = 9503. State = [[-0.1692465  -0.13803864  0.2276529   1.        ]]. Action = [[ 0.98078895  0.21621025 -0.98642814  0.9437871 ]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 9504. State = [[-0.1529533  -0.13620684  0.24240208  1.        ]]. Action = [[0.9887341  0.22093642 0.8463613  0.8542751 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 9505. State = [[-0.13227169 -0.13558264  0.26251805  1.        ]]. Action = [[ 0.9741361  -0.4535722  -0.84065455  0.87948906]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 9506. State = [[-0.11925744 -0.13962801  0.26368243  1.        ]]. Action = [[ 0.97277117 -0.37561125 -0.34278953  0.8693507 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 9507. State = [[-0.08738109 -0.1378505   0.26267266  1.        ]]. Action = [[0.95545554 0.41417265 0.18037295 0.86669874]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 9508. State = [[-0.05393543 -0.14012629  0.2673725   1.        ]]. Action = [[ 0.83080626 -0.40900826  0.03286636  0.75905466]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 9509. State = [[-0.02347144 -0.15560716  0.26591387  1.        ]]. Action = [[ 0.9908893  -0.7597612  -0.440696    0.55667424]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 9510. State = [[ 0.01011067 -0.17966598  0.24903129  1.        ]]. Action = [[ 0.97223306 -0.6298343  -0.6064173   0.5477028 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 9511. State = [[ 0.04509394 -0.20624338  0.22317725  1.        ]]. Action = [[ 0.97636175 -0.82647747 -0.84029055  0.54828477]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 9512. State = [[ 0.08509998 -0.23637971  0.20443182  1.        ]]. Action = [[ 0.901139   -0.6962106   0.4941119   0.22940028]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 9513. State = [[ 0.11663777 -0.25326213  0.20981838  1.        ]]. Action = [[ 0.9399743  -0.8294465   0.92021954  0.73691916]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 9514. State = [[ 0.12885407 -0.25721404  0.21173802  1.        ]]. Action = [[ 0.92799115 -0.430205    0.6211356   0.8358946 ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 9515. State = [[ 0.12974687 -0.25740036  0.21298003  1.        ]]. Action = [[ 0.8523264  -0.87972635 -0.6821038   0.93805337]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 9516. State = [[ 0.1297668  -0.25738144  0.21300532  1.        ]]. Action = [[ 0.7280984  -0.39690864  0.7250092   0.9783759 ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 9517. State = [[ 0.12970322 -0.25744253  0.21299057  1.        ]]. Action = [[-0.02445865 -0.9789127   0.9522619   0.607219  ]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 9518. State = [[ 0.12970322 -0.25744253  0.21299057  1.        ]]. Action = [[-0.09896398 -0.9266435   0.9991405   0.95624304]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 9519. State = [[ 0.12972316 -0.2574236   0.21301584  1.        ]]. Action = [[-0.15075862 -0.6279689  -0.6313837   0.9701326 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 9520. State = [[ 0.12967943 -0.2574365   0.21283622  1.        ]]. Action = [[ 0.9953649 -0.5910376  0.9984834  0.8441322]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 9521. State = [[ 0.12968752 -0.25741464  0.2127847   1.        ]]. Action = [[ 0.78504944 -0.63102984  0.5024388   0.8671005 ]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 9522. State = [[ 0.12966757 -0.25743353  0.21275942  1.        ]]. Action = [[ 0.60212755 -0.9632209   0.9795877   0.83791447]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 9523. State = [[ 0.12966757 -0.25743353  0.21275942  1.        ]]. Action = [[ 0.8264029  -0.89417607  0.99872875  0.73614573]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 9524. State = [[ 0.12966757 -0.25743353  0.21275942  1.        ]]. Action = [[ 0.9783945 -0.5152643  0.8864505  0.9861417]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 9525. State = [[ 0.12966757 -0.25743353  0.21275942  1.        ]]. Action = [[ 0.7741678  -0.97024727  0.9789262   0.82163143]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 9526. State = [[ 0.12966757 -0.25743353  0.21275942  1.        ]]. Action = [[ 0.9350128  -0.6885241   0.76028943  0.94461775]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 9527. State = [[ 0.12966368 -0.25740862  0.21263035  1.        ]]. Action = [[ 0.70858073 -0.90506625  0.9885888   0.8253832 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 9528. State = [[ 0.12482742 -0.27580538  0.22727294  1.        ]]. Action = [[-0.70604193 -0.89756835  0.96100295  0.9505745 ]]. Reward = [0.]
Curr episode timestep = 30
Current timestep = 9529. State = [[ 0.11816651 -0.2953036   0.24418443  1.        ]]. Action = [[ 0.3690288  -0.823463    0.9886079   0.80169463]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 9530. State = [[ 0.11675892 -0.29970208  0.24729724  1.        ]]. Action = [[ 0.53764796 -0.17675626  0.8754039   0.7555013 ]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 9531. State = [[ 0.11680042 -0.2996886   0.24744728  1.        ]]. Action = [[0.41622376 0.48632932 0.5731183  0.58718574]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 9532. State = [[ 0.1167039  -0.29963812  0.24744251  1.        ]]. Action = [[ 0.98212385 -0.8833737  -0.8816145   0.5961722 ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 9533. State = [[ 0.11660564 -0.29958674  0.24743775  1.        ]]. Action = [[ 0.87439656 -0.08422536  0.99415255  0.31634116]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 9534. State = [[ 0.11650749 -0.2995354   0.24743307  1.        ]]. Action = [[ 0.7394619 -0.6375867  0.7690892  0.8451967]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 9535. State = [[ 0.11650749 -0.2995354   0.24743307  1.        ]]. Action = [[0.8371999  0.18358564 0.760375   0.9906304 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 9536. State = [[ 0.11650749 -0.2995354   0.24743307  1.        ]]. Action = [[ 0.97812176 -0.7113915   0.9473107   0.8804326 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 9537. State = [[ 0.11650749 -0.2995354   0.24743307  1.        ]]. Action = [[ 0.75373316 -0.7665666   0.52697456  0.93987346]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 9538. State = [[ 0.11650749 -0.2995354   0.24743307  1.        ]]. Action = [[ 0.7637465  -0.5865552   0.12917161  0.923738  ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 9539. State = [[ 0.11650749 -0.2995354   0.24743307  1.        ]]. Action = [[ 0.7969036  -0.5377643   0.38212705  0.8896203 ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 9540. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.47276258 -0.78284204 -0.34249747  0.98032427]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 9541. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.9467757  -0.6696206   0.80646527  0.9016938 ]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 9542. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.97797704 -0.61767995  0.8532462   0.94182515]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 9543. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.91632223 -0.6724927   0.964391    0.91743326]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 9544. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[-0.15530348 -0.6574203   0.69829607  0.9615401 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 9545. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.9869412 -0.7604093  0.9995148  0.9591346]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 9546. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.83837104 -0.8233077   0.99664676  0.99217343]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 9547. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.96355593 -0.7538483   0.9668107   0.95475435]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 9548. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.9025729 -0.9793407  0.9520863  0.737965 ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 9549. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.81851315 -0.95436496  0.91066384  0.9519563 ]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 9550. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.87663317 -0.85977525  0.10889721  0.9346576 ]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 9551. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.73713326 -0.3964969   0.9931302   0.8960185 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 9552. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.9267874 -0.629857   0.9412428  0.9895786]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 9553. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.85205996 -0.69636345  0.9902773   0.77370906]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 9554. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.82491493 -0.43684804  0.9988749   0.8856816 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 9555. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.9199922 -0.8612285  0.9908867  0.9384539]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 9556. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[-0.6029678  -0.85433954  0.9961386   0.4959911 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 9557. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.7054875  -0.620433    0.91119015  0.82132196]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 9558. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.9513807  -0.764102    0.95645714  0.92397976]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 9559. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.96365523 -0.93276936  0.99671745  0.9811343 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 9560. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[0.8361685  0.05843699 0.9678843  0.96472764]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 9561. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.5914054  -0.68150115  0.98789346  0.97928214]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 9562. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.6880144 -0.7650373  0.8315315  0.9057257]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 9563. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.94224644 -0.80546826  0.998016    0.9175124 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 9564. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.96301436 -0.7547004   0.88292336  0.87424517]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 9565. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.9136288  -0.25723165  0.99924207  0.7971306 ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 9566. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[0.8360493  0.25798237 0.99899006 0.8506565 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 9567. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.5743271 -0.7288184  0.8683114  0.9326482]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 9568. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.90954757 -0.93529135  0.957052    0.9496709 ]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 9569. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.12583697 -0.9128972   0.8542075   0.9669708 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 9570. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.6053674 -0.9259933  0.9867661  0.838778 ]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 9571. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.82258785 -0.5108427   0.93454707  0.8284199 ]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 9572. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[-0.10088563 -0.6245381   0.6576407   0.9288324 ]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 9573. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.6148894  -0.90636724  0.8698107   0.95495677]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 9574. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.9848039 -0.844956   0.9970174  0.9212793]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 9575. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.8383837  -0.76171297  0.2567085   0.9276409 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 9576. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.5156517  -0.15896142  0.99820983  0.94248414]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 9577. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.8705001 -0.7749985 -0.8310475  0.9144707]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 9578. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.9615874  -0.50895464  0.99440956  0.9691074 ]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 9579. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.8231914  -0.7698225   0.92580426  0.9634516 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 9580. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.9781766 -0.8312188 -0.8820394  0.9324666]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 9581. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.55463207 -0.61292344  0.9453137   0.9646919 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 9582. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.27283764 -0.8577484   0.97945535  0.8141241 ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 9583. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.96591854 -0.9168697   0.992998    0.9627502 ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 9584. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[0.8824364  0.64176273 0.9980829  0.9269086 ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 9585. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[0.9871299  0.3262856  0.9992366  0.98925614]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 9586. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.26479876 -0.8294593   0.92915225  0.7053709 ]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 9587. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.75621104 -0.8040016   0.9984487   0.90306807]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 9588. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[0.58688176 0.299006   0.61403286 0.78681886]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 9589. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.45448756 -0.91000193  0.97550964  0.8582592 ]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 9590. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.99889505 -0.90229     0.55410016  0.75700426]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 9591. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.09499824 -0.5372229  -0.8152484   0.93113124]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 9592. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.82131124 -0.42751217  0.46042895  0.9671098 ]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 9593. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.5233574  -0.88762593  0.9978081   0.79690826]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 9594. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.9012406  -0.85024524  0.77018404  0.9678407 ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 9595. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.5396677  -0.35008729  0.7388663   0.8117111 ]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 9596. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.99461865 -0.7598135   0.95391583  0.9120445 ]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 9597. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[ 0.88224673  0.1933161  -0.18259734  0.93288743]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 9598. State = [[ 0.11643394 -0.29949692  0.24742962  1.        ]]. Action = [[0.8532952  0.25623095 0.43532515 0.82161546]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 9599. State = [[-0.27123797  0.04615588  0.11252064  1.        ]]. Action = [[ 0.9913814  -0.22450072  0.99866796  0.84442925]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 9600. State = [[-0.26583955  0.04511869  0.10195318  1.        ]]. Action = [[ 0.24963558 -0.53340596  0.5085325   0.8407618 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 9601. State = [[-0.25481886  0.02927514  0.11428051  1.        ]]. Action = [[ 0.32268453 -0.543995    0.8852749   0.9898691 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 9602. State = [[-0.24728557  0.01647178  0.14318748  1.        ]]. Action = [[-0.09329468 -0.13336128  0.9484407   0.9671533 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 9603. State = [[-0.23650959  0.00684848  0.1789247   1.        ]]. Action = [[ 0.66228366 -0.34286833  0.85132897  0.9655094 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 9604. State = [[-0.21350682 -0.00134862  0.19588837  1.        ]]. Action = [[ 0.8569341  -0.18236434 -0.6144204   0.91985035]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 9605. State = [[-0.18884897 -0.01258726  0.1895478   1.        ]]. Action = [[ 0.5518429  -0.43095624 -0.24170363  0.9390726 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 9606. State = [[-0.17586124 -0.0201508   0.18363439  1.        ]]. Action = [[ 0.6658391  -0.10482335  0.8005395   0.9242468 ]]. Reward = [0.]
Curr episode timestep = 6
Action ignored: No entry zone
Current timestep = 9607. State = [[-0.17500046 -0.02134462  0.18351881  1.        ]]. Action = [[ 0.39820778 -0.48613548  0.6301713   0.9015908 ]]. Reward = [0.]
Curr episode timestep = 7
Action ignored: No entry zone
Current timestep = 9608. State = [[-0.17499484 -0.02151892  0.18347932  1.        ]]. Action = [[ 0.7352532  -0.21184993  0.46130037  0.9393736 ]]. Reward = [0.]
Curr episode timestep = 8
Action ignored: No entry zone
Current timestep = 9609. State = [[-0.17464487 -0.0214927   0.18364586  1.        ]]. Action = [[ 0.90464604 -0.45377845  0.37387192  0.8829379 ]]. Reward = [0.]
Curr episode timestep = 9
Action ignored: No entry zone
Current timestep = 9610. State = [[-0.17461926 -0.02148243  0.18365969  1.        ]]. Action = [[ 0.9690542  -0.05126339 -0.33184993  0.85584724]]. Reward = [0.]
Curr episode timestep = 10
Action ignored: No entry zone
Current timestep = 9611. State = [[-0.17461926 -0.02148243  0.18365969  1.        ]]. Action = [[ 0.54955983 -0.4275248   0.80302143  0.893878  ]]. Reward = [0.]
Curr episode timestep = 11
Action ignored: No entry zone
Current timestep = 9612. State = [[-0.17461926 -0.02148243  0.18365969  1.        ]]. Action = [[ 0.70290136 -0.45769036  0.33723068  0.85851   ]]. Reward = [0.]
Curr episode timestep = 12
Action ignored: No entry zone
Current timestep = 9613. State = [[-0.17461926 -0.02148243  0.18365969  1.        ]]. Action = [[ 0.72296095 -0.438178    0.79713523  0.921355  ]]. Reward = [0.]
Curr episode timestep = 13
Action ignored: No entry zone
Current timestep = 9614. State = [[-0.17461926 -0.02148243  0.18365969  1.        ]]. Action = [[ 0.88848615 -0.55505735  0.9438772   0.9372561 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: No entry zone
Current timestep = 9615. State = [[-0.17108151 -0.0325867   0.19119295  1.        ]]. Action = [[ 0.0524559 -0.6107171  0.7944467  0.8154992]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 9616. State = [[-0.16461986 -0.04443263  0.20378031  1.        ]]. Action = [[ 0.47036386 -0.38773715  0.592077    0.9184036 ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: No entry zone
Current timestep = 9617. State = [[-0.15152937 -0.05354915  0.21817893  1.        ]]. Action = [[ 0.89706755 -0.40939176  0.9498712   0.6919732 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 9618. State = [[-0.13119197 -0.06226665  0.24077126  1.        ]]. Action = [[ 0.7691667  -0.12119424 -0.1816147   0.69494486]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: No entry zone
Current timestep = 9619. State = [[-0.12671271 -0.06400325  0.24546258  1.        ]]. Action = [[ 0.84448886 -0.34088457 -0.37535995  0.6832142 ]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: No entry zone
Current timestep = 9620. State = [[-0.11772639 -0.07521249  0.25879616  1.        ]]. Action = [[ 0.5592874  -0.6555973   0.8140342   0.80497193]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 9621. State = [[-0.09744342 -0.08756479  0.2788033   1.        ]]. Action = [[ 0.78365684 -0.10752672 -0.04958248  0.6952617 ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 9622. State = [[-0.0742665  -0.10138102  0.27790397  1.        ]]. Action = [[ 0.9318211  -0.6994994  -0.64222085  0.45512974]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 9623. State = [[-0.04193687 -0.12119178  0.25661886  1.        ]]. Action = [[ 0.7033131  -0.19723338 -0.39826584  0.6506182 ]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 9624. State = [[-0.00940775 -0.13950679  0.26031694  1.        ]]. Action = [[ 0.8972399  -0.8040338   0.84831476  0.49291623]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 9625. State = [[ 0.01592485 -0.16869675  0.27026972  1.        ]]. Action = [[ 0.9277929  -0.93070495 -0.78987294  0.48667753]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 9626. State = [[ 0.05280739 -0.20243235  0.25026357  1.        ]]. Action = [[ 0.9236413  -0.74793607  0.14057827  0.5112668 ]]. Reward = [0.]
Curr episode timestep = 26
Current timestep = 9627. State = [[ 0.08474579 -0.22090355  0.24810588  1.        ]]. Action = [[ 0.9805732 -0.8403394  0.6534096  0.6578449]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 9628. State = [[ 0.09531141 -0.2257565   0.2495692   1.        ]]. Action = [[ 0.6944424  -0.86490154 -0.43675923  0.8811774 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 9629. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.98166883 -0.89454603  0.8968303   0.8295313 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 9630. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.833019   -0.7991077  -0.23367625  0.814373  ]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 9631. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.9641205  -0.9809042   0.58657444  0.76123834]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 9632. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.93646455 -0.8758084   0.5405214   0.7677907 ]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 9633. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.8756349  -0.90102446  0.7560351   0.9190943 ]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 9634. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.81043315 -0.91135865  0.9644362   0.5606246 ]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 9635. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.9554677 -0.8737926  0.9262979  0.8631829]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 9636. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.71426105 -0.50195664  0.96857214  0.8643029 ]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 9637. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.9706347  -0.93216914  0.9940001   0.8704059 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 9638. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.8007536  -0.5523445  -0.46662283  0.7851349 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 9639. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.90997195 -0.86824286  0.95886993  0.76597   ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 9640. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.81712174 -0.8348476   0.9721118   0.64626217]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 9641. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.757066   -0.28352112  0.9759221   0.7227812 ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 9642. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.5535666  -0.51483697  0.9848485   0.664224  ]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 9643. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.72404265 -0.8476186   0.2515      0.79440045]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 9644. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.33323145 -0.89949775  0.99207187  0.8269017 ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 9645. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.87633896 -0.9401566   0.25167537  0.77195764]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 9646. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.98312366 -0.86756796  0.7891886   0.6950972 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 9647. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.31106126 -0.877761   -0.55966264  0.78985393]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 9648. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.9979737  -0.9278414   0.81477034  0.73544395]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 9649. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.8283336  -0.925754    0.93357706  0.740235  ]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 9650. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.67926884 -0.95056814  0.9916992   0.798779  ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 9651. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.8702873  -0.8196158  -0.34257114  0.74492264]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 9652. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.903852  -0.760613   0.9104955  0.8637347]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 9653. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.8648387  -0.56503814  0.29401445  0.7499461 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 9654. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.9750962  -0.93584466  0.5405264   0.6579225 ]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 9655. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.94658613 -0.93224627 -0.6853266   0.8833798 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 9656. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.91583204 -0.06344163  0.9150605   0.810071  ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 9657. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.988343   -0.6803898   0.5899409   0.80443597]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 9658. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.8608681  -0.9023275  -0.01337671  0.63953257]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 9659. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.8699899 -0.6001314  0.0250181  0.6219199]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 9660. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.9095844 -0.8756303  0.9953191  0.6799866]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 9661. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.59877074 -0.8224564   0.78505254  0.6333196 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 9662. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.5048021  -0.24046695  0.08827949  0.70411205]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 9663. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[0.8816581  0.35403252 0.72222877 0.75809073]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 9664. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.8532566  -0.5059467   0.2403009   0.81607413]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 9665. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.5318816  -0.78212136  0.62346196  0.636914  ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 9666. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.9268017  -0.34603816  0.80762887  0.62732744]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 9667. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.9317415  -0.8399486   0.87817     0.82316494]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 9668. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.8959563  -0.85338634  0.99254537  0.8048898 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 9669. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.901417   -0.83048534  0.7649386   0.8121649 ]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 9670. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.772146   -0.7464665   0.97577643  0.75471354]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 9671. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.9312434 -0.7492461  0.9450524  0.8244262]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 9672. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.9119246  -0.63771033  0.9461174   0.5702276 ]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 9673. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.9388498  -0.8230767   0.94775844  0.61804295]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 9674. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.8469858  -0.8813939   0.9946635   0.87551403]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 9675. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.8803617  -0.5822349   0.87973964  0.8030627 ]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 9676. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.8939774  -0.87944204 -0.34118676  0.5312984 ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 9677. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.96394587 -0.859857    0.52515244  0.7950368 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 9678. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.9645648  -0.6464463   0.98217213  0.7591561 ]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 9679. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.7657448  -0.9192227  -0.00166529  0.6919069 ]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 9680. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.85396326 -0.9081667   0.99632835  0.83091784]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 9681. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.89103365 -0.13539219 -0.698046    0.8293891 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 9682. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.308555   -0.854243    0.17588556  0.82283425]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 9683. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.89669085 -0.5996202  -0.93385154  0.8635787 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 9684. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.8547087 -0.2793941  0.8176968  0.7617476]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 9685. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.90010667 -0.60240316  0.7589884   0.63065004]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 9686. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.96283996 -0.6351604   0.6426964   0.86691   ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 9687. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.9324231  -0.81974894 -0.98037565  0.9282305 ]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 9688. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.9804156  -0.00100344  0.9590609   0.82941294]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 9689. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.78544486 -0.92134136  0.40629947  0.8365017 ]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 9690. State = [[ 0.09680633 -0.22588484  0.25058606  1.        ]]. Action = [[ 0.9429022 -0.8517979 -0.7827083  0.8693738]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 9691. State = [[ 0.09678113 -0.22587354  0.25058478  1.        ]]. Action = [[ 0.9384999  -0.63156056  0.96965325  0.7862028 ]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 9692. State = [[ 0.09678113 -0.22587354  0.25058478  1.        ]]. Action = [[ 0.7215682  -0.7410864   0.43801236  0.7821002 ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 9693. State = [[ 0.09678113 -0.22587354  0.25058478  1.        ]]. Action = [[ 0.8528631  -0.945621   -0.08394504  0.7628553 ]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 9694. State = [[ 0.09678113 -0.22587354  0.25058478  1.        ]]. Action = [[ 0.55848694 -0.47926098  0.98061335  0.8761444 ]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 9695. State = [[ 0.09678113 -0.22587354  0.25058478  1.        ]]. Action = [[ 0.7688327  -0.69304013  0.8773842   0.8270751 ]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 9696. State = [[ 0.09678113 -0.22587354  0.25058478  1.        ]]. Action = [[ 0.7931397  -0.8631747   0.25201392  0.712095  ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 9697. State = [[ 0.09678113 -0.22587354  0.25058478  1.        ]]. Action = [[ 0.65924025 -0.03594458  0.4546734   0.8178787 ]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 9698. State = [[ 0.09678113 -0.22587354  0.25058478  1.        ]]. Action = [[ 0.8594798  -0.16903412  0.9023979   0.7027112 ]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 9699. State = [[ 0.09678113 -0.22587354  0.25058478  1.        ]]. Action = [[ 0.8173064 -0.8527524  0.4485395  0.8128438]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 9700. State = [[ 0.09678113 -0.22587354  0.25058478  1.        ]]. Action = [[ 0.8995888  -0.5294586   0.82317996  0.82805204]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 9701. State = [[-0.27082437  0.10624635  0.14005576  1.        ]]. Action = [[ 0.89411426 -0.8517131   0.98804116  0.5973562 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 9702. State = [[-0.2606618   0.09808861  0.14815864  1.        ]]. Action = [[ 0.5634029  -0.6483995   0.98144996  0.8447242 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 9703. State = [[-0.24544972  0.07601293  0.17035367  1.        ]]. Action = [[ 0.2609017  -0.7875797   0.952538    0.93584657]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 9704. State = [[-0.23536164  0.04941286  0.20788877  1.        ]]. Action = [[ 0.04501259 -0.69280416  0.9808109   0.96366215]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 9705. State = [[-0.22605656  0.02419107  0.24560238  1.        ]]. Action = [[ 0.35858965 -0.64717054  0.8720851   0.8753598 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 9706. State = [[-0.20760803  0.00261546  0.27867398  1.        ]]. Action = [[ 0.65626395 -0.49949777  0.80541503  0.9139054 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 9707. State = [[-0.18782213 -0.01430464  0.30896792  1.        ]]. Action = [[ 0.35877395 -0.34969145  0.5262468   0.7769326 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 9708. State = [[-0.16912544 -0.02830272  0.33497146  1.        ]]. Action = [[ 0.6595669 -0.3193847  0.5648112  0.8360758]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 9709. State = [[-0.1536288  -0.03827898  0.3438976   1.        ]]. Action = [[ 0.4444418  -0.10764116 -0.69909734  0.7009313 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 9710. State = [[-0.13315202 -0.04485863  0.3268746   1.        ]]. Action = [[ 0.61514735 -0.18969816 -0.5889362   0.48473704]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 9711. State = [[-0.10649868 -0.05157653  0.3083302   1.        ]]. Action = [[ 0.8367543  -0.1471157  -0.47372568  0.39990628]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 9712. State = [[-0.07467792 -0.06578071  0.30139363  1.        ]]. Action = [[ 0.6736529  -0.67771375  0.33207726  0.4471395 ]]. Reward = [0.]
Curr episode timestep = 10
Above hoop
Current timestep = 9713. State = [[-0.04902658 -0.08224601  0.30238715  1.        ]]. Action = [[ 0.91148925 -0.16417944 -0.10063827  0.60623324]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 9714. State = [[-0.01706486 -0.09801769  0.30011052  1.        ]]. Action = [[ 0.83906007 -0.73320556  0.03212154  0.40892935]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 9715. State = [[ 0.01114823 -0.12424774  0.2954338   1.        ]]. Action = [[ 0.95039093 -0.6562951  -0.60521746  0.3176527 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 9716. State = [[ 0.04969769 -0.15008888  0.28089067  1.        ]]. Action = [[ 0.8639405  -0.63362616  0.24003124  0.33987415]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 9717. State = [[ 0.08400631 -0.17710479  0.29411018  1.        ]]. Action = [[ 0.71048784 -0.79918486  0.7384181   0.38158512]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 9718. State = [[ 0.10730977 -0.1950931   0.30899477  1.        ]]. Action = [[ 0.6122881  -0.8872539   0.8320694   0.72168183]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 9719. State = [[ 0.1147889  -0.19786432  0.31306648  1.        ]]. Action = [[-0.02088529 -0.608366    0.7515423   0.83791924]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 9720. State = [[ 0.1174619 -0.1984011  0.3148096  1.       ]]. Action = [[ 0.74988735 -0.6779552   0.87680125  0.9149461 ]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 9721. State = [[ 0.11794709 -0.19859543  0.3136999   1.        ]]. Action = [[-0.0706076  -0.50790435  0.5360372   0.6337323 ]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 9722. State = [[ 0.1178021  -0.19862281  0.31330672  1.        ]]. Action = [[ 0.6422682  -0.7803054   0.98565745  0.88706315]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 9723. State = [[ 0.11778486 -0.19867285  0.3132477   1.        ]]. Action = [[ 0.6835532  -0.18551612 -0.30481195  0.9688605 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 9724. State = [[ 0.11778294 -0.19867264  0.31317216  1.        ]]. Action = [[ 0.5075804  -0.6595012   0.6842027   0.94561255]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 9725. State = [[ 0.11778294 -0.19867264  0.31317216  1.        ]]. Action = [[ 0.71542645 -0.6100355   0.96638787  0.8848592 ]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 9726. State = [[ 0.11776773 -0.19872254  0.3131893   1.        ]]. Action = [[ 0.08897817 -0.34455138  0.8437624   0.85728335]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 9727. State = [[ 0.1160991  -0.20583898  0.31126922  1.        ]]. Action = [[-0.52129084 -0.32420772 -0.41360497  0.9634414 ]]. Reward = [0.]
Curr episode timestep = 25
Current timestep = 9728. State = [[ 0.11491284 -0.21162665  0.30909485  1.        ]]. Action = [[-0.2864617  -0.92221683  0.7734345   0.9654207 ]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 9729. State = [[ 0.11457972 -0.21287696  0.30884168  1.        ]]. Action = [[ 0.40958166 -0.60655653  0.9883294   0.9800291 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 9730. State = [[ 0.1144319  -0.21344279  0.3087593   1.        ]]. Action = [[ 0.1051029  -0.19075966 -0.6088848   0.9552444 ]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 9731. State = [[ 0.11439776 -0.21374409  0.30877748  1.        ]]. Action = [[ 0.09386396 -0.7659871   0.98841476  0.9508159 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 9732. State = [[ 0.11439776 -0.21374409  0.30877748  1.        ]]. Action = [[ 0.2629801  -0.6397558   0.94696355  0.81355095]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 9733. State = [[ 0.11439776 -0.21374409  0.30877748  1.        ]]. Action = [[ 0.72445893 -0.71872175  0.81951857  0.89273286]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 9734. State = [[ 0.11439776 -0.21374409  0.30877748  1.        ]]. Action = [[0.39175642 0.09839642 0.99295557 0.91247654]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 9735. State = [[ 0.11439776 -0.21374409  0.30877748  1.        ]]. Action = [[ 0.9001498 -0.7693837  0.5430758  0.8105217]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 9736. State = [[ 0.11439776 -0.21374409  0.30877748  1.        ]]. Action = [[ 0.41404724 -0.94514793  0.04096591  0.87768435]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 9737. State = [[ 0.11439776 -0.21374409  0.30877748  1.        ]]. Action = [[ 0.31133604 -0.07362568  0.88479495  0.92334306]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 9738. State = [[ 0.11439776 -0.21374409  0.30877748  1.        ]]. Action = [[ 0.45788074 -0.32728028 -0.3553301   0.9358177 ]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 9739. State = [[ 0.11439776 -0.21374409  0.30877748  1.        ]]. Action = [[ 0.5231464 -0.8545429 -0.2607919  0.8732333]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 9740. State = [[ 0.11439776 -0.21374409  0.30877748  1.        ]]. Action = [[-0.04291594 -0.34062362  0.8984275   0.8928838 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 9741. State = [[ 0.11439776 -0.21374409  0.30877748  1.        ]]. Action = [[ 0.8429909  -0.45261347  0.40892053  0.97075224]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 9742. State = [[ 0.11439776 -0.21374409  0.30877748  1.        ]]. Action = [[ 0.10316145 -0.24419338  0.992453    0.8870239 ]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 9743. State = [[ 0.11439776 -0.21374409  0.30877748  1.        ]]. Action = [[-0.14139462 -0.9189044   0.99170995  0.8388815 ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 9744. State = [[ 0.10737231 -0.22605686  0.3016016   1.        ]]. Action = [[-0.31679416 -0.7579559  -0.60977715  0.80657494]]. Reward = [0.]
Curr episode timestep = 42
Current timestep = 9745. State = [[ 0.10358778 -0.24091482  0.28768554  1.        ]]. Action = [[ 0.64093494 -0.82399863  0.46402144  0.9738109 ]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 9746. State = [[ 0.10315067 -0.24307144  0.285955    1.        ]]. Action = [[ 0.8922883  -0.6593008  -0.17400247  0.8308048 ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 9747. State = [[ 0.1030715  -0.24335541  0.2858247   1.        ]]. Action = [[ 0.90796876 -0.94490796  0.02171695  0.9698132 ]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 9748. State = [[ 0.1030715  -0.24335541  0.2858247   1.        ]]. Action = [[ 0.74080896 -0.69431853  0.46972442  0.9431937 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 9749. State = [[ 0.1030715  -0.24335541  0.2858247   1.        ]]. Action = [[ 0.5977371   0.02987194 -0.9065607   0.9075959 ]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 9750. State = [[ 0.1030715  -0.24335541  0.2858247   1.        ]]. Action = [[ 0.8891685  -0.69800013  0.99726486  0.9807215 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 9751. State = [[ 0.1030715  -0.24335541  0.2858247   1.        ]]. Action = [[ 0.43098664 -0.23613936 -0.6313259   0.8988812 ]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 9752. State = [[ 0.1030715  -0.24335541  0.2858247   1.        ]]. Action = [[ 0.9065211  -0.28677058  0.9331074   0.886389  ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 9753. State = [[ 0.1030715  -0.24335541  0.2858247   1.        ]]. Action = [[ 0.9369712  -0.89257884 -0.27344757  0.9450065 ]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 9754. State = [[ 0.1030715  -0.24335541  0.2858247   1.        ]]. Action = [[ 0.7618139  -0.2759812   0.96284914  0.952314  ]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 9755. State = [[ 0.1030715  -0.24335541  0.2858247   1.        ]]. Action = [[0.23217654 0.07988346 0.9881964  0.9174204 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 9756. State = [[ 0.1030715  -0.24335541  0.2858247   1.        ]]. Action = [[ 0.9780557  -0.426921    0.02410662  0.7112396 ]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 9757. State = [[ 0.1030715  -0.24335541  0.2858247   1.        ]]. Action = [[ 0.79970646 -0.40531468  0.9648968   0.9702332 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 9758. State = [[ 0.1030715  -0.24335541  0.2858247   1.        ]]. Action = [[ 0.9439788  -0.62278837  0.9890015   0.9749501 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 9759. State = [[ 0.10306247 -0.24343778  0.28582472  1.        ]]. Action = [[ 0.91757035 -0.6968642   0.42520416  0.9004195 ]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 9760. State = [[ 0.10306247 -0.24343778  0.28582472  1.        ]]. Action = [[0.9174638  0.52892625 0.6419003  0.9469006 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 9761. State = [[ 0.10306247 -0.24343778  0.28582472  1.        ]]. Action = [[ 0.8923392  -0.84756017  0.80310154  0.89415   ]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 9762. State = [[ 0.10306247 -0.24343778  0.28582472  1.        ]]. Action = [[ 0.6509818  -0.5646458   0.63865924  0.8832936 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 9763. State = [[ 0.10306247 -0.24343778  0.28582472  1.        ]]. Action = [[ 0.7960328  -0.50674635  0.3511082   0.81487155]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 9764. State = [[ 0.10306247 -0.24343778  0.28582472  1.        ]]. Action = [[ 0.57492137 -0.6726977   0.9684217   0.9089184 ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 9765. State = [[ 0.10306247 -0.24343778  0.28582472  1.        ]]. Action = [[ 0.30802214 -0.9510216   0.02659154  0.8433839 ]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 9766. State = [[ 0.10306247 -0.24343778  0.28582472  1.        ]]. Action = [[ 0.9231374  -0.42440826  0.9474158   0.92892003]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 9767. State = [[ 0.10306247 -0.24343778  0.28582472  1.        ]]. Action = [[ 0.5895171  -0.44737732  0.9484029   0.9290621 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 9768. State = [[ 0.10306247 -0.24343778  0.28582472  1.        ]]. Action = [[ 0.9176853  -0.15000314  0.207484    0.63865674]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 9769. State = [[ 0.10306247 -0.24343778  0.28582472  1.        ]]. Action = [[ 0.8458837  -0.52770054  0.49897075  0.75772095]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 9770. State = [[ 0.10306247 -0.24343778  0.28582472  1.        ]]. Action = [[ 0.88396573 -0.7147797   0.45557308  0.9370167 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 9771. State = [[ 0.10306247 -0.24343778  0.28582472  1.        ]]. Action = [[ 0.906811   -0.60242414  0.5576353   0.9083891 ]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 9772. State = [[ 0.10306247 -0.24343778  0.28582472  1.        ]]. Action = [[ 0.8456855  -0.94562143 -0.20327026  0.95260954]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 9773. State = [[ 0.10306247 -0.24343778  0.28582472  1.        ]]. Action = [[0.6640372  0.141464   0.97116876 0.8973484 ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 9774. State = [[ 0.10306247 -0.24343778  0.28582472  1.        ]]. Action = [[ 0.7358829  -0.86865383  0.47334576  0.92726374]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 9775. State = [[ 0.1014008  -0.24022338  0.2814126   1.        ]]. Action = [[-0.22616184  0.35755515 -0.3536172   0.8035133 ]]. Reward = [0.]
Curr episode timestep = 73
Current timestep = 9776. State = [[ 0.10089123 -0.23899856  0.2794298   1.        ]]. Action = [[ 0.89902306 -0.33679497 -0.54538006  0.9282925 ]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 9777. State = [[ 0.10059404 -0.2389758   0.27877304  1.        ]]. Action = [[ 0.713979   -0.6489399  -0.00657475  0.79515433]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 9778. State = [[ 0.10035285 -0.23934945  0.2783797   1.        ]]. Action = [[ 0.5108254  -0.8616668   0.95867383  0.85494184]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 9779. State = [[ 0.10031796 -0.23890615  0.27823973  1.        ]]. Action = [[ 0.8133006 -0.814689   0.8787308  0.8809488]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 9780. State = [[ 0.10026503 -0.23909709  0.2779954   1.        ]]. Action = [[ 0.8821187  -0.82086253 -0.9917563   0.8941008 ]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 9781. State = [[ 0.10015962 -0.23919988  0.27787426  1.        ]]. Action = [[ 0.93003523 -0.0607329   0.88618946  0.90595317]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 9782. State = [[ 0.10015962 -0.23919988  0.27787426  1.        ]]. Action = [[ 0.5184014  -0.57291687  0.76076424  0.82365155]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 9783. State = [[ 0.10015962 -0.23919988  0.27787426  1.        ]]. Action = [[ 0.9724308  -0.84626764  0.72605455  0.8899343 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 9784. State = [[ 0.10015962 -0.23919988  0.27787426  1.        ]]. Action = [[ 0.754861   -0.01134825  0.97961617  0.9168737 ]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 9785. State = [[ 0.10015962 -0.23919988  0.27787426  1.        ]]. Action = [[ 0.19167078 -0.2509979  -0.28680515  0.8917093 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 9786. State = [[ 0.10015962 -0.23919988  0.27787426  1.        ]]. Action = [[ 0.95170844 -0.25761944  0.61029243  0.7527101 ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 9787. State = [[ 0.10015962 -0.23919988  0.27787426  1.        ]]. Action = [[ 0.7184042  -0.9566881  -0.06035513  0.95431554]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 9788. State = [[ 0.10015962 -0.23919988  0.27787426  1.        ]]. Action = [[ 0.93472123 -0.11228204  0.52169025  0.765265  ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 9789. State = [[ 0.10015962 -0.23919988  0.27787426  1.        ]]. Action = [[ 0.8696375 -0.5743144  0.8915777  0.8639846]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 9790. State = [[ 0.10015962 -0.23919988  0.27787426  1.        ]]. Action = [[ 0.8522799  -0.98087317 -0.47129607  0.85238147]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 9791. State = [[ 0.10015962 -0.23919988  0.27787426  1.        ]]. Action = [[ 0.9625435  -0.6167269   0.8609867   0.88048196]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 9792. State = [[ 0.10015962 -0.23919988  0.27787426  1.        ]]. Action = [[ 0.7499125  -0.25524873  0.9147068   0.8437407 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 9793. State = [[ 0.10015962 -0.23919988  0.27787426  1.        ]]. Action = [[ 0.68420064 -0.5696738   0.97216153  0.7197124 ]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 9794. State = [[ 0.10015962 -0.23919988  0.27787426  1.        ]]. Action = [[ 0.71757984 -0.8278879   0.90166163  0.96422327]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 9795. State = [[ 0.10015962 -0.23919988  0.27787426  1.        ]]. Action = [[ 0.9702097 -0.869773   0.9247265  0.786664 ]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 9796. State = [[ 0.10015962 -0.23919988  0.27787426  1.        ]]. Action = [[ 0.777545   -0.7076134  -0.29289675  0.92525315]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 9797. State = [[ 0.10015962 -0.23919988  0.27787426  1.        ]]. Action = [[ 0.94026065 -0.8100506  -0.5453563   0.90186584]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 9798. State = [[ 0.10015962 -0.23919988  0.27787426  1.        ]]. Action = [[ 0.8579006  -0.88216466  0.54148245  0.9641272 ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 9799. State = [[ 0.10015962 -0.23919988  0.27787426  1.        ]]. Action = [[ 0.88688445 -0.8532549   0.9827292   0.8816049 ]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 9800. State = [[ 0.1001471  -0.23913841  0.27784997  1.        ]]. Action = [[0.42375326 0.5388619  0.87157345 0.9527252 ]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 9801. State = [[ 0.1001471  -0.23913841  0.27784997  1.        ]]. Action = [[ 0.5315535  -0.74160916  0.89860106  0.87642074]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 9802. State = [[ 0.1001471  -0.23913841  0.27784997  1.        ]]. Action = [[ 0.917887   -0.8293661   0.4604522   0.84994864]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 9803. State = [[-0.2630225  -0.03295048  0.11153495  1.        ]]. Action = [[ 0.7661755  -0.91535544  0.9571109   0.80944824]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 9804. State = [[-0.25987542 -0.04276448  0.10499783  1.        ]]. Action = [[ 0.23399293 -0.24606872  0.86457443  0.95502424]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 9805. State = [[-0.25315115 -0.05676693  0.1244818   1.        ]]. Action = [[ 0.12673378 -0.42917705  0.99337053  0.97110057]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 9806. State = [[-0.2410072  -0.07145914  0.15985568  1.        ]]. Action = [[ 0.69227767 -0.40979373  0.9555881   0.98127365]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 9807. State = [[-0.21669479 -0.08154774  0.19787832  1.        ]]. Action = [[ 0.6758915  -0.08403766  0.90105045  0.9139465 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 9808. State = [[-0.18564421 -0.09242563  0.2348639   1.        ]]. Action = [[ 0.8796942  -0.38436127  0.89720654  0.73348796]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 9809. State = [[-0.16364306 -0.10092288  0.2596057   1.        ]]. Action = [[ 0.65678    -0.28970218 -0.531195    0.90924037]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 9810. State = [[-0.14939454 -0.10230402  0.27272227  1.        ]]. Action = [[0.8331094  0.08999741 0.5892247  0.64369047]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 9811. State = [[-0.12675363 -0.10383881  0.28465697  1.        ]]. Action = [[ 0.6959746  -0.14341521 -0.5133513   0.7380638 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 9812. State = [[-0.09812332 -0.1049979   0.2741183   1.        ]]. Action = [[ 0.8530828   0.04682732 -0.2721337   0.66854775]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 9813. State = [[-0.06537894 -0.1107915   0.27193552  1.        ]]. Action = [[ 0.8399824  -0.42936635  0.29138136  0.49778068]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 9814. State = [[-0.0357866  -0.12583566  0.27466032  1.        ]]. Action = [[ 0.68646383 -0.54647493 -0.18561095  0.2815168 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 9815. State = [[-0.00846159 -0.14821504  0.27219045  1.        ]]. Action = [[ 0.9039488  -0.77072984 -0.16365027  0.4960804 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 9816. State = [[ 0.02340758 -0.17449045  0.26269162  1.        ]]. Action = [[ 0.96841073 -0.49011242 -0.35853243  0.5517769 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 9817. State = [[ 0.06225139 -0.19896351  0.26031914  1.        ]]. Action = [[ 0.9041209  -0.7941305   0.57155704  0.4356991 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 9818. State = [[ 0.09076358 -0.21625248  0.2694153   1.        ]]. Action = [[ 0.96731675 -0.8613663  -0.37878138  0.5681839 ]]. Reward = [0.]
Curr episode timestep = 14
Action ignored: Workspace boundary
Current timestep = 9819. State = [[ 0.10034559 -0.21952489  0.2726126   1.        ]]. Action = [[ 0.89701474 -0.78799707  0.72022414  0.7470975 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 9820. State = [[ 0.10173095 -0.22068319  0.27285904  1.        ]]. Action = [[ 0.9410956  -0.98740077  0.9040301   0.903121  ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 9821. State = [[ 0.10165251 -0.221265    0.27271366  1.        ]]. Action = [[ 0.7400782 -0.8760627  0.7383959  0.8611045]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 9822. State = [[ 0.10164316 -0.2212285   0.27263173  1.        ]]. Action = [[ 0.9704926  -0.93825936  0.02005327  0.88706803]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 9823. State = [[ 0.10164316 -0.2212285   0.27263173  1.        ]]. Action = [[ 0.9222388  -0.41124618  0.71950483  0.8863678 ]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 9824. State = [[ 0.10164316 -0.2212285   0.27263173  1.        ]]. Action = [[ 0.879596   -0.76991725  0.97242665  0.67995405]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 9825. State = [[ 0.10164316 -0.2212285   0.27263173  1.        ]]. Action = [[ 0.73530316 -0.5485099   0.96519446  0.8352916 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 9826. State = [[ 0.10164316 -0.2212285   0.27263173  1.        ]]. Action = [[ 0.48743737 -0.9688998   0.9911202   0.82022524]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 9827. State = [[ 0.10163716 -0.22122738  0.27255794  1.        ]]. Action = [[ 0.27913165 -0.846361    0.7867367   0.73630977]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 9828. State = [[ 0.10163716 -0.22122738  0.27255794  1.        ]]. Action = [[ 0.7484398  -0.1945759   0.93919134  0.8657677 ]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 9829. State = [[ 0.10163716 -0.22122738  0.27255794  1.        ]]. Action = [[ 0.23870814 -0.8339743   0.9523804   0.8425331 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 9830. State = [[ 0.1016311  -0.22122626  0.27248347  1.        ]]. Action = [[-0.02065653 -0.93040955  0.6084069   0.87047887]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 9831. State = [[ 0.1016311  -0.22122626  0.27248347  1.        ]]. Action = [[ 0.85685515 -0.9147163   0.08113849  0.7447374 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 9832. State = [[ 0.1016311  -0.22122626  0.27248347  1.        ]]. Action = [[ 0.89148486 -0.8209349  -0.44832468  0.67030764]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 9833. State = [[ 0.1016311  -0.22122626  0.27248347  1.        ]]. Action = [[ 0.92329717 -0.37488806  0.44101357  0.6308415 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 9834. State = [[ 0.1016311  -0.22122626  0.27248347  1.        ]]. Action = [[ 0.78311586 -0.77725816  0.74758315  0.8699517 ]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 9835. State = [[ 0.1016311  -0.22122626  0.27248347  1.        ]]. Action = [[ 0.9816508  -0.58579457  0.9936483   0.92317593]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 9836. State = [[ 0.10162509 -0.22122514  0.27240968  1.        ]]. Action = [[ 0.69944024 -0.7242441   0.78450704  0.8291124 ]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 9837. State = [[ 0.10162509 -0.22122514  0.27240968  1.        ]]. Action = [[ 0.8812399  -0.08541322  0.9837879   0.7970047 ]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 9838. State = [[ 0.10162509 -0.22122514  0.27240968  1.        ]]. Action = [[ 0.7854357  -0.6224703   0.9936018   0.67352414]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 9839. State = [[ 0.10162509 -0.22122514  0.27240968  1.        ]]. Action = [[ 0.53920484 -0.9035847   0.95331454  0.85406256]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 9840. State = [[ 0.10162509 -0.22122514  0.27240968  1.        ]]. Action = [[ 0.90473175 -0.98479146  0.9028573   0.8787136 ]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 9841. State = [[ 0.10162509 -0.22122514  0.27240968  1.        ]]. Action = [[ 0.79305077 -0.55243766  0.6847117   0.9128492 ]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 9842. State = [[ 0.10162509 -0.22122514  0.27240968  1.        ]]. Action = [[ 0.853876   -0.84230757  0.76150703  0.8560749 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 9843. State = [[ 0.10162509 -0.22122514  0.27240968  1.        ]]. Action = [[ 0.8512031  -0.7674494   0.96647716  0.8971083 ]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 9844. State = [[ 0.1004627  -0.23591107  0.2795954   1.        ]]. Action = [[-0.05783689 -0.8648944   0.40372705  0.93066096]]. Reward = [0.]
Curr episode timestep = 40
Current timestep = 9845. State = [[ 0.09964437 -0.25128964  0.28790858  1.        ]]. Action = [[ 0.84243405 -0.85768306 -0.13781524  0.8002043 ]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 9846. State = [[ 0.09928387 -0.25338387  0.2879043   1.        ]]. Action = [[ 0.67900515 -0.5634207   0.5265715   0.9407294 ]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 9847. State = [[ 0.09924338 -0.2537134   0.28790447  1.        ]]. Action = [[ 0.9531665  -0.73087114  0.77609336  0.87208533]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 9848. State = [[ 0.09923328 -0.2537954   0.2879045   1.        ]]. Action = [[ 0.9610537  -0.65170646  0.49805033  0.8933563 ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 9849. State = [[ 0.09913412 -0.25375006  0.2878993   1.        ]]. Action = [[0.9111291  0.412763   0.9181311  0.98719084]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 9850. State = [[ 0.09913412 -0.25375006  0.2878993   1.        ]]. Action = [[ 0.5917268   0.01452303 -0.8630289   0.9776995 ]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 9851. State = [[ 0.09913412 -0.25375006  0.2878993   1.        ]]. Action = [[ 0.8840046 -0.7143866 -0.5600748  0.9498408]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 9852. State = [[ 0.09913412 -0.25375006  0.2878993   1.        ]]. Action = [[ 0.7879932  -0.81078386  0.6306844   0.91165257]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 9853. State = [[ 0.09913412 -0.25375006  0.2878993   1.        ]]. Action = [[0.85929847 0.01083243 0.21632087 0.9239447 ]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 9854. State = [[ 0.09913412 -0.25375006  0.2878993   1.        ]]. Action = [[0.8706354 0.657315  0.8281114 0.8643894]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 9855. State = [[ 0.09913412 -0.25375006  0.2878993   1.        ]]. Action = [[ 0.89245963 -0.06221133  0.9912765   0.89448214]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 9856. State = [[ 0.09913412 -0.25375006  0.2878993   1.        ]]. Action = [[ 0.96138775 -0.78611207  0.9681399   0.9312172 ]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 9857. State = [[ 0.09913412 -0.25375006  0.2878993   1.        ]]. Action = [[0.42058122 0.9134885  0.9714153  0.87749314]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 9858. State = [[ 0.10123505 -0.24610962  0.29376915  1.        ]]. Action = [[-0.1586479   0.6581212   0.4518609   0.93276906]]. Reward = [0.]
Curr episode timestep = 54
Current timestep = 9859. State = [[ 0.10459388 -0.2397512   0.30230302  1.        ]]. Action = [[ 0.63225305 -0.8338273  -0.50880724  0.96663976]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 9860. State = [[ 0.10420854 -0.2439831   0.30758017  1.        ]]. Action = [[-0.17867595 -0.36991036  0.20977008  0.9646113 ]]. Reward = [0.]
Curr episode timestep = 56
Current timestep = 9861. State = [[ 0.10283934 -0.24999772  0.3123511   1.        ]]. Action = [[ 0.39513135 -0.46071875 -0.25337642  0.88273764]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 9862. State = [[ 0.10263681 -0.25040954  0.3124513   1.        ]]. Action = [[0.7762642  0.19719899 0.01671219 0.9680915 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 9863. State = [[ 0.10263681 -0.25040954  0.3124513   1.        ]]. Action = [[ 0.906054   -0.14865947 -0.02851951  0.9582689 ]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 9864. State = [[ 0.10261147 -0.25039822  0.31245     1.        ]]. Action = [[ 0.902501    0.29350352 -0.03316903  0.99675214]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 9865. State = [[ 0.10261147 -0.25039822  0.31245     1.        ]]. Action = [[0.845503   0.39841366 0.7877281  0.9261509 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 9866. State = [[ 0.10261147 -0.25039822  0.31245     1.        ]]. Action = [[ 0.51658165 -0.63734823 -0.8468652   0.97026443]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 9867. State = [[ 0.10261147 -0.25039822  0.31245     1.        ]]. Action = [[ 0.5272491  -0.4842279   0.7616222   0.98060954]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 9868. State = [[ 0.10261147 -0.25039822  0.31245     1.        ]]. Action = [[ 0.78744006 -0.7985667   0.84250975  0.9862087 ]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 9869. State = [[ 0.10261147 -0.25039822  0.31245     1.        ]]. Action = [[0.8531172  0.7923422  0.94401217 0.8851521 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 9870. State = [[ 0.10261147 -0.25039822  0.31245     1.        ]]. Action = [[ 0.7771447  -0.85931027  0.967968    0.93870854]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 9871. State = [[ 0.10261147 -0.25039822  0.31245     1.        ]]. Action = [[ 0.97197294  0.89180124 -0.3388958   0.9904978 ]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 9872. State = [[ 0.10261147 -0.25039822  0.31245     1.        ]]. Action = [[ 0.9463608  -0.94796413  0.9443705   0.9362818 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 9873. State = [[ 0.10261147 -0.25039822  0.31245     1.        ]]. Action = [[0.95910645 0.37067974 0.99665534 0.93366575]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 9874. State = [[ 0.10263051 -0.2503769   0.31247512  1.        ]]. Action = [[ 0.50999665 -0.13276684  0.44240928  0.92471397]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 9875. State = [[ 0.10263051 -0.2503769   0.31247512  1.        ]]. Action = [[0.8762243  0.8105153  0.98359823 0.79475605]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 9876. State = [[ 0.10156005 -0.25559756  0.3108741   1.        ]]. Action = [[-0.29278857 -0.29367197 -0.43621546  0.9455457 ]]. Reward = [0.]
Curr episode timestep = 72
Current timestep = 9877. State = [[ 0.1007862  -0.25850484  0.3099659   1.        ]]. Action = [[0.9193628  0.36377883 0.32870638 0.96004486]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 9878. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[0.8915329 0.8676126 0.6003772 0.9491644]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 9879. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[0.6604903  0.24682736 0.6064656  0.962878  ]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 9880. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[0.9404247  0.91415715 0.6848872  0.8162142 ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 9881. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[0.8792465  0.6519147  0.27534628 0.9716277 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 9882. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[ 0.4335785  -0.86877126  0.8324683   0.95456576]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 9883. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[0.6978122  0.7163112  0.08549809 0.99373305]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 9884. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[ 0.29044783 -0.7745916   0.8715813   0.9761232 ]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 9885. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[ 0.74691534  0.5098636  -0.6530227   0.9176512 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 9886. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[0.7051817  0.6027198  0.9252305  0.98311746]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 9887. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[0.5761666  0.3826928  0.61275184 0.9582763 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 9888. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[ 0.95822453 -0.04864943  0.8394172   0.9638214 ]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 9889. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[ 0.72202754 -0.886572    0.80969596  0.9913933 ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 9890. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[ 0.9155235  -0.34836322  0.9817369   0.9905766 ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 9891. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[0.8843142  0.23415303 0.937098   0.97272027]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 9892. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[ 0.5446763  -0.28732026  0.57801056  0.9479245 ]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 9893. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[ 0.8503872   0.54427147 -0.25540483  0.93299854]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 9894. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[ 0.09596527 -0.69727236  0.94561505  0.9688598 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 9895. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[ 0.5495722  0.8486457 -0.8218586  0.9632642]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 9896. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[ 0.69157934 -0.7168824   0.9817363   0.8454113 ]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 9897. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[0.87707484 0.8392683  0.9407909  0.96016455]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 9898. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[0.9428365  0.39187956 0.9244815  0.96385837]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 9899. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[ 0.7786758  -0.71826196  0.7898009   0.9795749 ]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 9900. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[ 0.94159377 -0.31291938  0.98044086  0.8935325 ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 9901. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[ 0.9086387  -0.52327746 -0.9131266   0.88410854]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 9902. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[ 0.98126364 -0.8031086  -0.26028764  0.84535134]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 9903. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[ 0.46135962 -0.8216232   0.5137522   0.98634195]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 9904. State = [[ 0.10063925 -0.25912866  0.31008923  1.        ]]. Action = [[ 0.93601966  0.7387662  -0.70957994  0.96480894]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 9905. State = [[-0.26460272 -0.0133824   0.11294059  1.        ]]. Action = [[ 0.71330583 -0.8504039  -0.7370582   0.9817827 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 9906. State = [[-0.2592965  -0.02544202  0.10799342  1.        ]]. Action = [[ 0.43120432 -0.5128233   0.9818034   0.89861536]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 9907. State = [[-0.24846047 -0.04520921  0.13025193  1.        ]]. Action = [[ 0.4024048  -0.60536176  0.89780676  0.939572  ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 9908. State = [[-0.23931547 -0.06141327  0.16436157  1.        ]]. Action = [[-0.01463628 -0.22938204  0.960601    0.9391155 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 9909. State = [[-0.22799133 -0.07737561  0.20130669  1.        ]]. Action = [[ 0.51852274 -0.56841224  0.9861959   0.8736255 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 9910. State = [[-0.20228253 -0.09171654  0.23828979  1.        ]]. Action = [[ 0.90275145 -0.1035822   0.7393633   0.9818454 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 9911. State = [[-0.18073636 -0.0961396   0.26050285  1.        ]]. Action = [[ 0.691833   -0.3622434  -0.58938503  0.87212706]]. Reward = [0.]
Curr episode timestep = 5
Action ignored: No entry zone
Current timestep = 9912. State = [[-0.16843067 -0.09724516  0.26727387  1.        ]]. Action = [[ 0.7802328  -0.02862412  0.01110005  0.6460855 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 9913. State = [[-0.1440139  -0.10155727  0.27439612  1.        ]]. Action = [[ 0.786379   -0.24001193  0.10355628  0.86834383]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 9914. State = [[-0.11778768 -0.10329039  0.27077663  1.        ]]. Action = [[ 0.6898663   0.13528061 -0.56733096  0.5633161 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 9915. State = [[-0.08957915 -0.10838649  0.2706009   1.        ]]. Action = [[ 0.6412895  -0.33692223  0.83853006  0.57576203]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 9916. State = [[-0.06451049 -0.1181232   0.2898833   1.        ]]. Action = [[ 0.6515281  -0.34235173  0.18563807  0.6202998 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 9917. State = [[-0.03984142 -0.13833117  0.29878655  1.        ]]. Action = [[ 0.5896094 -0.7365075  0.1520772  0.683951 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 9918. State = [[-0.01632102 -0.16243239  0.2983402   1.        ]]. Action = [[ 0.93445385 -0.5319387  -0.52265847  0.5685923 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 9919. State = [[ 0.01869379 -0.18200518  0.28530923  1.        ]]. Action = [[ 0.9777777  -0.40638274  0.03309762  0.31556594]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 9920. State = [[ 0.05106291 -0.20427127  0.277005    1.        ]]. Action = [[ 0.8471043  -0.9319573  -0.7282967   0.18146491]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 9921. State = [[ 0.07947617 -0.2256957   0.25598547  1.        ]]. Action = [[ 0.98684335 -0.7038519   0.8113828   0.5315981 ]]. Reward = [0.]
Curr episode timestep = 15
Action ignored: Workspace boundary
Current timestep = 9922. State = [[ 0.09137268 -0.22924623  0.25482807  1.        ]]. Action = [[ 0.98068404 -0.69214576  0.08823836  0.7377925 ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: Workspace boundary
Current timestep = 9923. State = [[ 0.09374607 -0.22982107  0.25653404  1.        ]]. Action = [[ 0.899292   -0.92386156 -0.0258826   0.8759706 ]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: Workspace boundary
Current timestep = 9924. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.8029952  -0.39403373  0.94671583  0.90250444]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: Workspace boundary
Current timestep = 9925. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.80526686 -0.7457144   0.95061576  0.8206513 ]]. Reward = [0.]
Curr episode timestep = 19
Action ignored: Workspace boundary
Current timestep = 9926. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.9252415  -0.47896832 -0.8726718   0.85536957]]. Reward = [0.]
Curr episode timestep = 20
Action ignored: Workspace boundary
Current timestep = 9927. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.9803542  -0.31389964 -0.00351131  0.8600725 ]]. Reward = [0.]
Curr episode timestep = 21
Action ignored: Workspace boundary
Current timestep = 9928. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.9729297  -0.05573136  0.17640865  0.7551111 ]]. Reward = [0.]
Curr episode timestep = 22
Action ignored: Workspace boundary
Current timestep = 9929. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.892413   -0.6657374   0.44181788  0.87142825]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
Current timestep = 9930. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[0.90452504 0.18656301 0.88715935 0.88870776]]. Reward = [0.]
Curr episode timestep = 24
Action ignored: Workspace boundary
Current timestep = 9931. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.7364397  -0.2426368   0.79378915  0.8544104 ]]. Reward = [0.]
Curr episode timestep = 25
Action ignored: Workspace boundary
Current timestep = 9932. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.57436824 -0.28129816  0.55857265  0.89812493]]. Reward = [0.]
Curr episode timestep = 26
Action ignored: Workspace boundary
Current timestep = 9933. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[0.9869015  0.07369649 0.86671424 0.7420981 ]]. Reward = [0.]
Curr episode timestep = 27
Action ignored: Workspace boundary
Current timestep = 9934. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.8849294  -0.861856   -0.44654715  0.94975364]]. Reward = [0.]
Curr episode timestep = 28
Action ignored: Workspace boundary
Current timestep = 9935. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.9689119  -0.26041394 -0.35107672  0.8472291 ]]. Reward = [0.]
Curr episode timestep = 29
Action ignored: Workspace boundary
Current timestep = 9936. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.8169334  -0.24989474  0.7876961   0.7048638 ]]. Reward = [0.]
Curr episode timestep = 30
Action ignored: Workspace boundary
Current timestep = 9937. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.87875867 -0.73045945 -0.93339247  0.7911396 ]]. Reward = [0.]
Curr episode timestep = 31
Action ignored: Workspace boundary
Current timestep = 9938. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.9356177  -0.6609428   0.14870644  0.91729546]]. Reward = [0.]
Curr episode timestep = 32
Action ignored: Workspace boundary
Current timestep = 9939. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.73725843 -0.1879679  -0.4719277   0.90617085]]. Reward = [0.]
Curr episode timestep = 33
Action ignored: Workspace boundary
Current timestep = 9940. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[0.6335983  0.14024568 0.9932821  0.81401205]]. Reward = [0.]
Curr episode timestep = 34
Action ignored: Workspace boundary
Current timestep = 9941. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.95628    -0.6080954   0.12499011  0.8656421 ]]. Reward = [0.]
Curr episode timestep = 35
Action ignored: Workspace boundary
Current timestep = 9942. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[0.9666319  0.16283202 0.42360783 0.830781  ]]. Reward = [0.]
Curr episode timestep = 36
Action ignored: Workspace boundary
Current timestep = 9943. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.60059977 -0.7813831   0.9749913   0.83567786]]. Reward = [0.]
Curr episode timestep = 37
Action ignored: Workspace boundary
Current timestep = 9944. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.7739587 -0.8586546 -0.9548585  0.837597 ]]. Reward = [0.]
Curr episode timestep = 38
Action ignored: Workspace boundary
Current timestep = 9945. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.8574276  -0.9490664  -0.42888904  0.89378417]]. Reward = [0.]
Curr episode timestep = 39
Action ignored: Workspace boundary
Current timestep = 9946. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.641608   -0.35602236  0.0265106   0.88276434]]. Reward = [0.]
Curr episode timestep = 40
Action ignored: Workspace boundary
Current timestep = 9947. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.9601022  -0.01106083 -0.10182041  0.78651595]]. Reward = [0.]
Curr episode timestep = 41
Action ignored: Workspace boundary
Current timestep = 9948. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.7557049  -0.76634175  0.7719207   0.9321623 ]]. Reward = [0.]
Curr episode timestep = 42
Action ignored: Workspace boundary
Current timestep = 9949. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[0.9726441  0.20696902 0.0783056  0.81663215]]. Reward = [0.]
Curr episode timestep = 43
Action ignored: Workspace boundary
Current timestep = 9950. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.96334124 -0.49321097  0.31347632  0.9108381 ]]. Reward = [0.]
Curr episode timestep = 44
Action ignored: Workspace boundary
Current timestep = 9951. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.930946  -0.8173152 -0.3501104  0.9418905]]. Reward = [0.]
Curr episode timestep = 45
Action ignored: Workspace boundary
Current timestep = 9952. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.5252099   0.08699787 -0.5745484   0.82444334]]. Reward = [0.]
Curr episode timestep = 46
Action ignored: Workspace boundary
Current timestep = 9953. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.9463198  -0.2061603   0.79675484  0.91884136]]. Reward = [0.]
Curr episode timestep = 47
Action ignored: Workspace boundary
Current timestep = 9954. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.62728024 -0.24726212  0.88646567  0.8557029 ]]. Reward = [0.]
Curr episode timestep = 48
Action ignored: Workspace boundary
Current timestep = 9955. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.97667956 -0.40552366 -0.7782974   0.7292671 ]]. Reward = [0.]
Curr episode timestep = 49
Action ignored: Workspace boundary
Current timestep = 9956. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.9713025  -0.48552293  0.23109221  0.9567523 ]]. Reward = [0.]
Curr episode timestep = 50
Action ignored: Workspace boundary
Current timestep = 9957. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[0.6807418  0.6539718  0.00606573 0.743757  ]]. Reward = [0.]
Curr episode timestep = 51
Action ignored: Workspace boundary
Current timestep = 9958. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.69462395 -0.77346104  0.038077    0.8430892 ]]. Reward = [0.]
Curr episode timestep = 52
Action ignored: Workspace boundary
Current timestep = 9959. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.78975534 -0.9674684   0.71086586  0.8859339 ]]. Reward = [0.]
Curr episode timestep = 53
Action ignored: Workspace boundary
Current timestep = 9960. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.8916347  -0.26709044 -0.6789869   0.93523157]]. Reward = [0.]
Curr episode timestep = 54
Action ignored: Workspace boundary
Current timestep = 9961. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.9459615  -0.10845286  0.62656474  0.8245075 ]]. Reward = [0.]
Curr episode timestep = 55
Action ignored: Workspace boundary
Current timestep = 9962. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.96429324 -0.9563469   0.20120859  0.5204954 ]]. Reward = [0.]
Curr episode timestep = 56
Action ignored: Workspace boundary
Current timestep = 9963. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.8308264 -0.6725218  0.9780505  0.7901015]]. Reward = [0.]
Curr episode timestep = 57
Action ignored: Workspace boundary
Current timestep = 9964. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.8966019  -0.5717307  -0.91007286  0.5360007 ]]. Reward = [0.]
Curr episode timestep = 58
Action ignored: Workspace boundary
Current timestep = 9965. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.8906543  -0.979174    0.75782776  0.9368861 ]]. Reward = [0.]
Curr episode timestep = 59
Action ignored: Workspace boundary
Current timestep = 9966. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.93379164  0.7063832  -0.79119104  0.9304249 ]]. Reward = [0.]
Curr episode timestep = 60
Action ignored: Workspace boundary
Current timestep = 9967. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.9362948  -0.83586013 -0.36738956  0.9316747 ]]. Reward = [0.]
Curr episode timestep = 61
Action ignored: Workspace boundary
Current timestep = 9968. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[0.9361484  0.84377027 0.41030276 0.7486086 ]]. Reward = [0.]
Curr episode timestep = 62
Action ignored: Workspace boundary
Current timestep = 9969. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.94627905 -0.77440387 -0.81855696  0.9075062 ]]. Reward = [0.]
Curr episode timestep = 63
Action ignored: Workspace boundary
Current timestep = 9970. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.9714596  -0.29534674  0.5361264   0.78641987]]. Reward = [0.]
Curr episode timestep = 64
Action ignored: Workspace boundary
Current timestep = 9971. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.98524606 -0.89360195  0.95097256  0.8892944 ]]. Reward = [0.]
Curr episode timestep = 65
Action ignored: Workspace boundary
Current timestep = 9972. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.6211915  -0.879847   -0.08292705  0.91806555]]. Reward = [0.]
Curr episode timestep = 66
Action ignored: Workspace boundary
Current timestep = 9973. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.4263556  -0.9006125  -0.0563724   0.91700125]]. Reward = [0.]
Curr episode timestep = 67
Action ignored: Workspace boundary
Current timestep = 9974. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[0.73229957 0.31317735 0.19727147 0.8397281 ]]. Reward = [0.]
Curr episode timestep = 68
Action ignored: Workspace boundary
Current timestep = 9975. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.9778197  -0.35109192 -0.90602756  0.9199884 ]]. Reward = [0.]
Curr episode timestep = 69
Action ignored: Workspace boundary
Current timestep = 9976. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.95283544 -0.54047143  0.4265145   0.8732283 ]]. Reward = [0.]
Curr episode timestep = 70
Action ignored: Workspace boundary
Current timestep = 9977. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.7120143  -0.98052806  0.2448541   0.756397  ]]. Reward = [0.]
Curr episode timestep = 71
Action ignored: Workspace boundary
Current timestep = 9978. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.9659476  -0.9563707  -0.69080347  0.91416   ]]. Reward = [0.]
Curr episode timestep = 72
Action ignored: Workspace boundary
Current timestep = 9979. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.9860178 -0.6089172 -0.4886123  0.9307891]]. Reward = [0.]
Curr episode timestep = 73
Action ignored: Workspace boundary
Current timestep = 9980. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.6663096  -0.7385051  -0.09092766  0.87602687]]. Reward = [0.]
Curr episode timestep = 74
Action ignored: Workspace boundary
Current timestep = 9981. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.9377732  -0.64918256 -0.85040116  0.7864274 ]]. Reward = [0.]
Curr episode timestep = 75
Action ignored: Workspace boundary
Current timestep = 9982. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.88871515 -0.12393254 -0.63121057  0.7962227 ]]. Reward = [0.]
Curr episode timestep = 76
Action ignored: Workspace boundary
Current timestep = 9983. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.96696496 -0.40766823 -0.2626983   0.7945795 ]]. Reward = [0.]
Curr episode timestep = 77
Action ignored: Workspace boundary
Current timestep = 9984. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.9324374  -0.39056754  0.6578462   0.8109877 ]]. Reward = [0.]
Curr episode timestep = 78
Action ignored: Workspace boundary
Current timestep = 9985. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.8027431 -0.5006951  0.6703093  0.8850863]]. Reward = [0.]
Curr episode timestep = 79
Action ignored: Workspace boundary
Current timestep = 9986. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.96763134 -0.38529038 -0.7573152   0.6293459 ]]. Reward = [0.]
Curr episode timestep = 80
Action ignored: Workspace boundary
Current timestep = 9987. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.9747224  -0.41932     0.22666168  0.7320447 ]]. Reward = [0.]
Curr episode timestep = 81
Action ignored: Workspace boundary
Current timestep = 9988. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.95533705 -0.31060135  0.07562411  0.8758631 ]]. Reward = [0.]
Curr episode timestep = 82
Action ignored: Workspace boundary
Current timestep = 9989. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.8863026   0.06757951 -0.4047271   0.6068368 ]]. Reward = [0.]
Curr episode timestep = 83
Action ignored: Workspace boundary
Current timestep = 9990. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.9294307  -0.57378536 -0.26199615  0.94000363]]. Reward = [0.]
Curr episode timestep = 84
Action ignored: Workspace boundary
Current timestep = 9991. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.8129654  -0.6894324   0.10909057  0.7315986 ]]. Reward = [0.]
Curr episode timestep = 85
Action ignored: Workspace boundary
Current timestep = 9992. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[0.9314203  0.41985762 0.04393268 0.9183667 ]]. Reward = [0.]
Curr episode timestep = 86
Action ignored: Workspace boundary
Current timestep = 9993. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.96273637 -0.86660635 -0.6912218   0.88271904]]. Reward = [0.]
Curr episode timestep = 87
Action ignored: Workspace boundary
Current timestep = 9994. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.63124454 -0.9602014   0.26677418  0.83905697]]. Reward = [0.]
Curr episode timestep = 88
Action ignored: Workspace boundary
Current timestep = 9995. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.9839275  -0.21774125 -0.33152926  0.62811553]]. Reward = [0.]
Curr episode timestep = 89
Action ignored: Workspace boundary
Current timestep = 9996. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[0.9451479  0.50045943 0.90059996 0.8308165 ]]. Reward = [0.]
Curr episode timestep = 90
Action ignored: Workspace boundary
Current timestep = 9997. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.88632834  0.14829504 -0.48710603  0.8700936 ]]. Reward = [0.]
Curr episode timestep = 91
Action ignored: Workspace boundary
Current timestep = 9998. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.9861245  -0.79040337  0.4772849   0.84121025]]. Reward = [0.]
Curr episode timestep = 92
Action ignored: Workspace boundary
Current timestep = 9999. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.9173424  -0.6275072   0.91957283  0.97170067]]. Reward = [0.]
Curr episode timestep = 93
Action ignored: Workspace boundary
Current timestep = 10000. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.45020938  0.06004167 -0.8865092   0.78982866]]. Reward = [0.]
Curr episode timestep = 94
Action ignored: Workspace boundary
Current timestep = 10001. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.96246743 -0.9845914   0.13291502  0.8947655 ]]. Reward = [0.]
Curr episode timestep = 95
Action ignored: Workspace boundary
Current timestep = 10002. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[0.97110224 0.35630834 0.08718312 0.8050518 ]]. Reward = [0.]
Curr episode timestep = 96
Action ignored: Workspace boundary
Current timestep = 10003. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[0.1274836  0.317374   0.9072945  0.90212464]]. Reward = [0.]
Curr episode timestep = 97
Action ignored: Workspace boundary
Current timestep = 10004. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.39712536 -0.54003865 -0.6152166   0.69540787]]. Reward = [0.]
Curr episode timestep = 98
Action ignored: Workspace boundary
Current timestep = 10005. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.9139286   0.48558974 -0.26231414  0.78104734]]. Reward = [0.]
Curr episode timestep = 99
Action ignored: Workspace boundary
Current timestep = 10006. State = [[ 0.09372646 -0.22987917  0.25654864  1.        ]]. Action = [[ 0.90889347 -0.41813123 -0.8502938   0.9220654 ]]. Reward = [0.]
Curr episode timestep = 100
Action ignored: Workspace boundary
Current timestep = 10007. State = [[-0.27173257  0.07678159  0.13852912  1.        ]]. Action = [[ 0.9459808  -0.9779854   0.67102265  0.9328501 ]]. Reward = [0.]
Curr episode timestep = 101
Action ignored: Workspace boundary
Current timestep = 10008. State = [[-0.26816264  0.07253969  0.14432372  1.        ]]. Action = [[ 0.08303511 -0.3473003   0.7929971   0.9203923 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 10009. State = [[-0.26430786  0.06842592  0.15186031  1.        ]]. Action = [[-0.10447115 -0.67059004  0.72311115  0.97191834]]. Reward = [0.]
Curr episode timestep = 1
Action ignored: Workspace boundary
Current timestep = 10010. State = [[-0.26334786  0.06793281  0.15409486  1.        ]]. Action = [[-0.17308092 -0.63933057  0.9040711   0.95857954]]. Reward = [0.]
Curr episode timestep = 2
Action ignored: Workspace boundary
Current timestep = 10011. State = [[-0.26333758  0.06755535  0.15411806  1.        ]]. Action = [[-0.16477919 -0.47948027  0.72415817  0.89367247]]. Reward = [0.]
Curr episode timestep = 3
Action ignored: Workspace boundary
Current timestep = 10012. State = [[-0.2579828   0.05669596  0.16565576  1.        ]]. Action = [[ 0.3641355  -0.668636    0.9204681   0.99443984]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 10013. State = [[-0.2526321   0.03493186  0.19611302  1.        ]]. Action = [[-0.03857076 -0.67492306  0.9051372   0.87236905]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 10014. State = [[-0.24966837  0.01407079  0.22962375  1.        ]]. Action = [[ 0.12890053 -0.44412822  0.71736705  0.9547744 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 10015. State = [[-0.24639805 -0.00512084  0.25975758  1.        ]]. Action = [[-0.00174052 -0.54632896  0.81857634  0.9180349 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 10016. State = [[-0.2425657  -0.01890352  0.2837015   1.        ]]. Action = [[ 0.1911217  -0.11080384  0.22756553  0.9234071 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 10017. State = [[-0.22692442 -0.02582614  0.30134273  1.        ]]. Action = [[ 0.6015277  -0.18192685  0.57035017  0.8248178 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 10018. State = [[-0.20849915 -0.03783088  0.3101815   1.        ]]. Action = [[ 0.67719626 -0.47467542 -0.74230915  0.92682683]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 10019. State = [[-0.18469009 -0.04822702  0.29779163  1.        ]]. Action = [[ 0.84738517 -0.02595621 -0.49529296  0.86778045]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 10020. State = [[-0.15208203 -0.05827285  0.28127632  1.        ]]. Action = [[ 0.80813515 -0.53916943 -0.35963845  0.72421265]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 10021. State = [[-0.12003438 -0.07823352  0.27851784  1.        ]]. Action = [[ 0.63118494 -0.5599969   0.48317552  0.66460955]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 10022. State = [[-0.1009727  -0.0973963   0.27943626  1.        ]]. Action = [[ 0.9369607  -0.38926494 -0.78649706  0.65175176]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 10023. State = [[-0.06577042 -0.11537004  0.25959435  1.        ]]. Action = [[ 0.69471693 -0.570973   -0.03204334  0.54172635]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 10024. State = [[-0.04507201 -0.12750623  0.2544968   1.        ]]. Action = [[ 0.9125185  -0.57220757 -0.6413274   0.612262  ]]. Reward = [0.]
Curr episode timestep = 16
Action ignored: No entry zone
Current timestep = 10025. State = [[-0.04111205 -0.12903209  0.2565364   1.        ]]. Action = [[ 0.9580425  -0.6632426  -0.42570472  0.7287662 ]]. Reward = [0.]
Curr episode timestep = 17
Action ignored: No entry zone
Current timestep = 10026. State = [[-0.04084926 -0.12979554  0.2563212   1.        ]]. Action = [[ 0.9235289  -0.16661596 -0.583678    0.48602986]]. Reward = [0.]
Curr episode timestep = 18
Action ignored: No entry zone
Current timestep = 10027. State = [[-0.03088959 -0.1399729   0.2587071   1.        ]]. Action = [[ 0.9357537  -0.66328585  0.12822771  0.5029193 ]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 10028. State = [[ 8.6160650e-04 -1.6660163e-01  2.5892901e-01  1.0000000e+00]]. Action = [[ 0.9899107  -0.8393028  -0.09401608  0.63492465]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 10029. State = [[ 0.03339161 -0.19245572  0.24813542  1.        ]]. Action = [[ 0.8748163  -0.44912177 -0.71586466  0.31680727]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 10030. State = [[ 0.06303404 -0.21556653  0.2198156   1.        ]]. Action = [[ 0.8673142  -0.8677791  -0.87183946  0.5582657 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 10031. State = [[ 0.09383962 -0.23635164  0.19327505  1.        ]]. Action = [[ 0.99203825 -0.7315886  -0.77138394  0.2252872 ]]. Reward = [0.]
Curr episode timestep = 23
Action ignored: Workspace boundary
