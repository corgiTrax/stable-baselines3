Current timestep = 0. State = [[-0.25350463 -0.04425733  0.10824718  1.        ]]. Action = [[0.         0.         0.14792418 1.        ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 0 is [False, True, 2, False, True]
Human Feedback received at timestep 0 of 1
Current timestep = 1. State = [[-0.25270247 -0.04499241  0.10848768  1.        ]]. Action = [[ 0.          0.         -0.06322646  1.        ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 1 is [False, True, 2, False, True]
Human Feedback received at timestep 1 of 0
Current timestep = 2. State = [[-0.24808557 -0.04790312  0.1224921   1.        ]]. Action = [[0.        0.        1.8394613 1.       ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 2 is [False, True, 2, False, True]
Human Feedback received at timestep 2 of 1
Current timestep = 3. State = [[-0.24705814 -0.04922733  0.15434876  1.        ]]. Action = [[ 0.         0.        -1.9858321  1.       ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 3 is [False, True, 2, False, True]
Human Feedback received at timestep 3 of -1
Current timestep = 4. State = [[-0.25423348 -0.04678746  0.09585869  1.        ]]. Action = [[ 0.        0.       -1.460188  1.      ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 4 is [False, True, 2, False, True]
Human Feedback received at timestep 4 of -1
Current timestep = 5. State = [[-0.25069407 -0.04911305  0.0584465   1.        ]]. Action = [[0.       0.       1.071372 1.      ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 5 is [False, True, 2, False, True]
Human Feedback received at timestep 5 of 1
Current timestep = 6. State = [[-0.24313936 -0.05177012  0.08387168  1.        ]]. Action = [[0.        0.        1.1012096 1.       ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 6 is [False, True, 2, False, True]
Human Feedback received at timestep 6 of 1
Current timestep = 7. State = [[-0.24519952 -0.05195768  0.10432521  1.        ]]. Action = [[ 0.         0.        -1.2056057  1.       ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 7 is [False, True, 2, False, True]
Human Feedback received at timestep 7 of -1
Current timestep = 8. State = [[-0.25104123 -0.05112808  0.08535454  1.        ]]. Action = [[ 0.         0.        -1.3219001  1.       ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 8 is [False, True, 2, False, True]
Human Feedback received at timestep 8 of 0
Current timestep = 9. State = [[-0.24666803 -0.05131669  0.09396811  1.        ]]. Action = [[0.        0.        1.0571685 1.       ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 9 is [False, True, 2, False, True]
Human Feedback received at timestep 9 of 1
Current timestep = 10. State = [[-0.23925619 -0.05274866  0.12063896  1.        ]]. Action = [[0.       0.       1.064919 1.      ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 10 is [False, True, 2, False, True]
Human Feedback received at timestep 10 of 1
Current timestep = 11. State = [[-0.23631503 -0.05339618  0.16254726  1.        ]]. Action = [[0.        0.        1.3197918 1.       ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 11 is [False, True, 2, False, True]
Human Feedback received at timestep 11 of 1
Current timestep = 12. State = [[-0.23577635 -0.05290925  0.21753816  1.        ]]. Action = [[0.        0.        1.9584606 1.       ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 12 is [False, True, 2, False, True]
Human Feedback received at timestep 12 of 1
Current timestep = 13. State = [[-0.24216917 -0.05173463  0.28686643  1.        ]]. Action = [[0.         0.         0.67376685 1.        ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 13 is [False, True, 2, True, False]
Human Feedback received at timestep 13 of 1
Current timestep = 14. State = [[-0.24197184 -0.05118983  0.32120594  1.        ]]. Action = [[0.        0.        1.2122025 1.       ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 14 is [False, True, 2, True, False]
Human Feedback received at timestep 14 of 1
Current timestep = 15. State = [[-0.23833418 -0.05169132  0.35501245  1.        ]]. Action = [[0.        0.        1.9365926 1.       ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 15 is [False, True, 2, True, False]
Human Feedback received at timestep 15 of 0
Current timestep = 16. State = [[-0.23846287 -0.05175573  0.35347077  1.        ]]. Action = [[ 0.          0.         -0.53065133  1.        ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 16 is [False, True, 2, True, False]
Human Feedback received at timestep 16 of 0
Current timestep = 17. State = [[-0.2385476  -0.05200475  0.35955805  1.        ]]. Action = [[0.        0.        0.9402919 1.       ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 17 is [False, True, 2, True, False]
Human Feedback received at timestep 17 of 0
Current timestep = 18. State = [[-0.23884405 -0.05206328  0.372679    1.        ]]. Action = [[ 0.         0.        -0.6494551  1.       ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 18 is [False, True, 2, True, False]
Human Feedback received at timestep 18 of 0
Current timestep = 19. State = [[-0.23954189 -0.05229261  0.35905096  1.        ]]. Action = [[ 0.          0.         -0.72502995  1.        ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 19 is [False, True, 2, True, False]
Human Feedback received at timestep 19 of 0
Current timestep = 20. State = [[-0.2347742  -0.05305108  0.34077972  1.        ]]. Action = [[0.        0.        1.8078151 1.       ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 20 is [False, True, 2, True, False]
Human Feedback received at timestep 20 of 0
Current timestep = 21. State = [[-0.23479348 -0.05307275  0.3407593   1.        ]]. Action = [[0.        0.        1.5686059 1.       ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 21 is [False, True, 2, True, False]
Human Feedback received at timestep 21 of 0
Current timestep = 22. State = [[-0.23473693 -0.05298299  0.3465005   1.        ]]. Action = [[0.        0.        0.8686731 1.       ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 22 is [False, True, 2, True, False]
Human Feedback received at timestep 22 of 0
Current timestep = 23. State = [[-0.23554431 -0.05273518  0.357049    1.        ]]. Action = [[0.        0.        1.4898419 1.       ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 23 is [False, True, 2, True, False]
Human Feedback received at timestep 23 of 0
Current timestep = 24. State = [[-0.23554431 -0.05273518  0.357049    1.        ]]. Action = [[0.        0.        1.4806275 1.       ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 24 is [False, True, 2, True, False]
Human Feedback received at timestep 24 of 0
Current timestep = 25. State = [[-0.23573291 -0.0524527   0.36267647  1.        ]]. Action = [[0.         0.         0.46260786 1.        ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 25 is [False, True, 2, True, False]
Human Feedback received at timestep 25 of -1
Current timestep = 26. State = [[-0.23837882 -0.05189108  0.37270775  1.        ]]. Action = [[0.        0.        1.2664523 1.       ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 26 is [False, True, 2, True, False]
Human Feedback received at timestep 26 of 0
Current timestep = 27. State = [[-0.23859759 -0.05186887  0.37270012  1.        ]]. Action = [[0.        0.        1.9139802 1.       ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 27 is [False, True, 2, True, False]
Human Feedback received at timestep 27 of 0
Current timestep = 28. State = [[-0.24024384 -0.05164815  0.36173862  1.        ]]. Action = [[ 0.         0.        -1.3949707  1.       ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 28 is [False, True, 2, True, False]
Human Feedback received at timestep 28 of 0
Current timestep = 29. State = [[-0.23427474 -0.05262359  0.34610572  1.        ]]. Action = [[0.        0.        1.0143542 1.       ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 29 is [False, True, 2, True, False]
Human Feedback received at timestep 29 of 1
Current timestep = 30. State = [[-0.23899263 -0.05175774  0.34706685  1.        ]]. Action = [[ 0.        0.       -1.495794  1.      ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 30 is [False, True, 2, True, False]
Human Feedback received at timestep 30 of 0
Current timestep = 31. State = [[-0.2396184  -0.05173832  0.30525228  1.        ]]. Action = [[ 0.        0.       -1.312231  1.      ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 31 is [False, True, 2, True, False]
Human Feedback received at timestep 31 of -1
Current timestep = 32. State = [[-0.2355318  -0.05237865  0.27756542  1.        ]]. Action = [[0.        0.        1.6497111 1.       ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 32 is [False, True, 2, True, False]
Human Feedback received at timestep 32 of 1
Current timestep = 33. State = [[-0.23908795 -0.05153151  0.32748026  1.        ]]. Action = [[0.        0.        1.2461827 1.       ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 33 is [False, True, 2, True, False]
Human Feedback received at timestep 33 of 1
Current timestep = 34. State = [[-0.2398775  -0.05136463  0.37120175  1.        ]]. Action = [[0.        0.        0.8335047 1.       ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 34 is [False, True, 2, True, False]
Human Feedback received at timestep 34 of -1
Current timestep = 35. State = [[-0.2386173  -0.05191914  0.39574972  1.        ]]. Action = [[ 0.          0.         -0.44815707  1.        ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 35 is [False, True, 2, True, False]
Human Feedback received at timestep 35 of 0
Current timestep = 36. State = [[-0.23859175 -0.05206168  0.39486742  1.        ]]. Action = [[0.        0.        1.5625958 1.       ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 36 is [False, True, 2, True, False]
Human Feedback received at timestep 36 of 0
Current timestep = 37. State = [[-0.23859175 -0.05206168  0.39486742  1.        ]]. Action = [[0.        0.        1.5356183 1.       ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 37 is [False, True, 2, True, False]
Human Feedback received at timestep 37 of 0
Current timestep = 38. State = [[-0.23859175 -0.05206168  0.39486742  1.        ]]. Action = [[0.        0.        1.0776708 1.       ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 38 is [False, True, 2, True, False]
Human Feedback received at timestep 38 of 0
Current timestep = 39. State = [[-0.23859175 -0.05206168  0.39486742  1.        ]]. Action = [[0.        0.        1.8389452 1.       ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 39 is [False, True, 2, True, False]
Human Feedback received at timestep 39 of 0
Current timestep = 40. State = [[-0.23859175 -0.05206168  0.39486742  1.        ]]. Action = [[0.        0.        1.1479197 1.       ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 40 is [False, True, 2, True, False]
Human Feedback received at timestep 40 of 0
Current timestep = 41. State = [[-0.23859175 -0.05206168  0.39486742  1.        ]]. Action = [[0.        0.        1.8299136 1.       ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 41 is [False, True, 2, True, False]
Human Feedback received at timestep 41 of 0
Current timestep = 42. State = [[-0.24138056 -0.05225262  0.37931532  1.        ]]. Action = [[ 0.         0.        -1.5068818  1.       ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 42 is [False, True, 2, True, False]
Human Feedback received at timestep 42 of 1
Current timestep = 43. State = [[-0.23481226 -0.05229146  0.33070448  1.        ]]. Action = [[ 0.         0.        -0.6667323  1.       ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 43 is [False, True, 2, True, False]
Human Feedback received at timestep 43 of -1
Current timestep = 44. State = [[-0.23562291 -0.05209813  0.30406174  1.        ]]. Action = [[ 0.         0.        -0.6236527  1.       ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 44 is [False, True, 2, True, False]
Human Feedback received at timestep 44 of -1
Current timestep = 45. State = [[-0.23574114 -0.05198018  0.27752897  1.        ]]. Action = [[ 0.         0.        -0.8146055  1.       ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 45 is [False, True, 2, True, False]
Human Feedback received at timestep 45 of -1
Current timestep = 46. State = [[-0.23916715 -0.05157588  0.25125924  1.        ]]. Action = [[ 0.          0.         -0.08248281  1.        ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 46 is [False, True, 2, True, False]
Human Feedback received at timestep 46 of 0
Current timestep = 47. State = [[-0.24020912 -0.05124667  0.24952376  1.        ]]. Action = [[0.         0.         0.35673118 1.        ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 47 is [False, True, 2, True, False]
Human Feedback received at timestep 47 of 0
Current timestep = 48. State = [[-0.23974456 -0.0514206   0.2519952   1.        ]]. Action = [[0.         0.         0.20513725 1.        ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 48 is [False, True, 2, True, False]
Human Feedback received at timestep 48 of 1
Current timestep = 49. State = [[-0.24001622 -0.05156189  0.24581733  1.        ]]. Action = [[ 0.         0.        -1.0499182  1.       ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 49 is [False, True, 2, True, False]
Human Feedback received at timestep 49 of -1
Current timestep = 50. State = [[-0.23763786 -0.05211558  0.23433593  1.        ]]. Action = [[0.        0.        0.9992659 1.       ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 50 is [False, True, 2, True, False]
Human Feedback received at timestep 50 of 1
Current timestep = 51. State = [[-0.25884724  0.04130403  0.11600574  1.        ]]. Action = [[ 0.          0.         -0.00102901  1.        ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 52. State = [[-0.2586904   0.04722503  0.0949409   1.        ]]. Action = [[ 0.         0.        -1.2641317  1.       ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 52 is [False, True, 2, False, True]
Human Feedback received at timestep 52 of -1
Current timestep = 53. State = [[-0.25936186  0.04797629  0.05096317  1.        ]]. Action = [[ 0.         0.        -0.2603172  1.       ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 53 is [False, True, 2, False, True]
Human Feedback received at timestep 53 of -1
Current timestep = 54. State = [[-0.2582617   0.0482159   0.04109973  1.        ]]. Action = [[ 0.        0.       -0.232221  1.      ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 54 is [False, True, 2, False, True]
Human Feedback received at timestep 54 of -1
Current timestep = 55. State = [[-0.25345322  0.04778298  0.04287146  1.        ]]. Action = [[0.        0.        1.0263667 1.       ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 55 is [False, True, 2, False, True]
Human Feedback received at timestep 55 of 1
Current timestep = 56. State = [[-0.25021657  0.04988727  0.05480338  1.        ]]. Action = [[ 0.          0.         -0.23657346  1.        ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 56 is [False, True, 2, False, True]
Human Feedback received at timestep 56 of 0
Current timestep = 57. State = [[-0.25034678  0.04986887  0.05478649  1.        ]]. Action = [[ 0.         0.        -0.9549228  1.       ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 57 is [False, True, 2, False, True]
Human Feedback received at timestep 57 of 0
Current timestep = 58. State = [[-0.24679871  0.04905527  0.06793702  1.        ]]. Action = [[0.        0.        1.4831872 1.       ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 58 is [False, True, 2, False, True]
Human Feedback received at timestep 58 of 1
Current timestep = 59. State = [[-0.24580531  0.05092994  0.11591486  1.        ]]. Action = [[0.       0.       1.351213 1.      ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 59 is [False, True, 2, False, True]
Human Feedback received at timestep 59 of 1
Current timestep = 60. State = [[-0.24539223  0.05083122  0.16606572  1.        ]]. Action = [[0.        0.        0.8371544 1.       ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 60 is [False, True, 2, False, True]
Human Feedback received at timestep 60 of 1
Current timestep = 61. State = [[-0.24962798  0.05152123  0.18033458  1.        ]]. Action = [[ 0.        0.       -1.540031  1.      ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 61 is [False, True, 2, False, True]
Human Feedback received at timestep 61 of -1
Current timestep = 62. State = [[-0.25602823  0.05102927  0.1385897   1.        ]]. Action = [[ 0.          0.         -0.66826344  1.        ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 62 is [False, True, 2, False, True]
Human Feedback received at timestep 62 of -1
Current timestep = 63. State = [[-0.25221068  0.05114495  0.13000807  1.        ]]. Action = [[0.        0.        1.1777277 1.       ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 63 is [False, True, 2, False, True]
Human Feedback received at timestep 63 of 1
Current timestep = 64. State = [[-0.24785705  0.05184074  0.15200302  1.        ]]. Action = [[0.        0.        0.1353817 1.       ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 64 is [False, True, 2, False, True]
Human Feedback received at timestep 64 of 1
Current timestep = 65. State = [[-0.24777578  0.05184585  0.1544299   1.        ]]. Action = [[0.         0.         0.00653768 1.        ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 65 is [False, True, 2, False, True]
Human Feedback received at timestep 65 of 0
Current timestep = 66. State = [[-0.24635388  0.05211042  0.16413508  1.        ]]. Action = [[0.        0.        0.6933062 1.       ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 66 is [False, True, 2, False, True]
Human Feedback received at timestep 66 of 1
Current timestep = 67. State = [[-0.2467249   0.05207803  0.18238947  1.        ]]. Action = [[ 0.          0.         -0.27156675  1.        ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 67 is [False, True, 2, False, True]
Human Feedback received at timestep 67 of 0
Current timestep = 68. State = [[-0.24703664  0.05209516  0.18564302  1.        ]]. Action = [[0.        0.        0.5395081 1.       ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 68 is [False, True, 2, False, True]
Human Feedback received at timestep 68 of 1
Current timestep = 69. State = [[-0.24948835  0.05185128  0.1838577   1.        ]]. Action = [[ 0.         0.        -1.0037426  1.       ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 69 is [False, True, 2, False, True]
Human Feedback received at timestep 69 of -1
Current timestep = 70. State = [[-0.2537674   0.05130252  0.1633222   1.        ]]. Action = [[ 0.         0.        -0.5962894  1.       ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 70 is [False, True, 2, False, True]
Human Feedback received at timestep 70 of -1
Current timestep = 71. State = [[-0.25626674  0.05159968  0.1391168   1.        ]]. Action = [[ 0.         0.        -1.0707414  1.       ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 71 is [False, True, 2, False, True]
Human Feedback received at timestep 71 of -1
Current timestep = 72. State = [[-0.25975788  0.05132809  0.09869305  1.        ]]. Action = [[ 0.          0.         -0.68200374  1.        ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 72 is [False, True, 2, False, True]
Human Feedback received at timestep 72 of -1
Current timestep = 73. State = [[-0.26091677  0.0513417   0.07324498  1.        ]]. Action = [[ 0.         0.        -0.8755791  1.       ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 73 is [False, True, 2, False, True]
Human Feedback received at timestep 73 of -1
Current timestep = 74. State = [[-0.25889257  0.05103054  0.04702135  1.        ]]. Action = [[0.         0.         0.20245504 1.        ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 74 is [False, True, 2, False, True]
Human Feedback received at timestep 74 of 0
Current timestep = 75. State = [[-0.2535445   0.05083733  0.0587608   1.        ]]. Action = [[0.        0.        1.2246456 1.       ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 75 is [False, True, 2, False, True]
Human Feedback received at timestep 75 of 1
Current timestep = 76. State = [[-0.24815275  0.05189718  0.08314188  1.        ]]. Action = [[ 0.          0.         -0.03550076  1.        ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 76 is [False, True, 2, False, True]
Human Feedback received at timestep 76 of 0
Current timestep = 77. State = [[-0.24469794  0.05172415  0.09804907  1.        ]]. Action = [[0.        0.        1.5043716 1.       ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 77 is [False, True, 2, False, True]
Human Feedback received at timestep 77 of 1
Current timestep = 78. State = [[-0.24143507  0.05258489  0.13908443  1.        ]]. Action = [[ 0.          0.         -0.19186592  1.        ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 78 is [False, True, 2, False, True]
Human Feedback received at timestep 78 of 0
Current timestep = 79. State = [[-0.24253456  0.0521322   0.1434098   1.        ]]. Action = [[0.         0.         0.49947333 1.        ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 79 is [False, True, 2, False, True]
Human Feedback received at timestep 79 of 1
Current timestep = 80. State = [[-0.2420524   0.05240821  0.156099    1.        ]]. Action = [[0.         0.         0.32212162 1.        ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 80 is [False, True, 2, False, True]
Human Feedback received at timestep 80 of 1
Current timestep = 81. State = [[-0.2460755   0.0520716   0.16224134  1.        ]]. Action = [[ 0.          0.         -0.62965345  1.        ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 81 is [False, True, 2, False, True]
Human Feedback received at timestep 81 of -1
Current timestep = 82. State = [[-0.24742708  0.05187255  0.16040619  1.        ]]. Action = [[0.        0.        0.5788789 1.       ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 82 is [False, True, 2, False, True]
Human Feedback received at timestep 82 of 1
Current timestep = 83. State = [[-0.2436394   0.05207344  0.18126377  1.        ]]. Action = [[0.        0.        1.8195448 1.       ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 83 is [False, True, 2, False, True]
Human Feedback received at timestep 83 of 1
Current timestep = 84. State = [[-0.24821903  0.05148633  0.2399718   1.        ]]. Action = [[0.         0.         0.54743385 1.        ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 84 is [False, True, 2, True, False]
Human Feedback received at timestep 84 of 1
Current timestep = 85. State = [[-0.24618813  0.05203867  0.2666923   1.        ]]. Action = [[0.        0.        0.7902498 1.       ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 85 is [False, True, 2, True, False]
Human Feedback received at timestep 85 of 1
Current timestep = 86. State = [[-0.24515411  0.05261664  0.29791144  1.        ]]. Action = [[0.        0.        0.8862753 1.       ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 86 is [False, True, 2, True, False]
Human Feedback received at timestep 86 of 1
Current timestep = 87. State = [[-0.2434912   0.05328332  0.32179978  1.        ]]. Action = [[ 0.         0.        -0.4748305  1.       ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 87 is [False, True, 2, True, False]
Human Feedback received at timestep 87 of 0
Current timestep = 88. State = [[-0.24415277  0.05271469  0.31712267  1.        ]]. Action = [[ 0.          0.         -0.35468602  1.        ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 88 is [False, True, 2, True, False]
Human Feedback received at timestep 88 of 0
Current timestep = 89. State = [[-0.24451593  0.05260313  0.3106289   1.        ]]. Action = [[0.         0.         0.02708507 1.        ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 89 is [False, True, 2, True, False]
Human Feedback received at timestep 89 of 0
Current timestep = 90. State = [[-0.24452955  0.05266985  0.30854434  1.        ]]. Action = [[ 0.         0.        -0.2823236  1.       ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 90 is [False, True, 2, True, False]
Human Feedback received at timestep 90 of 0
Current timestep = 91. State = [[-0.24412109  0.05257005  0.29231757  1.        ]]. Action = [[ 0.         0.        -0.8555639  1.       ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 91 is [False, True, 2, True, False]
Human Feedback received at timestep 91 of -1
Current timestep = 92. State = [[-0.24102433  0.05251939  0.2674768   1.        ]]. Action = [[ 0.          0.         -0.06181562  1.        ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 92 is [False, True, 2, True, False]
Human Feedback received at timestep 92 of 0
Current timestep = 93. State = [[-0.24147822  0.05233774  0.26846293  1.        ]]. Action = [[0.        0.        0.5119829 1.       ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 93 is [False, True, 2, True, False]
Human Feedback received at timestep 93 of 1
Current timestep = 94. State = [[-0.24059534  0.05243329  0.27923617  1.        ]]. Action = [[0.        0.        0.7159133 1.       ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 94 is [False, True, 2, True, False]
Human Feedback received at timestep 94 of 1
Current timestep = 95. State = [[-0.24262445  0.05265651  0.30601406  1.        ]]. Action = [[0.         0.         0.73119926 1.        ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 95 is [False, True, 2, True, False]
Human Feedback received at timestep 95 of 1
Current timestep = 96. State = [[-0.24399126  0.05284348  0.33263236  1.        ]]. Action = [[0.       0.       0.756969 1.      ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 96 is [False, True, 2, True, False]
Human Feedback received at timestep 96 of 1
Current timestep = 97. State = [[-0.24378134  0.05306729  0.34788463  1.        ]]. Action = [[ 0.         0.        -0.6926091  1.       ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 97 is [False, True, 2, True, False]
Human Feedback received at timestep 97 of 0
Current timestep = 98. State = [[-0.24376746  0.05303085  0.342252    1.        ]]. Action = [[0.        0.        0.0637188 1.       ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 98 is [False, True, 2, True, False]
Human Feedback received at timestep 98 of 0
Current timestep = 99. State = [[-0.24374342  0.05309534  0.33806702  1.        ]]. Action = [[ 0.         0.        -0.4473071  1.       ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 99 is [False, True, 2, True, False]
Human Feedback received at timestep 99 of 0
Current timestep = 100. State = [[-0.23958589  0.05362058  0.32588813  1.        ]]. Action = [[ 0.56805897  0.         -0.2939092   1.        ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 100 is [False, True, 0, True, False]
Human Feedback received at timestep 100 of 0
Current timestep = 101. State = [[-0.22572309  0.05447104  0.3187909   1.        ]]. Action = [[0.20445156 0.         0.62123656 1.        ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 101 is [False, True, 0, True, False]
Human Feedback received at timestep 101 of 1
Current timestep = 102. State = [[-0.22329947  0.05498735  0.32198432  1.        ]]. Action = [[-0.8033549  0.        -0.6005765  1.       ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 102 is [False, True, 0, True, False]
Human Feedback received at timestep 102 of -1
Current timestep = 103. State = [[-0.2628432   0.13284934  0.11147609  1.        ]]. Action = [[ 0.00820351  0.         -0.06897473  1.        ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 104. State = [[-0.26009867  0.14870226  0.09806002  1.        ]]. Action = [[-0.74755734  0.          0.77247834  1.        ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 104 is [False, True, 0, True, False]
Human Feedback received at timestep 104 of -1
Current timestep = 105. State = [[-0.26009867  0.14870226  0.09806002  1.        ]]. Action = [[-0.79319423  0.          1.5602288   1.        ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 105 is [False, True, 0, True, False]
Human Feedback received at timestep 105 of 0
Current timestep = 106. State = [[-0.26009867  0.14870226  0.09806002  1.        ]]. Action = [[-0.60348755  0.          1.7068357   1.        ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 106 is [False, True, 0, True, False]
Human Feedback received at timestep 106 of 0
Current timestep = 107. State = [[-0.25033066  0.14907943  0.11115229  1.        ]]. Action = [[0.46704817 0.         1.3974686  1.        ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 107 is [False, True, 0, True, False]
Human Feedback received at timestep 107 of 1
Current timestep = 108. State = [[-0.23575331  0.15123384  0.13619353  1.        ]]. Action = [[0.42826545 0.         0.0221324  1.        ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 108 is [False, True, 0, True, False]
Human Feedback received at timestep 108 of 1
Current timestep = 109. State = [[-0.22182114  0.15325765  0.1527065   1.        ]]. Action = [[0.14676368 0.         1.0872784  1.        ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 109 is [False, True, 0, True, False]
Human Feedback received at timestep 109 of 1
Current timestep = 110. State = [[-0.21873647  0.15397663  0.18866618  1.        ]]. Action = [[-0.27206677  0.          0.87592006  1.        ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 110 is [False, True, 0, True, False]
Human Feedback received at timestep 110 of -1
Current timestep = 111. State = [[-0.21193382  0.15367068  0.21560054  1.        ]]. Action = [[0.820526   0.         0.12582779 1.        ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 111 is [False, True, 0, True, False]
Human Feedback received at timestep 111 of 1
Current timestep = 112. State = [[-0.19068952  0.15350369  0.23342061  1.        ]]. Action = [[0.4603758 0.        0.7581668 1.       ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 112 is [False, True, 0, True, False]
Human Feedback received at timestep 112 of 1
Current timestep = 113. State = [[-0.1617751   0.15530586  0.26239336  1.        ]]. Action = [[0.8503479 0.        0.775542  1.       ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 113 is [False, True, 0, True, False]
Human Feedback received at timestep 113 of 1
Current timestep = 114. State = [[-0.13914232  0.15575899  0.28558105  1.        ]]. Action = [[ 0.28118932  0.         -0.03961766  1.        ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 114 is [False, True, 0, True, False]
Human Feedback received at timestep 114 of 1
Current timestep = 115. State = [[-0.13405076  0.15688816  0.28042427  1.        ]]. Action = [[-0.49225807  0.         -0.643816    1.        ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 115 is [False, True, 0, True, False]
Human Feedback received at timestep 115 of -1
Current timestep = 116. State = [[-0.13664778  0.15816478  0.2793001   1.        ]]. Action = [[-0.18361086  0.          0.8767395   1.        ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 116 is [False, True, 0, True, False]
Human Feedback received at timestep 116 of 0
Current timestep = 117. State = [[-0.13635883  0.15860038  0.30219176  1.        ]]. Action = [[0.43096495 0.         0.68380547 1.        ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 117 is [False, True, 0, True, False]
Human Feedback received at timestep 117 of 1
Current timestep = 118. State = [[-0.13096772  0.15663296  0.31044447  1.        ]]. Action = [[ 0.5589721   0.         -0.81483793  1.        ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 118 is [False, True, 0, True, False]
Human Feedback received at timestep 118 of 1
Current timestep = 119. State = [[-0.11816289  0.15596896  0.28838363  1.        ]]. Action = [[ 0.24944222  0.         -0.5184046   1.        ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 119 is [False, True, 0, True, False]
Human Feedback received at timestep 119 of 1
Current timestep = 120. State = [[-0.10826063  0.1566833   0.27756393  1.        ]]. Action = [[-0.48219496  0.         -1.2229248   1.        ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 120 is [False, True, 0, True, False]
Human Feedback received at timestep 120 of 0
Current timestep = 121. State = [[-0.09684023  0.15640773  0.28867966  1.        ]]. Action = [[0.75996435 0.         0.84061766 1.        ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 121 is [False, True, 0, True, False]
Human Feedback received at timestep 121 of 1
Current timestep = 122. State = [[-0.07389711  0.15485384  0.30624166  1.        ]]. Action = [[ 0.9919276   0.         -0.15206742  1.        ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 122 is [False, True, 0, True, False]
Human Feedback received at timestep 122 of 1
Current timestep = 123. State = [[-0.0385916   0.15728706  0.29796574  1.        ]]. Action = [[ 0.38981736  0.         -0.07850945  1.        ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 123 is [False, True, 0, True, False]
Human Feedback received at timestep 123 of 1
Current timestep = 124. State = [[-0.02789505  0.15724145  0.29373917  1.        ]]. Action = [[-0.23609751  0.         -0.09030354  1.        ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 124 is [False, True, 0, True, False]
Human Feedback received at timestep 124 of 0
Current timestep = 125. State = [[-0.01851217  0.15691371  0.3066119   1.        ]]. Action = [[0.9428909 0.        0.8913884 1.       ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 125 is [False, True, 0, True, False]
Human Feedback received at timestep 125 of 1
Current timestep = 126. State = [[0.00935996 0.15756993 0.33180827 1.        ]]. Action = [[0.9593495 0.        0.3467188 1.       ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 126 is [False, True, 0, False, True]
Human Feedback received at timestep 126 of 1
Current timestep = 127. State = [[0.04337281 0.15648939 0.33659208 1.        ]]. Action = [[ 0.9799584   0.         -0.84730756  1.        ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 127 is [False, True, 0, False, True]
Human Feedback received at timestep 127 of -1
Current timestep = 128. State = [[0.08303734 0.16088669 0.301928   1.        ]]. Action = [[ 0.17137969  0.         -0.23548925  1.        ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 128 is [False, True, 0, False, True]
Human Feedback received at timestep 128 of 0
Current timestep = 129. State = [[0.0893619 0.1625546 0.299414  1.       ]]. Action = [[ 0.6034179  0.        -0.4631641  1.       ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 129 is [False, True, 0, False, True]
Human Feedback received at timestep 129 of 0
Current timestep = 130. State = [[0.08998845 0.16248214 0.3005701  1.        ]]. Action = [[0.1326412  0.         0.12362576 1.        ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 130 is [False, True, 0, False, True]
Human Feedback received at timestep 130 of -1
Current timestep = 131. State = [[0.09058774 0.16170767 0.3002894  1.        ]]. Action = [[ 0.7260765   0.         -0.03323662  1.        ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 131 is [False, True, 0, False, True]
Human Feedback received at timestep 131 of 0
Current timestep = 132. State = [[0.09058774 0.16170767 0.3002894  1.        ]]. Action = [[0.315791   0.         0.16397643 1.        ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 132 is [False, True, 0, False, True]
Human Feedback received at timestep 132 of 0
Current timestep = 133. State = [[0.09058774 0.16170767 0.3002894  1.        ]]. Action = [[ 0.85283685  0.         -0.3478601   1.        ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 133 is [False, True, 0, False, True]
Human Feedback received at timestep 133 of 0
Current timestep = 134. State = [[0.09058774 0.16170767 0.3002894  1.        ]]. Action = [[ 0.8496182  0.        -1.5881991  1.       ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 134 is [False, True, 0, False, True]
Human Feedback received at timestep 134 of 0
Current timestep = 135. State = [[0.09058453 0.1617069  0.30021045 1.        ]]. Action = [[0.8961904  0.         0.31437802 1.        ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 135 is [False, True, 0, False, True]
Human Feedback received at timestep 135 of 0
Current timestep = 136. State = [[0.09058453 0.1617069  0.30021045 1.        ]]. Action = [[0.96261764 0.         0.7185383  1.        ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 136 is [False, True, 0, False, True]
Human Feedback received at timestep 136 of 0
Current timestep = 137. State = [[0.09058135 0.16170612 0.30013222 1.        ]]. Action = [[0.4039259 0.        0.5755336 1.       ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 137 is [False, True, 0, False, True]
Human Feedback received at timestep 137 of 0
Current timestep = 138. State = [[0.09057494 0.16170456 0.299975   1.        ]]. Action = [[ 0.6679201   0.         -0.21889651  1.        ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 138 is [False, True, 0, False, True]
Human Feedback received at timestep 138 of 0
Current timestep = 139. State = [[0.09057173 0.16170378 0.2998968  1.        ]]. Action = [[0.67531335 0.         0.6070173  1.        ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 139 is [False, True, 0, False, True]
Human Feedback received at timestep 139 of 0
Current timestep = 140. State = [[0.09056848 0.16170299 0.29981783 1.        ]]. Action = [[0.61399984 0.         0.345577   1.        ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 140 is [False, True, 0, False, True]
Human Feedback received at timestep 140 of 0
Current timestep = 141. State = [[0.09056848 0.16170299 0.29981783 1.        ]]. Action = [[ 0.8403715  0.        -0.7638962  1.       ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 141 is [False, True, 0, False, True]
Human Feedback received at timestep 141 of 0
Current timestep = 142. State = [[0.09056848 0.16170299 0.29981783 1.        ]]. Action = [[ 0.5546212   0.         -0.44635093  1.        ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 142 is [False, True, 0, False, True]
Human Feedback received at timestep 142 of 0
Current timestep = 143. State = [[0.09056848 0.16170299 0.29981783 1.        ]]. Action = [[0.67233634 0.         0.16919804 1.        ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 143 is [False, True, 0, False, True]
Human Feedback received at timestep 143 of 0
Current timestep = 144. State = [[0.09056848 0.16170299 0.29981783 1.        ]]. Action = [[ 0.4741119   0.         -0.50292885  1.        ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 144 is [False, True, 0, False, True]
Human Feedback received at timestep 144 of 0
Current timestep = 145. State = [[0.09056848 0.16170299 0.29981783 1.        ]]. Action = [[ 0.33377862  0.         -0.04793704  1.        ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 145 is [False, True, 0, False, True]
Human Feedback received at timestep 145 of 0
Current timestep = 146. State = [[0.09056848 0.16170299 0.29981783 1.        ]]. Action = [[0.6797755  0.         0.72612166 1.        ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 146 is [False, True, 0, False, True]
Human Feedback received at timestep 146 of 0
Current timestep = 147. State = [[0.09056848 0.16170299 0.29981783 1.        ]]. Action = [[ 0.21465135  0.         -0.68615866  1.        ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 147 is [False, True, 0, False, True]
Human Feedback received at timestep 147 of 0
Current timestep = 148. State = [[0.09056848 0.16170299 0.29981783 1.        ]]. Action = [[ 0.29758906  0.         -0.86203265  1.        ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 148 is [False, True, 0, False, True]
Human Feedback received at timestep 148 of 0
Current timestep = 149. State = [[0.09056848 0.16170299 0.29981783 1.        ]]. Action = [[ 0.5906873   0.         -0.62679124  1.        ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 149 is [False, True, 0, False, True]
Human Feedback received at timestep 149 of 0
Current timestep = 150. State = [[0.09056848 0.16170299 0.29981783 1.        ]]. Action = [[0.87154496 0.         1.242744   1.        ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 150 is [False, True, 0, False, True]
Human Feedback received at timestep 150 of 0
Current timestep = 151. State = [[0.09056848 0.16170299 0.29981783 1.        ]]. Action = [[ 0.4186815   0.         -0.47265387  1.        ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 151 is [False, True, 0, False, True]
Human Feedback received at timestep 151 of 0
Current timestep = 152. State = [[0.09056848 0.16170299 0.29981783 1.        ]]. Action = [[0.52565145 0.         0.09068084 1.        ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 152 is [False, True, 0, False, True]
Human Feedback received at timestep 152 of 0
Current timestep = 153. State = [[0.09056848 0.16170299 0.29981783 1.        ]]. Action = [[0.5176834 0.        0.5890312 1.       ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 153 is [False, True, 0, False, True]
Human Feedback received at timestep 153 of 0
Current timestep = 154. State = [[0.09056848 0.16170299 0.29981783 1.        ]]. Action = [[0.7888267 0.        0.2704339 1.       ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 154 is [False, True, 0, False, True]
Human Feedback received at timestep 154 of 0
Current timestep = 155. State = [[-0.2660887   0.09382818  0.11328854  1.        ]]. Action = [[-0.05511755  0.          0.07192659  1.        ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 156. State = [[-0.25020838  0.10572882  0.11319151  1.        ]]. Action = [[0.7363367 0.        1.5296903 1.       ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 156 is [False, True, 0, True, False]
Human Feedback received at timestep 156 of 1
Current timestep = 157. State = [[-0.22420643  0.10822719  0.15774387  1.        ]]. Action = [[0.5323471 0.        1.6313629 1.       ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 157 is [False, True, 0, True, False]
Human Feedback received at timestep 157 of 1
Current timestep = 158. State = [[-0.19853213  0.10957979  0.21392363  1.        ]]. Action = [[0.77617574 0.         0.7341969  1.        ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 158 is [False, True, 0, True, False]
Human Feedback received at timestep 158 of 1
Current timestep = 159. State = [[-0.16910443  0.11149518  0.2453879   1.        ]]. Action = [[0.79741716 0.         0.56161714 1.        ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 159 is [False, True, 0, True, False]
Human Feedback received at timestep 159 of 1
Current timestep = 160. State = [[-0.14553393  0.11089105  0.26898634  1.        ]]. Action = [[0.28001773 0.         0.26840162 1.        ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 160 is [False, True, 0, True, False]
Human Feedback received at timestep 160 of 1
Current timestep = 161. State = [[-0.1393059   0.11116172  0.2748835   1.        ]]. Action = [[ 0.01718795  0.         -0.21292102  1.        ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 161 is [False, True, 0, True, False]
Human Feedback received at timestep 161 of 0
Current timestep = 162. State = [[-0.12996836  0.11066112  0.26607075  1.        ]]. Action = [[ 0.755635    0.         -0.38321388  1.        ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 162 is [False, True, 0, True, False]
Human Feedback received at timestep 162 of 1
Current timestep = 163. State = [[-0.10454383  0.11185192  0.27247584  1.        ]]. Action = [[0.4074098 0.        1.1961489 1.       ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 163 is [False, True, 0, True, False]
Human Feedback received at timestep 163 of 1
Current timestep = 164. State = [[-0.08227488  0.11185368  0.29561293  1.        ]]. Action = [[ 0.7223022   0.         -0.22765028  1.        ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 164 is [False, True, 0, True, False]
Human Feedback received at timestep 164 of 1
Current timestep = 165. State = [[-0.0578184   0.11207745  0.30122226  1.        ]]. Action = [[0.68126297 0.         0.30327725 1.        ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 165 is [False, True, 0, True, False]
Human Feedback received at timestep 165 of 1
Current timestep = 166. State = [[-0.0308817   0.11202287  0.3052128   1.        ]]. Action = [[ 0.90041304  0.         -0.12292099  1.        ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 166 is [False, True, 0, True, False]
Human Feedback received at timestep 166 of 1
Current timestep = 167. State = [[0.00504448 0.11349384 0.3061631  1.        ]]. Action = [[0.79956317 0.         0.23160243 1.        ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 167 is [False, True, 0, False, True]
Human Feedback received at timestep 167 of 1
Current timestep = 168. State = [[0.03821439 0.11378673 0.31627366 1.        ]]. Action = [[0.7624061  0.         0.32951856 1.        ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 168 is [False, True, 0, False, True]
Human Feedback received at timestep 168 of -1
Current timestep = 169. State = [[0.06879363 0.11520207 0.32424945 1.        ]]. Action = [[0.6297567  0.         0.02768183 1.        ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 169 is [False, True, 0, False, True]
Human Feedback received at timestep 169 of -1
Current timestep = 170. State = [[0.08658264 0.11703889 0.32481518 1.        ]]. Action = [[0.5932858  0.         0.03872442 1.        ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 170 is [False, True, 0, False, True]
Human Feedback received at timestep 170 of -1
Current timestep = 171. State = [[0.08646198 0.11697441 0.32113478 1.        ]]. Action = [[ 0.04120672  0.         -0.51716447  1.        ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 171 is [False, True, 0, False, True]
Human Feedback received at timestep 171 of -1
Current timestep = 172. State = [[0.091681   0.11638776 0.30656207 1.        ]]. Action = [[ 0.87522316  0.         -1.4839122   1.        ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 172 is [False, True, 0, False, True]
Human Feedback received at timestep 172 of 0
Current timestep = 173. State = [[0.09168611 0.11633477 0.30657136 1.        ]]. Action = [[ 0.603662    0.         -0.25849426  1.        ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 173 is [False, True, 0, False, True]
Human Feedback received at timestep 173 of 0
Current timestep = 174. State = [[0.09168611 0.11633477 0.30657136 1.        ]]. Action = [[ 0.7236788   0.         -0.65591073  1.        ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 174 is [False, True, 0, False, True]
Human Feedback received at timestep 174 of 0
Current timestep = 175. State = [[0.09172178 0.1159642  0.30663642 1.        ]]. Action = [[ 0.3541174   0.         -0.55016625  1.        ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 175 is [False, True, 0, False, True]
Human Feedback received at timestep 175 of 0
Current timestep = 176. State = [[0.09172178 0.1159642  0.30663642 1.        ]]. Action = [[ 0.8395344   0.         -0.46201587  1.        ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 176 is [False, True, 0, False, True]
Human Feedback received at timestep 176 of 0
Current timestep = 177. State = [[0.09172178 0.1159642  0.30663642 1.        ]]. Action = [[ 0.3495729   0.         -0.75812244  1.        ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 177 is [False, True, 0, False, True]
Human Feedback received at timestep 177 of 0
Current timestep = 178. State = [[0.09172178 0.1159642  0.30663642 1.        ]]. Action = [[0.857962   0.         0.92862654 1.        ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 178 is [False, True, 0, False, True]
Human Feedback received at timestep 178 of 0
Current timestep = 179. State = [[0.09172178 0.1159642  0.30663642 1.        ]]. Action = [[ 0.2362392   0.         -0.03169429  1.        ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 179 is [False, True, 0, False, True]
Human Feedback received at timestep 179 of 0
Current timestep = 180. State = [[0.0888871  0.11732637 0.3016747  1.        ]]. Action = [[-0.8876352  0.        -0.7771659  1.       ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 180 is [False, True, 0, False, True]
Human Feedback received at timestep 180 of 1
Current timestep = 181. State = [[0.07944231 0.11701642 0.28421524 1.        ]]. Action = [[ 0.17410433  0.         -0.6708152   1.        ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 181 is [False, True, 0, False, True]
Human Feedback received at timestep 181 of 0
Current timestep = 182. State = [[0.08175506 0.11800248 0.26235408 1.        ]]. Action = [[0.5471475 0.        0.6701155 1.       ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 182 is [False, True, 0, False, True]
Human Feedback received at timestep 182 of 0
Current timestep = 183. State = [[0.08175506 0.11800248 0.26235408 1.        ]]. Action = [[ 0.51991963  0.         -0.31823683  1.        ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 183 is [False, True, 0, False, True]
Human Feedback received at timestep 183 of 0
Current timestep = 184. State = [[0.08175506 0.11800248 0.26235408 1.        ]]. Action = [[0.73427725 0.         0.45839024 1.        ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 184 is [False, True, 0, False, True]
Human Feedback received at timestep 184 of 0
Current timestep = 185. State = [[0.08175506 0.11800248 0.26235408 1.        ]]. Action = [[0.9949713  0.         0.21466064 1.        ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 185 is [False, True, 0, False, True]
Human Feedback received at timestep 185 of 0
Current timestep = 186. State = [[0.08175506 0.11800248 0.26235408 1.        ]]. Action = [[0.7574136 0.        0.2376852 1.       ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 186 is [False, True, 0, False, True]
Human Feedback received at timestep 186 of 0
Current timestep = 187. State = [[0.08175506 0.11800248 0.26235408 1.        ]]. Action = [[0.8418796 0.        1.6143713 1.       ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 187 is [False, True, 0, False, True]
Human Feedback received at timestep 187 of 0
Current timestep = 188. State = [[0.08175506 0.11800248 0.26235408 1.        ]]. Action = [[ 0.81612563  0.         -0.12393892  1.        ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 188 is [False, True, 0, False, True]
Human Feedback received at timestep 188 of 0
Current timestep = 189. State = [[0.08175506 0.11800248 0.26235408 1.        ]]. Action = [[0.92926764 0.         0.75748825 1.        ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 189 is [False, True, 0, False, True]
Human Feedback received at timestep 189 of 0
Current timestep = 190. State = [[0.08143979 0.11776169 0.25814176 1.        ]]. Action = [[-0.07614738  0.         -0.35457253  1.        ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 190 is [False, True, 0, False, True]
Human Feedback received at timestep 190 of 0
Current timestep = 191. State = [[0.0829031  0.11760953 0.2559148  1.        ]]. Action = [[-0.11948496  0.          0.7521014   1.        ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 191 is [False, True, 0, False, True]
Human Feedback received at timestep 191 of 0
Current timestep = 192. State = [[0.08323725 0.11815003 0.2648638  1.        ]]. Action = [[0.73214436 0.         0.5536685  1.        ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 192 is [False, True, 0, False, True]
Human Feedback received at timestep 192 of 0
Current timestep = 193. State = [[0.08323725 0.11815003 0.2648638  1.        ]]. Action = [[0.53056335 0.         0.4755826  1.        ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 193 is [False, True, 0, False, True]
Human Feedback received at timestep 193 of 0
Current timestep = 194. State = [[0.08323725 0.11815003 0.2648638  1.        ]]. Action = [[0.9356816 0.        0.5684371 1.       ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 194 is [False, True, 0, False, True]
Human Feedback received at timestep 194 of 0
Current timestep = 195. State = [[0.08323725 0.11815003 0.2648638  1.        ]]. Action = [[0.8746977  0.         0.35173965 1.        ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 195 is [False, True, 0, False, True]
Human Feedback received at timestep 195 of 0
Current timestep = 196. State = [[0.08011352 0.12106334 0.27810526 1.        ]]. Action = [[-0.9873179  0.         0.7549255  1.       ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 196 is [False, True, 0, False, True]
Human Feedback received at timestep 196 of 1
Current timestep = 197. State = [[0.05245748 0.12242638 0.30140814 1.        ]]. Action = [[ 0.9473121  0.        -0.9901397  1.       ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 197 is [False, True, 0, False, True]
Human Feedback received at timestep 197 of 0
Current timestep = 198. State = [[0.05155991 0.12187069 0.29237092 1.        ]]. Action = [[ 0.42304516  0.         -0.7449374   1.        ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 198 is [False, True, 0, False, True]
Human Feedback received at timestep 198 of 0
Current timestep = 199. State = [[0.05647133 0.12091102 0.27600023 1.        ]]. Action = [[ 0.7662897  0.        -0.1621995  1.       ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 199 is [False, True, 0, False, True]
Human Feedback received at timestep 199 of -1
Current timestep = 200. State = [[0.0665208  0.11948111 0.26269928 1.        ]]. Action = [[ 0.89183104  0.24714172 -0.01554143  1.        ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 200 is [False, True, 1, False, True]
Human Feedback received at timestep 200 of 0
Current timestep = 201. State = [[0.0665208  0.11948111 0.26269928 1.        ]]. Action = [[ 0.7925563  -0.4330923   0.24539757  1.        ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 201 is [False, True, 1, False, True]
Human Feedback received at timestep 201 of 0
Current timestep = 202. State = [[0.06659226 0.11951829 0.2628093  1.        ]]. Action = [[0.8404989  0.5582218  0.18077946 1.        ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 202 is [False, True, 1, False, True]
Human Feedback received at timestep 202 of 0
Current timestep = 203. State = [[0.06689888 0.11687062 0.2711542  1.        ]]. Action = [[-0.79501235 -0.19577086  0.5140798   1.        ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 203 is [False, True, 1, False, True]
Human Feedback received at timestep 203 of 0
Current timestep = 204. State = [[0.05726555 0.11683738 0.27375728 1.        ]]. Action = [[-0.81353045  0.05327988 -0.80257225  1.        ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 204 is [False, True, 1, False, True]
Human Feedback received at timestep 204 of 1
Current timestep = 205. State = [[0.04353786 0.11442568 0.25538954 1.        ]]. Action = [[ 0.5336387  -0.22638398 -0.10989761  1.        ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 205 is [False, True, 1, False, True]
Human Feedback received at timestep 205 of -1
Current timestep = 206. State = [[0.05069705 0.11853531 0.26623672 1.        ]]. Action = [[0.75047493 0.6085352  0.995276   1.        ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 206 is [False, True, 1, False, True]
Human Feedback received at timestep 206 of -1
Current timestep = 207. State = [[-0.26192778 -0.03011406  0.11208511  1.        ]]. Action = [[ 0.87044    -0.97808987 -0.4875127   1.        ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 208. State = [[-0.2556994  -0.04320171  0.1035319   1.        ]]. Action = [[ 0.4872384  -0.46815532  0.71936107  1.        ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 208 is [False, True, 1, True, False]
Human Feedback received at timestep 208 of -1
Current timestep = 209. State = [[-0.23590484 -0.05467779  0.12431736  1.        ]]. Action = [[0.7339463  0.09924257 1.3949227  1.        ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 209 is [False, True, 1, True, False]
Human Feedback received at timestep 209 of 0
Current timestep = 210. State = [[-0.20581508 -0.07060838  0.17922796  1.        ]]. Action = [[ 0.5718912  -0.95319504  1.1512818   1.        ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 210 is [False, True, 1, True, False]
Human Feedback received at timestep 210 of -1
Current timestep = 211. State = [[-0.1800258  -0.10059812  0.22564206  1.        ]]. Action = [[ 0.5359397  -0.59226936  1.4125628   1.        ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 211 is [False, True, 1, True, False]
Human Feedback received at timestep 211 of -1
Current timestep = 212. State = [[-0.16171323 -0.1165833   0.27802816  1.        ]]. Action = [[0.30131352 0.02374184 0.9455373  1.        ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 212 is [False, True, 1, True, False]
Human Feedback received at timestep 212 of 0
Current timestep = 213. State = [[-0.14739902 -0.12985846  0.30513605  1.        ]]. Action = [[ 0.4352255  -0.85132396 -0.09465659  1.        ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 213 is [False, True, 1, True, False]
Human Feedback received at timestep 213 of -1
Current timestep = 214. State = [[-0.13461071 -0.15990292  0.3297053   1.        ]]. Action = [[ 0.42391753 -0.9114203   1.341939    1.        ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 214 is [False, True, 1, True, False]
Human Feedback received at timestep 214 of -1
Current timestep = 215. State = [[-0.12051507 -0.17752516  0.35201117  1.        ]]. Action = [[ 0.8255044   0.13751459 -1.0693208   1.        ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 215 is [False, True, 1, True, False]
Human Feedback received at timestep 215 of 1
Current timestep = 216. State = [[-0.08983202 -0.1791486   0.3247703   1.        ]]. Action = [[ 0.10759032  0.09778214 -0.255522    1.        ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 216 is [False, True, 1, True, False]
Human Feedback received at timestep 216 of 1
Current timestep = 217. State = [[-0.08851999 -0.18933357  0.31320313  1.        ]]. Action = [[-0.02451903 -0.8522752  -0.44334972  1.        ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 217 is [False, True, 1, True, False]
Human Feedback received at timestep 217 of -1
Current timestep = 218. State = [[-0.08125001 -0.215925    0.3022416   1.        ]]. Action = [[ 0.6407547  -0.75627637 -0.05953121  1.        ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 218 is [False, True, 1, True, False]
Human Feedback received at timestep 218 of -1
Current timestep = 219. State = [[-0.06689994 -0.24468036  0.29947734  1.        ]]. Action = [[-0.11537081 -0.63697505  0.1438458   1.        ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 219 is [False, True, 1, True, False]
Human Feedback received at timestep 219 of -1
Current timestep = 220. State = [[-0.06484528 -0.2677929   0.2956154   1.        ]]. Action = [[ 0.6312444  -0.612649   -0.49964702  1.        ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 220 is [False, True, 1, True, False]
Human Feedback received at timestep 220 of -1
Current timestep = 221. State = [[-0.03654818 -0.28844658  0.29072848  1.        ]]. Action = [[ 0.68489075 -0.32147205  0.44729996  1.        ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 221 is [False, True, 1, True, False]
Human Feedback received at timestep 221 of -1
Current timestep = 222. State = [[-0.01130489 -0.29603362  0.31337014  1.        ]]. Action = [[ 0.6610954  -0.02543557  1.1724262   1.        ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 222 is [False, True, 1, True, False]
Human Feedback received at timestep 222 of -1
Current timestep = 223. State = [[ 0.00680513 -0.29944557  0.3419913   1.        ]]. Action = [[ 0.02468765 -0.18317819 -0.70705104  1.        ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 223 is [False, True, 1, True, False]
Human Feedback received at timestep 223 of -1
Current timestep = 224. State = [[ 0.01817397 -0.29310402  0.32071522  1.        ]]. Action = [[0.7648587  0.7992308  0.02937818 1.        ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 224 is [False, True, 1, True, False]
Human Feedback received at timestep 224 of 1
Current timestep = 225. State = [[ 0.04110885 -0.28591388  0.31618744  1.        ]]. Action = [[ 0.34070945 -0.31262726 -0.1297772   1.        ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 225 is [False, True, 1, True, False]
Human Feedback received at timestep 225 of -1
Current timestep = 226. State = [[ 0.05129253 -0.28996527  0.30896673  1.        ]]. Action = [[-0.6438225   0.10034215 -0.39048934  1.        ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 226 is [False, True, 1, True, False]
Human Feedback received at timestep 226 of -1
Current timestep = 227. State = [[ 0.04902852 -0.29102573  0.30698553  1.        ]]. Action = [[-0.47690862 -0.82495385 -0.02481222  1.        ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 227 is [False, True, 1, True, False]
Human Feedback received at timestep 227 of 0
Current timestep = 228. State = [[ 0.04898619 -0.291024    0.3069329   1.        ]]. Action = [[ 0.7468543  -0.5556352   0.60588837  1.        ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 228 is [False, True, 1, True, False]
Human Feedback received at timestep 228 of 0
Current timestep = 229. State = [[ 0.04402774 -0.28446147  0.31148624  1.        ]]. Action = [[-0.8929334   0.6527915   0.40321636  1.        ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 229 is [False, True, 1, True, False]
Human Feedback received at timestep 229 of 1
Current timestep = 230. State = [[ 0.02184523 -0.26679718  0.31766078  1.        ]]. Action = [[-0.37921804  0.35395455  0.00776601  1.        ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 230 is [False, True, 1, True, False]
Human Feedback received at timestep 230 of 1
Current timestep = 231. State = [[ 0.01642785 -0.24909073  0.32283068  1.        ]]. Action = [[0.7926054  0.48241103 0.37949872 1.        ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 231 is [False, True, 1, True, False]
Human Feedback received at timestep 231 of 1
Current timestep = 232. State = [[ 0.03196907 -0.22214405  0.3270588   1.        ]]. Action = [[ 0.92400527  0.8226981  -0.08189499  1.        ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 232 is [False, True, 1, True, False]
Human Feedback received at timestep 232 of 1
Current timestep = 233. State = [[ 0.05215318 -0.1886487   0.32893717  1.        ]]. Action = [[0.38054037 0.737862   0.14768839 1.        ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 233 is [False, True, 1, True, False]
Human Feedback received at timestep 233 of 1
Current timestep = 234. State = [[ 0.06714001 -0.16212973  0.33351794  1.        ]]. Action = [[0.5969627  0.6217296  0.20817661 1.        ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 234 is [False, True, 1, True, False]
Human Feedback received at timestep 234 of 1
Current timestep = 235. State = [[ 0.08462358 -0.13982907  0.33305678  1.        ]]. Action = [[-0.34235126  0.45157933 -0.5494106   1.        ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 235 is [False, True, 1, True, False]
Human Feedback received at timestep 235 of 1
Current timestep = 236. State = [[ 0.08323859 -0.11787017  0.31514794  1.        ]]. Action = [[ 0.02630115  0.8276248  -0.9833101   1.        ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 236 is [False, True, 1, True, False]
Human Feedback received at timestep 236 of 1
Current timestep = 237. State = [[ 0.07925866 -0.10261388  0.27887926  1.        ]]. Action = [[-0.68157357 -0.3255012  -0.7281039   1.        ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 237 is [False, True, 1, True, False]
Human Feedback received at timestep 237 of -1
Current timestep = 238. State = [[ 0.07246343 -0.0987875   0.27882734  1.        ]]. Action = [[-0.67931974  0.7612902   1.58043     1.        ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 238 is [False, True, 1, True, False]
Human Feedback received at timestep 238 of 1
Current timestep = 239. State = [[ 0.05295574 -0.06690388  0.32275835  1.        ]]. Action = [[0.41158724 0.6360264  0.721576   1.        ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 239 is [False, True, 1, True, False]
Human Feedback received at timestep 239 of 1
Current timestep = 240. State = [[ 0.04825522 -0.04248573  0.34241885  1.        ]]. Action = [[-0.2700708   0.68364525  0.4413061   1.        ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 240 is [False, True, 1, True, False]
Human Feedback received at timestep 240 of 1
Current timestep = 241. State = [[ 0.04504432 -0.01514977  0.36338776  1.        ]]. Action = [[0.47876155 0.7301202  0.71639013 1.        ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 241 is [False, True, 1, True, False]
Human Feedback received at timestep 241 of 1
Current timestep = 242. State = [[0.05375659 0.00721989 0.3888875  1.        ]]. Action = [[0.49885106 0.31776595 0.2847619  1.        ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 242 is [False, True, 1, False, True]
Human Feedback received at timestep 242 of 1
Current timestep = 243. State = [[0.06210268 0.02964205 0.3959427  1.        ]]. Action = [[-0.12991846  0.92549706 -0.23252463  1.        ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 243 is [False, True, 1, False, True]
Human Feedback received at timestep 243 of 1
Current timestep = 244. State = [[0.06071759 0.05208376 0.3827531  1.        ]]. Action = [[ 0.23205411  0.10597718 -0.8211801   1.        ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 244 is [False, True, 1, False, True]
Human Feedback received at timestep 244 of -1
Current timestep = 245. State = [[0.06600937 0.06767792 0.35000992 1.        ]]. Action = [[-0.283085    0.6148207  -0.49064577  1.        ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 245 is [False, True, 1, False, True]
Human Feedback received at timestep 245 of -1
Current timestep = 246. State = [[0.06245957 0.08004882 0.3438558  1.        ]]. Action = [[ 0.9160329   0.83851945 -0.15004349  1.        ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 246 is [False, True, 1, False, True]
Human Feedback received at timestep 246 of 0
Current timestep = 247. State = [[0.06024666 0.08686036 0.3439928  1.        ]]. Action = [[-0.38435376  0.3323865   0.01414537  1.        ]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 247 is [False, True, 1, False, True]
Human Feedback received at timestep 247 of -1
Current timestep = 248. State = [[0.05352663 0.10653626 0.3526391  1.        ]]. Action = [[-0.5558819  0.736449   0.6035509  1.       ]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 248 is [False, True, 1, False, True]
Human Feedback received at timestep 248 of -1
Current timestep = 249. State = [[0.03686211 0.1422632  0.36287433 1.        ]]. Action = [[-0.636476    0.8841965  -0.12341285  1.        ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 249 is [False, True, 1, False, True]
Human Feedback received at timestep 249 of -1
Current timestep = 250. State = [[0.02168124 0.16612644 0.3631662  1.        ]]. Action = [[ 0.17877758 -0.06180161 -0.01653039  1.        ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 250 is [False, True, 1, False, True]
Human Feedback received at timestep 250 of 0
Current timestep = 251. State = [[0.01842385 0.17578949 0.35181752 1.        ]]. Action = [[ 0.11955106  0.7469399  -0.9998181   1.        ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 251 is [False, True, 1, False, True]
Human Feedback received at timestep 251 of -1
Current timestep = 252. State = [[0.01371128 0.20245148 0.31959727 1.        ]]. Action = [[-0.60215497  0.8023819  -0.607857    1.        ]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 252 is [False, True, 1, False, True]
Human Feedback received at timestep 252 of -1
Current timestep = 253. State = [[0.00521137 0.22957298 0.30132377 1.        ]]. Action = [[ 0.84999704  0.47237623 -0.5457872   1.        ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 253 is [False, True, 1, False, True]
Human Feedback received at timestep 253 of -1
Current timestep = 254. State = [[0.01682954 0.24711728 0.28254345 1.        ]]. Action = [[-0.198547    0.37937903  0.77037144  1.        ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 254 is [False, True, 1, False, True]
Human Feedback received at timestep 254 of -1
Current timestep = 255. State = [[0.01268253 0.26146308 0.2880198  1.        ]]. Action = [[-0.17728311  0.50836945 -0.46375406  1.        ]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 255 is [False, True, 1, False, True]
Human Feedback received at timestep 255 of -1
Current timestep = 256. State = [[0.00671846 0.27118823 0.28467175 1.        ]]. Action = [[0.35532844 0.5012523  0.39516902 1.        ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 256 is [False, True, 1, False, True]
Human Feedback received at timestep 256 of 0
Current timestep = 257. State = [[0.01362852 0.26673573 0.28894097 1.        ]]. Action = [[ 0.881307   -0.30174017  0.40326595  1.        ]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 257 is [False, True, 1, False, True]
Human Feedback received at timestep 257 of 0
Current timestep = 258. State = [[0.03150977 0.25445622 0.29962027 1.        ]]. Action = [[ 0.15568829 -0.49391645  0.4801631   1.        ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 258 is [False, True, 1, False, True]
Human Feedback received at timestep 258 of 1
Current timestep = 259. State = [[-0.25975332 -0.05388126  0.10492741  1.        ]]. Action = [[-0.07659215  0.21735823  0.36138773  1.        ]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 260. State = [[-0.2507515  -0.0567739   0.10009682  1.        ]]. Action = [[0.7359407 0.5109371 1.2812974 1.       ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 260 is [False, True, 1, True, False]
Human Feedback received at timestep 260 of 0
Current timestep = 261. State = [[-0.22429821 -0.04466391  0.1333066   1.        ]]. Action = [[0.7384174  0.41140723 0.7858865  1.        ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 261 is [False, True, 1, True, False]
Human Feedback received at timestep 261 of 1
Current timestep = 262. State = [[-0.19949263 -0.02919869  0.16459517  1.        ]]. Action = [[0.34502733 0.35171235 0.8415911  1.        ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 262 is [False, True, 1, True, False]
Human Feedback received at timestep 262 of 1
Current timestep = 263. State = [[-0.18684286 -0.02043696  0.18698235  1.        ]]. Action = [[0.56115174 0.6419573  0.59261656 1.        ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 263 is [False, True, 1, True, False]
Human Feedback received at timestep 263 of 0
Current timestep = 264. State = [[-0.17516728 -0.01152711  0.20514122  1.        ]]. Action = [[0.766165  0.5401628 1.5311322 1.       ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 264 is [False, True, 1, True, False]
Human Feedback received at timestep 264 of 1
Current timestep = 265. State = [[-0.14646943  0.00504928  0.24876797  1.        ]]. Action = [[ 0.6441679  0.2741636 -0.1563462  1.       ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 265 is [False, True, 1, False, True]
Human Feedback received at timestep 265 of 1
Current timestep = 266. State = [[-0.12437302  0.01229525  0.2601562   1.        ]]. Action = [[0.6903045  0.14133501 0.4795053  1.        ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 266 is [False, True, 1, False, True]
Human Feedback received at timestep 266 of 1
Current timestep = 267. State = [[-0.09801062  0.01498523  0.28891397  1.        ]]. Action = [[ 0.5799506 -0.1853646  1.1599708  1.       ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 267 is [False, True, 1, False, True]
Human Feedback received at timestep 267 of 0
Current timestep = 268. State = [[-0.07801586  0.01175291  0.30870727  1.        ]]. Action = [[ 0.42699528 -0.18116754 -0.5461819   1.        ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 268 is [False, True, 1, False, True]
Human Feedback received at timestep 268 of 1
Current timestep = 269. State = [[-0.05856203  0.01000892  0.30608207  1.        ]]. Action = [[0.6617558  0.11086142 0.37400913 1.        ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 269 is [False, True, 1, False, True]
Human Feedback received at timestep 269 of 0
Current timestep = 270. State = [[-0.0336482   0.00948197  0.32465506  1.        ]]. Action = [[ 0.78989816 -0.1283086   0.7220218   1.        ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 270 is [False, True, 1, False, True]
Human Feedback received at timestep 270 of 0
Current timestep = 271. State = [[-0.00143651  0.00927098  0.35114253  1.        ]]. Action = [[0.79090333 0.05387914 0.5602405  1.        ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 271 is [False, True, 1, False, True]
Human Feedback received at timestep 271 of 0
Current timestep = 272. State = [[0.0285795  0.01364135 0.37538087 1.        ]]. Action = [[0.73107433 0.29997408 0.67571044 1.        ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 272 is [False, True, 1, False, True]
Human Feedback received at timestep 272 of -1
Current timestep = 273. State = [[0.04883188 0.01871031 0.38041756 1.        ]]. Action = [[ 0.7488067   0.00849569 -1.6079185   1.        ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 273 is [False, True, 1, False, True]
Human Feedback received at timestep 273 of 0
Current timestep = 274. State = [[0.08652503 0.02037225 0.32931003 1.        ]]. Action = [[ 0.870378    0.12208092 -0.15834272  1.        ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 274 is [False, True, 1, False, True]
Human Feedback received at timestep 274 of 0
Current timestep = 275. State = [[0.08213075 0.01979092 0.3193425  1.        ]]. Action = [[-0.7283912  -0.04901278 -1.1623857   1.        ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 275 is [False, True, 1, False, True]
Human Feedback received at timestep 275 of 1
Current timestep = 276. State = [[0.07523252 0.02097273 0.28873935 1.        ]]. Action = [[-7.2930622e-01  9.9670887e-04 -4.5962286e-01  1.0000000e+00]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 276 is [False, True, 1, False, True]
Human Feedback received at timestep 276 of 1
Current timestep = 277. State = [[0.06522475 0.02143463 0.27396047 1.        ]]. Action = [[ 0.5624043  -0.11215538  0.18461585  1.        ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 277 is [False, True, 1, False, True]
Human Feedback received at timestep 277 of 1
Current timestep = 278. State = [[0.0662627  0.01782167 0.27614203 1.        ]]. Action = [[ 0.9534421 -0.0928095  1.3631449  1.       ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 278 is [False, True, 1, False, True]
Human Feedback received at timestep 278 of 0
Current timestep = 279. State = [[0.06625322 0.01702407 0.27628642 1.        ]]. Action = [[0.9416256  0.02549505 1.1192863  1.        ]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 279 is [False, True, 1, False, True]
Human Feedback received at timestep 279 of 0
Current timestep = 280. State = [[0.0677428  0.01916919 0.27712584 1.        ]]. Action = [[0.49388683 0.19429052 0.03202105 1.        ]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 280 is [False, True, 1, False, True]
Human Feedback received at timestep 280 of -1
Current timestep = 281. State = [[0.07616133 0.02121813 0.29081818 1.        ]]. Action = [[ 0.38077104 -0.03054476  1.0554566   1.        ]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 281 is [False, True, 1, False, True]
Human Feedback received at timestep 281 of 0
Current timestep = 282. State = [[0.08640382 0.02203964 0.31167337 1.        ]]. Action = [[ 0.614939   -0.14034069 -0.46372283  1.        ]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 282 is [False, True, 1, False, True]
Human Feedback received at timestep 282 of 0
Current timestep = 283. State = [[0.08640382 0.02203964 0.31167337 1.        ]]. Action = [[ 0.9517572  -0.06835067 -0.45728552  1.        ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 283 is [False, True, 1, False, True]
Human Feedback received at timestep 283 of 0
Current timestep = 284. State = [[0.08640382 0.02203964 0.31167337 1.        ]]. Action = [[0.58589077 0.06303787 0.12579513 1.        ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 284 is [False, True, 1, False, True]
Human Feedback received at timestep 284 of 0
Current timestep = 285. State = [[0.08640382 0.02203964 0.31167337 1.        ]]. Action = [[ 0.49997175  0.01340914 -0.18935299  1.        ]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 285 is [False, True, 1, False, True]
Human Feedback received at timestep 285 of 0
Current timestep = 286. State = [[0.08640382 0.02203964 0.31167337 1.        ]]. Action = [[ 0.98723674  0.08108306 -0.05683517  1.        ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 286 is [False, True, 1, False, True]
Human Feedback received at timestep 286 of 0
Current timestep = 287. State = [[0.08223497 0.02430177 0.30537102 1.        ]]. Action = [[-0.8918007   0.10078704 -0.8221681   1.        ]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 287 is [False, True, 1, False, True]
Human Feedback received at timestep 287 of -1
Current timestep = 288. State = [[0.07550241 0.02658376 0.29625958 1.        ]]. Action = [[ 0.99344444 -0.12742382  0.8908284   1.        ]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 288 is [False, True, 1, False, True]
Human Feedback received at timestep 288 of 0
Current timestep = 289. State = [[0.07346053 0.02490058 0.30830204 1.        ]]. Action = [[-0.70032436 -0.13856792  0.8777971   1.        ]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 289 is [False, True, 1, False, True]
Human Feedback received at timestep 289 of 1
Current timestep = 290. State = [[0.05742048 0.0220819  0.3119344  1.        ]]. Action = [[ 0.73620427 -0.11565578 -0.9964539   1.        ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 290 is [False, True, 1, False, True]
Human Feedback received at timestep 290 of 1
Current timestep = 291. State = [[0.06426992 0.01735391 0.28652802 1.        ]]. Action = [[ 0.575439   -0.15921712  0.00159073  1.        ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 291 is [False, True, 1, False, True]
Human Feedback received at timestep 291 of 1
Current timestep = 292. State = [[0.07299785 0.01343404 0.28312227 1.        ]]. Action = [[ 0.6933851  -0.14923668 -0.47276926  1.        ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 292 is [False, True, 1, False, True]
Human Feedback received at timestep 292 of 0
Current timestep = 293. State = [[0.07299785 0.01343404 0.28312227 1.        ]]. Action = [[ 0.777653   -0.07462299 -0.576118    1.        ]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 293 is [False, True, 1, False, True]
Human Feedback received at timestep 293 of 0
Current timestep = 294. State = [[0.072804   0.01153359 0.29602462 1.        ]]. Action = [[-0.87500745 -0.05857652  0.8836558   1.        ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 294 is [False, True, 1, False, True]
Human Feedback received at timestep 294 of 1
Current timestep = 295. State = [[0.07087116 0.00767473 0.321823   1.        ]]. Action = [[ 0.58011603 -0.14432871  0.7272191   1.        ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 295 is [False, True, 1, False, True]
Human Feedback received at timestep 295 of 1
Current timestep = 296. State = [[0.07146435 0.00353604 0.33507672 1.        ]]. Action = [[ 0.90408695 -0.16556752 -0.3920027   1.        ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 296 is [False, True, 1, False, True]
Human Feedback received at timestep 296 of 0
Current timestep = 297. State = [[0.07135408 0.0035464  0.33507177 1.        ]]. Action = [[0.8866489  0.03891742 0.28782988 1.        ]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 297 is [False, True, 1, False, True]
Human Feedback received at timestep 297 of 0
Current timestep = 298. State = [[0.07129589 0.0018086  0.3336404  1.        ]]. Action = [[-0.2094413  -0.20033467 -0.49630213  1.        ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 298 is [False, True, 1, False, True]
Human Feedback received at timestep 298 of 0
Current timestep = 299. State = [[7.0531972e-02 6.3318228e-05 3.3165124e-01 1.0000000e+00]]. Action = [[ 0.6162677  -0.01526004 -0.9697497   1.        ]]. Reward = [0.]
Curr episode timestep = 39
Current timestep = 300. State = [[-0.2673873   0.07115051  0.11627629  1.        ]]. Action = [[-0.19245768 -0.12868714  0.49549675 -0.95672095]]. Reward = [100.]
Curr episode timestep = 40
Current timestep = 301. State = [[-0.25683504  0.0749806   0.11365164  1.        ]]. Action = [[ 0.62446475 -0.37999916  1.3288767   0.91730297]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 301 is [False, True, 3, False]
Human Feedback received at timestep 301 of 1
Current timestep = 302. State = [[-0.26538533  0.1456822   0.12320468  1.        ]]. Action = [[ 0.8734106  -0.11927158  0.49786782 -0.6134604 ]]. Reward = [-10.]
Curr episode timestep = 1
Current timestep = 303. State = [[-0.2553691   0.1555452   0.11451142  1.        ]]. Action = [[ 0.46962488 -0.4497472   0.65265656  0.11435628]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 303 is [False, True, 3, False]
Human Feedback received at timestep 303 of 1
Current timestep = 304. State = [[-0.25374058 -0.11656059  0.11900283  1.        ]]. Action = [[ 0.8559735  -0.42229658  0.72439575 -0.47791255]]. Reward = [-10.]
Curr episode timestep = 1
Current timestep = 305. State = [[-0.24760973 -0.07427809  0.12472438  1.        ]]. Action = [[ 0.7897599   0.32516873  1.6911342  -0.90508354]]. Reward = [-10.]
Curr episode timestep = 0
Current timestep = 306. State = [[-0.24798255 -0.12500034  0.12193608  1.        ]]. Action = [[ 0.57781696  0.27995586  1.2833657  -0.16054428]]. Reward = [-10.]
Curr episode timestep = 0
Current timestep = 307. State = [[-0.2377564 -0.1327001  0.1158905  1.       ]]. Action = [[0.8758955 0.5383724 1.048516  0.0686084]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 307 is [False, True, 3, False]
Human Feedback received at timestep 307 of 1
Current timestep = 308. State = [[-0.211365   -0.12329346  0.14319003  1.        ]]. Action = [[0.515955   0.22821069 0.7715702  0.00871885]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 308 is [False, True, 3, False]
Human Feedback received at timestep 308 of 1
Current timestep = 309. State = [[-0.19509009 -0.11845679  0.16271736  1.        ]]. Action = [[0.62502813 0.58080745 0.88040495 0.05941093]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 309 is [False, True, 3, False]
Human Feedback received at timestep 309 of 0
Current timestep = 310. State = [[-0.19506265 -0.11827715  0.16277158  1.        ]]. Action = [[ 0.5869715   0.12831426 -0.23736     0.32178032]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 310 is [False, True, 3, False]
Human Feedback received at timestep 310 of 0
Current timestep = 311. State = [[-0.19506265 -0.11827715  0.16277158  1.        ]]. Action = [[ 0.6649363   0.3117354  -0.05406749  0.87999535]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 311 is [False, True, 3, False]
Human Feedback received at timestep 311 of 0
Current timestep = 312. State = [[-0.19506265 -0.11827715  0.16277158  1.        ]]. Action = [[ 0.7913723   0.31741607 -0.05221617 -0.1403392 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 312 is [False, True, 3, False]
Human Feedback received at timestep 312 of 0
Current timestep = 313. State = [[-0.19506265 -0.11827715  0.16277158  1.        ]]. Action = [[ 0.5684042   0.13519311 -0.07704651  0.09818852]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 313 is [False, True, 3, False]
Human Feedback received at timestep 313 of 0
Current timestep = 314. State = [[-0.19506265 -0.11827715  0.16277158  1.        ]]. Action = [[0.7700093  0.26859438 1.1790142  0.93604314]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 314 is [False, True, 3, False]
Human Feedback received at timestep 314 of 0
Current timestep = 315. State = [[-0.19506265 -0.11827715  0.16277158  1.        ]]. Action = [[ 0.82037437  0.14505792  1.0535908  -0.0616585 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 315 is [False, True, 3, False]
Human Feedback received at timestep 315 of 0
Current timestep = 316. State = [[-0.19207855 -0.11163068  0.1737835   1.        ]]. Action = [[0.17159021 0.38459456 0.85975266 0.88720226]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 316 is [False, True, 3, False]
Human Feedback received at timestep 316 of 1
Current timestep = 317. State = [[-0.1880492  -0.10355697  0.19651721  1.        ]]. Action = [[0.8495064 0.3553325 0.7996247 0.9272311]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 317 is [False, True, 3, False]
Human Feedback received at timestep 317 of 0
Current timestep = 318. State = [[-0.18716463 -0.10352115  0.19705722  1.        ]]. Action = [[0.7227609  0.06287408 0.3046577  0.7380487 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 318 is [False, True, 3, False]
Human Feedback received at timestep 318 of 0
Current timestep = 319. State = [[-0.1871476  -0.10346074  0.19705106  1.        ]]. Action = [[0.85211897 0.19756103 0.63926744 0.7200525 ]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 319 is [False, True, 3, False]
Human Feedback received at timestep 319 of 0
Current timestep = 320. State = [[-0.17527138 -0.09804471  0.20903318  1.        ]]. Action = [[0.8058188  0.30550563 0.86960435 0.73433876]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 320 is [False, True, 3, False]
Human Feedback received at timestep 320 of 1
Current timestep = 321. State = [[-0.14108641 -0.08730159  0.25025734  1.        ]]. Action = [[0.57342196 0.18317997 1.3695211  0.7275467 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 321 is [False, True, 3, False]
Human Feedback received at timestep 321 of 1
Current timestep = 322. State = [[-0.11689748 -0.08357857  0.29026663  1.        ]]. Action = [[ 0.64811826  0.0335983  -0.04277062  0.97965765]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 322 is [False, True, 3, False]
Human Feedback received at timestep 322 of 1
Current timestep = 323. State = [[-0.09577459 -0.08038288  0.30736986  1.        ]]. Action = [[0.5081036  0.14594555 0.9926088  0.9940438 ]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 323 is [False, True, 3, True]
Human Feedback received at timestep 323 of 1
Current timestep = 324. State = [[-0.07052639 -0.07314945  0.3447615   1.        ]]. Action = [[0.7197225  0.17731595 0.9733901  0.8815516 ]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 324 is [False, True, 3, True]
Human Feedback received at timestep 324 of -1
Current timestep = 325. State = [[-0.05288456 -0.06712589  0.36376256  1.        ]]. Action = [[ 0.46446514  0.14158249 -0.9531081   0.3703984 ]]. Reward = [0.]
Curr episode timestep = 18
Scene graph at timestep 325 is [False, True, 3, True]
Human Feedback received at timestep 325 of -1
Current timestep = 326. State = [[-0.03443468 -0.05941009  0.3381826   1.        ]]. Action = [[ 0.61727905  0.23867178 -0.48496866  0.96442175]]. Reward = [0.]
Curr episode timestep = 19
Scene graph at timestep 326 is [False, True, 3, True]
Human Feedback received at timestep 326 of -1
Current timestep = 327. State = [[-0.01393008 -0.05377786  0.31935158  1.        ]]. Action = [[ 0.4164977  -0.03189361 -0.9987215   0.48421407]]. Reward = [0.]
Curr episode timestep = 20
Scene graph at timestep 327 is [False, True, 3, True]
Human Feedback received at timestep 327 of -1
Current timestep = 328. State = [[ 0.00538642 -0.05302633  0.27980503  1.        ]]. Action = [[ 0.50555944  0.06081891 -0.9096432   0.92189825]]. Reward = [0.]
Curr episode timestep = 21
Scene graph at timestep 328 is [False, True, 3, True]
Human Feedback received at timestep 328 of -1
Current timestep = 329. State = [[ 0.02939492 -0.05215704  0.25454724  1.        ]]. Action = [[0.46641326 0.15987813 0.51397586 0.94463086]]. Reward = [0.]
Curr episode timestep = 22
Scene graph at timestep 329 is [False, True, 3, True]
Human Feedback received at timestep 329 of -1
Current timestep = 330. State = [[ 0.04985541 -0.04997887  0.27865845  1.        ]]. Action = [[ 0.8123032  -0.14685786  1.1569524   0.5494211 ]]. Reward = [0.]
Curr episode timestep = 23
Scene graph at timestep 330 is [False, True, 3, True]
Human Feedback received at timestep 330 of -1
Current timestep = 331. State = [[ 0.07089958 -0.05231511  0.31190315  1.        ]]. Action = [[-0.46691513 -0.04208875  0.3658178   0.8597982 ]]. Reward = [0.]
Curr episode timestep = 24
Scene graph at timestep 331 is [False, True, 3, True]
Human Feedback received at timestep 331 of -1
Current timestep = 332. State = [[ 0.07348099 -0.05357246  0.31959322  1.        ]]. Action = [[ 0.38446522 -0.05284876 -0.05516469  0.42968416]]. Reward = [0.]
Curr episode timestep = 25
Scene graph at timestep 332 is [False, True, 3, True]
Human Feedback received at timestep 332 of 0
Current timestep = 333. State = [[ 0.07567773 -0.05573591  0.3244329   1.        ]]. Action = [[ 0.06680763 -0.17698222  0.45151758  0.8580699 ]]. Reward = [0.]
Curr episode timestep = 26
Scene graph at timestep 333 is [False, True, 3, True]
Human Feedback received at timestep 333 of -1
Current timestep = 334. State = [[ 0.08198193 -0.05986575  0.34690237  1.        ]]. Action = [[0.1420567  0.1424663  0.6913655  0.89745224]]. Reward = [0.]
Curr episode timestep = 27
Scene graph at timestep 334 is [False, True, 3, True]
Human Feedback received at timestep 334 of -1
Current timestep = 335. State = [[ 0.08687389 -0.05842218  0.36683783  1.        ]]. Action = [[0.5715432  0.07614684 0.734622   0.64251935]]. Reward = [0.]
Curr episode timestep = 28
Scene graph at timestep 335 is [False, True, 3, True]
Human Feedback received at timestep 335 of 0
Current timestep = 336. State = [[ 0.0858364  -0.05676183  0.3589262   1.        ]]. Action = [[ 0.08925581  0.11583233 -0.9540303   0.73775756]]. Reward = [0.]
Curr episode timestep = 29
Scene graph at timestep 336 is [False, True, 3, True]
Human Feedback received at timestep 336 of 0
Current timestep = 337. State = [[ 0.0887593  -0.05424022  0.3303496   1.        ]]. Action = [[-0.1527965   0.02194178 -0.4027983   0.9643713 ]]. Reward = [0.]
Curr episode timestep = 30
Scene graph at timestep 337 is [False, True, 3, True]
Human Feedback received at timestep 337 of 0
Current timestep = 338. State = [[ 0.08944052 -0.05313247  0.3227787   1.        ]]. Action = [[0.711679   0.05046368 0.3471043  0.9855716 ]]. Reward = [0.]
Curr episode timestep = 31
Scene graph at timestep 338 is [False, True, 3, True]
Human Feedback received at timestep 338 of 0
Current timestep = 339. State = [[ 0.08943861 -0.05313246  0.32263422  1.        ]]. Action = [[ 0.6236888   0.04551578 -0.51674426  0.5750592 ]]. Reward = [0.]
Curr episode timestep = 32
Scene graph at timestep 339 is [False, True, 3, True]
Human Feedback received at timestep 339 of 0
Current timestep = 340. State = [[ 0.08783999 -0.05123797  0.31576318  1.        ]]. Action = [[-0.41851944  0.08893013 -0.589509    0.86974645]]. Reward = [0.]
Curr episode timestep = 33
Scene graph at timestep 340 is [False, True, 3, True]
Human Feedback received at timestep 340 of -1
Current timestep = 341. State = [[ 0.08763748 -0.04519416  0.30847716  1.        ]]. Action = [[-0.0866276   0.15958488  0.12138534  0.8768114 ]]. Reward = [0.]
Curr episode timestep = 34
Scene graph at timestep 341 is [False, True, 3, True]
Human Feedback received at timestep 341 of 0
Current timestep = 342. State = [[ 0.08306014 -0.04157247  0.31648257  1.        ]]. Action = [[-0.8650659  -0.00162393  0.47929502  0.5711212 ]]. Reward = [0.]
Curr episode timestep = 35
Scene graph at timestep 342 is [False, True, 3, True]
Human Feedback received at timestep 342 of -1
Current timestep = 343. State = [[ 0.05577509 -0.03747256  0.31795695  1.        ]]. Action = [[-0.65101063 -0.02216953 -0.80058837  0.630466  ]]. Reward = [0.]
Curr episode timestep = 36
Scene graph at timestep 343 is [False, True, 3, True]
Human Feedback received at timestep 343 of -1
Current timestep = 344. State = [[ 0.04349475 -0.03926495  0.28774655  1.        ]]. Action = [[ 0.9186677  -0.0990817  -0.12296963  0.60877633]]. Reward = [0.]
Curr episode timestep = 37
Scene graph at timestep 344 is [False, True, 3, True]
Human Feedback received at timestep 344 of -1
Current timestep = 345. State = [[ 0.05204779 -0.04533944  0.2876292   1.        ]]. Action = [[ 0.7661972  -0.31294274  0.10239172  0.8321302 ]]. Reward = [0.]
Curr episode timestep = 38
Scene graph at timestep 345 is [False, True, 3, True]
Human Feedback received at timestep 345 of -1
Current timestep = 346. State = [[ 0.0658259  -0.05327452  0.29087403  1.        ]]. Action = [[ 0.08527851 -0.14017797  0.31933427  0.10682142]]. Reward = [0.]
Curr episode timestep = 39
Scene graph at timestep 346 is [False, True, 3, True]
Human Feedback received at timestep 346 of -1
Current timestep = 347. State = [[ 0.06739093 -0.05801113  0.29474398  1.        ]]. Action = [[ 7.8647435e-01  2.0611286e-04 -2.4132121e-01  7.8747964e-01]]. Reward = [0.]
Curr episode timestep = 40
Scene graph at timestep 347 is [False, True, 3, True]
Human Feedback received at timestep 347 of -1
Current timestep = 348. State = [[ 0.06738811 -0.05856408  0.29495808  1.        ]]. Action = [[0.9013071  0.11572051 0.5344188  0.8716929 ]]. Reward = [0.]
Curr episode timestep = 41
Scene graph at timestep 348 is [False, True, 3, True]
Human Feedback received at timestep 348 of 0
Current timestep = 349. State = [[ 0.06738811 -0.05856408  0.29495808  1.        ]]. Action = [[0.91347814 0.1289053  0.01152134 0.6011956 ]]. Reward = [0.]
Curr episode timestep = 42
Scene graph at timestep 349 is [False, True, 3, True]
Human Feedback received at timestep 349 of 0
Current timestep = 350. State = [[ 0.0664271  -0.05512763  0.30395338  1.        ]]. Action = [[-0.70600545  0.2864324   0.52619267  0.8813131 ]]. Reward = [0.]
Curr episode timestep = 43
Scene graph at timestep 350 is [False, True, 3, True]
Human Feedback received at timestep 350 of -1
Current timestep = 351. State = [[ 0.06403332 -0.05017684  0.32080933  1.        ]]. Action = [[0.38109303 0.08987272 0.7224841  0.82301664]]. Reward = [0.]
Curr episode timestep = 44
Scene graph at timestep 351 is [False, True, 3, True]
Human Feedback received at timestep 351 of -1
Current timestep = 352. State = [[ 0.06725018 -0.0481461   0.3323374   1.        ]]. Action = [[ 0.5349746  -0.11537266 -0.4441887   0.6672518 ]]. Reward = [0.]
Curr episode timestep = 45
Scene graph at timestep 352 is [False, True, 3, True]
Human Feedback received at timestep 352 of -1
Current timestep = 353. State = [[ 0.07204986 -0.05082401  0.33710894  1.        ]]. Action = [[-0.97193515 -0.10404402  0.4744711   0.9340501 ]]. Reward = [0.]
Curr episode timestep = 46
Scene graph at timestep 353 is [False, True, 3, True]
Human Feedback received at timestep 353 of -1
Current timestep = 354. State = [[ 0.06765659 -0.05506706  0.36478928  1.        ]]. Action = [[ 0.38904798 -0.05318552  1.1640205   0.50253975]]. Reward = [0.]
Curr episode timestep = 47
Scene graph at timestep 354 is [False, True, 3, True]
Human Feedback received at timestep 354 of -1
Current timestep = 355. State = [[ 0.0655864  -0.05721396  0.38580528  1.        ]]. Action = [[-0.77373195  0.18768907  0.96965885  0.8422301 ]]. Reward = [0.]
Curr episode timestep = 48
Scene graph at timestep 355 is [False, True, 3, True]
Human Feedback received at timestep 355 of 0
Current timestep = 356. State = [[ 0.06618138 -0.05733465  0.37883964  1.        ]]. Action = [[ 0.42786694 -0.05525649 -0.74765396  0.87405765]]. Reward = [0.]
Curr episode timestep = 49
Scene graph at timestep 356 is [False, True, 3, True]
Human Feedback received at timestep 356 of -1
Current timestep = 357. State = [[ 0.06924614 -0.056432    0.35293305  1.        ]]. Action = [[ 0.50697327 -0.04526454 -1.5303847   0.6046655 ]]. Reward = [0.]
Curr episode timestep = 50
Scene graph at timestep 357 is [False, True, 3, True]
Human Feedback received at timestep 357 of -1
Current timestep = 358. State = [[-0.26296055 -0.08332039  0.11272801  1.        ]]. Action = [[ 0.6707456   0.02341068 -1.3384235   0.84827805]]. Reward = [0.]
Curr episode timestep = 51
Current timestep = 359. State = [[-0.25509256 -0.09516864  0.1093857   1.        ]]. Action = [[ 0.61005795 -0.04330897  1.5863662   0.7723105 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 359 is [False, True, 3, False]
Human Feedback received at timestep 359 of 1
Current timestep = 360. State = [[-0.23380135 -0.09388775  0.15002179  1.        ]]. Action = [[0.90779054 0.29856205 0.55532    0.7778952 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 360 is [False, True, 3, False]
Human Feedback received at timestep 360 of 1
Current timestep = 361. State = [[-0.19988865 -0.08693189  0.18018754  1.        ]]. Action = [[0.7223587  0.37572145 1.2037027  0.8248403 ]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 361 is [False, True, 3, False]
Human Feedback received at timestep 361 of 1
Current timestep = 362. State = [[-0.1787282  -0.07893702  0.21214275  1.        ]]. Action = [[0.57735825 0.13470864 0.47104383 0.9437053 ]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 362 is [False, True, 3, False]
Human Feedback received at timestep 362 of 0
Current timestep = 363. State = [[-0.17847773 -0.07853432  0.21280226  1.        ]]. Action = [[0.5935036  0.27832675 0.10504532 0.9080446 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 363 is [False, True, 3, False]
Human Feedback received at timestep 363 of 0
Current timestep = 364. State = [[-0.17059296 -0.0754643   0.22345449  1.        ]]. Action = [[0.5695691  0.21232712 0.8311722  0.2177186 ]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 364 is [False, True, 3, False]
Human Feedback received at timestep 364 of 1
Current timestep = 365. State = [[-0.15340388 -0.07052539  0.24645478  1.        ]]. Action = [[ 0.7267231   0.01963592 -0.23685813  0.87089944]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 365 is [False, True, 3, False]
Human Feedback received at timestep 365 of 0
Current timestep = 366. State = [[-0.14336231 -0.06407825  0.26449445  1.        ]]. Action = [[0.46932745 0.32057667 1.2261572  0.5215051 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 366 is [False, True, 3, False]
Human Feedback received at timestep 366 of 1
Current timestep = 367. State = [[-0.12483624 -0.05512501  0.2950454   1.        ]]. Action = [[ 0.6765324   0.10954559 -0.3359518   0.9174354 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 367 is [False, True, 3, False]
Human Feedback received at timestep 367 of 1
Current timestep = 368. State = [[-0.11117208 -0.04811053  0.2844924   1.        ]]. Action = [[ 0.73680687  0.14058816 -1.0638177   0.46644104]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 368 is [False, True, 3, False]
Human Feedback received at timestep 368 of 1
Current timestep = 369. State = [[-0.08347952 -0.04577335  0.25447077  1.        ]]. Action = [[ 0.9010644   0.04107428 -0.7633796   0.78397894]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 369 is [False, True, 3, True]
Human Feedback received at timestep 369 of 0
Current timestep = 370. State = [[-0.08349745 -0.04568422  0.2541559   1.        ]]. Action = [[ 0.23209453 -0.02825642 -0.44696283  0.8887359 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 370 is [False, True, 3, True]
Human Feedback received at timestep 370 of 0
Current timestep = 371. State = [[-0.08304581 -0.04059507  0.25507012  1.        ]]. Action = [[-0.03468132  0.3519988   0.21781754  0.87636876]]. Reward = [0.]
Curr episode timestep = 12
Scene graph at timestep 371 is [False, True, 3, True]
Human Feedback received at timestep 371 of -1
Current timestep = 372. State = [[-0.07561311 -0.03439111  0.25477865  1.        ]]. Action = [[ 0.48740637 -0.12608445 -0.34102404  0.8802948 ]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 372 is [False, True, 3, True]
Human Feedback received at timestep 372 of -1
Current timestep = 373. State = [[-0.0644563  -0.0350813   0.25149736  1.        ]]. Action = [[-0.04652733 -0.04910886  0.23576975  0.24451435]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 373 is [False, True, 3, True]
Human Feedback received at timestep 373 of -1
Current timestep = 374. State = [[-0.05597356 -0.0367399   0.24994302  1.        ]]. Action = [[ 0.7969897  -0.09943014 -0.26555622  0.8390207 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 374 is [False, True, 3, True]
Human Feedback received at timestep 374 of -1
Current timestep = 375. State = [[-0.04078107 -0.03760018  0.24723239  1.        ]]. Action = [[ 0.27284503 -0.13079965 -0.86784625  0.87318945]]. Reward = [0.]
Curr episode timestep = 16
Scene graph at timestep 375 is [False, True, 3, True]
Human Feedback received at timestep 375 of 0
Current timestep = 376. State = [[-0.0352142  -0.03886084  0.2520889   1.        ]]. Action = [[ 0.38419998 -0.10434085  0.34462023  0.29635537]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 377. State = [[-0.01935058 -0.04195957  0.26088595  1.        ]]. Action = [[ 0.4899044  -0.08813947  0.08383179  0.55439556]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 378. State = [[ 3.0318432e-04 -4.3558687e-02  2.6200244e-01  1.0000000e+00]]. Action = [[ 0.72759056  0.01449847 -0.16502237  0.26954818]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 379. State = [[ 0.0272586  -0.04236285  0.2642421   1.        ]]. Action = [[0.41649556 0.22945213 0.52732587 0.95741665]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 380. State = [[ 0.04895852 -0.04024256  0.28382495  1.        ]]. Action = [[0.9684534  0.04283273 0.47918892 0.96067   ]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 381. State = [[ 0.07105883 -0.03716346  0.29500487  1.        ]]. Action = [[-0.5844132   0.07230973  0.05899596  0.8898816 ]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 382. State = [[ 0.06576646 -0.03948575  0.28873664  1.        ]]. Action = [[-0.8158425  -0.21067804 -0.79915094  0.74702024]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 383. State = [[-0.26880002  0.128234    0.11789324  1.        ]]. Action = [[ 0.47779238  0.05597413  0.6256819  -0.0348143 ]]. Reward = [100.]
Curr episode timestep = 24
Current timestep = 384. State = [[-0.25633198  0.13851942  0.11571921  1.        ]]. Action = [[ 0.50647295 -0.3774057   1.3234692   0.866807  ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 384 is [False, True, 3, False]
Human Feedback received at timestep 384 of 1
Current timestep = 385. State = [[-0.23382767  0.1282282   0.14971955  1.        ]]. Action = [[ 0.8297725  -0.32102716  0.9465976   0.7599416 ]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 385 is [False, True, 3, False]
Human Feedback received at timestep 385 of 1
Current timestep = 386. State = [[-0.20547935  0.11553991  0.18059477  1.        ]]. Action = [[ 0.59074426 -0.45733845  0.24835849  0.44201124]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 386 is [False, True, 3, False]
Human Feedback received at timestep 386 of 1
Current timestep = 387. State = [[-0.18291223  0.10165756  0.20345792  1.        ]]. Action = [[ 0.45707953 -0.30858713  1.057879    0.45632195]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 387 is [False, True, 3, False]
Human Feedback received at timestep 387 of 1
Current timestep = 388. State = [[-0.15847331  0.08808137  0.2395959   1.        ]]. Action = [[ 0.52990043 -0.38611138  0.69996595  0.6028167 ]]. Reward = [0.]
Curr episode timestep = 4
Scene graph at timestep 388 is [False, True, 3, False]
Human Feedback received at timestep 388 of 1
Current timestep = 389. State = [[-0.13539933  0.07634162  0.27198067  1.        ]]. Action = [[ 0.76474595 -0.27282238  0.95709825  0.83901167]]. Reward = [0.]
Curr episode timestep = 5
Scene graph at timestep 389 is [False, True, 3, False]
Human Feedback received at timestep 389 of 1
Current timestep = 390. State = [[-0.10974031  0.06832116  0.30537423  1.        ]]. Action = [[ 0.522485   -0.21520555  0.47137308  0.6157775 ]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 390 is [False, True, 3, False]
Human Feedback received at timestep 390 of 1
Current timestep = 391. State = [[-0.08955073  0.06098175  0.32747096  1.        ]]. Action = [[ 0.78425956 -0.12546527  0.35719252  0.6923729 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 392. State = [[-0.07045803  0.05273838  0.3249766   1.        ]]. Action = [[ 0.88487124 -0.26739216 -1.1778501   0.25998414]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 393. State = [[-0.03450366  0.04314177  0.3011939   1.        ]]. Action = [[ 0.679463   -0.2425313   0.22120476  0.41353536]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 394. State = [[-0.0078608   0.03655153  0.31693015  1.        ]]. Action = [[ 0.23800135 -0.12185967  1.1890292   0.47187757]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 395. State = [[0.0090901  0.03285995 0.35078678 1.        ]]. Action = [[ 0.7098527  -0.06428415  0.543623    0.44189024]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 396. State = [[0.02509579 0.0312307  0.36091185 1.        ]]. Action = [[ 0.02962315 -0.0246743  -0.3563925   0.0718261 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 397. State = [[0.03661593 0.02925645 0.36907104 1.        ]]. Action = [[ 0.7334595  -0.03022659  0.9408593   0.23692918]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 398. State = [[0.05077027 0.02845263 0.37890586 1.        ]]. Action = [[-0.25280076 -0.03584725 -0.53558385  0.44196963]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 399. State = [[0.05152138 0.02419852 0.36857098 1.        ]]. Action = [[ 0.4765165  -0.16984594 -0.95991373  0.02838659]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 400. State = [[0.07582255 0.02233518 0.33651617 1.        ]]. Action = [[ 0.4981321  -0.29024816 -0.07576931  0.44281352]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 401. State = [[0.07990964 0.01546689 0.3453333  1.        ]]. Action = [[ 0.24256134 -0.36976004  0.74638176  0.3896501 ]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 402. State = [[0.0832791  0.00935988 0.35753837 1.        ]]. Action = [[ 0.93109465 -0.2425319  -1.1537467   0.18795538]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 403. State = [[-0.26506868 -0.06848893  0.11273658  1.        ]]. Action = [[-0.14216399 -0.28132355 -1.249647   -0.03049457]]. Reward = [-10.]
Curr episode timestep = 19
Current timestep = 404. State = [[-0.25462723 -0.07709132  0.10816924  1.        ]]. Action = [[0.8067634  0.19973326 1.4382904  0.55289316]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 404 is [False, True, 3, False]
Human Feedback received at timestep 404 of 1
Current timestep = 405. State = [[-0.23025718 -0.07516868  0.14510134  1.        ]]. Action = [[0.8310298  0.14897156 0.5210929  0.54346967]]. Reward = [0.]
Curr episode timestep = 1
Scene graph at timestep 405 is [False, True, 3, False]
Human Feedback received at timestep 405 of 1
Current timestep = 406. State = [[-0.19627403 -0.07220446  0.17533979  1.        ]]. Action = [[0.60173225 0.12423813 1.4477515  0.40212488]]. Reward = [0.]
Curr episode timestep = 2
Scene graph at timestep 406 is [False, True, 3, False]
Human Feedback received at timestep 406 of 1
Current timestep = 407. State = [[-0.17956248 -0.0695532   0.21405765  1.        ]]. Action = [[0.60625696 0.17539513 0.62197185 0.40663147]]. Reward = [0.]
Curr episode timestep = 3
Scene graph at timestep 407 is [False, True, 3, False]
Human Feedback received at timestep 407 of 0
Current timestep = 408. State = [[-0.16847306 -0.06826228  0.2287917   1.        ]]. Action = [[0.69689107 0.077075   1.0816195  0.47744942]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 409. State = [[-0.14956991 -0.06598982  0.26320317  1.        ]]. Action = [[0.07609534 0.06298029 0.5434196  0.40281844]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 410. State = [[-0.13705231 -0.06304809  0.28419837  1.        ]]. Action = [[0.650967   0.07765174 0.22181678 0.29462075]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 411. State = [[-0.12102283 -0.05791047  0.28978452  1.        ]]. Action = [[ 0.69709635  0.05170119 -0.7168801   0.32000244]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 412. State = [[-0.09008665 -0.05470483  0.28856578  1.        ]]. Action = [[0.7125485  0.11086226 1.01156    0.3579842 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 412 is [False, True, 3, True]
Human Feedback received at timestep 412 of -1
Current timestep = 413. State = [[-0.0582136  -0.05108171  0.3231263   1.        ]]. Action = [[ 0.8322611  -0.03204536  0.8321073   0.38167584]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 413 is [False, True, 3, True]
Human Feedback received at timestep 413 of -1
Current timestep = 414. State = [[-0.0284847  -0.05105535  0.34458786  1.        ]]. Action = [[ 0.5949272   0.04134107 -0.13953066  0.31848598]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 415. State = [[-0.26831236  0.12732111  0.11949854  1.        ]]. Action = [[-0.11499673  0.13438821 -0.68060064 -0.04954487]]. Reward = [100.]
Curr episode timestep = 11
Current timestep = 416. State = [[-0.25221318  0.13733399  0.11528263  1.        ]]. Action = [[ 0.79705596 -0.3814237   1.1365364   0.5434065 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 416 is [False, True, 3, False]
Human Feedback received at timestep 416 of 1
Current timestep = 417. State = [[-0.23194844  0.12568218  0.14296591  1.        ]]. Action = [[ 0.18924963 -0.36748195  0.7533994   0.37909973]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 418. State = [[-0.2138072   0.11344726  0.17468664  1.        ]]. Action = [[ 0.880283   -0.33224916  0.97307134  0.34608293]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 419. State = [[-0.18370615  0.10302704  0.21382089  1.        ]]. Action = [[ 0.58625674 -0.3104651   1.0867014   0.43096423]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 420. State = [[-0.15591702  0.0907682   0.25263333  1.        ]]. Action = [[ 0.80426216 -0.35894084  0.750896    0.37011838]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 421. State = [[-0.12697949  0.07850041  0.28148854  1.        ]]. Action = [[ 0.8561063  -0.29591012  0.19871855  0.38908732]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 422. State = [[-0.09879447  0.06752691  0.28714886  1.        ]]. Action = [[ 0.90209556 -0.256047   -0.4312818   0.02797103]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 422 is [False, True, 3, True]
Human Feedback received at timestep 422 of 1
Current timestep = 423. State = [[-0.06235071  0.05649709  0.27456936  1.        ]]. Action = [[ 0.7430475  -0.22162294 -0.21110773  0.05058658]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 424. State = [[-0.04495765  0.0509093   0.27152655  1.        ]]. Action = [[-0.10931325 -0.22228658  0.13076639  0.28810775]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 425. State = [[-0.04280168  0.04721784  0.27364874  1.        ]]. Action = [[ 0.32102847 -0.25782913 -0.96200454  0.07174397]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 426. State = [[-0.0399915   0.04202615  0.27095392  1.        ]]. Action = [[ 0.17175078 -0.24851781 -0.24364555  0.06208539]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 427. State = [[-0.03495143  0.0329157   0.26357368  1.        ]]. Action = [[ 0.30428863 -0.1772371  -0.33101428  0.18625855]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 428. State = [[-0.02192491  0.02363102  0.25067595  1.        ]]. Action = [[ 0.7647234  -0.20489985 -0.5106299   0.34941137]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 429. State = [[0.001881   0.0206568  0.23322308 1.        ]]. Action = [[ 0.8595092  -0.2662531  -0.4261651   0.09014583]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 430. State = [[0.00782163 0.01671368 0.2503978  1.        ]]. Action = [[-0.34879148 -0.16500795  1.5741487   0.02554452]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 431. State = [[0.01370168 0.00942356 0.29270768 1.        ]]. Action = [[ 0.7377957  -0.18651718  0.66288614  0.09529912]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 432. State = [[0.02721498 0.0036189  0.3065771  1.        ]]. Action = [[ 0.8819232  -0.15884852 -0.7968142   0.04812837]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 433. State = [[ 0.05597086 -0.00232656  0.28360742  1.        ]]. Action = [[ 0.56877184 -0.11144739 -0.2590767   0.00264561]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 434. State = [[ 0.08179912 -0.00782005  0.27529567  1.        ]]. Action = [[ 0.46644413 -0.20013136  0.04138207  0.03982151]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 435. State = [[ 0.09415729 -0.01418177  0.2877646   1.        ]]. Action = [[-0.6231508  -0.16654742  0.6414299   0.17193198]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 436. State = [[ 0.09193961 -0.02096721  0.31073675  1.        ]]. Action = [[-0.1472866  -0.07975137  0.73181343  0.0348258 ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 437. State = [[ 0.08523662 -0.02329762  0.31860015  1.        ]]. Action = [[-0.46579337 -0.04893684 -1.1198597   0.06109524]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 438. State = [[ 0.07360739 -0.02848151  0.2979114   1.        ]]. Action = [[-0.9061539  -0.2719466  -0.5375035   0.02002573]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 439. State = [[-0.2633244  -0.11928071  0.11242066  1.        ]]. Action = [[-0.6616145  -0.05932164  0.49420524 -0.05853832]]. Reward = [100.]
Curr episode timestep = 23
Current timestep = 440. State = [[-0.2544416  -0.1316785   0.10801174  1.        ]]. Action = [[0.8105252  0.24342442 1.5723476  0.1945405 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 440 is [False, True, 3, False]
Human Feedback received at timestep 440 of 1
Current timestep = 441. State = [[-0.22935142 -0.1250031   0.15179598  1.        ]]. Action = [[0.83800614 0.33908486 0.87999916 0.48476696]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 442. State = [[-0.20515601 -0.11589375  0.18868075  1.        ]]. Action = [[0.19991016 0.21411407 1.1322384  0.5349028 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 443. State = [[-0.18647537 -0.1042854   0.23151945  1.        ]]. Action = [[0.69266164 0.36825168 0.980721   0.60542667]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 444. State = [[-0.16757582 -0.09615483  0.25835562  1.        ]]. Action = [[ 0.42715144  0.29421782 -0.22461283  0.20395958]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 445. State = [[-0.15670839 -0.09407344  0.26370245  1.        ]]. Action = [[ 0.6758814   0.07629025 -0.07312572  0.31283474]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 446. State = [[-0.26805767  0.12231555  0.11916529  1.        ]]. Action = [[ 0.6171074   0.28369296  0.32976818 -0.00968301]]. Reward = [-10.]
Curr episode timestep = 6
Current timestep = 447. State = [[-0.25447896  0.13148262  0.11761173  1.        ]]. Action = [[ 0.5379149  -0.35517168  1.4253993   0.4826131 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 448. State = [[-0.23258765  0.12232794  0.15478002  1.        ]]. Action = [[ 0.8430772 -0.3166914  1.1812358  0.5639099]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 449. State = [[-0.20331086  0.11138283  0.19839825  1.        ]]. Action = [[ 0.6785841 -0.3399855  0.8669164  0.5037067]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 450. State = [[-0.17755114  0.10131234  0.23736672  1.        ]]. Action = [[ 0.3824123  -0.24826777  0.9826181   0.45599473]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 451. State = [[-0.15765649  0.09035128  0.27185038  1.        ]]. Action = [[ 0.47725558 -0.3592986   0.67001295  0.6065242 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 452. State = [[-0.13643225  0.07763833  0.2974351   1.        ]]. Action = [[ 0.76925004 -0.33935142  0.26115036  0.29847872]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 453. State = [[-0.1134697   0.06466728  0.3115829   1.        ]]. Action = [[ 0.6249068  -0.3550073   0.15563846  0.04460263]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 454. State = [[-0.08844717  0.05572938  0.3256419   1.        ]]. Action = [[ 0.9092649  -0.11615574  0.48601294  0.25283825]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 454 is [False, True, 3, True]
Human Feedback received at timestep 454 of -1
Current timestep = 455. State = [[-0.05892529  0.04475088  0.3325558   1.        ]]. Action = [[ 0.5581491  -0.33405757 -0.7087281   0.29291153]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 455 is [False, True, 3, True]
Human Feedback received at timestep 455 of -1
Current timestep = 456. State = [[-0.03704371  0.03401286  0.30576476  1.        ]]. Action = [[-0.19082642 -0.35102028 -0.66914785  0.05124605]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 457. State = [[-0.03305843  0.02117112  0.28847113  1.        ]]. Action = [[ 0.74466777 -0.32206672 -0.7145841   0.17738688]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 458. State = [[-0.0117195   0.00903207  0.2655799   1.        ]]. Action = [[ 0.35181952 -0.24240911  0.11501122  0.20081568]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 459. State = [[ 0.00517189 -0.00257398  0.26230836  1.        ]]. Action = [[ 0.80539286 -0.28326738 -0.31776345  0.0742166 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 460. State = [[ 0.0372359  -0.01270804  0.26850298  1.        ]]. Action = [[ 0.73336315 -0.24688381  1.262239    0.02451885]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 461. State = [[-0.2640689  -0.00970938  0.11294676  1.        ]]. Action = [[ 0.33783126 -0.17663783  1.5055327  -0.06282479]]. Reward = [100.]
Curr episode timestep = 14
Current timestep = 462. State = [[-0.25281984 -0.01371508  0.1098801   1.        ]]. Action = [[ 0.9233966  -0.06950808  1.3885436   0.80800974]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 462 is [False, True, 3, False]
Human Feedback received at timestep 462 of 1
Current timestep = 463. State = [[-0.22192314 -0.02026528  0.15279211  1.        ]]. Action = [[ 0.6243179  -0.12397587  1.3709342   0.7950096 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 464. State = [[-0.19802992 -0.0213362   0.19144674  1.        ]]. Action = [[0.79544663 0.01251042 0.25146317 0.49765134]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 465. State = [[-0.16647556 -0.02201628  0.21740812  1.        ]]. Action = [[ 0.88450384 -0.04769558  1.1826372   0.36082208]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 466. State = [[-0.13238159 -0.02514657  0.25171047  1.        ]]. Action = [[ 0.6052077  -0.20220864  0.26429176  0.4166745 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 467. State = [[-0.11275262 -0.02748391  0.27149308  1.        ]]. Action = [[0.2768786  0.01349103 0.5609484  0.38026953]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 468. State = [[-0.09716734 -0.02923501  0.27970955  1.        ]]. Action = [[ 0.65339863 -0.07024997 -0.46633518  0.16963947]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 468 is [False, True, 3, True]
Human Feedback received at timestep 468 of 1
Current timestep = 469. State = [[-0.08199905 -0.0298933   0.2739572   1.        ]]. Action = [[ 0.71147776 -0.1403845  -0.9817351   0.40127254]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 470. State = [[-0.07953317 -0.03002517  0.26800174  1.        ]]. Action = [[ 0.41705585  0.01376534 -0.43943787  0.11354244]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 471. State = [[-0.05630758 -0.03043784  0.27034667  1.        ]]. Action = [[ 0.7169461  -0.0208503   0.7741821   0.01884782]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 472. State = [[-0.02837905 -0.03175886  0.29742634  1.        ]]. Action = [[ 0.9902873  -0.08218288  0.8604789   0.00484526]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 473. State = [[-0.25957945 -0.15793273  0.11868405  1.        ]]. Action = [[ 0.3545785   0.08386755 -0.12778842 -0.04469889]]. Reward = [100.]
Curr episode timestep = 11
Current timestep = 474. State = [[-0.24967417 -0.16953239  0.11512315  1.        ]]. Action = [[0.9220996  0.6058316  1.3039064  0.58022785]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 474 is [False, True, 3, False]
Human Feedback received at timestep 474 of 1
Current timestep = 475. State = [[-0.2165772  -0.14853236  0.14905997  1.        ]]. Action = [[0.85488045 0.6148324  0.88284206 0.1887443 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 476. State = [[-0.18621768 -0.13010094  0.18623297  1.        ]]. Action = [[0.7849276  0.4336326  1.2753701  0.41597712]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 477. State = [[-0.16351715 -0.12026636  0.21879147  1.        ]]. Action = [[0.8404193  0.49848425 0.33985353 0.31998444]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 478. State = [[-0.14750457 -0.11256742  0.23965861  1.        ]]. Action = [[0.83058023 0.4188069  1.2708814  0.25537276]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 479. State = [[-0.12648836 -0.10341885  0.27212664  1.        ]]. Action = [[ 0.70148015  0.44790244 -0.9627638   0.17107582]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 480. State = [[-0.12203747 -0.10282372  0.2770454   1.        ]]. Action = [[ 0.91391754  0.2692008  -1.1173991   0.19607627]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 481. State = [[-0.11192712 -0.09627017  0.29138115  1.        ]]. Action = [[0.7511331  0.38805854 1.0493872  0.24982262]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 482. State = [[-0.09270646 -0.08431054  0.3092583   1.        ]]. Action = [[ 0.6888175   0.18193424 -0.963398    0.25482845]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 482 is [False, True, 3, True]
Human Feedback received at timestep 482 of -1
Current timestep = 483. State = [[-0.06885945 -0.07802819  0.28479433  1.        ]]. Action = [[ 0.5694394  0.1128819 -0.7059474  0.0560981]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 484. State = [[-0.05051654 -0.07616379  0.26831946  1.        ]]. Action = [[ 0.25857377  0.23256767 -1.0412666   0.04749739]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 485. State = [[-0.03780528 -0.07435408  0.2744407   1.        ]]. Action = [[0.80495715 0.12532306 0.70194626 0.0662365 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 486. State = [[-0.02050576 -0.06757975  0.28733328  1.        ]]. Action = [[ 0.2046994   0.2527423  -0.07322979  0.0921973 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 487. State = [[-0.0063258  -0.06335849  0.29833704  1.        ]]. Action = [[ 0.36384702 -0.04686362  0.7704766   0.01567614]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 488. State = [[ 0.01104494 -0.05914375  0.31776935  1.        ]]. Action = [[0.7946365  0.2454722  0.17951846 0.037328  ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 489. State = [[-0.26836765  0.12845753  0.1162693   1.        ]]. Action = [[ 0.7926445  -0.18794906  0.5690098  -0.04957342]]. Reward = [100.]
Curr episode timestep = 15
Current timestep = 490. State = [[-0.24939705  0.13806142  0.11736511  1.        ]]. Action = [[ 0.78124917 -0.3528086   1.4864731   0.7671422 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 490 is [False, True, 3, False]
Human Feedback received at timestep 490 of 1
Current timestep = 491. State = [[-0.22358193  0.12851661  0.15842421  1.        ]]. Action = [[ 0.824648   -0.31447715  1.1469531   0.740903  ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 492. State = [[-0.19447054  0.11883288  0.20438929  1.        ]]. Action = [[ 0.4422742  -0.34366608  1.5441937   0.27257323]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 493. State = [[-0.17561042  0.10777711  0.26137772  1.        ]]. Action = [[ 0.35198557 -0.30249435  1.3070993   0.48851645]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 494. State = [[-0.15360466  0.09634887  0.31077138  1.        ]]. Action = [[ 0.8433089  -0.27908146  0.82210493  0.37793088]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 495. State = [[-0.12800738  0.08531209  0.33514598  1.        ]]. Action = [[ 0.66910744 -0.33164024 -0.18243575  0.22980416]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 496. State = [[-0.11164478  0.07806642  0.33287582  1.        ]]. Action = [[ 0.20197093 -0.09155393 -0.30855465  0.10613835]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 497. State = [[-0.268827    0.11765649  0.11741319  1.        ]]. Action = [[ 0.91466355 -0.31563163 -0.1138742  -0.04026371]]. Reward = [100.]
Curr episode timestep = 7
Current timestep = 498. State = [[-0.2590089   0.12682556  0.11338607  1.        ]]. Action = [[ 0.28810227 -0.34997296  1.098772    0.42258048]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 499. State = [[-0.2414752   0.11837999  0.13780554  1.        ]]. Action = [[ 0.7866647  -0.24417406  0.7134235   0.64985967]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 500. State = [[-0.20845595  0.10781234  0.17422801  1.        ]]. Action = [[ 0.8720794  -0.31424272  1.4956012   0.7148135 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 501. State = [[-0.18983325  0.10360003  0.21279879  1.        ]]. Action = [[ 0.7976401  -0.31873286 -0.10270202  0.37274456]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 502. State = [[-0.17433575  0.0977242   0.22912334  1.        ]]. Action = [[ 0.77481246 -0.3305732   0.9011586   0.50707126]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 503. State = [[-0.14872785  0.08672512  0.25731695  1.        ]]. Action = [[ 0.65728426 -0.33200216  0.2925508   0.44243276]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 504. State = [[-0.12971987  0.07494847  0.26876256  1.        ]]. Action = [[ 0.43426847 -0.3229512  -0.13532388  0.22230887]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 505. State = [[-0.11030892  0.06479561  0.2793738   1.        ]]. Action = [[ 0.5216217  -0.21106803  0.7840314   0.20986581]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 506. State = [[-0.25859317 -0.10322714  0.1158752   1.        ]]. Action = [[ 0.3671491  -0.2714206  -0.3263631  -0.05843496]]. Reward = [100.]
Curr episode timestep = 8
Current timestep = 507. State = [[-0.25016028 -0.11322148  0.1102771   1.        ]]. Action = [[0.81145644 0.29511023 1.006186   0.6309304 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 508. State = [[-0.22706425 -0.10793085  0.1367871   1.        ]]. Action = [[0.79802835 0.28470945 1.1984186  0.539829  ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 509. State = [[-0.20067865 -0.0990732   0.1784089   1.        ]]. Action = [[0.35682654 0.22300875 0.8677368  0.6670165 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 510. State = [[-0.18709655 -0.09377613  0.20129399  1.        ]]. Action = [[0.8211498  0.26580882 0.86819124 0.5237558 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 511. State = [[-0.1842419  -0.09330012  0.20309636  1.        ]]. Action = [[0.7046695  0.43959963 0.408365   0.5527632 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 512. State = [[-0.18403924 -0.09327631  0.2033762   1.        ]]. Action = [[ 0.35484362  0.08110201 -0.62593246  0.38108873]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 513. State = [[-0.17218062 -0.09367391  0.21913664  1.        ]]. Action = [[0.7502544  0.003497   1.2243309  0.49443483]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 514. State = [[-0.15492648 -0.09332338  0.2508478   1.        ]]. Action = [[ 0.57578313  0.09477925 -0.38394785  0.36135375]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 515. State = [[-0.14812332 -0.08998384  0.25682572  1.        ]]. Action = [[0.45919716 0.20101368 0.02052641 0.21558166]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 516. State = [[-0.12946016 -0.08378884  0.27291977  1.        ]]. Action = [[0.78114486 0.09551561 0.86730814 0.23272586]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 517. State = [[-0.09840807 -0.07988293  0.29493728  1.        ]]. Action = [[ 0.89885354  0.06967616 -0.03724575  0.08807671]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 517 is [False, True, 3, True]
Human Feedback received at timestep 517 of 1
Current timestep = 518. State = [[-0.07047052 -0.07604894  0.29755273  1.        ]]. Action = [[ 0.06271935 -0.11892349 -0.14954436  0.0280931 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 518 is [False, True, 3, True]
Human Feedback received at timestep 518 of -1
Current timestep = 519. State = [[-0.06803712 -0.07414506  0.28960586  1.        ]]. Action = [[ 0.66222906  0.16752613 -0.6851964   0.00986552]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 520. State = [[-0.04311597 -0.07293863  0.2776706   1.        ]]. Action = [[0.2066977 0.1181848 0.3457632 0.0098877]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 521. State = [[-0.03338317 -0.07203658  0.29065287  1.        ]]. Action = [[ 0.19073999 -0.0039556   0.85516715  0.01389599]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 522. State = [[-0.01851999 -0.06962866  0.32383624  1.        ]]. Action = [[0.34688604 0.17106175 1.117476   0.02460575]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 523. State = [[-0.26792127  0.03192991  0.11878739  1.        ]]. Action = [[ 0.5268507   0.21224153  0.6125095  -0.00743663]]. Reward = [100.]
Curr episode timestep = 16
Current timestep = 524. State = [[-0.2576356   0.03582272  0.11236282  1.        ]]. Action = [[ 0.70966125 -0.11363953  0.9426899   0.8366256 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 524 is [False, True, 3, False]
Human Feedback received at timestep 524 of 1
Current timestep = 525. State = [[-0.23348854  0.03225853  0.13773213  1.        ]]. Action = [[ 0.419842   -0.21449381  1.3951795   0.72287273]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 526. State = [[-0.21811026  0.02647552  0.17971423  1.        ]]. Action = [[ 0.4807843  -0.24044049  0.4406638   0.73627865]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 527. State = [[-0.19411878  0.02151628  0.21046557  1.        ]]. Action = [[ 0.63871694 -0.08843374  1.3087006   0.56639147]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 528. State = [[-0.17759754  0.01835876  0.2435075   1.        ]]. Action = [[ 0.7204796   0.03256989 -0.10044992  0.47479606]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 529. State = [[-0.16401187  0.01320258  0.25293225  1.        ]]. Action = [[ 0.8918884  -0.29389095  0.17519927  0.4775523 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 530. State = [[-0.14326122  0.00574966  0.28012973  1.        ]]. Action = [[-0.02329695 -0.20675933  1.4913633   0.47331297]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 531. State = [[-0.12844802 -0.00301583  0.30782995  1.        ]]. Action = [[ 0.8700268  -0.2381115  -0.487808    0.04992688]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 532. State = [[-0.26380634 -0.06615271  0.11611938  1.        ]]. Action = [[ 0.7929301  -0.13774842 -0.45479202 -0.07361782]]. Reward = [-10.]
Curr episode timestep = 8
Current timestep = 533. State = [[-0.25387532 -0.07455319  0.11192559  1.        ]]. Action = [[0.77970576 0.18390131 1.5463815  0.81562304]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 534. State = [[-0.22997245 -0.07243027  0.15937875  1.        ]]. Action = [[0.81382823 0.17545795 1.7380433  0.9517033 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 535. State = [[-0.19878867 -0.06458671  0.20961645  1.        ]]. Action = [[0.81840587 0.36783624 0.07915092 0.3842039 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 536. State = [[-0.17127433 -0.05704967  0.2350136   1.        ]]. Action = [[0.3954532  0.00777578 1.1380906  0.76320624]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 537. State = [[-0.14310841 -0.05336867  0.27695927  1.        ]]. Action = [[0.8683872  0.16581917 1.3608654  0.7487576 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 538. State = [[-0.12031841 -0.05029129  0.30451715  1.        ]]. Action = [[ 0.3822565  -0.19252253 -1.0912524   0.46362543]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 539. State = [[-0.09588359 -0.05029597  0.28990924  1.        ]]. Action = [[0.92113423 0.14128494 0.03891039 0.10330403]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 539 is [False, True, 3, True]
Human Feedback received at timestep 539 of -1
Current timestep = 540. State = [[-0.26107493 -0.15550664  0.11812539  1.        ]]. Action = [[ 0.7939453  -0.11949927 -0.24483931 -0.07139724]]. Reward = [100.]
Curr episode timestep = 7
Current timestep = 541. State = [[-0.2517804  -0.16670603  0.11653439  1.        ]]. Action = [[0.81966794 0.6512742  1.6390436  0.96933365]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 541 is [False, True, 3, False]
Human Feedback received at timestep 541 of 1
Current timestep = 542. State = [[-0.2201944  -0.14536752  0.16513097  1.        ]]. Action = [[0.96782386 0.5877563  1.3702116  0.95581675]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 543. State = [[-0.19763003 -0.13484819  0.20068382  1.        ]]. Action = [[0.9563732  0.26553404 0.04538417 0.5028343 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 544. State = [[-0.19508825 -0.13362361  0.20324856  1.        ]]. Action = [[0.8915678  0.42607117 0.6621871  0.82365155]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 545. State = [[-0.18409145 -0.12559229  0.2177265   1.        ]]. Action = [[0.6644604  0.4414642  1.1084938  0.84417796]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 546. State = [[-0.15580074 -0.11516182  0.25402746  1.        ]]. Action = [[0.92383146 0.09294116 0.5239885  0.8254955 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 547. State = [[-0.12434284 -0.10395434  0.26888567  1.        ]]. Action = [[ 0.91807806  0.444242   -0.41852224  0.6673676 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 548. State = [[-0.09518264 -0.09219886  0.26057065  1.        ]]. Action = [[ 0.5153073   0.2078687  -0.1763289   0.49330866]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 548 is [False, True, 3, True]
Human Feedback received at timestep 548 of -1
Current timestep = 549. State = [[-0.06916057 -0.0861408   0.26500326  1.        ]]. Action = [[0.55696917 0.04293609 0.4936397  0.2520368 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 550. State = [[-0.2673116   0.11335825  0.11621345  1.        ]]. Action = [[ 0.36021674  0.04702306 -0.5457355  -0.0189181 ]]. Reward = [100.]
Curr episode timestep = 9
Current timestep = 551. State = [[-0.25703883  0.12123784  0.10614333  1.        ]]. Action = [[ 0.53458023 -0.36031485  0.5810132   0.6539099 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 551 is [False, True, 3, False]
Human Feedback received at timestep 551 of 1
Current timestep = 552. State = [[-0.23399973  0.11101692  0.12235934  1.        ]]. Action = [[ 0.63199806 -0.27680558  1.0655622   0.8888352 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 553. State = [[-0.20900221  0.10088214  0.16490363  1.        ]]. Action = [[ 0.7940018 -0.39075    1.443362   0.7770412]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 554. State = [[-0.17960557  0.09156981  0.21223535  1.        ]]. Action = [[ 0.5887828  -0.14355922  0.66396976  0.76322603]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 555. State = [[-0.15249468  0.08496185  0.24831222  1.        ]]. Action = [[ 0.6144204 -0.2646166  1.3394523  0.6681371]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 556. State = [[-0.12794505  0.07468332  0.29484072  1.        ]]. Action = [[ 0.5436077  -0.31279433  0.92404556  0.14048147]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 557. State = [[-0.10836624  0.06467015  0.33939803  1.        ]]. Action = [[ 0.20914137 -0.2101078   1.2121572   0.12232935]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 558. State = [[-0.2623421   0.00643523  0.12054934  1.        ]]. Action = [[ 0.7125726  -0.18639195  1.0728583  -0.01784319]]. Reward = [100.]
Curr episode timestep = 7
Current timestep = 559. State = [[-0.2590476   0.00710261  0.1061504   1.        ]]. Action = [[ 0.3693664  -0.16367203  0.3134377   0.9754112 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 560. State = [[-0.24155016  0.00351386  0.11128968  1.        ]]. Action = [[ 0.8128766  -0.1846782   0.36255908  0.9647405 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 561. State = [[-0.2153901  -0.00336235  0.12851803  1.        ]]. Action = [[ 0.6336117 -0.2455455  1.3217888  0.9856007]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 562. State = [[-0.18685922 -0.01121252  0.17354888  1.        ]]. Action = [[ 0.8034668  -0.2203995   0.82628775  0.9811716 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 563. State = [[-0.16420922 -0.01703112  0.19635226  1.        ]]. Action = [[ 0.5132716  -0.12904918  0.45631027  0.7636466 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 564. State = [[-0.1484608  -0.02434493  0.21892323  1.        ]]. Action = [[ 0.7022835  -0.33961165  1.5936673   0.58625364]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 565. State = [[-0.12429702 -0.02954744  0.27475628  1.        ]]. Action = [[0.53503513 0.06757581 1.2706358  0.37370503]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 566. State = [[-0.10331923 -0.02897585  0.3123146   1.        ]]. Action = [[ 0.44363666  0.09524524 -0.04654765  0.14655972]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 567. State = [[-0.09125525 -0.02849376  0.3178967   1.        ]]. Action = [[ 0.2747383  -0.04920763 -0.1195302   0.13731134]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 567 is [False, True, 3, True]
Human Feedback received at timestep 567 of -1
Current timestep = 568. State = [[-0.07766995 -0.02857427  0.31484476  1.        ]]. Action = [[ 0.8558049   0.00131977 -0.2895007   0.02477658]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 568 is [False, True, 3, True]
Human Feedback received at timestep 568 of -1
Current timestep = 569. State = [[-0.26877362  0.13371477  0.14401908  1.        ]]. Action = [[ 0.508657   -0.13816547 -0.06899321 -0.03569645]]. Reward = [100.]
Curr episode timestep = 10
Current timestep = 570. State = [[-0.25727075  0.13117659  0.1471471   1.        ]]. Action = [[ 0.698565   -0.37622416  0.6664572   0.89086246]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 570 is [False, True, 3, False]
Human Feedback received at timestep 570 of 1
Current timestep = 571. State = [[-0.23351057  0.11834852  0.15983096  1.        ]]. Action = [[ 0.6502335  -0.4342612   0.33782744  0.9636917 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 572. State = [[-0.20881055  0.10516176  0.17251545  1.        ]]. Action = [[ 0.9003434  -0.36954677  0.20488691  0.9234371 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 573. State = [[-0.18031015  0.09362718  0.1926551   1.        ]]. Action = [[ 0.53553534 -0.28382182  0.8047118   0.6996596 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 574. State = [[-0.15474507  0.08305035  0.2241362   1.        ]]. Action = [[ 0.31943977 -0.27048326  1.2056537   0.5945524 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 575. State = [[-0.14324376  0.07758464  0.25337338  1.        ]]. Action = [[ 0.90513253 -0.11388195  0.08194637  0.07913494]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 576. State = [[-0.13409959  0.07120139  0.26690844  1.        ]]. Action = [[ 0.4727341  -0.35688186  0.7406354   0.01084018]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 577. State = [[-0.11362641  0.05790146  0.29648346  1.        ]]. Action = [[ 0.7925744  -0.36734778  0.70816755  0.02055848]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 578. State = [[-0.1029544   0.04766452  0.3191494   1.        ]]. Action = [[-0.8137668  -0.27736259  0.01421547  0.05537617]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 579. State = [[-0.10422607  0.03719095  0.3220322   1.        ]]. Action = [[ 0.57234263 -0.19043249  0.01344919  0.06655288]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 580. State = [[-0.2686981   0.09521184  0.1193159   1.        ]]. Action = [[ 0.09473276 -0.17555285  0.60586023 -0.04055429]]. Reward = [-10.]
Curr episode timestep = 10
Current timestep = 581. State = [[-0.25223878  0.10170071  0.11809749  1.        ]]. Action = [[ 0.7527417 -0.3803525  1.4346173  0.9342983]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 582. State = [[-0.22963046  0.09294602  0.15298691  1.        ]]. Action = [[ 0.72094774 -0.24156278  0.86018276  0.98159456]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 583. State = [[-0.19924186  0.08326112  0.19055785  1.        ]]. Action = [[ 0.68655896 -0.32975304  1.2314105   0.87446964]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 584. State = [[-0.18042117  0.07779393  0.22267649  1.        ]]. Action = [[ 0.69242024 -0.2570175   0.77479935  0.77237153]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 585. State = [[-0.17593761  0.07731722  0.22648655  1.        ]]. Action = [[ 0.50418925 -0.24975204 -0.4394908   0.385108  ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 586. State = [[-0.16705047  0.07167352  0.23528172  1.        ]]. Action = [[ 0.6748905  -0.2954023   0.61720514  0.4230535 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 587. State = [[-0.14365943  0.06159165  0.26667228  1.        ]]. Action = [[ 0.46868932 -0.31467307  0.9815819   0.33636093]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 588. State = [[-0.12258296  0.05437568  0.29391935  1.        ]]. Action = [[ 0.7984036  -0.10013294  0.21410894  0.07174206]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 589. State = [[-0.10137396  0.0493372   0.2999893   1.        ]]. Action = [[ 0.74193263 -0.04497284 -0.5992758   0.07012987]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 590. State = [[-0.07141059  0.04439483  0.29458138  1.        ]]. Action = [[ 0.66555333 -0.27890992  0.4556582   0.14008176]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 590 is [False, True, 3, True]
Human Feedback received at timestep 590 of -1
Current timestep = 591. State = [[-0.2666671   0.11882009  0.1180007   1.        ]]. Action = [[ 0.42329693 -0.10675675 -0.26713562 -0.01836634]]. Reward = [100.]
Curr episode timestep = 10
Current timestep = 592. State = [[-0.2521015   0.13077578  0.11119686  1.        ]]. Action = [[ 0.8174323 -0.2093215  0.8541615  0.8577553]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 592 is [False, True, 3, False]
Human Feedback received at timestep 592 of 1
Current timestep = 593. State = [[-0.22088718  0.12142359  0.13450445  1.        ]]. Action = [[ 0.8947978  -0.3922609   0.95698047  0.34359288]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 594. State = [[-0.19310048  0.10898167  0.15524022  1.        ]]. Action = [[ 0.60008574 -0.4249634  -0.27873623  0.95018816]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 595. State = [[-0.1809594   0.1018041   0.15720658  1.        ]]. Action = [[ 0.56934047 -0.37109548  1.0183768   0.924634  ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 596. State = [[-0.1773115   0.0957289   0.16293551  1.        ]]. Action = [[ 0.06403804 -0.3124284   0.549881    0.7070739 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 597. State = [[-0.17210332  0.08859026  0.16873558  1.        ]]. Action = [[ 0.43865514 -0.22090816 -0.17465639  0.90410185]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 598. State = [[-0.17009728  0.08808368  0.17031404  1.        ]]. Action = [[ 0.45326102 -0.33799458  1.3452406   0.93068814]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 599. State = [[-0.16968887  0.08765061  0.17054842  1.        ]]. Action = [[ 0.76477647 -0.25653237  0.8758657   0.8572117 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 600. State = [[-0.16939636  0.08765087  0.17070471  1.        ]]. Action = [[ 0.57192564 -0.32155204  0.30074382  0.8674885 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 601. State = [[-0.16939636  0.08765087  0.17070471  1.        ]]. Action = [[ 0.9048861  -0.25924134  1.0093973   0.807634  ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 602. State = [[-0.16078828  0.08610259  0.18942522  1.        ]]. Action = [[ 0.32508373 -0.11907083  1.4613423   0.8863573 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 603. State = [[-0.14858884  0.07895625  0.23848319  1.        ]]. Action = [[ 0.3424008  -0.31872833  1.1314893   0.7757381 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 604. State = [[-0.13291827  0.07060889  0.28741595  1.        ]]. Action = [[ 0.33044553 -0.1337161   1.1578355   0.6284983 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 605. State = [[-0.12004118  0.06287618  0.31476355  1.        ]]. Action = [[ 0.31106102 -0.33053225 -0.21384406  0.20809221]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 606. State = [[-0.10527086  0.05240139  0.3273433   1.        ]]. Action = [[ 0.8943857  -0.2512194   0.6428983   0.16271508]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 607. State = [[-0.08205579  0.04153968  0.33468026  1.        ]]. Action = [[ 0.6278722  -0.2739216  -0.55384743  0.1222949 ]]. Reward = [0.]
Curr episode timestep = 15
Scene graph at timestep 607 is [False, True, 3, True]
Human Feedback received at timestep 607 of -1
Current timestep = 608. State = [[-0.06005846  0.03259797  0.31700307  1.        ]]. Action = [[ 0.37750506 -0.10889274 -0.4790895   0.03976917]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 609. State = [[-0.04973196  0.02995149  0.29996678  1.        ]]. Action = [[-0.4182557  -0.1745714  -0.86787915  0.04381478]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 610. State = [[-0.04738566  0.02076755  0.27561906  1.        ]]. Action = [[ 0.5440024  -0.2862283  -1.0953391   0.08293009]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 611. State = [[-0.0307191   0.01424706  0.24920188  1.        ]]. Action = [[0.4926169  0.01084757 0.7037649  0.02791619]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 612. State = [[-0.02130827  0.01384539  0.25511718  1.        ]]. Action = [[ 0.7074697  -0.02794451 -0.86602616 -0.02530032]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 613. State = [[-0.02134753  0.01383953  0.2548001   1.        ]]. Action = [[ 0.30412567 -0.2532254  -0.9139682  -0.06221187]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 614. State = [[-0.02134753  0.01383953  0.2548001   1.        ]]. Action = [[ 0.82594347 -0.26536107 -0.7313409  -0.04902297]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 615. State = [[-0.2619246  -0.09335577  0.11540327  1.        ]]. Action = [[ 0.5243361  -0.17081505  0.8093419  -0.0509007 ]]. Reward = [100.]
Curr episode timestep = 23
Current timestep = 616. State = [[-0.2537769  -0.10141967  0.10396616  1.        ]]. Action = [[0.8035079  0.32574117 0.49180984 0.9930533 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 616 is [False, True, 3, False]
Human Feedback received at timestep 616 of 1
Current timestep = 617. State = [[-0.2351074  -0.09545458  0.11768242  1.        ]]. Action = [[0.43230236 0.292773   1.0334287  0.9922123 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 618. State = [[-0.21533558 -0.08394531  0.15535194  1.        ]]. Action = [[0.63276744 0.43650794 1.1848326  0.99362516]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 619. State = [[-0.19523376 -0.06963324  0.18633898  1.        ]]. Action = [[ 0.27201176  0.260208   -0.0708065   0.9887712 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 620. State = [[-0.17762202 -0.06096366  0.20662388  1.        ]]. Action = [[0.4008968  0.1305207  1.3276763  0.97481394]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 621. State = [[-0.16663316 -0.05732011  0.23754808  1.        ]]. Action = [[ 0.642267   -0.04010248  0.1517644   0.7729373 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 622. State = [[-0.1537322  -0.05759234  0.25456914  1.        ]]. Action = [[ 0.6285355  -0.09272569  1.2369196   0.75683117]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 623. State = [[-0.13479233 -0.0588545   0.28861812  1.        ]]. Action = [[ 0.4338051  -0.10934889 -0.08415663  0.8755615 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 624. State = [[-0.12194632 -0.0602077   0.29024222  1.        ]]. Action = [[ 0.6322341  -0.02591753 -0.5488509   0.55996656]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 625. State = [[-0.09469457 -0.06118589  0.2769434   1.        ]]. Action = [[ 0.710191    0.02608812 -0.07618237  0.52307105]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 625 is [False, True, 3, True]
Human Feedback received at timestep 625 of -1
Current timestep = 626. State = [[-0.07445634 -0.05904942  0.27329132  1.        ]]. Action = [[-0.45212096  0.187258   -0.23314178  0.25823236]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 627. State = [[-0.0757808  -0.05696969  0.27222785  1.        ]]. Action = [[ 0.63153744  0.14627194 -1.011784    0.10525703]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 628. State = [[-0.07630264 -0.05387967  0.2702901   1.        ]]. Action = [[ 0.29723048  0.19019663 -0.05472863  0.161165  ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 629. State = [[-0.06598791 -0.0512553   0.2795447   1.        ]]. Action = [[ 0.72158027 -0.05794191  1.1907599   0.0441072 ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 630. State = [[-0.04252043 -0.05034747  0.31617764  1.        ]]. Action = [[ 0.5852952  -0.03209269  0.9117353   0.07734084]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 631. State = [[-0.2624765   0.00500528  0.11696272  1.        ]]. Action = [[ 0.61137164 -0.00276512  0.36053848 -0.03236514]]. Reward = [100.]
Curr episode timestep = 15
Current timestep = 632. State = [[-0.25316066  0.00359993  0.11368135  1.        ]]. Action = [[ 0.7156478  -0.22401965  1.218704    0.9749402 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 632 is [False, True, 3, False]
Human Feedback received at timestep 632 of 1
Current timestep = 633. State = [[-0.22921157 -0.00184435  0.14514868  1.        ]]. Action = [[ 0.7969265  -0.18877977  0.91816735  0.9975637 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 634. State = [[-0.19955024 -0.00623642  0.1837226   1.        ]]. Action = [[ 0.53723323 -0.06913334  1.2002714   0.99025285]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 635. State = [[-0.18427211 -0.00721032  0.21255751  1.        ]]. Action = [[ 0.7691908  -0.09996229  0.43832302  0.8841481 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 636. State = [[-0.1753294  -0.00892543  0.22931468  1.        ]]. Action = [[ 0.19686711 -0.07865441  1.348455    0.8143306 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 637. State = [[-0.16354279 -0.0137682   0.2791124   1.        ]]. Action = [[ 0.5582218  -0.21041346  0.95040274  0.83779895]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 638. State = [[-0.14401555 -0.02034724  0.30591142  1.        ]]. Action = [[ 0.45330548 -0.16549218 -0.16391397  0.7615981 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 639. State = [[-0.13229235 -0.0226779   0.31474805  1.        ]]. Action = [[ 0.20603919 -0.01043874  0.2868755   0.55114675]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 640. State = [[-0.11892114 -0.02430164  0.32838413  1.        ]]. Action = [[ 0.6570473  -0.08167189  0.4957037   0.3962115 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 641. State = [[-0.09408157 -0.03068072  0.35627502  1.        ]]. Action = [[ 0.7314669  -0.27736282  1.0020988   0.0975312 ]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 641 is [False, True, 3, True]
Human Feedback received at timestep 641 of -1
Current timestep = 642. State = [[-0.06305469 -0.0377387   0.38644224  1.        ]]. Action = [[0.883971   0.00439358 0.2219119  0.00766492]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 642 is [False, True, 3, True]
Human Feedback received at timestep 642 of -1
Current timestep = 643. State = [[-0.03642492 -0.03767736  0.38624686  1.        ]]. Action = [[ 0.585963   -0.00342548 -0.7831081   0.04688859]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 644. State = [[-0.0153911  -0.03700141  0.35993075  1.        ]]. Action = [[ 0.66918087  0.05321133 -0.8215859   0.02822292]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 645. State = [[-0.27258587  0.12066288  0.13723496  1.        ]]. Action = [[-0.13519341  0.00893593 -0.9957874  -0.0612005 ]]. Reward = [100.]
Curr episode timestep = 13
Current timestep = 646. State = [[-0.2583328   0.13066052  0.13039055  1.        ]]. Action = [[ 0.705307  -0.384273   0.9002433  0.9616115]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 646 is [False, True, 3, False]
Human Feedback received at timestep 646 of 1
Current timestep = 647. State = [[-0.2280955   0.1192638   0.15590602  1.        ]]. Action = [[ 0.8270222  -0.41174936  1.3326664   0.88600206]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 648. State = [[-0.20028262  0.10670299  0.2027973   1.        ]]. Action = [[ 0.68742406 -0.33950317  0.8320997   0.89328957]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 649. State = [[-0.16955538  0.09467894  0.24008416  1.        ]]. Action = [[ 0.8784821  -0.3489594   0.98323774  0.84486175]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 650. State = [[-0.13717473  0.08248127  0.26855794  1.        ]]. Action = [[ 0.8321936  -0.31642044 -0.01736403  0.76276994]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 651. State = [[-0.109791    0.06967642  0.2709623   1.        ]]. Action = [[ 0.83483243 -0.38602906 -0.38878584  0.24005604]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 652. State = [[-0.0794137   0.05673783  0.271766    1.        ]]. Action = [[ 0.47769094 -0.27576917  0.521451    0.10702455]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 652 is [False, True, 3, True]
Human Feedback received at timestep 652 of -1
Current timestep = 653. State = [[-0.05887252  0.04608392  0.28831875  1.        ]]. Action = [[ 0.653584   -0.1820594   0.13755345  0.00806355]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 654. State = [[-0.03405524  0.03827126  0.2933592   1.        ]]. Action = [[ 0.5830612  -0.3271528   0.28840566  0.00528121]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 655. State = [[-0.01693358  0.02630105  0.2935614   1.        ]]. Action = [[ 0.9131131  -0.16885716 -1.1245668   0.01423526]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 656. State = [[-0.2682599   0.14182262  0.11552004  1.        ]]. Action = [[ 0.56865644 -0.22207606  0.37465882 -0.0278638 ]]. Reward = [100.]
Curr episode timestep = 10
Current timestep = 657. State = [[-0.25472504  0.15317608  0.11407275  1.        ]]. Action = [[ 0.5954473  -0.36114693  1.335238    0.9789616 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 657 is [False, True, 3, False]
Human Feedback received at timestep 657 of 1
Current timestep = 658. State = [[-0.2335232   0.14127745  0.1499417   1.        ]]. Action = [[ 0.410663   -0.36850452  0.9727874   0.9799268 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 659. State = [[-0.21194956  0.12756187  0.19177425  1.        ]]. Action = [[ 0.81589615 -0.51377916  1.395978    0.93525124]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 660. State = [[-0.19039977  0.11418767  0.2349911   1.        ]]. Action = [[ 0.12845016 -0.28551674  0.55865526  0.89049983]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 661. State = [[-0.17585693  0.10087287  0.26519126  1.        ]]. Action = [[ 0.46841407 -0.43435305  0.93432283  0.8071002 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 662. State = [[-0.15385619  0.08696563  0.3021784   1.        ]]. Action = [[ 0.70493007 -0.31149364  0.91782     0.6734376 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 663. State = [[-0.12868597  0.07374505  0.32510668  1.        ]]. Action = [[ 0.8891566  -0.37769544 -0.28091443  0.24238443]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 664. State = [[-0.11191191  0.0620811   0.32267046  1.        ]]. Action = [[-0.20958531 -0.30574864 -0.1383605   0.150262  ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 665. State = [[-0.10341927  0.04841202  0.32416177  1.        ]]. Action = [[ 0.787192   -0.3339789   0.07785177  0.14276016]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 666. State = [[-0.08036415  0.03871339  0.32460913  1.        ]]. Action = [[ 0.63288736 -0.12737548  0.09177065  0.13318539]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 666 is [False, True, 3, True]
Human Feedback received at timestep 666 of -1
Current timestep = 667. State = [[-0.05781014  0.03130503  0.3323253   1.        ]]. Action = [[ 0.16196525 -0.22809577  0.28306556  0.06021941]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 668. State = [[-0.04551975  0.02446613  0.34180355  1.        ]]. Action = [[ 0.7529571  -0.11840415  0.2570815   0.03243768]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 669. State = [[-0.02435923  0.01968567  0.34581226  1.        ]]. Action = [[ 0.43680704 -0.08302522 -0.1899066   0.0280627 ]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 670. State = [[-0.00415833  0.01360282  0.3472169   1.        ]]. Action = [[ 0.53277063 -0.21988147  0.27571154  0.01006579]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 671. State = [[-0.2724894   0.05878945  0.12157051  1.        ]]. Action = [[ 0.8984071  -0.14379972 -0.5378127  -0.02630025]]. Reward = [100.]
Curr episode timestep = 14
Current timestep = 672. State = [[-0.25788397  0.05779669  0.13419774  1.        ]]. Action = [[ 0.79394615 -0.2061007   1.6426752   0.98856854]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 672 is [False, True, 3, False]
Human Feedback received at timestep 672 of 1
Current timestep = 673. State = [[-0.23235467  0.05341493  0.18185425  1.        ]]. Action = [[ 0.6137371  -0.18842041  1.1951392   0.9889679 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 674. State = [[-0.20958196  0.04663567  0.2255858   1.        ]]. Action = [[ 0.40860534 -0.3200143   1.0174909   0.8996074 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 675. State = [[-0.19523293  0.0375661   0.26469553  1.        ]]. Action = [[ 0.08096159 -0.17030859  0.89059114  0.9458622 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 676. State = [[-0.183568    0.03231106  0.28410295  1.        ]]. Action = [[ 0.6619086  -0.08160514 -0.50831413  0.8454101 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 677. State = [[-0.16764218  0.02733723  0.28837234  1.        ]]. Action = [[ 0.268466   -0.26521355  0.5818019   0.72694397]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 678. State = [[-0.15690015  0.01798346  0.29133368  1.        ]]. Action = [[ 0.4504633  -0.18546182 -0.816849    0.47626746]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 679. State = [[-0.1368857   0.01104279  0.27442455  1.        ]]. Action = [[ 0.4819491  -0.23566324 -0.20368195  0.45447147]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 680. State = [[-0.11409671  0.00330055  0.27788934  1.        ]]. Action = [[ 0.7170911  -0.19374377  0.68985367  0.37011707]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 681. State = [[-0.09270508 -0.006242    0.29343712  1.        ]]. Action = [[ 0.5032697  -0.27778596  0.16958022  0.08148134]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 681 is [False, True, 3, True]
Human Feedback received at timestep 681 of -1
Current timestep = 682. State = [[-0.06881608 -0.01428701  0.30103165  1.        ]]. Action = [[ 0.66891897 -0.13825381  0.09947944  0.06758046]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 683. State = [[-0.0436615  -0.01732647  0.30228484  1.        ]]. Action = [[ 0.84603894  0.01261461 -0.03443718  0.09325361]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 684. State = [[-0.02586771 -0.01865766  0.29508725  1.        ]]. Action = [[-0.61141765 -0.0980354  -0.6681268   0.04305649]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 685. State = [[-0.02332176 -0.02504694  0.28292185  1.        ]]. Action = [[ 0.96832323 -0.13776779 -0.30099034  0.01827109]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 686. State = [[ 0.00295699 -0.02727547  0.26840055  1.        ]]. Action = [[ 0.72406805 -0.02335268 -0.01985335  0.04579079]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 687. State = [[ 0.02122768 -0.02783196  0.26414376  1.        ]]. Action = [[-0.15995121 -0.00646281 -0.03244364  0.02001989]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 688. State = [[-0.26310703 -0.04084362  0.11376438  1.        ]]. Action = [[ 0.5379126  -0.11672497 -0.2015264  -0.01519644]]. Reward = [100.]
Curr episode timestep = 16
Current timestep = 689. State = [[-0.25132775 -0.04746906  0.10885823  1.        ]]. Action = [[ 0.90618086 -0.00504035  1.0194595   0.9683864 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 689 is [False, True, 3, False]
Human Feedback received at timestep 689 of 1
Current timestep = 690. State = [[-0.22253808 -0.05012215  0.1374959   1.        ]]. Action = [[ 0.5601504  -0.02462357  1.2380142   0.8864353 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 691. State = [[-0.2066279  -0.05013283  0.17411093  1.        ]]. Action = [[0.24266076 0.18113315 0.38148642 0.9231715 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 692. State = [[-0.19060138 -0.04720557  0.20020263  1.        ]]. Action = [[0.36214185 0.12806833 1.2381682  0.9209583 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 693. State = [[-0.18065126 -0.04516993  0.23243289  1.        ]]. Action = [[0.8012328  0.05409741 0.1417563  0.86686826]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 694. State = [[-0.1804568  -0.04442371  0.23520172  1.        ]]. Action = [[ 0.35308993  0.08404541 -0.3846178   0.8768387 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 695. State = [[-0.17123711 -0.04418642  0.24141619  1.        ]]. Action = [[ 0.7560531  -0.03947508  0.2802403   0.8909321 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 696. State = [[-0.14651316 -0.04513611  0.26443738  1.        ]]. Action = [[ 0.5622997  -0.12125438  0.88222504  0.8179498 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 697. State = [[-0.12410851 -0.04522477  0.27804348  1.        ]]. Action = [[ 0.47007632  0.15360963 -0.6037042   0.493958  ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 698. State = [[-0.10987006 -0.04486251  0.2735422   1.        ]]. Action = [[ 0.20522201 -0.09589022  0.2098527   0.30664968]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 699. State = [[-0.09604473 -0.04598692  0.29551038  1.        ]]. Action = [[ 0.5085639  -0.04869592  1.4298823   0.16845441]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 699 is [False, True, 3, True]
Human Feedback received at timestep 699 of -1
Current timestep = 700. State = [[-0.07165588 -0.04727716  0.33135024  1.        ]]. Action = [[ 0.6230954  -0.05789059 -0.06949341  0.05172706]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 701. State = [[-0.05176901 -0.04584434  0.33115637  1.        ]]. Action = [[ 0.9119172   0.16511965 -0.1873728   0.01205611]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 702. State = [[-0.02152703 -0.04501231  0.32186672  1.        ]]. Action = [[ 0.8860227  -0.04906559 -0.3715824   0.04142594]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 703. State = [[-0.26775366  0.09855636  0.11946388  1.        ]]. Action = [[-0.08313179 -0.07978565 -0.44166017 -0.00089866]]. Reward = [100.]
Curr episode timestep = 14
Current timestep = 704. State = [[-0.24977453  0.10776429  0.11556402  1.        ]]. Action = [[ 0.9191239 -0.2838418  1.3745556  0.9678179]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 704 is [False, True, 3, False]
Human Feedback received at timestep 704 of 1
Current timestep = 705. State = [[-0.21728387  0.09949293  0.15879217  1.        ]]. Action = [[ 0.49593318 -0.29505444  1.6206827   0.8316145 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 706. State = [[-0.20576988  0.0897821   0.19420762  1.        ]]. Action = [[ 0.29052353 -0.32211554 -0.5454552   0.8858427 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 707. State = [[-0.20129058  0.08401858  0.19428308  1.        ]]. Action = [[ 0.8365805  -0.13611418  0.75129485  0.90066934]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 708. State = [[-0.20019819  0.08343562  0.19485417  1.        ]]. Action = [[ 0.6862979  -0.25627112  0.89302516  0.8425393 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 709. State = [[-0.19998291  0.08335277  0.19499482  1.        ]]. Action = [[ 0.72040987 -0.19958758  0.40506458  0.9065826 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 710. State = [[-0.19998291  0.08335277  0.19499482  1.        ]]. Action = [[ 0.7746968 -0.2735532 -0.7331259  0.8327272]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 711. State = [[-0.1892016   0.08212795  0.20527263  1.        ]]. Action = [[ 0.6833682  -0.06200314  0.89968395  0.8423438 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 712. State = [[-0.17168851  0.08041297  0.22102584  1.        ]]. Action = [[ 0.58742857 -0.28156024  0.5150745   0.7471123 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 713. State = [[-0.15703648  0.07393833  0.24131718  1.        ]]. Action = [[ 0.86214733 -0.37797678  1.5783117   0.6837673 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 714. State = [[-0.13505849  0.06771576  0.27983236  1.        ]]. Action = [[ 0.22901964 -0.34238684 -0.37706566  0.30465674]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 715. State = [[-0.12869984  0.06357624  0.28018108  1.        ]]. Action = [[ 0.27353752 -0.22483867 -0.52943254  0.1693703 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 716. State = [[-0.1167239  0.0537188  0.2802135  1.       ]]. Action = [[ 0.72940814 -0.31089747  0.30096054  0.12270141]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 717. State = [[-0.0897764   0.04601974  0.2823126   1.        ]]. Action = [[ 0.92659545 -0.15285331 -0.0294081   0.15559578]]. Reward = [0.]
Curr episode timestep = 13
Scene graph at timestep 717 is [False, True, 3, True]
Human Feedback received at timestep 717 of -1
Current timestep = 718. State = [[-0.0543872   0.03705464  0.2872057   1.        ]]. Action = [[ 0.8886125  -0.27092922  0.1090796   0.10562193]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 718 is [False, True, 3, True]
Human Feedback received at timestep 718 of -1
Current timestep = 719. State = [[-0.2634981  -0.0279886   0.11550763  1.        ]]. Action = [[ 0.37774277 -0.1920147  -0.06387651 -0.00473678]]. Reward = [100.]
Curr episode timestep = 15
Current timestep = 720. State = [[-0.2529892  -0.034176    0.10947916  1.        ]]. Action = [[ 0.8224176  -0.07362062  1.0089946   0.96344864]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 720 is [False, True, 3, False]
Human Feedback received at timestep 720 of 1
Current timestep = 721. State = [[-0.22625163 -0.04035161  0.12828884  1.        ]]. Action = [[0.74072325 0.06017947 0.34071994 0.8993368 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 722. State = [[-0.20178084 -0.0414883   0.14013948  1.        ]]. Action = [[ 0.5586935  -0.00106716  0.28388882  0.96452355]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 723. State = [[-0.17879939 -0.04231959  0.15460832  1.        ]]. Action = [[0.5597675  0.02146316 0.42046452 0.951689  ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 724. State = [[-0.16240847 -0.04238943  0.1647686   1.        ]]. Action = [[0.6886718  0.07182562 0.8886039  0.9162837 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 725. State = [[-0.16105375 -0.04246905  0.16559488  1.        ]]. Action = [[0.66842663 0.10615921 0.43997288 0.91749585]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 726. State = [[-0.16105375 -0.04246905  0.16559488  1.        ]]. Action = [[ 0.7976067  -0.05439997  0.91889954  0.9171388 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 727. State = [[-0.16105375 -0.04246905  0.16559488  1.        ]]. Action = [[ 0.7108154  -0.07781547  1.0595984   0.8338219 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 728. State = [[-0.16113488 -0.04246372  0.16559142  1.        ]]. Action = [[ 0.61474085 -0.17030525  0.55153394  0.7913673 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 729. State = [[-0.16113488 -0.04246372  0.16559142  1.        ]]. Action = [[0.6032386  0.03943074 0.5526626  0.7817937 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 730. State = [[-0.16113488 -0.04246372  0.16559142  1.        ]]. Action = [[ 0.09465432 -0.1273964   0.84048486  0.9405334 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 731. State = [[-0.16113488 -0.04246372  0.16559142  1.        ]]. Action = [[ 0.63429487 -0.15658575  1.1949687   0.8315909 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 732. State = [[-0.16113488 -0.04246372  0.16559142  1.        ]]. Action = [[0.84782124 0.16208076 1.1966856  0.82888365]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 733. State = [[-0.14814898 -0.04282923  0.18351775  1.        ]]. Action = [[ 0.64445245 -0.05956686  1.6005359   0.889616  ]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 734. State = [[-0.13425343 -0.04274755  0.22577111  1.        ]]. Action = [[ 0.53882    -0.02610344  0.92285204  0.8921926 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 735. State = [[-0.12386981 -0.0430287   0.23728016  1.        ]]. Action = [[ 0.5407784  -0.02043134  0.55053663  0.5759876 ]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 736. State = [[-0.1010645  -0.04307064  0.26384854  1.        ]]. Action = [[0.61560595 0.10493839 0.8879602  0.38769197]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 737. State = [[-0.08058413 -0.03965256  0.29818165  1.        ]]. Action = [[0.36843526 0.15506268 0.70927954 0.21063042]]. Reward = [0.]
Curr episode timestep = 17
Scene graph at timestep 737 is [False, True, 3, True]
Human Feedback received at timestep 737 of -1
Current timestep = 738. State = [[-0.06030091 -0.03505294  0.32523444  1.        ]]. Action = [[ 0.6117879  -0.0379079   0.23311615  0.10732567]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 739. State = [[-0.04731055 -0.03461501  0.33009246  1.        ]]. Action = [[ 0.46508336  0.01165783 -0.31774068  0.09519935]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 740. State = [[-0.02935436 -0.03431271  0.3178804   1.        ]]. Action = [[ 0.6878784   0.02264309 -0.49476564  0.050439  ]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 741. State = [[-0.00149137 -0.03272609  0.31528217  1.        ]]. Action = [[0.74070036 0.05571115 0.5986676  0.04234409]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 742. State = [[ 0.02166995 -0.03187153  0.32327905  1.        ]]. Action = [[ 0.27871776 -0.04037923 -0.15374494  0.00627923]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 743. State = [[-0.25918466 -0.10424343  0.11767687  1.        ]]. Action = [[ 0.03942847 -0.08468074  0.70081544 -0.02732736]]. Reward = [100.]
Curr episode timestep = 23
Current timestep = 744. State = [[-0.24990849 -0.11577337  0.11174467  1.        ]]. Action = [[0.7942774  0.19480574 0.95432854 0.9038991 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 744 is [False, True, 3, False]
Human Feedback received at timestep 744 of 1
Current timestep = 745. State = [[-0.22586717 -0.11117184  0.13627236  1.        ]]. Action = [[0.7577841  0.29013014 1.1534095  0.9480201 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 746. State = [[-0.19883779 -0.10154255  0.18078434  1.        ]]. Action = [[0.59241736 0.37873185 1.4275367  0.9279189 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 747. State = [[-0.1804277  -0.09223105  0.22063577  1.        ]]. Action = [[0.707603   0.12867188 0.9405875  0.93408465]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 748. State = [[-0.16941065 -0.09085333  0.23882215  1.        ]]. Action = [[0.5182204  0.04593933 1.039      0.79921794]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 749. State = [[-0.15020335 -0.08774102  0.2674973   1.        ]]. Action = [[0.5396304  0.17009044 0.13695669 0.66932285]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 750. State = [[-0.13624012 -0.08271774  0.29003382  1.        ]]. Action = [[0.03685486 0.14437294 0.98735714 0.61021185]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 751. State = [[-0.12805654 -0.07501519  0.3114488   1.        ]]. Action = [[ 0.05588865  0.15659118 -0.09032798  0.39957297]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 752. State = [[-0.1296638  -0.06472152  0.31466246  1.        ]]. Action = [[-0.1875025   0.33339787  0.3124361   0.11218965]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 753. State = [[-0.12530874 -0.05480936  0.32891354  1.        ]]. Action = [[0.63701177 0.2190826  0.36127615 0.21151066]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 754. State = [[-0.11409183 -0.04430289  0.3337444   1.        ]]. Action = [[ 0.79574025  0.2630223  -1.1392329   0.10294735]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 755. State = [[-0.08051616 -0.03844201  0.3044758   1.        ]]. Action = [[ 0.6994972   0.08291316 -0.2755264   0.0995729 ]]. Reward = [0.]
Curr episode timestep = 11
Scene graph at timestep 755 is [False, True, 3, True]
Human Feedback received at timestep 755 of -1
Current timestep = 756. State = [[-0.04652891 -0.03478959  0.2944602   1.        ]]. Action = [[ 0.86715984 -0.04181266 -0.02298748  0.07439375]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 757. State = [[-0.0191713 -0.0335453  0.2905517  1.       ]]. Action = [[ 0.7558404   0.11701167 -0.02301717  0.03867459]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 758. State = [[ 0.0120452  -0.03341071  0.3013074   1.        ]]. Action = [[ 0.91347635 -0.14409572  0.7647381   0.0235467 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 759. State = [[ 0.03520409 -0.0351299   0.31977338  1.        ]]. Action = [[-0.22817528 -0.09616852  0.14787698  0.01455712]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 760. State = [[-0.26237074 -0.17017296  0.1174635   1.        ]]. Action = [[-0.08396584 -0.03138381  0.8001981  -0.03766721]]. Reward = [100.]
Curr episode timestep = 16
Current timestep = 761. State = [[-0.25647768 -0.18451527  0.1126001   1.        ]]. Action = [[0.57193387 0.4638282  0.99347925 0.9585012 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 761 is [False, True, 3, False]
Human Feedback received at timestep 761 of 1
Current timestep = 762. State = [[-0.23803075 -0.16711387  0.13621932  1.        ]]. Action = [[0.5827553 0.6663424 1.1509628 0.9648402]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 763. State = [[-0.21700056 -0.14457846  0.17891975  1.        ]]. Action = [[0.5762501  0.598582   0.88952255 0.9734278 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 764. State = [[-0.18994188 -0.12774141  0.2136886   1.        ]]. Action = [[0.8266233  0.276088   1.1644373  0.94459677]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 765. State = [[-0.1675897  -0.11308676  0.24533428  1.        ]]. Action = [[ 0.04145503  0.41512942 -0.21570134  0.9167862 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 766. State = [[-0.15680653 -0.1005027   0.25584435  1.        ]]. Action = [[0.5101156  0.22833288 0.8129473  0.71798086]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 767. State = [[-0.13111885 -0.09151825  0.27206293  1.        ]]. Action = [[ 0.9411551   0.18211842 -0.32311487  0.8718802 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 768. State = [[-0.10617835 -0.08330441  0.26572144  1.        ]]. Action = [[ 0.8331642   0.28151512 -0.7048844   0.5880085 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 769. State = [[-0.06919428 -0.07245274  0.26855975  1.        ]]. Action = [[0.8137442  0.29201388 1.4141693  0.3729477 ]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 769 is [False, True, 3, True]
Human Feedback received at timestep 769 of -1
Current timestep = 770. State = [[-0.03626508 -0.06552733  0.30316707  1.        ]]. Action = [[ 0.648916   -0.12539297  0.0777905   0.07874334]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 771. State = [[-0.02144521 -0.0641339   0.2963254   1.        ]]. Action = [[ 0.7498126   0.07110047 -1.2131937   0.02773106]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 772. State = [[ 0.00703114 -0.06375325  0.2577129   1.        ]]. Action = [[ 0.7429669  -0.01304859 -0.91867924  0.01614964]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 773. State = [[ 0.04647705 -0.06487319  0.22971295  1.        ]]. Action = [[ 0.94585586 -0.00927514  0.16558719  0.03982282]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 774. State = [[-0.2697956   0.08876099  0.11365171  1.        ]]. Action = [[ 0.76479614  0.02994001  1.2347703  -0.02465767]]. Reward = [-10.]
Curr episode timestep = 13
Current timestep = 775. State = [[-0.2522052   0.09511845  0.1132682   1.        ]]. Action = [[ 0.8836491  -0.29143798  1.6078739   0.9609542 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 775 is [False, True, 3, False]
Human Feedback received at timestep 775 of 1
Current timestep = 776. State = [[-0.21737516  0.08536168  0.16408214  1.        ]]. Action = [[ 0.7461226  -0.41367835  1.728589    0.7042103 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 777. State = [[-0.18930878  0.07201754  0.22384846  1.        ]]. Action = [[ 0.88948584 -0.35739517  0.89405036  0.8242651 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 778. State = [[-0.16813387  0.06244598  0.25732195  1.        ]]. Action = [[-0.12138754 -0.1997248   0.6144004   0.60012364]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 779. State = [[-0.1554976   0.05045672  0.29087222  1.        ]]. Action = [[ 0.65243745 -0.47369033  1.3374262   0.20304096]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 780. State = [[-0.13103838  0.03647159  0.33092526  1.        ]]. Action = [[ 0.87988234 -0.2622571   0.24728608  0.14359295]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 781. State = [[-0.10942601  0.0259401   0.3359415   1.        ]]. Action = [[ 0.71064246 -0.23474884 -0.7737653   0.11431468]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 782. State = [[-0.08261102  0.01504042  0.3114925   1.        ]]. Action = [[ 0.84358907 -0.30811906 -1.0356932   0.11080027]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 782 is [False, True, 3, True]
Human Feedback received at timestep 782 of -1
Current timestep = 783. State = [[-0.04811802  0.00836943  0.28919923  1.        ]]. Action = [[ 0.2329675  -0.06252438  0.52348566  0.10035276]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 783 is [False, True, 3, True]
Human Feedback received at timestep 783 of -1
Current timestep = 784. State = [[-0.03598315  0.00600096  0.3073064   1.        ]]. Action = [[ 0.30867636 -0.04531765  0.74721193  0.05411601]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 785. State = [[-0.02591741  0.00200378  0.31662127  1.        ]]. Action = [[ 0.7928971  -0.16919386 -0.92920923  0.05672395]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 786. State = [[-2.2587415e-03 -9.9839864e-04  2.9365763e-01  1.0000000e+00]]. Action = [[ 0.1617465  -0.0034349  -0.12461066  0.00688183]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 787. State = [[ 0.01178478 -0.00634084  0.29749116  1.        ]]. Action = [[ 0.2747364  -0.25656307  0.6945987   0.08111739]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 788. State = [[ 0.01579792 -0.01056395  0.31609482  1.        ]]. Action = [[-0.8335916  -0.02010465  0.30575228  0.02567875]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 789. State = [[ 0.0135494  -0.01675184  0.32296354  1.        ]]. Action = [[ 0.48858786 -0.21421969 -0.0499357   0.01240098]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 790. State = [[-0.27048635  0.13604434  0.14252529  1.        ]]. Action = [[ 8.2158017e-01 -9.3289018e-02  2.1402836e-03 -7.0124865e-04]]. Reward = [100.]
Curr episode timestep = 15
Current timestep = 791. State = [[-0.25400284  0.13280568  0.15171225  1.        ]]. Action = [[ 0.901104   -0.40777647  1.3344064   0.8950677 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 791 is [False, True, 3, False]
Human Feedback received at timestep 791 of 1
Current timestep = 792. State = [[-0.22086658  0.11973892  0.19361562  1.        ]]. Action = [[ 0.8196919  -0.41301125  1.2522016   0.84145594]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 793. State = [[-0.1910942   0.10734782  0.23056023  1.        ]]. Action = [[ 0.89131975 -0.3217275   0.3016982   0.78497076]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 794. State = [[-0.17346321  0.09500334  0.24227083  1.        ]]. Action = [[-0.16772437 -0.4323809  -0.2972809   0.3852712 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 795. State = [[-0.16267148  0.08056808  0.24710143  1.        ]]. Action = [[ 0.75534797 -0.29144466  0.71098185  0.20480716]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 796. State = [[-0.13621822  0.0724628   0.26052907  1.        ]]. Action = [[ 0.7584312  -0.11288285 -0.14601064  0.14450526]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 797. State = [[-0.11729454  0.07070818  0.259897    1.        ]]. Action = [[ 0.5604327  -0.25593925 -0.6074419   0.20214391]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 798. State = [[-0.10737358  0.06490059  0.26931947  1.        ]]. Action = [[ 0.653517   -0.2989819   0.6923866   0.16526997]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 799. State = [[-0.08489395  0.05356809  0.28509167  1.        ]]. Action = [[ 0.73752284 -0.31477165 -0.15250325  0.14654219]]. Reward = [0.]
Curr episode timestep = 8
Scene graph at timestep 799 is [False, True, 3, True]
Human Feedback received at timestep 799 of -1
Current timestep = 800. State = [[-0.04929214  0.04301807  0.29627898  1.        ]]. Action = [[ 0.8026073  -0.17574614  0.95020485  0.22399509]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 801. State = [[-0.03066407  0.03418564  0.31513283  1.        ]]. Action = [[ 0.34432864 -0.28147125 -0.38944638  0.07630348]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 802. State = [[-0.01885979  0.02640475  0.296721    1.        ]]. Action = [[ 0.21984673 -0.09209394 -1.0229173   0.04984295]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 803. State = [[-0.00142008  0.01915249  0.2644129   1.        ]]. Action = [[ 0.83346975 -0.26750523 -0.8204422   0.05099928]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 804. State = [[0.02706389 0.0100189  0.244245   1.        ]]. Action = [[-0.0062651  -0.26131535  0.40663052  0.02964807]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 805. State = [[0.02888937 0.00298917 0.26027942 1.        ]]. Action = [[-0.7026616  -0.11747491  0.9836068   0.03248906]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 806. State = [[ 0.02789634 -0.00573207  0.30270496  1.        ]]. Action = [[ 6.7640543e-02 -1.6161609e-01  1.5479684e+00  8.5449219e-04]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 807. State = [[-0.26248762 -0.160377    0.11607268  1.        ]]. Action = [[ 0.7860048  -0.17000604 -0.69404364 -0.00555527]]. Reward = [100.]
Curr episode timestep = 16
Current timestep = 808. State = [[-0.2565785  -0.17420664  0.10122275  1.        ]]. Action = [[0.7583885  0.43470883 0.35846376 0.9824611 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 808 is [False, True, 3, False]
Human Feedback received at timestep 808 of 1
Current timestep = 809. State = [[-0.23242041 -0.157008    0.11241527  1.        ]]. Action = [[0.6347232  0.6020725  0.97169614 0.9922998 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 810. State = [[-0.20710732 -0.14139172  0.14968628  1.        ]]. Action = [[0.74804497 0.39604807 1.5277667  0.95801115]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 811. State = [[-0.18691556 -0.13163978  0.19071579  1.        ]]. Action = [[0.80545986 0.41075397 1.487874   0.97068787]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 812. State = [[-0.1745909  -0.1259986   0.21005438  1.        ]]. Action = [[0.5797131  0.2697935  0.98809576 0.923818  ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 813. State = [[-0.1596634  -0.12082524  0.2341894   1.        ]]. Action = [[0.9117751  0.4573561  0.17937279 0.920802  ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 814. State = [[-0.145827   -0.11703144  0.24637721  1.        ]]. Action = [[0.8673451  0.2113992  0.59502006 0.8969569 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 815. State = [[-0.12137159 -0.10510571  0.2805807   1.        ]]. Action = [[0.2912259  0.39164662 1.3447173  0.8254459 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 816. State = [[-0.10146215 -0.08749522  0.33093145  1.        ]]. Action = [[0.44857907 0.514364   1.3172112  0.37728286]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 817. State = [[-0.08640753 -0.07232507  0.3569966   1.        ]]. Action = [[ 0.7259662   0.24478137 -0.8952639   0.08642232]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 817 is [False, True, 3, True]
Human Feedback received at timestep 817 of -1
Current timestep = 818. State = [[-0.05663348 -0.06606116  0.3504624   1.        ]]. Action = [[0.6308203  0.03891909 0.53139734 0.10224068]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 819. State = [[-0.0401038  -0.06198687  0.35985112  1.        ]]. Action = [[ 0.7040732   0.12841082 -0.36672425  0.02435243]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 820. State = [[-0.01437218 -0.05765164  0.35192466  1.        ]]. Action = [[0.40971255 0.14687717 0.14384437 0.01358974]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 821. State = [[-0.25953174 -0.13420062  0.11608406  1.        ]]. Action = [[ 0.33973062 -0.11853451 -0.34622526 -0.00886112]]. Reward = [100.]
Curr episode timestep = 13
Current timestep = 822. State = [[-0.25180086 -0.14687352  0.11337449  1.        ]]. Action = [[0.6919583  0.36900473 1.3578556  0.98167324]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 822 is [False, True, 3, False]
Human Feedback received at timestep 822 of 1
Current timestep = 823. State = [[-0.22861299 -0.13542244  0.15097947  1.        ]]. Action = [[0.8195393  0.48156786 1.2919388  0.97315526]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 824. State = [[-0.20304124 -0.1207249   0.19584319  1.        ]]. Action = [[0.43652844 0.30442238 0.95936775 0.96565056]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 825. State = [[-0.18738483 -0.1139548   0.22165078  1.        ]]. Action = [[ 0.82980204  0.49204087 -0.49702883  0.8928015 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 826. State = [[-0.17439361 -0.10613865  0.23254628  1.        ]]. Action = [[0.7029656 0.4103881 0.6051965 0.9292704]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 827. State = [[-0.15756778 -0.09786129  0.25040168  1.        ]]. Action = [[ 0.82715654  0.25145078 -0.03688109  0.9354131 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 828. State = [[-0.1563864  -0.09705679  0.25160825  1.        ]]. Action = [[ 0.04680634  0.22708583 -0.470497    0.5725212 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 829. State = [[-0.15194152 -0.09698019  0.25841746  1.        ]]. Action = [[ 0.31610286 -0.00992054  0.5524788   0.71857405]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 830. State = [[-0.130496   -0.09686854  0.28344798  1.        ]]. Action = [[0.7999697  0.05718601 0.8786955  0.6389123 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 831. State = [[-0.10911353 -0.09197222  0.3112219   1.        ]]. Action = [[0.22688675 0.24124944 0.09086895 0.20758343]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 832. State = [[-0.09806395 -0.08197979  0.32538432  1.        ]]. Action = [[0.49850976 0.304708   0.49449825 0.1407448 ]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 832 is [False, True, 3, True]
Human Feedback received at timestep 832 of 1
Current timestep = 833. State = [[-0.07619902 -0.06822302  0.35169277  1.        ]]. Action = [[0.8101517  0.32178903 0.62568855 0.10937774]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 834. State = [[-0.05788727 -0.06168883  0.37760308  1.        ]]. Action = [[-0.3563044   0.03490877  0.86553645  0.09977591]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 835. State = [[-0.05844473 -0.05461655  0.39406115  1.        ]]. Action = [[-0.3604262   0.25931203 -0.15081263  0.12343192]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 836. State = [[-0.06288577 -0.04446415  0.39184397  1.        ]]. Action = [[-0.01405323  0.22650218 -0.43001413  0.0222261 ]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 837. State = [[-0.06723341 -0.03600091  0.37728238  1.        ]]. Action = [[ 0.63926744  0.15873301 -1.8471801   0.08952582]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 838. State = [[-0.05603502 -0.03294922  0.32223523  1.        ]]. Action = [[0.7318467  0.21585321 0.949723   0.03161144]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 839. State = [[-0.04730358 -0.03170962  0.3130802   1.        ]]. Action = [[ 0.7577965   0.00891888 -0.03189206  0.10258198]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 840. State = [[-0.03120865 -0.03131243  0.29999298  1.        ]]. Action = [[-0.11349452 -0.05092305 -0.85825706  0.05140603]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 841. State = [[-0.03002412 -0.02981964  0.2831238   1.        ]]. Action = [[-0.40920174  0.13315105  0.09754038  0.09057629]]. Reward = [0.]
Curr episode timestep = 19
Current timestep = 842. State = [[-0.02936325 -0.02847047  0.27800298  1.        ]]. Action = [[ 0.56848776  0.02848756 -0.41633248  0.06077659]]. Reward = [0.]
Curr episode timestep = 20
Current timestep = 843. State = [[-0.02673221 -0.02806164  0.2677463   1.        ]]. Action = [[ 0.75096154  0.04181087 -0.91533613  0.06664121]]. Reward = [0.]
Curr episode timestep = 21
Current timestep = 844. State = [[-0.01524001 -0.02855928  0.27540892  1.        ]]. Action = [[ 0.8606305  -0.10767722  0.50881004  0.06303382]]. Reward = [0.]
Curr episode timestep = 22
Current timestep = 845. State = [[ 0.00922866 -0.03228711  0.28490227  1.        ]]. Action = [[ 0.7020323  -0.21480227  0.37900925  0.01309931]]. Reward = [0.]
Curr episode timestep = 23
Current timestep = 846. State = [[ 0.03611368 -0.03654752  0.3044427   1.        ]]. Action = [[ 0.61704266 -0.09142518  0.7877464   0.0251894 ]]. Reward = [0.]
Curr episode timestep = 24
Current timestep = 847. State = [[-0.27165774  0.07015028  0.13559702  1.        ]]. Action = [[ 0.04268348 -0.05630362 -0.03148067 -0.03887087]]. Reward = [100.]
Curr episode timestep = 25
Current timestep = 848. State = [[-0.25731418  0.07681321  0.13164352  1.        ]]. Action = [[ 0.78075385 -0.2182715   1.2488022   0.887861  ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 848 is [False, True, 3, False]
Human Feedback received at timestep 848 of 1
Current timestep = 849. State = [[-0.23320028  0.07052108  0.17064488  1.        ]]. Action = [[ 0.21668065 -0.21177745  1.4899993   0.7696414 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 850. State = [[-0.21890564  0.06517496  0.21828307  1.        ]]. Action = [[ 0.75682867 -0.19077331  0.72786283  0.8557973 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 851. State = [[-0.19170962  0.05960384  0.2485911   1.        ]]. Action = [[ 0.64931846 -0.16147548  0.64283156  0.6638384 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 852. State = [[-0.173079    0.05607346  0.26761463  1.        ]]. Action = [[ 0.8545041  -0.1357044  -0.3806604   0.14103198]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 853. State = [[-0.16400477  0.04986416  0.27573955  1.        ]]. Action = [[ 0.4638369  -0.34266615  0.35410953  0.15774155]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 854. State = [[-0.14587387  0.0430767   0.29007608  1.        ]]. Action = [[ 0.8663627  -0.03552949  0.17913628  0.2112248 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 855. State = [[-0.12342911  0.03712201  0.28892     1.        ]]. Action = [[ 0.4902935  -0.2953232  -0.67753637  0.15608561]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 856. State = [[-0.10193734  0.03105728  0.2702722   1.        ]]. Action = [[ 0.43916392 -0.09160244 -0.4539863   0.16426373]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 857. State = [[-0.07944601  0.02520801  0.25916386  1.        ]]. Action = [[ 0.6810751  -0.21437186 -0.04472649  0.07226682]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 857 is [False, True, 3, True]
Human Feedback received at timestep 857 of -1
Current timestep = 858. State = [[-0.05660107  0.01903565  0.25915146  1.        ]]. Action = [[ 0.47696388 -0.12044144  0.1943152   0.12768126]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 858 is [False, True, 3, True]
Human Feedback received at timestep 858 of -1
Current timestep = 859. State = [[-0.04271298  0.0155503   0.26381302  1.        ]]. Action = [[-0.08203727 -0.27915215 -0.78798854  0.01792753]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 860. State = [[-0.03470404  0.01381487  0.26925915  1.        ]]. Action = [[ 0.7739711  -0.08603525  0.33904028  0.04128885]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 861. State = [[-0.00976471  0.00809248  0.27647123  1.        ]]. Action = [[ 0.7621367  -0.22990394  0.09919524  0.06518137]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 862. State = [[2.0495251e-02 9.3943084e-04 2.8990149e-01 1.0000000e+00]]. Action = [[ 0.49882102 -0.1721412   0.68280816  0.03635347]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 863. State = [[-0.26886174  0.09898049  0.11699469  1.        ]]. Action = [[ 0.07110763 -0.11072099  0.5016537  -0.05337155]]. Reward = [100.]
Curr episode timestep = 15
Current timestep = 864. State = [[-0.25092983  0.10751118  0.11454698  1.        ]]. Action = [[ 0.8857837 -0.2392239  1.5782919  0.8602716]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 864 is [False, True, 3, False]
Human Feedback received at timestep 864 of 1
Current timestep = 865. State = [[-0.2173997   0.09761177  0.1635745   1.        ]]. Action = [[ 0.81423473 -0.4421177   1.3403134   0.8559818 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 866. State = [[-0.18884856  0.08596788  0.21136166  1.        ]]. Action = [[ 0.7648256  -0.31608713  1.0564961   0.7774681 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 867. State = [[-0.16695747  0.08007637  0.23990577  1.        ]]. Action = [[ 0.5514109  -0.26934206  0.21968603  0.27056694]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 868. State = [[-0.16336595  0.0780337   0.24372533  1.        ]]. Action = [[ 0.44943738 -0.4182219  -0.10095513  0.178164  ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 869. State = [[-0.1536819   0.07315625  0.2570002   1.        ]]. Action = [[ 0.6757637  -0.2661112   0.8419037   0.13823783]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 870. State = [[-0.13825543  0.07013749  0.27837798  1.        ]]. Action = [[ 0.42865467 -0.25577652 -0.6876161   0.17979324]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 871. State = [[-0.13769744  0.06879236  0.27923274  1.        ]]. Action = [[ 0.94516826 -0.14481169 -0.93633103  0.17945862]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 872. State = [[-0.13311784  0.06440773  0.288008    1.        ]]. Action = [[ 0.20608687 -0.24005497  0.6478586   0.10714734]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 873. State = [[-0.11458772  0.05372595  0.31223768  1.        ]]. Action = [[ 0.91470885 -0.40835863  0.5262561   0.16187847]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 874. State = [[-0.09142087  0.04197216  0.32810795  1.        ]]. Action = [[ 0.76449084 -0.27726257 -0.20783293  0.12112153]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 874 is [False, True, 3, True]
Human Feedback received at timestep 874 of -1
Current timestep = 875. State = [[-0.0647833   0.03100094  0.31931347  1.        ]]. Action = [[ 0.51200104 -0.16491514 -1.2484797   0.09790695]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 876. State = [[-0.04449027  0.0234702   0.2904178   1.        ]]. Action = [[ 0.412318   -0.2571566   0.19542766  0.10789418]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 877. State = [[-0.02916323  0.01985823  0.2863275   1.        ]]. Action = [[ 0.4358008   0.00547087 -0.143605    0.11364698]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 878. State = [[-0.00751895  0.0163459   0.29471615  1.        ]]. Action = [[ 0.67822766 -0.11402565  0.9234004   0.09071493]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 879. State = [[-2.6435733e-01  9.8558306e-04  1.1497254e-01  1.0000000e+00]]. Action = [[ 0.31429923 -0.2772231   0.8616612  -0.00209218]]. Reward = [100.]
Curr episode timestep = 15
Current timestep = 880. State = [[-0.260579   -0.00155616  0.10968477  1.        ]]. Action = [[ 0.3356216  -0.11010826  1.1697738   0.8399658 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 880 is [False, True, 3, False]
Human Feedback received at timestep 880 of 1
Current timestep = 881. State = [[-0.24479626 -0.00809587  0.14469746  1.        ]]. Action = [[ 0.61529565 -0.10778952  1.3126581   0.9046509 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 882. State = [[-0.22141191 -0.01165477  0.19224215  1.        ]]. Action = [[ 0.84337676 -0.15483582  1.1897125   0.9080825 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 883. State = [[-0.18852568 -0.01476572  0.23472643  1.        ]]. Action = [[0.77489114 0.03415477 0.8204205  0.69671834]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 884. State = [[-0.16565637 -0.01521741  0.25929648  1.        ]]. Action = [[ 0.8936596  -0.01090848 -0.11479676  0.7186203 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 885. State = [[-0.16399737 -0.01705364  0.26156795  1.        ]]. Action = [[-0.2166546  -0.13264829 -0.10504007  0.25051904]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 886. State = [[-0.16436918 -0.01870716  0.2615878   1.        ]]. Action = [[ 0.546515   -0.22156435 -0.6136632   0.17265916]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 887. State = [[-0.15658735 -0.01882599  0.27458712  1.        ]]. Action = [[0.6739428  0.08720636 1.1190023  0.19870806]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 888. State = [[-0.13807976 -0.01811446  0.29112607  1.        ]]. Action = [[ 0.70520306 -0.00508255 -0.8475592   0.11692822]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 889. State = [[-0.1161238  -0.01893538  0.2891775   1.        ]]. Action = [[ 0.5595094  -0.12894928  0.5641961   0.11481285]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 890. State = [[-0.09833173 -0.01779244  0.29258072  1.        ]]. Action = [[ 0.8313334   0.14307821 -0.8435291   0.11429822]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 890 is [False, True, 3, True]
Human Feedback received at timestep 890 of 1
Current timestep = 891. State = [[-0.06109767 -0.01775992  0.26941136  1.        ]]. Action = [[ 0.63323545 -0.08243698 -0.02593541  0.09571815]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 892. State = [[-0.04169084 -0.02024633  0.26320422  1.        ]]. Action = [[ 0.7232965  -0.12584138 -0.55830467  0.10275245]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 893. State = [[-0.01740965 -0.02395906  0.24899952  1.        ]]. Action = [[ 0.15531838 -0.16040796  0.02934074  0.07027924]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 894. State = [[-0.0018389  -0.02828483  0.25745782  1.        ]]. Action = [[ 0.5703888  -0.1352117   0.6129749   0.04576242]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 895. State = [[ 0.01779696 -0.03356188  0.28326273  1.        ]]. Action = [[ 0.66910386 -0.18005937  0.7641916   0.02837408]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 896. State = [[-0.26812324  0.06734908  0.11943915  1.        ]]. Action = [[-0.67907655  0.04696214  0.35529518 -0.00792432]]. Reward = [100.]
Curr episode timestep = 16
Current timestep = 897. State = [[-0.2538567   0.07303005  0.11654054  1.        ]]. Action = [[ 0.79918027 -0.2401635   1.1960402   0.8606522 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 897 is [False, True, 3, False]
Human Feedback received at timestep 897 of 1
Current timestep = 898. State = [[-0.22519809  0.06595783  0.1498302   1.        ]]. Action = [[ 0.48535657 -0.2557271   1.2807117   0.8416755 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 899. State = [[-0.20431294  0.05896036  0.19917423  1.        ]]. Action = [[ 0.6468954  -0.20941198  1.5084181   0.72692394]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 900. State = [[-0.17274243  0.04875352  0.25912595  1.        ]]. Action = [[ 0.83561003 -0.3339095   1.053947    0.6160085 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 901. State = [[-0.14781821  0.03888204  0.29410347  1.        ]]. Action = [[ 0.32081568 -0.29548603  0.5322685   0.12532687]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 902. State = [[-0.12921989  0.02974348  0.31287178  1.        ]]. Action = [[ 0.72989726 -0.20485055  0.09311152  0.09895945]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 903. State = [[-0.10637647  0.02380648  0.32170197  1.        ]]. Action = [[ 0.7412511  -0.14104933  0.03807449  0.13130212]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 904. State = [[-0.08205584  0.02071028  0.33456984  1.        ]]. Action = [[ 0.50325584 -0.07956427  0.801944    0.13735688]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 904 is [False, True, 3, True]
Human Feedback received at timestep 904 of -1
Current timestep = 905. State = [[-0.06611089  0.01238171  0.353097    1.        ]]. Action = [[-0.17287743 -0.29870522 -0.42605352  0.12867105]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 906. State = [[-0.06441999  0.00426006  0.34429848  1.        ]]. Action = [[ 0.25032783 -0.21607697 -0.20337522  0.09847188]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 907. State = [[-0.05469465 -0.00444817  0.34699115  1.        ]]. Action = [[ 0.42111945 -0.19846445  0.75022054  0.1258682 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 908. State = [[-0.04044161 -0.00836886  0.35771814  1.        ]]. Action = [[ 0.6429434   0.02348268 -0.18765342  0.11234593]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 909. State = [[-0.01770746 -0.00653807  0.35213068  1.        ]]. Action = [[ 0.5946872   0.05829811 -0.17629504  0.06087291]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 910. State = [[ 0.00211149 -0.00936333  0.34152836  1.        ]]. Action = [[ 0.6577616  -0.15990049 -0.5713215   0.00182664]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 911. State = [[-0.26519158 -0.02689387  0.11511871  1.        ]]. Action = [[ 0.7400923  -0.00805509 -0.6633408  -0.02029634]]. Reward = [100.]
Curr episode timestep = 14
Current timestep = 912. State = [[-0.25674596 -0.03182157  0.10317959  1.        ]]. Action = [[ 0.8284569  -0.00430179  0.26401186  0.8442688 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 912 is [False, True, 3, False]
Human Feedback received at timestep 912 of 1
Current timestep = 913. State = [[-0.22811598 -0.03537298  0.11721822  1.        ]]. Action = [[ 0.90198827 -0.07740372  1.4099321   0.62665355]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 914. State = [[-0.19542307 -0.03809063  0.15868343  1.        ]]. Action = [[ 0.85999274 -0.00153333  0.86004066  0.80224586]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 915. State = [[-0.17053883 -0.03908494  0.18177588  1.        ]]. Action = [[0.8482832  0.10019815 0.99715614 0.8209593 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 916. State = [[-0.16710936 -0.03925038  0.1840653   1.        ]]. Action = [[ 0.7515149  -0.05428559  0.6363406   0.7426219 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 917. State = [[-0.1653984  -0.03932286  0.18516289  1.        ]]. Action = [[ 0.5008073  -0.09138024  0.7926016   0.7265991 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 918. State = [[-0.15631302 -0.04140011  0.20168915  1.        ]]. Action = [[ 0.5098734  -0.12806958  1.2274408   0.6403289 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 919. State = [[-0.13449958 -0.04237315  0.24145621  1.        ]]. Action = [[0.83473706 0.05847812 0.67115974 0.5170604 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 920. State = [[-0.11303481 -0.04254686  0.26252604  1.        ]]. Action = [[ 0.39402926 -0.10083652 -0.7276468   0.12090755]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 921. State = [[-0.09905397 -0.04226845  0.27629974  1.        ]]. Action = [[ 0.9396596  -0.04799438  0.8008807   0.09963679]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 921 is [False, True, 3, True]
Human Feedback received at timestep 921 of 1
Current timestep = 922. State = [[-0.06775939 -0.04153989  0.3065263   1.        ]]. Action = [[0.7914591  0.08014214 0.24552345 0.12278461]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 923. State = [[-0.04215316 -0.03800972  0.30954763  1.        ]]. Action = [[ 0.80699515  0.21604764 -0.23986888  0.1038034 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 924. State = [[-0.01763322 -0.03429148  0.31393617  1.        ]]. Action = [[-0.02293944  0.09719098  0.609704    0.04932261]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 925. State = [[-0.00372215 -0.0332443   0.33051053  1.        ]]. Action = [[ 0.8594917  -0.11553961  0.30686235  0.01584005]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 926. State = [[-0.2622525  -0.06026333  0.11744133  1.        ]]. Action = [[ 0.9186456   0.05361521 -0.15315938 -0.00526625]]. Reward = [100.]
Curr episode timestep = 14
Current timestep = 927. State = [[-0.25132254 -0.06944533  0.11311027  1.        ]]. Action = [[0.84360516 0.0294286  1.6076033  0.9463651 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 927 is [False, True, 3, False]
Human Feedback received at timestep 927 of 1
Current timestep = 928. State = [[-0.22534499 -0.07167026  0.15454493  1.        ]]. Action = [[ 0.69889474 -0.07155871  0.46395183  0.95442295]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 929. State = [[-0.19891731 -0.07042415  0.17466243  1.        ]]. Action = [[0.73967314 0.31773782 0.5277405  0.8427794 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 930. State = [[-0.17810182 -0.06837241  0.18842871  1.        ]]. Action = [[0.56115794 0.02152109 0.48315334 0.8298068 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 931. State = [[-0.17686127 -0.06752615  0.18896142  1.        ]]. Action = [[ 0.7054546   0.4837494  -0.0891664   0.84174466]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 932. State = [[-0.16449548 -0.06523222  0.205227    1.        ]]. Action = [[0.76445603 0.15825093 1.2636855  0.7602149 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 933. State = [[-0.14412023 -0.0615994   0.23593377  1.        ]]. Action = [[ 0.72303367  0.08009851 -0.4567243   0.70597506]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 934. State = [[-0.13243482 -0.05971814  0.248434    1.        ]]. Action = [[0.6209712  0.12341058 0.57687974 0.25730705]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 935. State = [[-0.11045109 -0.05823711  0.28158292  1.        ]]. Action = [[ 0.4520681  -0.17036128  1.3472345   0.15390265]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 936. State = [[-0.08957592 -0.0589825   0.3202388   1.        ]]. Action = [[ 0.6170287  -0.03425491  0.28428245  0.09913683]]. Reward = [0.]
Curr episode timestep = 9
Scene graph at timestep 936 is [False, True, 3, True]
Human Feedback received at timestep 936 of -1
Current timestep = 937. State = [[-0.06947691 -0.05898518  0.34891182  1.        ]]. Action = [[0.56803036 0.0247879  0.9649868  0.10690963]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 937 is [False, True, 3, True]
Human Feedback received at timestep 937 of -1
Current timestep = 938. State = [[-0.05148372 -0.05485295  0.36847177  1.        ]]. Action = [[ 0.6216986   0.20738828 -1.2672675   0.11351562]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 939. State = [[-0.02786986 -0.0500641   0.32926282  1.        ]]. Action = [[ 0.8200735  0.0608021 -0.7808502  0.0548445]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 940. State = [[-0.2701978   0.07198867  0.11791732  1.        ]]. Action = [[ 0.94238687 -0.03379071 -1.074883   -0.00470418]]. Reward = [100.]
Curr episode timestep = 13
Current timestep = 941. State = [[-0.25500354  0.07606429  0.1170307   1.        ]]. Action = [[ 0.7149621  -0.3665632   1.3941574   0.84124124]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 941 is [False, True, 3, False]
Human Feedback received at timestep 941 of 1
Current timestep = 942. State = [[-0.22253487  0.06763442  0.15868858  1.        ]]. Action = [[ 0.8708255  -0.2446568   1.6469359   0.87711453]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 943. State = [[-0.19316915  0.05864011  0.21554983  1.        ]]. Action = [[ 0.77660656 -0.33367836  1.0070527   0.7295673 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 944. State = [[-0.17268582  0.05311224  0.24333774  1.        ]]. Action = [[ 0.5998826  -0.23754871 -0.07366395  0.47232056]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 945. State = [[-0.16837287  0.05267591  0.24740602  1.        ]]. Action = [[ 0.49872255 -0.19178128 -0.28092062  0.17411315]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 946. State = [[-0.15928179  0.04983881  0.25419334  1.        ]]. Action = [[ 0.74517274 -0.16500604  0.36169314  0.16751015]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 947. State = [[-0.14492449  0.04664223  0.26776174  1.        ]]. Action = [[ 0.6117749  -0.19198084 -0.69268537  0.15218353]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 948. State = [[-0.14356127  0.03997853  0.2613836   1.        ]]. Action = [[ 0.22272682 -0.3697121  -0.55155134  0.15119934]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 949. State = [[-0.12612619  0.02912805  0.2601472   1.        ]]. Action = [[ 0.7265378  -0.34070903  0.46587205  0.13252032]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 950. State = [[-0.10404118  0.01746707  0.2844378   1.        ]]. Action = [[ 0.47524834 -0.29281747  1.3006301   0.11155713]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 951. State = [[-0.08480316  0.00769991  0.30455142  1.        ]]. Action = [[ 0.48408937 -0.12419868 -0.7760123   0.13455296]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 951 is [False, True, 3, True]
Human Feedback received at timestep 951 of -1
Current timestep = 952. State = [[-0.06565413  0.00175285  0.2864357   1.        ]]. Action = [[ 0.5963261  -0.13268936 -0.6347778   0.1109755 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 953. State = [[-0.04642833 -0.00227977  0.26230365  1.        ]]. Action = [[ 0.49004817 -0.10380167 -0.8979864   0.07772839]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 954. State = [[-0.02211062 -0.00732012  0.24549986  1.        ]]. Action = [[ 0.40878344 -0.19289947  0.4773383   0.06920004]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 955. State = [[-0.00136741 -0.01263471  0.2627213   1.        ]]. Action = [[ 0.8125887  -0.10429937  0.96720934  0.00771523]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 956. State = [[-0.26311353 -0.02789092  0.11667032  1.        ]]. Action = [[ 0.5906079  -0.11003911  0.01301241 -0.03715277]]. Reward = [100.]
Curr episode timestep = 15
Current timestep = 957. State = [[-0.25464797 -0.03324838  0.10924076  1.        ]]. Action = [[0.66672015 0.02556372 0.9899392  0.8619056 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 957 is [False, True, 3, False]
Human Feedback received at timestep 957 of 1
Current timestep = 958. State = [[-0.24108855 -0.0363975   0.11944034  1.        ]]. Action = [[ 0.2192446  -0.03737438 -0.483482    0.79830444]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 959. State = [[-0.22447751 -0.03699257  0.12869379  1.        ]]. Action = [[0.8200488  0.12569427 1.2466578  0.8869183 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 960. State = [[-0.19849923 -0.03735253  0.16016477  1.        ]]. Action = [[ 0.31329727 -0.044752    0.6093931   0.7802515 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 961. State = [[-0.18651001 -0.03785498  0.17558926  1.        ]]. Action = [[0.5967405 0.0373472 1.3701038 0.7941034]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 962. State = [[-0.18382762 -0.03800829  0.17759602  1.        ]]. Action = [[ 0.525941    0.01927805 -0.06940949  0.7153375 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 963. State = [[-0.18375573 -0.03799701  0.17846568  1.        ]]. Action = [[ 0.5484959  -0.12443769 -0.75574636  0.72863424]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 964. State = [[-0.183657   -0.037997    0.17882209  1.        ]]. Action = [[ 0.83361506 -0.04183191  0.02663946  0.758036  ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 965. State = [[-0.18364546 -0.03799299  0.17908646  1.        ]]. Action = [[0.82258236 0.007972   0.655926   0.72426033]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 966. State = [[-0.17249271 -0.03806682  0.19752456  1.        ]]. Action = [[0.65384865 0.03394699 1.6141429  0.7333691 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 967. State = [[-0.1577193 -0.0378825  0.236563   1.       ]]. Action = [[0.9373627  0.06803322 0.30273962 0.46180236]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 968. State = [[-0.14840148 -0.03797403  0.2468799   1.        ]]. Action = [[ 0.5907686  -0.0219577   0.28817964  0.1334064 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 969. State = [[-0.12861355 -0.03813622  0.26531568  1.        ]]. Action = [[0.655447   0.04415417 0.50977373 0.11050487]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 970. State = [[-0.11163819 -0.03672412  0.27684972  1.        ]]. Action = [[ 0.15291858  0.09406126 -0.2981161   0.09608543]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 971. State = [[-0.09847918 -0.03614096  0.27245978  1.        ]]. Action = [[ 0.68305206 -0.0908103  -0.08484685  0.1237464 ]]. Reward = [0.]
Curr episode timestep = 14
Scene graph at timestep 971 is [False, True, 3, True]
Human Feedback received at timestep 971 of 1
Current timestep = 972. State = [[-0.07437275 -0.03604437  0.27057374  1.        ]]. Action = [[ 0.59992456 -0.11686921  0.01026845  0.10831273]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 973. State = [[-0.0480909  -0.03643103  0.2742952   1.        ]]. Action = [[ 0.9247632  -0.02378827  0.15186262  0.10022473]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 974. State = [[-0.01637928 -0.03743928  0.28242368  1.        ]]. Action = [[ 0.6156255  -0.0789693   0.32105756  0.05984485]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 975. State = [[ 0.00794589 -0.03777796  0.29936978  1.        ]]. Action = [[0.63482165 0.03169858 0.63602567 0.00706625]]. Reward = [0.]
Curr episode timestep = 18
Current timestep = 976. State = [[-0.26916307  0.13969877  0.11892335  1.        ]]. Action = [[ 0.66627157  0.11481452 -0.3612864  -0.05130619]]. Reward = [100.]
Curr episode timestep = 19
Current timestep = 977. State = [[-0.252962    0.15086383  0.12073797  1.        ]]. Action = [[ 0.66891384 -0.36814958  1.7265301   0.8148122 ]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 977 is [False, True, 3, False]
Human Feedback received at timestep 977 of 1
Current timestep = 978. State = [[-0.22499305  0.13985045  0.17248917  1.        ]]. Action = [[ 0.7686671  -0.386598    1.5721991   0.67266524]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 979. State = [[-0.19844538  0.12757093  0.22576162  1.        ]]. Action = [[ 0.698959   -0.40437186  0.9133191   0.7135637 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 980. State = [[-0.16919065  0.11340988  0.25871646  1.        ]]. Action = [[ 0.8762567  -0.35668212  0.2610078   0.23450947]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 981. State = [[-0.13991633  0.10100039  0.27193347  1.        ]]. Action = [[ 0.8609021  -0.37243748 -0.01892507  0.11313963]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 982. State = [[-0.10938712  0.08930077  0.27977324  1.        ]]. Action = [[ 0.6663189  -0.25993288  0.35916042  0.13044441]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 983. State = [[-0.08057813  0.08105501  0.3050273   1.        ]]. Action = [[ 0.8952309  -0.10779613  1.3071125   0.13255465]]. Reward = [0.]
Curr episode timestep = 6
Scene graph at timestep 983 is [False, True, 3, True]
Human Feedback received at timestep 983 of -1
Current timestep = 984. State = [[-0.04816774  0.07224073  0.33653808  1.        ]]. Action = [[ 0.6349045  -0.37258273 -0.3544402   0.12505293]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 985. State = [[-0.02152564  0.05711716  0.32731614  1.        ]]. Action = [[ 0.8277495  -0.4440199  -0.0905112   0.02834427]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 986. State = [[-0.26497442 -0.02533535  0.11533523  1.        ]]. Action = [[ 0.19468784 -0.3002355   0.809021   -0.01436883]]. Reward = [100.]
Curr episode timestep = 9
Current timestep = 987. State = [[-0.2607387  -0.03113492  0.10541862  1.        ]]. Action = [[ 0.396891   -0.10931939  0.6675284   0.84584904]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 987 is [False, True, 3, False]
Human Feedback received at timestep 987 of 1
Current timestep = 988. State = [[-0.24503966 -0.03784339  0.12156072  1.        ]]. Action = [[0.65702105 0.08397257 0.86671495 0.82285404]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 989. State = [[-0.21933079 -0.04089086  0.15930058  1.        ]]. Action = [[ 0.7498144  -0.24619281  1.3977351   0.7983203 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 990. State = [[-0.18828678 -0.04275251  0.2095182   1.        ]]. Action = [[0.8571954  0.09590924 1.1380005  0.7807431 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 991. State = [[-0.15438397 -0.04380667  0.2523183   1.        ]]. Action = [[ 0.70474625 -0.03471577  0.86176014  0.5640731 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 992. State = [[-0.12977163 -0.044192    0.27581277  1.        ]]. Action = [[ 0.4013406   0.00263512 -0.3269074   0.19754899]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 993. State = [[-0.11411598 -0.04334287  0.27863228  1.        ]]. Action = [[ 0.7490549  -0.02816707  0.1263349   0.12824893]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 994. State = [[-0.0842455  -0.0435731   0.29323688  1.        ]]. Action = [[ 0.6927352  -0.07118249  0.80205774  0.0976609 ]]. Reward = [0.]
Curr episode timestep = 7
Scene graph at timestep 994 is [False, True, 3, True]
Human Feedback received at timestep 994 of -1
Current timestep = 995. State = [[-0.06536773 -0.04466747  0.31723976  1.        ]]. Action = [[-0.71123266  0.07153499  0.00614905  0.1018225 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 996. State = [[-0.06521439 -0.04419219  0.31112012  1.        ]]. Action = [[ 0.9452635   0.04706049 -0.5778992   0.09061027]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 997. State = [[-0.04111859 -0.04359571  0.3063066   1.        ]]. Action = [[ 0.93756056 -0.05475956  0.6219263   0.05069387]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 998. State = [[-0.01418451 -0.04381862  0.32383898  1.        ]]. Action = [[ 0.6542139  -0.07227361  0.47830892  0.01617825]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 999. State = [[-0.2680358   0.09431385  0.118765    1.        ]]. Action = [[ 0.75307846  0.01013708 -0.70924187 -0.04143679]]. Reward = [100.]
Curr episode timestep = 12
Current timestep = 1000. State = [[-0.2517783   0.10123733  0.11744758  1.        ]]. Action = [[ 0.83618665 -0.34084773  1.4063778   0.69815135]]. Reward = [0.]
Curr episode timestep = 0
Scene graph at timestep 1000 is [False, True, 3, False]
Human Feedback received at timestep 1000 of 1
Current timestep = 1001. State = [[-0.221258    0.09159463  0.1547991   1.        ]]. Action = [[ 0.6770308  -0.3533895   1.030396    0.72899055]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1002. State = [[-0.19608292  0.08371577  0.1859376   1.        ]]. Action = [[ 0.7879201  -0.13577521  0.32942605  0.7152672 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1003. State = [[-0.17762344  0.08085608  0.19885992  1.        ]]. Action = [[ 0.6253085  -0.18832457 -0.68525076  0.2951659 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1004. State = [[-0.17469035  0.08039311  0.2010016   1.        ]]. Action = [[ 0.6998887  -0.32011843 -0.49974847  0.24299908]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1005. State = [[-0.17471783  0.08039033  0.20100029  1.        ]]. Action = [[ 0.6336118  -0.38606358  0.720912    0.23512387]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1006. State = [[-0.16493073  0.07377267  0.21184506  1.        ]]. Action = [[ 0.5989026  -0.40771902  0.90803766  0.2537055 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1007. State = [[-0.13913213  0.06044878  0.24578477  1.        ]]. Action = [[ 0.6955216  -0.381891    0.94929075  0.21260464]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1008. State = [[-0.12430759  0.05201942  0.26701567  1.        ]]. Action = [[-0.39018083 -0.09893978 -0.25472713  0.12300849]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1009. State = [[-0.11887473  0.04457662  0.2744151   1.        ]]. Action = [[ 0.7059815  -0.20293528  0.624053    0.11153245]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1010. State = [[-0.09944561  0.03666374  0.2891417   1.        ]]. Action = [[ 0.7709172  -0.2783854  -0.0363729   0.10266399]]. Reward = [0.]
Curr episode timestep = 10
Scene graph at timestep 1010 is [False, True, 3, True]
Human Feedback received at timestep 1010 of 1
Current timestep = 1011. State = [[-0.08274728  0.02670443  0.29512927  1.        ]]. Action = [[-0.31553745 -0.25528258 -0.12388849  0.11251462]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1012. State = [[-0.07830758  0.01576969  0.29996976  1.        ]]. Action = [[ 0.6654042  -0.4173497   0.45699096  0.12957478]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1013. State = [[-0.06375187  0.0045969   0.31632984  1.        ]]. Action = [[ 0.47611213 -0.08062881  0.65925884  0.12009883]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 1014. State = [[-0.04805151 -0.00307015  0.32846442  1.        ]]. Action = [[ 0.9157028  -0.23129219 -0.57934403  0.07146275]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 1015. State = [[-0.2635697  -0.00703834  0.11740866  1.        ]]. Action = [[ 0.15657651 -0.18023717 -0.38840675 -0.00100982]]. Reward = [100.]
Curr episode timestep = 15
Current timestep = 1016. State = [[-0.25421417 -0.01243167  0.11397913  1.        ]]. Action = [[ 0.7283373  -0.22040856  1.3511305   0.8451991 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1017. State = [[-0.23050605 -0.02405568  0.15376157  1.        ]]. Action = [[ 0.6364379  -0.25552237  1.6670823   0.89702487]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1018. State = [[-0.20381464 -0.02763398  0.20651877  1.        ]]. Action = [[0.86048937 0.09771585 0.65658426 0.8682847 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1019. State = [[-0.17958793 -0.02808244  0.2279597   1.        ]]. Action = [[0.789767   0.10729814 0.29999757 0.5217271 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1020. State = [[-0.17280897 -0.02840375  0.23285818  1.        ]]. Action = [[ 0.32798946 -0.04926258  0.18478394  0.22237039]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1021. State = [[-0.15628856 -0.02897226  0.24764448  1.        ]]. Action = [[ 0.5166068  -0.0434882   0.640645    0.19168568]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1022. State = [[-0.13170655 -0.03013657  0.27545527  1.        ]]. Action = [[ 0.7678418  -0.07357627  0.93902326  0.12278509]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1023. State = [[-0.10760915 -0.0328256   0.31587952  1.        ]]. Action = [[ 0.22160935 -0.05230111  1.0528641   0.12918568]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1024. State = [[-0.08872565 -0.03457818  0.34874445  1.        ]]. Action = [[ 0.89544666 -0.05582207  0.21858001  0.14089036]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1025. State = [[-0.07086021 -0.0366305   0.35473397  1.        ]]. Action = [[ 0.67790055 -0.0937196  -0.8181188   0.091277  ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1026. State = [[-0.04449021 -0.03580132  0.3254453   1.        ]]. Action = [[ 0.85011554  0.13917744 -1.0253351   0.03401101]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1027. State = [[-0.27181432  0.08285954  0.14278859  1.        ]]. Action = [[ 0.36432064  0.01712227 -0.36606514 -0.00833631]]. Reward = [100.]
Curr episode timestep = 11
Current timestep = 1028. State = [[-0.25977483  0.0809482   0.15627208  1.        ]]. Action = [[ 0.6206943  -0.19999474  1.5840378   0.7914449 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1029. State = [[-0.23795372  0.07757277  0.20065306  1.        ]]. Action = [[ 0.66566825 -0.16729736  1.5557485   0.826555  ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1030. State = [[-0.2102553   0.07199442  0.2471013   1.        ]]. Action = [[ 0.7103884  -0.23862767  0.13602066  0.7078166 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1031. State = [[-0.18292055  0.0631877   0.27258444  1.        ]]. Action = [[ 0.8487898 -0.3195697  1.2748768  0.252563 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1032. State = [[-0.15004238  0.05138865  0.3018052   1.        ]]. Action = [[ 0.7884387  -0.3036521  -0.32746792  0.10941064]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1033. State = [[-0.12443056  0.04098268  0.3023318   1.        ]]. Action = [[ 0.5037391  -0.22555745  0.0532639   0.11901534]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1034. State = [[-0.10654535  0.03246943  0.29808792  1.        ]]. Action = [[ 0.7938323  -0.19194049 -0.8973607   0.11248124]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1035. State = [[-0.08195004  0.029333    0.27596816  1.        ]]. Action = [[ 0.74575853 -0.26707405 -1.3620971   0.12998068]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1036. State = [[-0.07714541  0.02940486  0.27458924  1.        ]]. Action = [[ 0.2876774  -0.12657005 -1.1994871   0.11726797]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1037. State = [[-0.07397466  0.02699795  0.273819    1.        ]]. Action = [[ 0.25854123 -0.12926507 -0.02372503  0.12305164]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1038. State = [[-0.05838499  0.02087345  0.2875188   1.        ]]. Action = [[ 0.90542054 -0.22991884  1.0334711   0.11970413]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1039. State = [[-0.02973768  0.01610074  0.31856847  1.        ]]. Action = [[ 0.65746367 -0.01302296  0.68458414  0.10073256]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1040. State = [[-0.26635084  0.0264554   0.11877577  1.        ]]. Action = [[ 0.75553155 -0.27145326  0.09438443 -0.02949291]]. Reward = [100.]
Curr episode timestep = 12
Current timestep = 1041. State = [[-0.25661108  0.02852093  0.1178733   1.        ]]. Action = [[ 0.62103224 -0.0300622   1.7087054   0.78076196]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1042. State = [[-0.23349757  0.02926227  0.16595525  1.        ]]. Action = [[0.826131   0.01439178 1.4260895  0.86064947]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1043. State = [[-0.20260298  0.02650544  0.21993293  1.        ]]. Action = [[ 0.6062274  -0.38459647  1.2188559   0.8250997 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1044. State = [[-0.17665079  0.01813103  0.26962465  1.        ]]. Action = [[ 0.3726852  -0.26850724  1.1984863   0.29411745]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1045. State = [[-0.16436793  0.01469757  0.29598427  1.        ]]. Action = [[ 0.3213619   0.07577682 -0.6829444   0.13697135]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1046. State = [[-0.14556763  0.0130861   0.30577633  1.        ]]. Action = [[ 0.714599   -0.14130807  1.2286458   0.10846627]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1047. State = [[-0.12008634  0.00667245  0.32586083  1.        ]]. Action = [[ 0.7755176  -0.2515378  -0.48635018  0.10262132]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1048. State = [[-0.09501225 -0.00207495  0.31530437  1.        ]]. Action = [[ 0.5369234  -0.28167856 -0.32310367  0.12880683]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1049. State = [[-0.08134746 -0.0108681   0.30070147  1.        ]]. Action = [[ 0.16436541 -0.24517    -0.7185085   0.12563467]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1050. State = [[-0.06748582 -0.01862929  0.28953043  1.        ]]. Action = [[ 0.30233598 -0.11373037  0.28511     0.12811983]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1051. State = [[-0.05463922 -0.01954682  0.29536477  1.        ]]. Action = [[0.7070749  0.20715952 0.17331481 0.08408201]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1052. State = [[-0.03439417 -0.01869675  0.30280367  1.        ]]. Action = [[ 0.14840293 -0.08071935  0.3351953   0.02460432]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1053. State = [[-0.2711554   0.05727187  0.12507284  1.        ]]. Action = [[ 0.60615396 -0.17974913  0.42528224 -0.02985632]]. Reward = [100.]
Curr episode timestep = 12
Current timestep = 1054. State = [[-0.25796652  0.05449862  0.1350902   1.        ]]. Action = [[ 0.74267733 -0.36449915  1.1480281   0.62356615]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1055. State = [[-0.2309387   0.04793287  0.16721654  1.        ]]. Action = [[ 0.8061352  -0.17302674  1.4793506   0.77957666]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1056. State = [[-0.20286418  0.04046228  0.21712911  1.        ]]. Action = [[ 0.5160434  -0.31339514  0.84854746  0.739892  ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1057. State = [[-0.17487887  0.0302733   0.24959005  1.        ]]. Action = [[ 0.7693684  -0.27689648  0.5656972   0.3099426 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1058. State = [[-0.14773467  0.02173916  0.2752836   1.        ]]. Action = [[ 0.86565614 -0.24134201  0.42541742  0.15007031]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1059. State = [[-0.12283354  0.01381522  0.29040337  1.        ]]. Action = [[ 0.42191553 -0.13878351 -0.10601914  0.1118989 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1060. State = [[-0.10678009  0.00905645  0.2840167   1.        ]]. Action = [[ 0.6207596  -0.06296521 -0.7683705   0.11289084]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1061. State = [[-0.08386441  0.00497088  0.26361015  1.        ]]. Action = [[ 0.2036649  -0.2139768  -0.13383055  0.11955774]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1062. State = [[-0.06948477  0.00150605  0.2601414   1.        ]]. Action = [[ 0.67939687 -0.03735417  0.06881046  0.12738669]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1063. State = [[-0.04604781 -0.00262897  0.2561086   1.        ]]. Action = [[ 0.8179703  -0.09749222 -0.36978745  0.1184653 ]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1064. State = [[-0.01926111 -0.00273365  0.2435695   1.        ]]. Action = [[ 0.5427555   0.19308567 -0.19790578  0.05569553]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1065. State = [[ 5.7850126e-04 -7.7932782e-04  2.3827103e-01  1.0000000e+00]]. Action = [[ 0.7797971  -0.2548653  -0.43979394 -0.01022601]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1066. State = [[ 1.6143919e-03 -5.3113286e-04  2.3751591e-01  1.0000000e+00]]. Action = [[ 0.6660249  -0.1822877  -0.46761358 -0.04050565]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1067. State = [[-0.26262784 -0.16971534  0.11828174  1.        ]]. Action = [[ 0.6904421  -0.17428505  0.05746484 -0.06902426]]. Reward = [100.]
Curr episode timestep = 13
Current timestep = 1068. State = [[-0.2555711  -0.18381293  0.11224152  1.        ]]. Action = [[0.76420546 0.5970559  1.0925686  0.60337055]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1069. State = [[-0.23261179 -0.16861248  0.14029369  1.        ]]. Action = [[0.72955346 0.4797647  1.1123681  0.7157004 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1070. State = [[-0.20156834 -0.14716437  0.1816402   1.        ]]. Action = [[0.9033091 0.6368966 1.0793092 0.7033379]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1071. State = [[-0.1754383  -0.13329095  0.21021579  1.        ]]. Action = [[ 0.7370534   0.37512732 -0.44768524  0.5643046 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1072. State = [[-0.16158403 -0.12645702  0.22462915  1.        ]]. Action = [[0.7706907  0.31683517 0.8118949  0.2717378 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1073. State = [[-0.14151327 -0.12021774  0.24517432  1.        ]]. Action = [[ 0.732934    0.04565322 -0.18026686  0.22651827]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1074. State = [[-0.12959714 -0.11492632  0.26130283  1.        ]]. Action = [[0.5925212  0.2771597  1.0000186  0.14415467]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1075. State = [[-0.10812774 -0.10653352  0.3049666   1.        ]]. Action = [[0.24714589 0.12737727 1.3506091  0.09883463]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1076. State = [[-0.09244926 -0.10040177  0.345961    1.        ]]. Action = [[0.74263644 0.21362507 0.33738112 0.10611129]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1077. State = [[-0.07491052 -0.08853541  0.3591954   1.        ]]. Action = [[ 0.5701506   0.42450273 -0.34918582  0.03279829]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1078. State = [[-0.05299047 -0.07648916  0.34452885  1.        ]]. Action = [[ 0.8070283   0.21922302 -0.67560506  0.00466204]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1079. State = [[-0.26204962  0.00128102  0.11623556  1.        ]]. Action = [[ 0.28671682  0.05775046 -0.5789895  -0.02659422]]. Reward = [100.]
Curr episode timestep = 11
Current timestep = 1080. State = [[-0.25256088 -0.002504    0.11716697  1.        ]]. Action = [[ 0.58978355 -0.13938111  1.8171175   0.7490568 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1081. State = [[-0.23036583 -0.00687605  0.16850206  1.        ]]. Action = [[ 0.80991197 -0.08633357  1.6773136   0.83829546]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1082. State = [[-0.19940092 -0.00991898  0.23136999  1.        ]]. Action = [[ 0.6758468 -0.1261307  1.1530118  0.7285955]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1083. State = [[-0.17170393 -0.01440026  0.2704174   1.        ]]. Action = [[ 0.5540234  -0.04213893  0.6211755   0.27896821]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1084. State = [[-0.1504829  -0.01604509  0.2907508   1.        ]]. Action = [[ 0.50074947 -0.08872962 -0.23847866  0.10491884]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1085. State = [[-0.13251954 -0.01945877  0.2992851   1.        ]]. Action = [[ 0.8149661  -0.15997905  0.39075255  0.09411085]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1086. State = [[-0.10186544 -0.0216938   0.32052177  1.        ]]. Action = [[ 8.86619210e-01 -2.22623348e-04  8.32988977e-01  1.16740584e-01]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1087. State = [[-0.07677127 -0.02178423  0.3324862   1.        ]]. Action = [[ 0.3137504   0.09752488 -0.7129959   0.11346936]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1088. State = [[-0.05470038 -0.0218498   0.32435423  1.        ]]. Action = [[ 0.6112876  -0.06997412  0.39770555  0.05968082]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1089. State = [[-0.26299226 -0.12098099  0.11893897  1.        ]]. Action = [[ 0.50030434 -0.06470042 -0.399328   -0.00566846]]. Reward = [100.]
Curr episode timestep = 9
Current timestep = 1090. State = [[-0.2575994  -0.13001819  0.10523809  1.        ]]. Action = [[0.6503439  0.45366848 0.19923663 0.85948133]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1091. State = [[-0.23697686 -0.11578786  0.11521619  1.        ]]. Action = [[0.8909192  0.54221296 1.0290675  0.80008376]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1092. State = [[-0.20702589 -0.10295936  0.14216803  1.        ]]. Action = [[0.7061521  0.23081887 0.5975809  0.7723129 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1093. State = [[-0.17887892 -0.09490585  0.17666231  1.        ]]. Action = [[0.28380835 0.10331357 1.7426846  0.7359803 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1094. State = [[-0.15978295 -0.08773637  0.23712946  1.        ]]. Action = [[0.63727164 0.23121476 1.4413705  0.25043988]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1095. State = [[-0.13588929 -0.08150372  0.2874765   1.        ]]. Action = [[0.4625435  0.09729755 0.48963118 0.12388885]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1096. State = [[-0.11954751 -0.07492225  0.31176615  1.        ]]. Action = [[0.03970766 0.20842803 0.46155477 0.09803367]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1097. State = [[-0.11044963 -0.06837802  0.3151854   1.        ]]. Action = [[ 0.7482263   0.11793053 -0.9486003   0.13129461]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1098. State = [[-0.08819751 -0.06292863  0.29648688  1.        ]]. Action = [[ 0.73668015  0.2206093  -0.5247731   0.1177665 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1099. State = [[-0.06601929 -0.05511874  0.2787976   1.        ]]. Action = [[ 0.15022111  0.1339134  -0.3245901   0.12637162]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1100. State = [[-0.04789298 -0.0505277   0.28384867  1.        ]]. Action = [[0.5815916  0.06246924 1.1969602  0.0898335 ]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1101. State = [[-0.02702151 -0.04832418  0.30684853  1.        ]]. Action = [[0.7602112  0.09522438 0.08086514 0.02549803]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1102. State = [[-0.26950076  0.11341773  0.12010392  1.        ]]. Action = [[ 0.34186792 -0.05022174  0.12482667 -0.0299961 ]]. Reward = [100.]
Curr episode timestep = 12
Current timestep = 1103. State = [[-0.25321662  0.12223952  0.11801863  1.        ]]. Action = [[ 0.8296313  -0.29025662  1.4352684   0.82579064]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1104. State = [[-0.22245309  0.1151317   0.16078535  1.        ]]. Action = [[ 0.7919874  -0.26708066  1.6198082   0.8252666 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1105. State = [[-0.188036    0.10390255  0.22471069  1.        ]]. Action = [[ 0.80524397 -0.42595464  1.6161089   0.79662585]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1106. State = [[-0.16022547  0.09098841  0.27756602  1.        ]]. Action = [[ 0.5500581  -0.3316998   0.7482648   0.27857447]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1107. State = [[-0.13699985  0.07982965  0.3029926   1.        ]]. Action = [[ 0.5483742  -0.29690242 -0.03376734  0.11490202]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1108. State = [[-0.12841111  0.07137867  0.3060641   1.        ]]. Action = [[ 0.13890648 -0.1534692  -0.28073144  0.11156774]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1109. State = [[-0.11553976  0.06348587  0.30633122  1.        ]]. Action = [[ 0.72065926 -0.27855635  0.1923604   0.1148895 ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1110. State = [[-0.09507031  0.05059982  0.30301586  1.        ]]. Action = [[ 0.34249043 -0.43755037 -0.4156983   0.13646603]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1111. State = [[-0.07671423  0.03416962  0.29041383  1.        ]]. Action = [[ 0.794981   -0.27463216 -0.72179747  0.14310837]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1112. State = [[-0.04611536  0.02450101  0.2663013   1.        ]]. Action = [[ 0.79810905 -0.2210626  -0.3847909   0.14157736]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1113. State = [[-0.02070843  0.01843119  0.26281598  1.        ]]. Action = [[-0.09832293 -0.14045519  0.79948545  0.08913302]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1114. State = [[-0.27021578  0.14805523  0.11855274  1.        ]]. Action = [[ 0.28683066 -0.26577038  0.4111395  -0.0127328 ]]. Reward = [100.]
Curr episode timestep = 11
Current timestep = 1115. State = [[-0.25578216  0.15945093  0.11163912  1.        ]]. Action = [[ 0.82969165 -0.38968325  0.83300734  0.8974135 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1116. State = [[-0.22464824  0.14799078  0.13594653  1.        ]]. Action = [[ 0.74577856 -0.4349233   1.5794721   0.8370745 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1117. State = [[-0.19694492  0.13303842  0.19037622  1.        ]]. Action = [[ 0.57445216 -0.3978597   0.79428935  0.82846713]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1118. State = [[-0.17169724  0.11920843  0.22861877  1.        ]]. Action = [[ 0.5479362  -0.4175805   1.2351139   0.43523896]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1119. State = [[-0.14572935  0.10302859  0.28074038  1.        ]]. Action = [[ 0.5539278  -0.54378736  1.8202119   0.2578267 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1120. State = [[-0.12827702  0.08787879  0.33405     1.        ]]. Action = [[ 0.433048   -0.19617498  0.06272364  0.1472069 ]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1121. State = [[-0.11178983  0.07692308  0.34199956  1.        ]]. Action = [[ 0.9003136  -0.38572228 -0.22759986  0.12588668]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1122. State = [[-0.0849384   0.06353237  0.33896515  1.        ]]. Action = [[ 0.43711138 -0.3464222   0.02475023  0.12446129]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1123. State = [[-0.07145737  0.04800363  0.333748    1.        ]]. Action = [[ 0.17704856 -0.40945506 -0.98666     0.13619614]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1124. State = [[-0.05757658  0.03153808  0.30350676  1.        ]]. Action = [[ 0.7285843  -0.31205046 -0.70806503  0.12444687]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1125. State = [[-0.03789497  0.02020849  0.2715301   1.        ]]. Action = [[ 0.02272749 -0.25112176 -0.9171319   0.09593296]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1126. State = [[-0.02441543  0.01332415  0.24488598  1.        ]]. Action = [[ 0.8835918  -0.11717927 -0.37218142  0.03972316]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1127. State = [[-5.3384044e-04  1.0575330e-02  2.2775462e-01  1.0000000e+00]]. Action = [[-0.4003595  -0.16268957 -0.20673776  0.02658677]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1128. State = [[-0.27058688  0.08755666  0.11689074  1.        ]]. Action = [[-0.06680119 -0.17005205  0.97425604 -0.03109854]]. Reward = [100.]
Curr episode timestep = 13
Current timestep = 1129. State = [[-0.2597242   0.09167778  0.11133979  1.        ]]. Action = [[ 0.6351795 -0.3648312  0.9530597  0.8546101]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1130. State = [[-0.23816262  0.08042645  0.13479182  1.        ]]. Action = [[ 0.41912365 -0.46025056  1.1799016   0.8761636 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1131. State = [[-0.21512194  0.06711882  0.18260765  1.        ]]. Action = [[ 0.7767736  -0.2876668   1.2343688   0.86591816]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1132. State = [[-0.19417901  0.05744499  0.2087598   1.        ]]. Action = [[ 0.26685858 -0.27274406 -0.49897957  0.7325965 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1133. State = [[-0.1755998   0.04869577  0.2209713   1.        ]]. Action = [[ 0.79358494 -0.18420923  1.0141158   0.32538795]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1134. State = [[-0.15537012  0.04463057  0.24016657  1.        ]]. Action = [[ 0.1857717  -0.22589421 -0.35526383  0.25485063]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1135. State = [[-0.15203635  0.04124159  0.24378091  1.        ]]. Action = [[ 0.05320764 -0.1649999   0.04028726  0.143731  ]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1136. State = [[-0.13881224  0.03561238  0.26155975  1.        ]]. Action = [[ 0.76118696 -0.19728446  1.2470684   0.1405046 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1137. State = [[-0.1136035   0.02749619  0.28758717  1.        ]]. Action = [[ 0.67450786 -0.22236931 -0.42161894  0.0968945 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1138. State = [[-0.08915359  0.02035883  0.2925132   1.        ]]. Action = [[ 0.7235296  -0.21807712  0.6155796   0.12302887]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1139. State = [[-0.06472159  0.01192508  0.32080424  1.        ]]. Action = [[ 0.27178717 -0.2725464   1.3382266   0.13138151]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1140. State = [[-0.04317626  0.00113112  0.35971028  1.        ]]. Action = [[ 0.9485121  -0.19569027  0.39275646  0.06920028]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1141. State = [[-0.26167917 -0.15576662  0.11790124  1.        ]]. Action = [[ 0.12584591 -0.24745375  0.3356707  -0.01473343]]. Reward = [100.]
Curr episode timestep = 12
Current timestep = 1142. State = [[-0.253867   -0.17051819  0.11514492  1.        ]]. Action = [[0.71523356 0.34155297 1.3785157  0.7661185 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1143. State = [[-0.23407553 -0.1586161   0.14997204  1.        ]]. Action = [[0.6741226  0.60789776 1.0645976  0.84112716]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1144. State = [[-0.20078804 -0.13662338  0.19548778  1.        ]]. Action = [[0.84986186 0.51080847 1.29211    0.87787116]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1145. State = [[-0.17488347 -0.1206766   0.24035898  1.        ]]. Action = [[0.19199562 0.24105883 0.87554526 0.36262846]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1146. State = [[-0.15733257 -0.10697482  0.26788285  1.        ]]. Action = [[0.72356653 0.48556018 0.12467742 0.13216901]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1147. State = [[-0.14550698 -0.09157531  0.275749    1.        ]]. Action = [[-0.03496248  0.33232605 -0.347494    0.08092129]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1148. State = [[-0.1421215  -0.08495279  0.27053174  1.        ]]. Action = [[ 0.7638408   0.11473382 -0.9400526   0.11319101]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1149. State = [[-0.14180179 -0.08385791  0.27050602  1.        ]]. Action = [[ 0.4302616   0.2512231  -1.048413    0.08889651]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1150. State = [[-0.14160413 -0.08329315  0.27049989  1.        ]]. Action = [[ 0.27112615  0.15176582 -1.1503747   0.08248281]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1151. State = [[-0.1404258  -0.08314353  0.26678538  1.        ]]. Action = [[ 0.15872419 -0.02392352 -0.31825113  0.10154438]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1152. State = [[-0.1363374  -0.08356091  0.26078823  1.        ]]. Action = [[ 0.20607924  0.14175165 -1.1504372   0.10961556]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1153. State = [[-0.1246984  -0.08163919  0.26974198  1.        ]]. Action = [[0.93608785 0.18688619 0.7978761  0.0912509 ]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1154. State = [[-0.0971286  -0.07497045  0.28770578  1.        ]]. Action = [[0.73141    0.22878134 0.02109504 0.10241437]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1155. State = [[-0.06551751 -0.06484394  0.29312944  1.        ]]. Action = [[0.8276186  0.23133874 0.25016952 0.13756311]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 1156. State = [[-0.03766612 -0.05369927  0.29389125  1.        ]]. Action = [[ 0.7011187   0.36296785 -0.4845878   0.02795768]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 1157. State = [[-0.26653236  0.0479816   0.11737519  1.        ]]. Action = [[ 0.90654624  0.127684   -0.01947033 -0.02624929]]. Reward = [100.]
Curr episode timestep = 15
Current timestep = 1158. State = [[-0.25410575  0.05242669  0.11178962  1.        ]]. Action = [[ 0.61636996 -0.17266393  1.0097387   0.90263665]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1159. State = [[-0.24119759  0.0470645   0.13401444  1.        ]]. Action = [[ 0.28245473 -0.31979644  0.8065634   0.897964  ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1160. State = [[-0.22497365  0.03571228  0.16638002  1.        ]]. Action = [[ 0.49089992 -0.42914152  1.1613917   0.9324323 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1161. State = [[-0.19996211  0.02483685  0.21106577  1.        ]]. Action = [[ 0.7507974  -0.15792781  1.0847363   0.77465737]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1162. State = [[-0.16965483  0.01646708  0.25147405  1.        ]]. Action = [[ 0.631798   -0.27069294  0.7741184   0.38356113]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1163. State = [[-0.15119433  0.01016311  0.27393776  1.        ]]. Action = [[ 0.51777315 -0.27935183 -1.2459553   0.20664895]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1164. State = [[-0.1374295   0.00719551  0.291387    1.        ]]. Action = [[ 0.83245826 -0.1648441   0.9590602   0.13150132]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1165. State = [[-0.11629057  0.00408969  0.3093925   1.        ]]. Action = [[ 0.6246011  -0.02034622 -0.66262794  0.13147962]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1166. State = [[-0.08900165  0.00384206  0.30207965  1.        ]]. Action = [[ 0.97394264 -0.01954776  0.13185835  0.11700487]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1167. State = [[-0.05500165  0.00183472  0.3111232   1.        ]]. Action = [[ 0.8154737  -0.12614483  0.4906788   0.11472571]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1168. State = [[-0.024644   -0.00348235  0.32543045  1.        ]]. Action = [[ 0.90348506 -0.19799459  0.17178607  0.02226782]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1169. State = [[-0.26909757  0.03960451  0.11916517  1.        ]]. Action = [[-0.30254495 -0.1406042   0.37854552 -0.01355726]]. Reward = [100.]
Curr episode timestep = 11
Current timestep = 1170. State = [[-0.25834522  0.04110192  0.11196473  1.        ]]. Action = [[ 0.5850203  -0.33746928  0.8452771   0.8690014 ]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1171. State = [[-0.24612884  0.03380451  0.12716292  1.        ]]. Action = [[ 0.05054545 -0.23548567  0.545259    0.8787751 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1172. State = [[-0.23128046  0.02877402  0.15460181  1.        ]]. Action = [[ 0.82688046 -0.0599705   1.2242527   0.85935915]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1173. State = [[-0.19968304  0.02359903  0.19936413  1.        ]]. Action = [[ 0.8299637  -0.27492404  1.1064858   0.7594764 ]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1174. State = [[-0.17593858  0.01870178  0.22867043  1.        ]]. Action = [[ 0.8863834  -0.10978353 -0.02761161  0.3582555 ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1175. State = [[-0.17200868  0.01809331  0.23203649  1.        ]]. Action = [[ 0.6767142  -0.155747    0.00193405  0.19659615]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1176. State = [[-0.15920088  0.01394618  0.24940091  1.        ]]. Action = [[ 0.87958884 -0.2520687   1.2094498   0.21347749]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1177. State = [[-0.13660641  0.00788558  0.27978086  1.        ]]. Action = [[ 0.16978335 -0.11872631 -0.15963054  0.15619314]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1178. State = [[-0.12978399  0.00375591  0.28497982  1.        ]]. Action = [[ 0.37646937 -0.14227253  0.1804266   0.11112118]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1179. State = [[-0.12321108 -0.00157204  0.2856954   1.        ]]. Action = [[-0.32624084 -0.11875391 -0.6832956   0.10209632]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1180. State = [[-0.12530367 -0.00721926  0.26879817  1.        ]]. Action = [[-0.06983709 -0.19492978 -0.48990965  0.10940135]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1181. State = [[-0.12025847 -0.00994484  0.25880447  1.        ]]. Action = [[0.47447383 0.0852468  0.22529721 0.11221397]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1182. State = [[-0.11649585 -0.00985209  0.26105443  1.        ]]. Action = [[ 0.8328335  -0.07320505 -0.72581327  0.10505891]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1183. State = [[-0.1071991  -0.00990633  0.26649886  1.        ]]. Action = [[ 0.81160533 -0.03868818  0.3386824   0.10039532]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 1184. State = [[-0.09225135 -0.00963816  0.26423162  1.        ]]. Action = [[-0.10797095  0.07244325 -0.35294747  0.09625304]]. Reward = [0.]
Curr episode timestep = 14
Current timestep = 1185. State = [[-0.08174773 -0.01229156  0.2622339   1.        ]]. Action = [[ 0.7634778  -0.1945898   0.14832377  0.11546886]]. Reward = [0.]
Curr episode timestep = 15
Current timestep = 1186. State = [[-0.05694719 -0.01559677  0.27694556  1.        ]]. Action = [[ 0.6057968  -0.12091029  1.0981698   0.09988892]]. Reward = [0.]
Curr episode timestep = 16
Current timestep = 1187. State = [[-0.03123563 -0.02334958  0.3118782   1.        ]]. Action = [[ 0.7964902  -0.24480575  0.67100286  0.04107118]]. Reward = [0.]
Curr episode timestep = 17
Current timestep = 1188. State = [[-0.2611263  -0.16363353  0.11856727  1.        ]]. Action = [[ 0.8564558   0.10069489 -0.14429653 -0.02655041]]. Reward = [100.]
Curr episode timestep = 18
Current timestep = 1189. State = [[-0.25363937 -0.1821016   0.10971539  1.        ]]. Action = [[0.71307755 0.17592728 0.6823735  0.89610267]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1190. State = [[-0.2361155  -0.17258078  0.12832429  1.        ]]. Action = [[0.46631575 0.6940578  1.4338512  0.8310251 ]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1191. State = [[-0.2159722  -0.15222396  0.1735287   1.        ]]. Action = [[0.51140606 0.3749231  0.71529007 0.8455365 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1192. State = [[-0.18917766 -0.13489579  0.20678721  1.        ]]. Action = [[0.8031883  0.54318595 1.1566265  0.66194856]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1193. State = [[-0.15737353 -0.11477215  0.25448287  1.        ]]. Action = [[0.6270689  0.39402366 1.2248902  0.27526975]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1194. State = [[-0.12848395 -0.1030772   0.2990652   1.        ]]. Action = [[0.8350682  0.15588331 0.65176105 0.15271115]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1195. State = [[-0.09766899 -0.0959851   0.34046358  1.        ]]. Action = [[0.88608277 0.23388648 1.338897   0.08552575]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1196. State = [[-0.07229412 -0.08704074  0.36740717  1.        ]]. Action = [[ 0.7658689   0.09794497 -0.87617326  0.07910693]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1197. State = [[-0.05116609 -0.08557985  0.34372205  1.        ]]. Action = [[-0.41376472 -0.01729178 -0.5432606   0.0159173 ]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1198. State = [[-0.25875026 -0.1351313   0.11609805  1.        ]]. Action = [[ 0.9280212   0.28025663 -0.94585156 -0.01361102]]. Reward = [100.]
Curr episode timestep = 9
Current timestep = 1199. State = [[-0.2503654  -0.14824587  0.10431819  1.        ]]. Action = [[0.8546796  0.29984295 0.4496565  0.81603336]]. Reward = [0.]
Curr episode timestep = 0
Current timestep = 1200. State = [[-0.22331278 -0.14048898  0.1154025   1.        ]]. Action = [[0.8755367  0.30629992 0.84737015 0.83362436]]. Reward = [0.]
Curr episode timestep = 1
Current timestep = 1201. State = [[-0.18920866 -0.13408136  0.14991362  1.        ]]. Action = [[0.81918883 0.19501317 1.537355   0.8257539 ]]. Reward = [0.]
Curr episode timestep = 2
Current timestep = 1202. State = [[-0.16760416 -0.12910467  0.19042253  1.        ]]. Action = [[0.74718595 0.3656993  0.9341843  0.52907515]]. Reward = [0.]
Curr episode timestep = 3
Current timestep = 1203. State = [[-0.16013734 -0.12436837  0.20873033  1.        ]]. Action = [[0.01376843 0.24792886 1.169671   0.294356  ]]. Reward = [0.]
Curr episode timestep = 4
Current timestep = 1204. State = [[-0.15773582 -0.1199163   0.23887265  1.        ]]. Action = [[0.58384943 0.4194094  0.03540754 0.26287138]]. Reward = [0.]
Curr episode timestep = 5
Current timestep = 1205. State = [[-0.15670471 -0.11974305  0.24036874  1.        ]]. Action = [[ 0.59140635  0.17960978 -0.5493568   0.21081948]]. Reward = [0.]
Curr episode timestep = 6
Current timestep = 1206. State = [[-0.15672995 -0.11973709  0.24036767  1.        ]]. Action = [[ 0.89965224  0.23101807 -0.6225581   0.2138102 ]]. Reward = [0.]
Curr episode timestep = 7
Current timestep = 1207. State = [[-0.1562898  -0.11980811  0.24064848  1.        ]]. Action = [[ 0.5237036   0.07784331 -0.12202525  0.22565615]]. Reward = [0.]
Curr episode timestep = 8
Current timestep = 1208. State = [[-0.14983644 -0.11724228  0.24450818  1.        ]]. Action = [[0.67525816 0.18051267 0.12967634 0.21143627]]. Reward = [0.]
Curr episode timestep = 9
Current timestep = 1209. State = [[-0.12554312 -0.11056571  0.26670238  1.        ]]. Action = [[0.8003688  0.14372337 1.1913424  0.20977783]]. Reward = [0.]
Curr episode timestep = 10
Current timestep = 1210. State = [[-0.09656817 -0.10432371  0.29942963  1.        ]]. Action = [[0.5543051  0.21743608 0.15930223 0.10615361]]. Reward = [0.]
Curr episode timestep = 11
Current timestep = 1211. State = [[-0.08203022 -0.09168942  0.30282053  1.        ]]. Action = [[ 0.6518774   0.35770345 -0.81937265  0.10850096]]. Reward = [0.]
Curr episode timestep = 12
Current timestep = 1212. State = [[-0.05257642 -0.08052898  0.27947044  1.        ]]. Action = [[ 0.67525077  0.21926498 -0.34737527  0.05082679]]. Reward = [0.]
Curr episode timestep = 13
Current timestep = 1213. State = [[-0.03226487 -0.07236885  0.2764235   1.        ]]. Action = [[0.00318968 0.16515303 0.48746872 0.00371361]]. Reward = [0.]
Curr episode timestep = 14
